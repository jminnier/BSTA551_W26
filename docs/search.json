[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BSTA 550: Introduction to Probability",
    "section": "",
    "text": "BSTA 550: Introduction to Probability\n\nFall 2025\n \nWelcome to Biostatistics and Probability! This course is designed to introduce history, concepts and distributions in probability, Monte Carlo simulation techniques, and Markov chains. Students will also learn how to write R codes for various statistical computations and plots. Previous experience in R is not required. R is free software available from http://www.r-project.org.\n \n\n\n\n\n\n\n\nInstructor\n Dr. Nicky Wakim\n Vanport 622A\n wakim@ohsu.edu\n\n\nOffice Hours\nCharles  Th 11am-12pm\nCharles  F 12-1pm\nNicky  Th 10-11am\n\n\nCourse details\n Mondays, Wednesdays\n Sept 29 - Dec 10\n 10:30 AM - 12 PM\n In-person, VPT 620M\n\n\nContacting me\nE-mail or Slack is the best way to get in contact with me. I will try to respond to all course-related e-mails within 24 hours Monday-Friday.\n\n\n\n\n\n\n\n\n View the source on GitHub"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Week\nDate\nLesson\nTopic\nTB\nKey Info\nSlides HTML\nSlides PDF\nSlides Notes\nExit tix\nRecord-ing\nMuddy Points\n\n\n\n\n1\n09/29\n\nWelcome\n\n\n\n\n\n\n\n\n\n\n\n\n1\nIntroduction to Probability\n1.1, 2.1, 2.2, 2.4.1\n\n\n\n\n\n \n\n\n\n\n10/01\n2\nIntroduction to Simulations\n2.3, 2.5\n\n\n\n\n\n\n\n\n\n\n10/02\n\nHW 0 due 11pm\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2\n10/06\n3\nLanguage of Probability\n2.2, 2.4\n\n\n\n\n\n  \n\n\n\n\n10/08\n4\nRules of Probability\n2.7, 3.3-3.5\n\n\n\n\n\n \n\n\n\n\n10/12\n\nHW 1 due 11pm\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\n10/13\n6\nAsync optional video: Calculus Review\n\n\n\n\n\n\n\n\n\n\n\n10/15\n5\nEqually Likely Outcomes\n3.6\n\n\n\n\n\n\n\n\n\n\n10/19\n\nHW 2 due 11 pm\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4\n10/20\n7\npmfs\n4.1, 4.2\n\n\n\n\n\n\n\n\n\n\n\n8\npdfs\n4.3\n\n\n\n\n\n\n\n\n\n\n10/22\n9\nCDFs\n4.4\n\n\n\n\n\n\n\n\n\n\n10/22\n\nQuiz 1 opens @ 3pm\n\n\n\n\n\n\n\n\n\n\n\n10/26\n\nHW 3 due 11 pm\n\n\n\n\n\n\n\n\n\n\n\n10/26\n\nQuiz 1 closes @ 11pm\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5\n10/27\n10\nTransformations of distributions\n4.6\n\n\n\n\n\n\n\n\n\n\n10/29\n11\nJoint distributions\n4.7\n\n\n\n \n\n  \n\n\n\n\n11/02\n\nHW 4 due 11 pm\n\n\n\n\n\n\n\n\n\n\n\n11/02\n\nMidterm feedback due @ 11pm\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6\n11/03\n12\nIndependence and Conditioning\n4.8, 4.9\n\n\n\n\n\n \n\n\n\n\n11/05\n\nReview of joint distributions, independence, conditioning\n\n\n\n\n \n\n\n\n\n\n\n11/05\n\nQuiz 2 opens @ 11pm\n\n\n\n\n\n\n\n\n\n\n\n11/09\n\nHW 5 due 11 pm\n\n\n\n\n\n\n\n\n\n\n\n11/09\n\nQuiz 2 closes @ 11pm\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7\n11/10\n13\nExpected Values\n5.1\n\n\n\n\n\n\n\n\n\n\n11/12\n14\nVariance\n5.2, 5.3\n\n\n\n\n\n \n\n\n\n\n11/16\n\nHW 6 due 11 pm\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8\n11/17\n15\nImportant discrete RVs\n6\n\n\n\n\n\n \n\n\n\n\n11/19\n16\nImportant continuous RVS\n7\n\n\n\n\n\n \n\n\n\n\n11/23\n\nHW 7 due 11 pm\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9\n11/24\n17\nCentral limit theorem\n8.1\n\n\n\n\n\n  \n\n\n\n\n11/26\n\nNo class\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10\n12/01\n\nNo class\n\n\n\n\n\n\n\n\n\n\n\n12/03\n18\nMoment Generating functions\n\n\n\n\n\n\n\n\n\n\n\n12/03\n\nQuiz 3 opens @ 3pm\n\n\n\n\n\n\n\n\n\n\n\n12/07\n\nHW 8 due 11 pm\n\n\n\n\n\n\n\n\n\n\n\n12/07\n\nQuiz 3 closes @ 11pm\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11\n12/08\n\nCatch-up day\n\n\n\n\n\n\n\n\n\n\n\n12/11\n\nOptional HW 9 due 11 pm"
  },
  {
    "objectID": "lessons/Continuous_distributions.html",
    "href": "lessons/Continuous_distributions.html",
    "title": "Continuous Random Variables",
    "section": "",
    "text": "Scenario: Events are equally likely to happen anywhere or anytime in an interval of values\nShorthand: \\(X \\sim \\text{U}[a,b]\\)\n\n\\[\nf_X(x) = \\dfrac{1}{b-a}, \\text{ for }a \\leq x \\leq b\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;a \\quad \\\\\n            \\dfrac{x-a}{b-a} & \\quad a \\leq x \\leq b\\quad \\\\\n            1 & \\quad x&gt;b \\quad\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{a+b}{2} \\text{, } \\text{ Var}(X) = \\dfrac{(b-a)^2}{12}\\]"
  },
  {
    "objectID": "lessons/Continuous_distributions.html#properties-of-continuous-uniform-rvs",
    "href": "lessons/Continuous_distributions.html#properties-of-continuous-uniform-rvs",
    "title": "Continuous Random Variables",
    "section": "",
    "text": "Scenario: Events are equally likely to happen anywhere or anytime in an interval of values\nShorthand: \\(X \\sim \\text{U}[a,b]\\)\n\n\\[\nf_X(x) = \\dfrac{1}{b-a}, \\text{ for }a \\leq x \\leq b\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;a \\quad \\\\\n            \\dfrac{x-a}{b-a} & \\quad a \\leq x \\leq b\\quad \\\\\n            1 & \\quad x&gt;b \\quad\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{a+b}{2} \\text{, } \\text{ Var}(X) = \\dfrac{(b-a)^2}{12}\\]"
  },
  {
    "objectID": "lessons/Continuous_distributions.html#properties-of-exponential-rvs",
    "href": "lessons/Continuous_distributions.html#properties-of-exponential-rvs",
    "title": "Continuous Random Variables",
    "section": "Properties of exponential RVs",
    "text": "Properties of exponential RVs\n\nScenario: Modeling the time until the next (first) event\nContinuous analog to the geometric distribution!\nShorthand: \\(X \\sim \\text{Exp}(\\lambda)\\)\n\n\\[\nf_X(x) = \\lambda e^{-\\lambda x}\\text{ for } x&gt;0, \\lambda&gt;0\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;0 \\quad \\\\\n            1 - e^{-\\lambda x} & \\quad x\\geq0 \\\\\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{1}{\\lambda}\\] \\[\\text{Var}(X) = \\dfrac{1}{\\lambda^2}\\]"
  },
  {
    "objectID": "lessons/Continuous_distributions.html#properties-of-gamma-rvs",
    "href": "lessons/Continuous_distributions.html#properties-of-gamma-rvs",
    "title": "Continuous Random Variables",
    "section": "Properties of gamma RVs",
    "text": "Properties of gamma RVs\n\nScenario: Modeling the time until the \\(r^{th}\\) event.\nContinuous analog to the Negative Binomial distribution\nShorthand: \\(X \\sim \\text{Gamma}(r, \\lambda)\\)\n\n\\[\nf_X(x) = \\dfrac{\\lambda^r}{\\Gamma(r)}x^{r-1} e^{-\\lambda x}\\text{ for } x&gt;0, \\lambda&gt;0, \\Gamma(r) = (r-1)!\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;0 \\quad \\\\\n            1 - e^{-\\lambda x}\\displaystyle\\sum_{j=0}^{r-1}\\dfrac{(\\lambda x)^j}{j!}  & \\quad x\\geq0 \\\\\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{r}{\\lambda}\\text{, }\\text{ Var}(X) = \\dfrac{r}{\\lambda^2}\\]\nCommon to see \\(\\alpha = r\\) and \\(\\beta = \\lambda\\)"
  },
  {
    "objectID": "lessons/Continuous_distributions.html#properties-of-normal-rvs",
    "href": "lessons/Continuous_distributions.html#properties-of-normal-rvs",
    "title": "Continuous Random Variables",
    "section": "Properties of Normal RVs",
    "text": "Properties of Normal RVs\n\nNo scenario description here because the Normal distribution is so universal\n\nCentral Limit Theorem (next class) makes it applicable to many types of events\n\nShorthand: \\(X \\sim \\text{Normal}(\\mu, \\sigma^2)\\)\n\n\\[\nf_X(x) = \\dfrac{1}{\\sqrt{2\\pi \\sigma^2}}e^{-(x-\\mu)^2/(2\\sigma^2)} \\text{, for} -inf &lt; x &lt; inf\n\\]\n\\[\\text{E}(X) = \\mu \\] \\[\\text{Var}(X) = \\sigma^2\\]"
  },
  {
    "objectID": "lessons/03_Independent_Events/03_IndependentEvents.html",
    "href": "lessons/03_Independent_Events/03_IndependentEvents.html",
    "title": "Chapter 3: Independent Events",
    "section": "",
    "text": "Define independence of 2-3 events given probability notation\nCalculate whether two or more events are independent"
  },
  {
    "objectID": "lessons/03_Independent_Events/03_IndependentEvents.html#learning-objectives",
    "href": "lessons/03_Independent_Events/03_IndependentEvents.html#learning-objectives",
    "title": "Chapter 3: Independent Events",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nDefine independence of 2-3 events given probability notation\nCalculate whether two or more events are independent"
  },
  {
    "objectID": "lessons/03_Independent_Events/03_IndependentEvents.html#revisiting-our-coin-toss",
    "href": "lessons/03_Independent_Events/03_IndependentEvents.html#revisiting-our-coin-toss",
    "title": "Chapter 3: Independent Events",
    "section": "Revisiting our coin toss",
    "text": "Revisiting our coin toss\nQuestion: Which of the following sequences of coin tosses of heads (\\(H\\)) and tails (\\(T\\)) is more likely to happen, assuming the coin is fair?\n\\[HTTHHHTHTHHTTTH\\] or \\[HTTTTTTTTHTTTTT\\]"
  },
  {
    "objectID": "lessons/03_Independent_Events/03_IndependentEvents.html#independent-events",
    "href": "lessons/03_Independent_Events/03_IndependentEvents.html#independent-events",
    "title": "Chapter 3: Independent Events",
    "section": "Independent Events",
    "text": "Independent Events\n\n\nDefinition: Independence\n\n\nEvents \\(A\\) and \\(B\\) are independent if \\[\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B).\\]\n\n\nNotation: For shorthand, we sometimes write \\[A \\mathrel{\\unicode{x2AEB}} B,\\] to denote that \\(A\\) and \\(B\\) are independent events."
  },
  {
    "objectID": "lessons/03_Independent_Events/03_IndependentEvents.html#example-of-two-dice",
    "href": "lessons/03_Independent_Events/03_IndependentEvents.html#example-of-two-dice",
    "title": "Chapter 3: Independent Events",
    "section": "Example of two dice",
    "text": "Example of two dice\n\n\nExample 1\n\n\nTwo dice (red and blue) are rolled. Let \\(A =\\) event a total of 7 appears, and \\(B =\\) event red die is a six. Are events \\(A\\) and \\(B\\) independent?"
  },
  {
    "objectID": "lessons/03_Independent_Events/03_IndependentEvents.html#independence-of-3-events",
    "href": "lessons/03_Independent_Events/03_IndependentEvents.html#independence-of-3-events",
    "title": "Chapter 3: Independent Events",
    "section": "Independence of 3 Events",
    "text": "Independence of 3 Events\n\n\nDefinition: Independence of 3 Events\n\n\nEvents \\(A\\), \\(B\\), and \\(C\\) are mutually independent if\n\n\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot \\mathbb{P}(B)\\)\n\\(\\mathbb{P}(A \\cap C) = \\mathbb{P}(A) \\cdot \\mathbb{P}(C)\\)\n\\(\\mathbb{P}(B \\cap C) = \\mathbb{P}(B) \\cdot \\mathbb{P}(C)\\)\n\n\\(\\mathbb{P}(A \\cap B \\cap C) = \\mathbb{P}(A) \\cdot \\mathbb{P}(B) \\cdot \\mathbb{P}(C)\\)\n\n\n\nRemark:\nOn your homework you will show that \\((1) \\not \\Rightarrow (2)\\) and \\((2) \\not \\Rightarrow (1)\\)."
  },
  {
    "objectID": "lessons/03_Independent_Events/03_IndependentEvents.html#probability-at-least-one-smoker",
    "href": "lessons/03_Independent_Events/03_IndependentEvents.html#probability-at-least-one-smoker",
    "title": "Chapter 3: Independent Events",
    "section": "Probability at least one smoker",
    "text": "Probability at least one smoker\n\n\n\n\nExample 2\n\n\nSuppose you take a random sample of \\(n\\) people, of which people are smokers and non-smokers independently of each other. Let\n\n\\(A_i =\\) event person \\(i\\) is a smoker, for \\(i=1, \\ldots ,n\\), and\n\\(p_i =\\) probability person \\(i\\) is a smoker, for \\(i=1, \\ldots ,n\\).\n\nFind the probability that at least one person in the random sample is a smoker."
  },
  {
    "objectID": "lessons/03_Independent_Events/03_IndependentEvents.html#building-geometric-series",
    "href": "lessons/03_Independent_Events/03_IndependentEvents.html#building-geometric-series",
    "title": "Chapter 3: Independent Events",
    "section": "Building geometric series",
    "text": "Building geometric series\n\n\nExample 3\n\n\n\\(A, B,\\) and \\(C\\) toss a fair coin in order. The first to throw heads wins. What are their respective chances of winning?\n\n\nLet\n\n\\(A_H\\) and \\(A_T\\) be the events player A tosses heads and tails, respectively.\nSimilarly define \\(B_H\\), \\(B_T\\), \\(C_H\\), and \\(C_T\\)."
  },
  {
    "objectID": "lessons/27_Continuous_distributions/27_Conditional_distributions.html",
    "href": "lessons/27_Continuous_distributions/27_Conditional_distributions.html",
    "title": "Chapter 27: Conditional Distributions",
    "section": "",
    "text": "Calculate the conditional probability density from a joint pdf"
  },
  {
    "objectID": "lessons/27_Continuous_distributions/27_Conditional_distributions.html#learning-objectives",
    "href": "lessons/27_Continuous_distributions/27_Conditional_distributions.html#learning-objectives",
    "title": "Chapter 27: Conditional Distributions",
    "section": "",
    "text": "Calculate the conditional probability density from a joint pdf"
  },
  {
    "objectID": "lessons/27_Continuous_distributions/27_Conditional_distributions.html#conditional-probabilities-weve-seen-before",
    "href": "lessons/27_Continuous_distributions/27_Conditional_distributions.html#conditional-probabilities-weve-seen-before",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Conditional probabilities we’ve seen before",
    "text": "Conditional probabilities we’ve seen before\n\n\nWhat do we know about conditional probabilities for events and discrete RVs?    \nFor events:\n\\[P(A | B) = \\dfrac{P(A \\cap B)}{P(B)}\\]    \nFor discrete RVs: \\[p_{X|Y}(x|y) = P(X=x|Y=y) = \\dfrac{p_{X,Y}(x,y)}{p_Y(y)}\\]\n\n\n\nWhat does it mean for conditional densities of continuous RVs?\nFor continuous RVs:"
  },
  {
    "objectID": "lessons/27_Continuous_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-first-try",
    "href": "lessons/27_Continuous_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-first-try",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf: first try!",
    "text": "Example starting from a joint pdf: first try!\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(2&lt;X&lt;10|Y=4)\\)"
  },
  {
    "objectID": "lessons/27_Continuous_distributions/27_Conditional_distributions.html#what-is-a-conditional-density",
    "href": "lessons/27_Continuous_distributions/27_Conditional_distributions.html#what-is-a-conditional-density",
    "title": "Chapter 27: Conditional Distributions",
    "section": "What is a conditional density?",
    "text": "What is a conditional density?\n\n\n\n\nDefinition: Conditional density\n\n\nThe conditional density of a r.v. \\(X\\) given \\(Y=y\\), is \\[f_{X|Y}(x|y)= \\frac{f_{X,Y}(x,y)}{f_Y(y)},\\] for \\(f_Y(y)&gt; 0\\)\n\n\n\n\n\nRemarks\n\nIt follows from the definition for the conditional density \\(f_{X|Y}(x|y)\\), that \\[f_{X,Y}(x,y)= f_{X|Y}(x|y)f_Y(y).\\]\n\n     \n\nFor a fixed value of \\(Y=y\\), the conditional density \\(f_{X|Y}(x|y)\\) is an actual pdf, meaning\n\n\\(f_{X|Y}(x|y)\\geq 0\\) for all \\(x\\) and \\(y\\), and\n\\(\\displaystyle\\int_{-\\infty}^{\\infty} f_{X|Y}(x|y)dx =1\\)."
  },
  {
    "objectID": "lessons/27_Continuous_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try",
    "href": "lessons/27_Continuous_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf: second try!",
    "text": "Example starting from a joint pdf: second try!\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(2&lt;X&lt;10|Y=4)\\)"
  },
  {
    "objectID": "lessons/27_Continuous_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf",
    "href": "lessons/27_Continuous_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf",
    "text": "Example starting from a joint pdf\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(X&gt;20 |Y=5)\\)"
  },
  {
    "objectID": "lessons/27_Continuous_distributions/27_Conditional_distributions.html#finding-probability-with-conditional-domain-and-pdf",
    "href": "lessons/27_Continuous_distributions/27_Conditional_distributions.html#finding-probability-with-conditional-domain-and-pdf",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Finding probability with conditional domain and pdf",
    "text": "Finding probability with conditional domain and pdf\n\n\n\n\nExample 2\n\n\nRandomly choose a point \\(X\\) from the interval \\([0,1]\\), and given \\(X=x\\), randomly choose a point \\(Y\\) from \\([0,x]\\). Find \\(\\mathbb{P}(0 &lt; Y &lt; \\frac14)\\)."
  },
  {
    "objectID": "lessons/27_Continuous_distributions/27_Conditional_distributions.html#independence-and-conditional-distributions",
    "href": "lessons/27_Continuous_distributions/27_Conditional_distributions.html#independence-and-conditional-distributions",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Independence and conditional distributions",
    "text": "Independence and conditional distributions\n    Question What is \\(f_{X|Y}(x|y)\\) if \\(X\\) and \\(Y\\) are independent?\n\\[f_{X|Y}(x|y) = \\dfrac{f_{X,Y}(x,y)}{f_y(y)} = \\dfrac{f_{X}(x)f_y(y)}{f_y(y)} = f_{X}(x)\\]\n       \n\nIf \\(f_{X|Y}(x|y)\\) does not depend on \\(y\\) (including the bounds/domain), then \\(X\\) and \\(Y\\) are independent."
  },
  {
    "objectID": "lessons/18_Poisson_rv/18_Poisson_rv.html",
    "href": "lessons/18_Poisson_rv/18_Poisson_rv.html",
    "title": "Chapter 18: Poisson RVs",
    "section": "",
    "text": "Identify the variable and the parameters of a Poisson distribution in a word problem, and state what the variable and parameters mean.\nUse the formulas for the pmf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons/18_Poisson_rv/18_Poisson_rv.html#learning-objectives",
    "href": "lessons/18_Poisson_rv/18_Poisson_rv.html#learning-objectives",
    "title": "Chapter 18: Poisson RVs",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nIdentify the variable and the parameters of a Poisson distribution in a word problem, and state what the variable and parameters mean.\nUse the formulas for the pmf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons/18_Poisson_rv/18_Poisson_rv.html#properties-of-poisson-rvs",
    "href": "lessons/18_Poisson_rv/18_Poisson_rv.html#properties-of-poisson-rvs",
    "title": "Chapter 18: Poisson RVs",
    "section": "Properties of Poisson RVs",
    "text": "Properties of Poisson RVs\n\nScenario: We are counting the number of successes in a fixed time period, which has a constant rate of successes\nShorthand: \\(X \\sim \\text{Poisson}(\\lambda)\\) or \\(X \\sim \\text{Pois}(\\lambda)\\)\n\n\\[\nX = \\text{Number of successes in a given period}\n\\]\n\\[ p_X(x) = P(X=x) = \\dfrac{e^{-\\lambda}\\lambda^x}{x!} \\text{ for } x = 0, 1, 2,3, ...\\]\n\\[ E(X) = \\lambda\\]\n\\[Var(X) = \\lambda\\]"
  },
  {
    "objectID": "lessons/18_Poisson_rv/18_Poisson_rv.html#distingushing-between-binomial-and-poisson-rvs",
    "href": "lessons/18_Poisson_rv/18_Poisson_rv.html#distingushing-between-binomial-and-poisson-rvs",
    "title": "Chapter 18: Poisson RVs",
    "section": "Distingushing between Binomial and Poisson RVs",
    "text": "Distingushing between Binomial and Poisson RVs\n\nRecall that if \\(X\\sim Binomial(n,p)\\), then\n\n\\(X\\) models the number of successes …\nin \\(n\\) independent (Bernoulli) trials …\nthat each have the same probability of success \\(p\\).\n\nPoisson r.v.’s are similar,\n\nexcept that instead of having \\(n\\) discrete independent trials,\nthere is a fixed time period during which the successes happen."
  },
  {
    "objectID": "lessons/18_Poisson_rv/18_Poisson_rv.html#examples-of-poisson-rvs",
    "href": "lessons/18_Poisson_rv/18_Poisson_rv.html#examples-of-poisson-rvs",
    "title": "Chapter 18: Poisson RVs",
    "section": "Examples of Poisson RVs",
    "text": "Examples of Poisson RVs\n\nNumber of visitors to an emergency room in an hour during a weekend night\nNumber of study participants enrolled in a study per week\nNumber of pedestrians walking through a square mile\nAny more?"
  },
  {
    "objectID": "lessons/18_Poisson_rv/18_Poisson_rv.html#emergency-room-visitors",
    "href": "lessons/18_Poisson_rv/18_Poisson_rv.html#emergency-room-visitors",
    "title": "Chapter 18: Poisson RVs",
    "section": "Emergency Room Visitors",
    "text": "Emergency Room Visitors\n\n\n\n\nExample 1\n\n\nSuppose an emergency room has an average of 50 visitors per day. Find the following probabilities.\n\nProbability of 30 visitors in a day.\nProbability of 8 visitors in an hour.\nProbability of at least 8 visitors in an hour."
  },
  {
    "objectID": "lessons/18_Poisson_rv/18_Poisson_rv.html#combining-independent-poisson-distributions",
    "href": "lessons/18_Poisson_rv/18_Poisson_rv.html#combining-independent-poisson-distributions",
    "title": "Chapter 18: Poisson RVs",
    "section": "Combining independent Poisson distributions",
    "text": "Combining independent Poisson distributions\n\n\nTheorem 1\n\n\nIf \\(X\\sim Pois(\\lambda_1)\\) and \\(Y\\sim Pois(\\lambda_2)\\) are independent of each other, then \\(Z=X+Y\\sim Pois(\\lambda_1 + \\lambda_2)\\)."
  },
  {
    "objectID": "lessons/18_Poisson_rv/18_Poisson_rv.html#two-emergency-rooms",
    "href": "lessons/18_Poisson_rv/18_Poisson_rv.html#two-emergency-rooms",
    "title": "Chapter 18: Poisson RVs",
    "section": "Two emergency rooms",
    "text": "Two emergency rooms\n\n\n\n\nExample 2\n\n\nSuppose emergency room 1 has an average of 50 visitors per day, and emergency room 2 has an average of 70 visitors per day, independently of each other. What is the probability distribution to model of the total number of visitors to both?"
  },
  {
    "objectID": "lessons/18_Poisson_rv/18_Poisson_rv.html#poisson-approximation-of-the-binomial",
    "href": "lessons/18_Poisson_rv/18_Poisson_rv.html#poisson-approximation-of-the-binomial",
    "title": "Chapter 18: Poisson RVs",
    "section": "Poisson Approximation of the Binomial",
    "text": "Poisson Approximation of the Binomial\nBoth Poisson and Binomial r.v.’s are counting the number of successes\n\nIf for a Binomial r.v.\n\nthe number of trials \\(n\\) is very large, and\nthe probability of success \\(p\\) is close to 0 or 1,\n\nthen the Poisson distribution can be used to approximate Binomial probabilities\n\nand we use \\(\\lambda = np\\)"
  },
  {
    "objectID": "lessons/18_Poisson_rv/18_Poisson_rv.html#medical-lab-errors",
    "href": "lessons/18_Poisson_rv/18_Poisson_rv.html#medical-lab-errors",
    "title": "Chapter 18: Poisson RVs",
    "section": "Medical lab errors",
    "text": "Medical lab errors\n\n\n\n\nExample 3\n\n\nSuppose that in the long run, errors in a medical testing lab are made 0.1% of the time. Find the probability that fewer than 4 mistakes are made in the next 2,000 tests.\n\nFind the probability using the Binomial distribution.\nApproximate the probability in part (1) using the Poisson distribution.\n\n\n\n\nTo do for extra practice - will also see a similar problem in BSTA 511\n\n\n\n\nChapter 18 Slides"
  },
  {
    "objectID": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html",
    "href": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "",
    "text": "Define basic terms related to events such as events, outcomes, and sample space.\nUse proper set notation for events\nCharacterize possible outcomes, when something random occurs\nDescribe events into which outcomes can be grouped\nDefine important terms and rules within set theory such as unions, intersections, complements, mutually exclusive, and De Morgan’s Laws"
  },
  {
    "objectID": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#learning-objectives",
    "href": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#learning-objectives",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDefine basic terms related to events such as events, outcomes, and sample space.\nUse proper set notation for events\nCharacterize possible outcomes, when something random occurs\nDescribe events into which outcomes can be grouped\nDefine important terms and rules within set theory such as unions, intersections, complements, mutually exclusive, and De Morgan’s Laws"
  },
  {
    "objectID": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#coin-toss-example-1-coin-13",
    "href": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#coin-toss-example-1-coin-13",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Coin Toss Example: 1 coin (1/3)",
    "text": "Coin Toss Example: 1 coin (1/3)\nSuppose you toss one coin.\n\nWhat are the possible outcomes?\n \nWhat is the sample space?\n \nWhat are the possible events?"
  },
  {
    "objectID": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#coin-toss-example-1-coin-23",
    "href": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#coin-toss-example-1-coin-23",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Coin Toss Example: 1 coin (2/3)",
    "text": "Coin Toss Example: 1 coin (2/3)\nSuppose you toss one coin.\n\nWhat are the possible outcomes?\n\nHeads (\\(H\\))\nTails (\\(T\\))\n\n\n \n\n\nNote\n\n\nWhen something happens at random, such as a coin toss, there are several possible outcomes, and exactly one of the outcomes will occur."
  },
  {
    "objectID": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#coin-toss-example-1-coin-33",
    "href": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#coin-toss-example-1-coin-33",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Coin Toss Example: 1 coin (3/3)",
    "text": "Coin Toss Example: 1 coin (3/3)\n\n\n\nWhat is the sample space?\n\n\\(S =\\)\n\n\n \n \n\nWhat are the possible events?\n\n\n\n\n\n\n \n\n\n\n\nNote #1\n\n\nWe use curly brackets (\\(\\{\\}\\)) to denote a set (collecting a list of outcomes or values)\n\n\n\n\nNote #2\n\n\nThe total number of possible events is \\[2^{|S|}\\] where \\(|S|\\) is the total number of outcomes in the sample space. Also, possible events are not necessarily something that can actually occur (i.e. getting a heads and a tails on a single coin flip)"
  },
  {
    "objectID": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#coin-toss-example-2-coins",
    "href": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#coin-toss-example-2-coins",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Coin Toss Example: 2 coins",
    "text": "Coin Toss Example: 2 coins\nSuppose you toss two coins.\n\nWhat is the sample space? Assume the coins are distinguishable\n\n\\(S =\\)\n\n\n \n\nWhat are some possible events?\n\n\\(A =\\) exactly one \\(H =\\)\n\\(B =\\) at least one \\(H =\\)"
  },
  {
    "objectID": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#more-info-on-events-and-sample-spaces",
    "href": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#more-info-on-events-and-sample-spaces",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "More info on events and sample spaces",
    "text": "More info on events and sample spaces\n\nWe usually use capital letters from the beginning of the alphabet to denote events. However, other letters might be chosen to be more descriptive.\n\n \n\nWe use the notation \\(|S|\\) to denote the size of the sample space.\n\n \n\nThe total number of possible events is \\(2^{|S|}\\), which is the total number of possible subsets of \\(S\\).\n\n \n\nThe empty set, denoted by \\(\\emptyset\\), is the set containing no outcomes."
  },
  {
    "objectID": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#example-keep-sampling-until",
    "href": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#example-keep-sampling-until",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Example: Keep sampling until…",
    "text": "Example: Keep sampling until…\nSuppose you keep sampling people until you have someone with high blood pressure (BP)\n \nWhat is the sample space?\n\nLet \\(H =\\) denote someone with high BP.\nLet \\(H^C =\\) denote someone with not high blood pressure, such as low or regular BP.\n\n \n\nThen, \\(S =\\)"
  },
  {
    "objectID": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#set-theory-12",
    "href": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#set-theory-12",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Set Theory (1/2)",
    "text": "Set Theory (1/2)\n\n\n \n\n\nDefinition: Union\n\n\nThe union of events \\(A\\) and \\(B\\), denoted by \\(A \\cup B\\), contains all outcomes that are in \\(A\\) or \\(B\\) or both\n\n\n\n\nDefinition: Intersection\n\n\nThe intersection of events \\(A\\) and \\(B\\), denoted by \\(A \\cap B\\), contains all outcomes that are both in \\(A\\) and \\(B\\).\n\n\n\nVenn diagrams"
  },
  {
    "objectID": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#set-theory-22",
    "href": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#set-theory-22",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Set Theory (2/2)",
    "text": "Set Theory (2/2)\n\n\n \n\n\nDefinition: Complement\n\n\nThe complement of event \\(A\\), denoted by \\(A^C\\) or \\(A'\\), contains all outcomes in the sample space \\(S\\) that are not in \\(A\\) .\n\n\n\n\nDefinition: Mutually Exclusive\n\n\nEvents \\(A\\) and \\(B\\) are mutually exclusive, or disjoint, if they have no outcomes in common. In this case \\(A \\cap B = \\emptyset\\), where \\(\\emptyset\\) is the empty set.\n\n\n\nVenn diagrams"
  },
  {
    "objectID": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#bp-example-variation-13",
    "href": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#bp-example-variation-13",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "BP example variation (1/3)",
    "text": "BP example variation (1/3)\n\nSuppose you have \\(n\\) subjects in a study.\nLet \\(H_i\\) be the event that person \\(i\\) has high BP, for \\(i=1\\ldots n\\).\n\n \nUse set theory notation to denote the following events:\n\nEvent subject \\(i\\) does not have high BP\nEvent all \\(n\\) subjects have high BP\nEvent at least one subject has high BP\nEvent all of them do not have high BP\nEvent at least one subject does not have high BP"
  },
  {
    "objectID": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#bp-example-variation-23",
    "href": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#bp-example-variation-23",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "BP example variation (2/3)",
    "text": "BP example variation (2/3)\n\nSuppose you have \\(n\\) subjects in a study.\nLet \\(H_i\\) be the event that person \\(i\\) has high BP, for \\(i=1\\ldots n\\).\n\nUse set theory notation to denote the following events:\n\nEvent subject \\(i\\) does not have high BP\n \nEvent all \\(n\\) subjects have high BP\n \n \nEvent at least one subject has high BP"
  },
  {
    "objectID": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#bp-example-variation-33",
    "href": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#bp-example-variation-33",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "BP example variation (3/3)",
    "text": "BP example variation (3/3)\n\nEvent all of them do not have high BP\n \n \n \nEvent at least one subject does not have high BP"
  },
  {
    "objectID": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#de-morgans-laws",
    "href": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#de-morgans-laws",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "De Morgan’s Laws",
    "text": "De Morgan’s Laws\n\n\nTheorem: De Morgan’s 1st Law\n\n\nFor a collection of events (sets) \\(A_1, A_2, A_3, \\ldots\\)\n\\[\\bigcap\\limits_{i=1}^{n}A_i^C = \\Big(\\bigcup\\limits_{i=1}^{n}A_i\\Big)^C\\]\n\n\n“all not A = \\((\\)at least one event A\\()^C\\)” or “intersection of the complements is the complement of the union”\n\n\nTheorem: De Morgan’s 2nd Law\n\n\nFor a collection of events (sets) \\(A_1, A_2, A_3, \\ldots\\)\n\\[\\bigcup\\limits_{i=1}^{n}A_i^C = \\Big(\\bigcap\\limits_{i=1}^{n}A_i\\Big)^C\\]\n\n\n“at least one event not A = \\((\\)all A\\()^C\\)” or “union of complements is complement of the intersection”"
  },
  {
    "objectID": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#remarks-on-de-morgans-laws",
    "href": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#remarks-on-de-morgans-laws",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Remarks on De Morgan’s Laws",
    "text": "Remarks on De Morgan’s Laws\n\nThese laws also hold for infinite collections of events.\n \nDraw Venn diagrams to convince yourself that these are true!\n \nThese laws are very useful when calculating probabilities.\n\nThis is because calculating the probability of the intersection of events is often much easier than the union of events.\nThis is not obvious right now, but we will see in the coming chapters why."
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities.html",
    "href": "lessons/25_Joint_densities/25_Joint_densities.html",
    "title": "Chapter 25: Joint densities",
    "section": "",
    "text": "Solve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities.html#learning-objectives",
    "href": "lessons/25_Joint_densities/25_Joint_densities.html#learning-objectives",
    "title": "Chapter 25: Joint densities",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nSolve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities.html#double-integrals-mini-lesson-13",
    "href": "lessons/25_Joint_densities/25_Joint_densities.html#double-integrals-mini-lesson-13",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (1/3)",
    "text": "Double Integrals Mini Lesson (1/3)\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 1\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} xy dydx\\)"
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities.html#double-integrals-mini-lesson-23",
    "href": "lessons/25_Joint_densities/25_Joint_densities.html#double-integrals-mini-lesson-23",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (2/3)",
    "text": "Double Integrals Mini Lesson (2/3)\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 2\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} (x+y) dydx\\)"
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities.html#double-integrals-mini-lesson-33",
    "href": "lessons/25_Joint_densities/25_Joint_densities.html#double-integrals-mini-lesson-33",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (3/3)",
    "text": "Double Integrals Mini Lesson (3/3)\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 3\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} e^{x+y} dydx\\)"
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "href": "lessons/25_Joint_densities/25_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "title": "Chapter 25: Joint densities",
    "section": "How to define the joint pdf for continuous RVs?",
    "text": "How to define the joint pdf for continuous RVs?\n\n\nFor a single continuous RV \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\), \\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\]\n\nFor two continuous RVs (\\(X\\) and \\(Y\\)), we can define the joint pdf, \\(f_{X,Y}(x,y)\\), such that for all real values \\(a,b, c, d\\) with \\(a \\leq b\\) and \\(c \\leq d\\), \\[\\mathbb{P}(a \\leq X \\leq b, c \\leq Y \\leq d) = \\int_a^b \\int_c^d f_{X,Y}(x,y)dydx\\]"
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities.html#important-properties-of-the-joint-pdf",
    "href": "lessons/25_Joint_densities/25_Joint_densities.html#important-properties-of-the-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Important properties of the joint pdf",
    "text": "Important properties of the joint pdf\n\nNote that \\(f_{X,Y}(x,y)\\neq \\mathbb{P}(X=x, Y=y)\\)!!!\nIn order for \\(f_{X,Y}(x,y)\\) to be a pdf, it needs to satisfy the properties\n\n\\(f_{X,Y}(x,y)\\geq 0\\) for all \\(x,y\\)\n\\(\\displaystyle\\int_{-\\infty}^{\\infty}\\displaystyle\\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dxdy=1\\)"
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "href": "lessons/25_Joint_densities/25_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "title": "Chapter 25: Joint densities",
    "section": "What is the joint cumulative distribution function?",
    "text": "What is the joint cumulative distribution function?\n\n\nDefinition: Joint cumulative distribution function (Joint CDF)\n\n\nThe joint cumulative distribution function (cdf) of continuous random variables \\(X\\) and \\(Y\\), is the function \\(F_{X,Y}(x,y)\\), such that for all real values of \\(x\\) and \\(y\\), \\[F_{X,Y}(x,y)= \\mathbb{P}(X \\leq x, Y \\leq y) = \\int_{-\\infty}^x\\int_{-\\infty}^y f_{X,Y}(s,t)dtds\\]\n\n\nRemarks:\n\nThe definition above for \\(F_{X,Y}(x,y)\\) is a function of \\(x\\) and \\(y\\).\nThe joint cdf at the point \\((a,b)\\), is \\[F_{X,Y}(a,b) = \\mathbb{P}(X \\leq a, Y \\leq b) = \\int_{-\\infty}^a\\int_{-\\infty}^b f_{X,Y}(s,t)dtds\\]"
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities.html#what-are-the-marginal-pdfs",
    "href": "lessons/25_Joint_densities/25_Joint_densities.html#what-are-the-marginal-pdfs",
    "title": "Chapter 25: Joint densities",
    "section": "What are the marginal pdf’s?",
    "text": "What are the marginal pdf’s?\n\n\nDefinition: Marginal pdf’s\n\n\nSuppose \\(X\\) and \\(Y\\) are continuous r.v.’s, with joint pdf \\(f_{X,Y}(x,y)\\). Then the marginal probability density functions are \\[\\begin{aligned}\nf_X(x)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dy\\\\\nf_Y(y)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dx\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities.html#example-of-joint-pdf",
    "href": "lessons/25_Joint_densities/25_Joint_densities.html#example-of-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)."
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities.html#example-of-joint-pdf-1",
    "href": "lessons/25_Joint_densities/25_Joint_densities.html#example-of-joint-pdf-1",
    "title": "Chapter 25: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "href": "lessons/25_Joint_densities/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "href": "lessons/25_Joint_densities/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "title": "Chapter 25: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(\\mathbb{P}(Y &lt; 3)\\)."
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-more",
    "href": "lessons/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-more",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.1\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nFind \\(\\mathbb{P}(|X-Y| &lt; 2)\\)"
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-more-1",
    "href": "lessons/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-more-1",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.2\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(M = \\max(X,Y)\\). Find the pdf for \\(M\\), that is \\(f_M(m)\\)."
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-more-2",
    "href": "lessons/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-more-2",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 3.3\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(Z = \\min(X,Y)\\). Find the pdf for \\(Z\\), that is \\(f_Z(z)\\)."
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-further",
    "href": "lessons/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-further",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even further!",
    "text": "Let’s complicate this even further!\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 4\n\n\nLet \\(X\\) and \\(Y\\) have joint density \\(f_{X,Y}(x,y)= \\frac85(x+y)\\) in the region \\(0 &lt; x &lt; 1,\\ \\frac12 &lt; y &lt;1\\). Find the pdf of the r.v. \\(Z\\), where \\(Z=XY\\).\n\n\n\n\n\n\nChapter 25 Slides"
  },
  {
    "objectID": "lessons/32_Exponential_rv/32_Exponential_rv.html",
    "href": "lessons/32_Exponential_rv/32_Exponential_rv.html",
    "title": "Chapter 32: Exponential Random Variables",
    "section": "",
    "text": "Identify the variable and the parameters in a story, and state in English what the variable and its parameters mean.\nUse the formulas for the density, CDF, expected value, and variance to answer questions and find probabilities.\n\n\ncode.sourceCode {\n  font-size: 1.5em;\n  /* or try font-size: xx-large; */\n}"
  },
  {
    "objectID": "lessons/32_Exponential_rv/32_Exponential_rv.html#learning-objectives",
    "href": "lessons/32_Exponential_rv/32_Exponential_rv.html#learning-objectives",
    "title": "Chapter 32: Exponential Random Variables",
    "section": "",
    "text": "Identify the variable and the parameters in a story, and state in English what the variable and its parameters mean.\nUse the formulas for the density, CDF, expected value, and variance to answer questions and find probabilities.\n\n\ncode.sourceCode {\n  font-size: 1.5em;\n  /* or try font-size: xx-large; */\n}"
  },
  {
    "objectID": "lessons/32_Exponential_rv/32_Exponential_rv.html#properties-of-exponential-rvs",
    "href": "lessons/32_Exponential_rv/32_Exponential_rv.html#properties-of-exponential-rvs",
    "title": "Chapter 32: Exponential Random Variables",
    "section": "Properties of exponential RVs",
    "text": "Properties of exponential RVs\n\nScenario: Modeling the time until the next (first) event\nContinuous analog to the geometric distribution!\nShorthand: \\(X \\sim \\text{Exp}(\\lambda)\\)\n\n\\[\nf_X(x) = \\lambda e^{-\\lambda x}\\text{ for } x&gt;0, \\lambda&gt;0\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;0 \\quad \\\\\n            1 - e^{-\\lambda x} & \\quad x\\geq0 \\\\\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{1}{\\lambda}\\] \\[\\text{Var}(X) = \\dfrac{1}{\\lambda^2}\\]"
  },
  {
    "objectID": "lessons/32_Exponential_rv/32_Exponential_rv.html#memoryless-property",
    "href": "lessons/32_Exponential_rv/32_Exponential_rv.html#memoryless-property",
    "title": "Chapter 32: Exponential Random Variables",
    "section": "Memoryless Property",
    "text": "Memoryless Property\n   \nIf \\(b&gt;0\\),\n\\[P(X &gt; a +b | X&gt; a) = P(X &gt; b)\\]\n     \n\nThis can be interpreted as:\n\nIf you have waited \\(a\\) seconds (or any other measure of time) without a success\nThen the probability that you have to wait \\(b\\) more seconds is the same as as the probability of waiting \\(b\\) seconds initially."
  },
  {
    "objectID": "lessons/32_Exponential_rv/32_Exponential_rv.html#identifying-exponential-rv-from-word-problems",
    "href": "lessons/32_Exponential_rv/32_Exponential_rv.html#identifying-exponential-rv-from-word-problems",
    "title": "Chapter 32: Exponential Random Variables",
    "section": "Identifying exponential RV from word problems",
    "text": "Identifying exponential RV from word problems\n\nLook for time between events/successes\nLook for a rate of the events over time period\nHow does it differ from the geometric distribution?\n\nGeometric is number of trials until first success\nExponential is time until first success\n\nRelation to the Poisson distribution?\n\nWhen the time between arrivals is exponential, the number of arrivals in a fixed time interval is Poisson with the mean \\(\\lambda\\)"
  },
  {
    "objectID": "lessons/32_Exponential_rv/32_Exponential_rv.html#helpful-r-code",
    "href": "lessons/32_Exponential_rv/32_Exponential_rv.html#helpful-r-code",
    "title": "Chapter 32: Exponential Random Variables",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re sitting at the bus stop, measuring the time until our bus arrives. We know the bus comes every 10 minutes on average.\n\nIf we want to know the probability that the bus arrives in the next 5 minutes:\n\npexp(q = 5, rate = 1/10)\n\n[1] 0.3934693\n\n\nIf we want to know the time, say \\(t\\), where the probability of the bus arriving at \\(t\\) or earlier is 0.35:\n\nqexp(p = 0.35, rate = 1/10)\n\n[1] 4.307829\n\n\nIf we want to know the probability that the bus arrives between 3 and 5 minutes:\n\npexp(q = 5, rate = 1/10) - pexp(q = 3, rate = 1/10)\n\n[1] 0.1342876\n\n\nIf we want to sample 20 bus arrival times from the distribution:\n\nrexp(n = 20, rate = 1/10)\n\n [1]  0.99673730 66.12062437 14.49579658  3.99838822 13.56471614  3.98639216\n [7]  4.70838893  7.97777662 20.16520858  0.43174262  9.59612923 17.57753393\n[13]  0.03792729 12.78806716  0.65926385  2.43805808 27.10900644 19.85506415\n[19]  8.87837111 30.28163620"
  },
  {
    "objectID": "lessons/32_Exponential_rv/32_Exponential_rv.html#transformation-of-independent-exponential-rvs",
    "href": "lessons/32_Exponential_rv/32_Exponential_rv.html#transformation-of-independent-exponential-rvs",
    "title": "Chapter 32: Exponential Random Variables",
    "section": "Transformation of independent exponential RVs",
    "text": "Transformation of independent exponential RVs\n\n\n\n\nExample 1\n\n\nLet \\(X_i \\sim \\textrm{Exp}(\\lambda_i)\\) be independent RVs, for \\(i=1 \\ldots n\\). Find the pdf for the first of the arrival times."
  },
  {
    "objectID": "lessons/10_Expected_Values/10_Expected_Values.html",
    "href": "lessons/10_Expected_Values/10_Expected_Values.html",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "",
    "text": "Calculate the mean (expected value) of discrete random variables"
  },
  {
    "objectID": "lessons/10_Expected_Values/10_Expected_Values.html#learning-objectives",
    "href": "lessons/10_Expected_Values/10_Expected_Values.html#learning-objectives",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate the mean (expected value) of discrete random variables"
  },
  {
    "objectID": "lessons/10_Expected_Values/10_Expected_Values.html#our-good-and-fair-friend-the-6-sided-die",
    "href": "lessons/10_Expected_Values/10_Expected_Values.html#our-good-and-fair-friend-the-6-sided-die",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Our good and fair friend, the 6-sided die",
    "text": "Our good and fair friend, the 6-sided die\n\n\n\n\nExample 1\n\n\nSuppose you roll a fair 6-sided die. What value do you expect to get?"
  },
  {
    "objectID": "lessons/10_Expected_Values/10_Expected_Values.html#what-is-an-expected-value",
    "href": "lessons/10_Expected_Values/10_Expected_Values.html#what-is-an-expected-value",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "What is an expected value?",
    "text": "What is an expected value?\n\n\nDefinition: Expected value\n\n\nThe expected value of a discrete r.v. \\(X\\) that takes on values \\(x_1, x_2, \\ldots, x_n\\) is \\[\\mathbb{E}[X] = \\sum_{i=1}^n x_ip_X(x_i).\\]\n\n\n\nExpected values are not necessarily an actual outcome\n\nIn previous example, we cannot roll a 3.5\nIt could be that our expected value is not in the sample space (\\(E(X) \\notin S\\))\n\nDefinition holds when \\(X\\) takes on countably infinitely many values:\n\n\\[\\mathbb{E}[X] = \\sum_{i=1}^\\infty x_ip_X(x_i)\\]"
  },
  {
    "objectID": "lessons/10_Expected_Values/10_Expected_Values.html#our-good-and-not-so-fair-friend-the-6-sided-die",
    "href": "lessons/10_Expected_Values/10_Expected_Values.html#our-good-and-not-so-fair-friend-the-6-sided-die",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Our good and not-so-fair friend, the 6-sided die",
    "text": "Our good and not-so-fair friend, the 6-sided die\n\n\n\n\nExample 2\n\n\nSuppose the die is 6-sided, but not fair. And the probabilities of each side is distributed as:\n\n\n\n\\(x\\)\n\\(p_X(x)\\)\n\n\n\n\n1\n0.10\n\n\n2\n0.05\n\n\n3\n0.02\n\n\n4\n0.30\n\n\n5\n0.50\n\n\n6\n0.03\n\n\n\nWhat value do you expect to get on a roll?"
  },
  {
    "objectID": "lessons/10_Expected_Values/10_Expected_Values.html#expected-value-of-a-bernoulli-distribution",
    "href": "lessons/10_Expected_Values/10_Expected_Values.html#expected-value-of-a-bernoulli-distribution",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Expected value of a Bernoulli distribution",
    "text": "Expected value of a Bernoulli distribution\n\n\n\n\nExample 3\n\n\nSuppose \\[X = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\quad\\mathrm{(success)}\\\\\n            0 & \\quad \\mathrm{with\\ probability}\\ 1-p \\quad\\mathrm{(failure)}\n        \\end{array}\n    \\right.\\] Find the expected value of \\(X\\)."
  },
  {
    "objectID": "lessons/10_Expected_Values/10_Expected_Values.html#lets-slightly-change-our-random-variable",
    "href": "lessons/10_Expected_Values/10_Expected_Values.html#lets-slightly-change-our-random-variable",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Let’s slightly change our random variable",
    "text": "Let’s slightly change our random variable\n\n\n\n\nExample 5\n\n\nSuppose \\[X = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\\\\n            -1 & \\quad \\mathrm{with\\ probability}\\ 1-p\n        \\end{array}\n    \\right.\\] Find the expected value of \\(X\\)."
  },
  {
    "objectID": "lessons/10_Expected_Values/10_Expected_Values.html#bullseye",
    "href": "lessons/10_Expected_Values/10_Expected_Values.html#bullseye",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Bullseye! 🎯",
    "text": "Bullseye! 🎯\n\n\n\n\nExample 5\n\n\nSuppose I throw darts at a dartboard until I hit the bullseye, and that my probability of hitting the bullseye is \\(p\\). Suppose further that all of my throws are independent, and that the probability of a bullseye never changes, no matter how many times I throw a dart. How many times should I expect to have to throw the dart until I hit the bullseye?"
  },
  {
    "objectID": "lessons/10_Expected_Values/10_Expected_Values.html#ghost",
    "href": "lessons/10_Expected_Values/10_Expected_Values.html#ghost",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Ghost! 👻",
    "text": "Ghost! 👻\n\n\n\n\nExample 6\n\n\nA ghost is trick-or-treating. It comes to a house where it is known that there are 30 candies in the bag and only one is a watermelon Jolly Rancher, which is the ghost’s favorite. The ghost takes pieces of candy without replacement until it gets the watermelon Jolly Rancher. How many pieces of candy do we expect the ghost to take?\n\n\nCan we model this with a distribution?"
  },
  {
    "objectID": "lessons/10_Expected_Values/10_Expected_Values.html#some-remarks-on-last-two-examples",
    "href": "lessons/10_Expected_Values/10_Expected_Values.html#some-remarks-on-last-two-examples",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Some remarks on last two examples",
    "text": "Some remarks on last two examples\nBoth examples are repeated random processes. They are fundamentally different though:\n\nThe bullseye example is “with replacement” since the probability of success remains constant.\nThe ghost trick-or-treating example is without replacement, and thus the probability of success changes with each trial."
  },
  {
    "objectID": "lessons/09_Joint_distributions/09_Joint_distributions.html",
    "href": "lessons/09_Joint_distributions/09_Joint_distributions.html",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "",
    "text": "Calculate probabilities for a pair of discrete random variables\nCalculate a joint, marginal, and conditional probability mass function (pmf)\nCalculate a joint, marginal, and conditional cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons/09_Joint_distributions/09_Joint_distributions.html#learning-objectives",
    "href": "lessons/09_Joint_distributions/09_Joint_distributions.html#learning-objectives",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate probabilities for a pair of discrete random variables\nCalculate a joint, marginal, and conditional probability mass function (pmf)\nCalculate a joint, marginal, and conditional cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons/09_Joint_distributions/09_Joint_distributions.html#what-is-a-joint-pmf",
    "href": "lessons/09_Joint_distributions/09_Joint_distributions.html#what-is-a-joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is a joint pmf?",
    "text": "What is a joint pmf?\n\n\nDefinition: joint pmf\n\n\nThe joint pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[p_{X,Y}(x,y) = \\mathbb{P}(X=x\\ and\\ Y=y) = \\mathbb{P}(X=x, Y=y)\\]"
  },
  {
    "objectID": "lessons/09_Joint_distributions/09_Joint_distributions.html#this-chapters-main-example",
    "href": "lessons/09_Joint_distributions/09_Joint_distributions.html#this-chapters-main-example",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "This chapter’s main example",
    "text": "This chapter’s main example\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?"
  },
  {
    "objectID": "lessons/09_Joint_distributions/09_Joint_distributions.html#joint-pmf",
    "href": "lessons/09_Joint_distributions/09_Joint_distributions.html#joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Joint pmf",
    "text": "Joint pmf\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)"
  },
  {
    "objectID": "lessons/09_Joint_distributions/09_Joint_distributions.html#marginal-pmfs",
    "href": "lessons/09_Joint_distributions/09_Joint_distributions.html#marginal-pmfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Marginal pmf’s",
    "text": "Marginal pmf’s\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)"
  },
  {
    "objectID": "lessons/09_Joint_distributions/09_Joint_distributions.html#remarks-on-the-joint-pmf",
    "href": "lessons/09_Joint_distributions/09_Joint_distributions.html#remarks-on-the-joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the joint pmf",
    "text": "Remarks on the joint pmf\nSome properties of joint pmf’s:\n\nA joint pmf \\(p_{X,Y}(x,y)\\) must satisfy the following properties:\n\n\\(p_{X,Y}(x,y)\\geq 0\\) for all \\(x, y\\).\n\\(\\sum \\limits_{\\{all\\ x\\}} \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)=1\\).\n\nMarginal pmf’s:\n\n\\(p_X(x) = \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)\\)\n\\(p_Y(y) = \\sum \\limits_{\\{all\\ x\\}} p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/09_Joint_distributions/09_Joint_distributions.html#what-is-a-joint-cdf",
    "href": "lessons/09_Joint_distributions/09_Joint_distributions.html#what-is-a-joint-cdf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is a joint CDF?",
    "text": "What is a joint CDF?\n\n\nDefinition: joint CDF\n\n\nThe joint CDF of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[F_{X,Y}(x,y) = \\mathbb{P}(X \\leq x\\ and\\ Y \\leq y) = \\mathbb{P}(X \\leq x, Y \\leq y)\\]"
  },
  {
    "objectID": "lessons/09_Joint_distributions/09_Joint_distributions.html#joint-cdfs",
    "href": "lessons/09_Joint_distributions/09_Joint_distributions.html#joint-cdfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Joint CDFs",
    "text": "Joint CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/09_Joint_distributions/09_Joint_distributions.html#marginal-cdfs",
    "href": "lessons/09_Joint_distributions/09_Joint_distributions.html#marginal-cdfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Marginal CDFs",
    "text": "Marginal CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)"
  },
  {
    "objectID": "lessons/09_Joint_distributions/09_Joint_distributions.html#remarks-on-the-joint-and-marginal-cdf",
    "href": "lessons/09_Joint_distributions/09_Joint_distributions.html#remarks-on-the-joint-and-marginal-cdf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the joint and marginal CDF",
    "text": "Remarks on the joint and marginal CDF\n\n\\(F_X(x)\\): right most columns of the CDf table (where the \\(Y\\) values are largest)\n\\(F_Y(y)\\): bottom row of the table (where X values are largest)\n\\(F_X(x)=\\lim\\limits_{y\\rightarrow\\infty}F_{X, Y}(x,y)\\)\n\\(F_Y(y)=\\lim\\limits_{x\\rightarrow\\infty}F_{X, Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/09_Joint_distributions/09_Joint_distributions.html#independence-and-conditioning",
    "href": "lessons/09_Joint_distributions/09_Joint_distributions.html#independence-and-conditioning",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Independence and Conditioning",
    "text": "Independence and Conditioning\nRecall that for events \\(A\\) and \\(B\\),\n\n\\(\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}\\)\n\\(A\\) and \\(B\\) are independent if and only if\n\n\\(\\mathbb{P}(A|B) = \\mathbb{P}(A)\\)\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A)\\cdot\\mathbb{P}(B)\\)\n\n\nIndependence and conditioning are defined similarly for r.v.’s, since \\[p_X(x) = \\mathbb{P}(X=x)\\ \\mathrm{and}\\ \\ p_{X,Y}(x,y) = \\mathbb{P}(X = x ,Y = y).\\]"
  },
  {
    "objectID": "lessons/09_Joint_distributions/09_Joint_distributions.html#what-is-the-conditional-pmf",
    "href": "lessons/09_Joint_distributions/09_Joint_distributions.html#what-is-the-conditional-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is the conditional pmf?",
    "text": "What is the conditional pmf?\n\n\nDefinition: conditional pmf\n\n\nThe conditional pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is defined as \\[p_{X|Y}(x|y) = \\mathbb{P}(X = x |Y = y) = \\frac{\\mathbb{P}(X = x\\ and\\ Y = y)}{\\mathbb{P}(Y = y)}\n=\\frac{p_{X,Y}(x,y) }{p_{Y}(y) }\\] if \\(p_{Y}(y) &gt; 0\\)."
  },
  {
    "objectID": "lessons/09_Joint_distributions/09_Joint_distributions.html#remarks-on-the-conditional-pmf",
    "href": "lessons/09_Joint_distributions/09_Joint_distributions.html#remarks-on-the-conditional-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the conditional pmf",
    "text": "Remarks on the conditional pmf\nThe following properties follow from the conditional pmf definition:\n\nIf \\(X \\perp Y\\) (independent)\n\n\\(p_{X|Y}(x|y) = p_X(x)\\) for all \\(x\\) and \\(y\\)\n\\(p_{X,Y}(x,y) = p_X(x)p_Y(y)\\) for all \\(x\\) and \\(y\\)\nWhich also implies (\\(\\Rightarrow\\)): \\(F_{X,Y}(x,y) = F_X(x)F_Y(y)\\) for all \\(x\\) and \\(y\\)\n\nIf \\(X_1, X_2, …, X_n\\) are independent\n\n\\[p_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1=x_1, X_2=x_2, …, X_n=x_n)=\\prod\\limits_{i=1}^np_{X_i}(x_i)\\]\n\\[F_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1\\leq x_1, X_2\\leq x_2, …, X_n\\leq x_n)=\\prod\\limits_{i=1}^nP(X_i \\leq x_i) = \\prod\\limits_{i=1}^nF_{X_i}(x_i)\\]"
  },
  {
    "objectID": "lessons/09_Joint_distributions/09_Joint_distributions.html#conditional-pmfs",
    "href": "lessons/09_Joint_distributions/09_Joint_distributions.html#conditional-pmfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Conditional pmf’s",
    "text": "Conditional pmf’s\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?\n\n\n\n\n\nRemark:\n\nTo show that \\(X\\) and \\(Y\\) are not independent, we just need to find one counter example\nHowever, to show that they are independent, we need to verify this for all possible pairs of \\(x\\) and \\(y\\)"
  },
  {
    "objectID": "lessons/09_Joint_distributions/09_Joint_distributions.html#hypothetical-4-sided-die",
    "href": "lessons/09_Joint_distributions/09_Joint_distributions.html#hypothetical-4-sided-die",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Hypothetical 4-sided die",
    "text": "Hypothetical 4-sided die\n\n\nExample 3\n\n\n\nSuppose you have a 4-sided die, and you roll the 4-sided die until the first 4 appears.\nLet \\(X\\) be the number of rolls required until (and including) the first 4.\nAfter the first 4, you keep rolling it again until you roll a 3.\nLet \\(Y\\) be the number of rolls, after the first 4, required until (and including) the 3.\n\n\nFind \\(p_{X,Y}(x,y)\\).\nUsing \\(p_{X,Y}(x,y)\\), find \\(p_{Y}(y)\\).\nFind \\(p_{X}(x)\\).\nAre \\(X\\) and \\(Y\\) are independent? Why or why not?\nFind \\(F_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html",
    "href": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "",
    "text": "Calculate conditional probability of an event using Bayes’ Theorem\nUtilize additional probability rules in probability calculations, specifically the Higher Order Multiplication Rule and the Law of Total Probabilities"
  },
  {
    "objectID": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#learning-objectives",
    "href": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#learning-objectives",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate conditional probability of an event using Bayes’ Theorem\nUtilize additional probability rules in probability calculations, specifically the Higher Order Multiplication Rule and the Law of Total Probabilities"
  },
  {
    "objectID": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#introduction",
    "href": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#introduction",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Introduction",
    "text": "Introduction\n\nSo we learned about conditional probabilities\n\nWe learned how the occurrence of event A affects event B (B conditional on A)\n\nCan we figure out information on how the occurrence of event B affects event A?\nWe can use the conditional probability (\\(\\mathbb{P}(A|B)\\)) to get information on the flipped conditional probability (\\(\\mathbb{P}(B|A)\\))"
  },
  {
    "objectID": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#bayes-rule-for-two-events",
    "href": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#bayes-rule-for-two-events",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Bayes’ Rule for two events",
    "text": "Bayes’ Rule for two events\n\n\n\n\nTheorem: Bayes’ Rule (for two events)\n\n\nFor any two events \\(A\\) and \\(B\\) with nonzero probabilties,\n\\[\\mathbb{P}(A| B) =\n\\frac{\\mathbb{P}(A) \\cdot \\mathbb{P}(B|A)}\n{\\mathbb{P}(B)}\\]"
  },
  {
    "objectID": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-higher-order-multiplication-rule",
    "href": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-higher-order-multiplication-rule",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with Higher Order Multiplication Rule",
    "text": "Calculating probability with Higher Order Multiplication Rule\n\n\n\n\nExample 1\n\n\nSuppose we draw 5 cards from a standard shuffled deck of 52 cards. What is the probability of a flush, that is all the cards are of the same suit (including straight flushes)?\n\n\n\n\n\nHigher Order Multiplication Rule\n\n\n\\[\\mathbb{P}(A_1\\cap A_2 \\cap  \\ldots \\cap A_n)=\\mathbb{P}(A_1)\\cdot\\mathbb{P}(A_2|A_1) \\cdot \\\\\n\\mathbb{P}(A_3|A_1A_2)\\ldots \\cdot\\mathbb{P}(A_n|A_1A_2\\ldots A_{n-1})\\]"
  },
  {
    "objectID": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-law-of-total-probability",
    "href": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-law-of-total-probability",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with Law of Total Probability",
    "text": "Calculating probability with Law of Total Probability\n\n\n\n\nExample 2\n\n\nSuppose 1% of people assigned female at birth (AFAB) and 5% of people assigned male at birth (AMAB) are color-blind. Assume person born is equally likely AFAB or AMAB (not including intersex). What is the probability that a person chosen at random is color-blind?\n\n\n\n\n\nLaw of Total Probability for 2 Events\n\n\nFor events \\(A\\) and \\(B\\),\n\\[%\\left(\n\\begin{array}{ccl}\n\\mathbb{P}(B)&=&\\mathbb{P}(B \\cap A) + \\mathbb{P}(B \\cap A^C)\\\\\n           &=& \\mathbb{P}(B|A) \\cdot \\mathbb{P}(A)+ \\mathbb{P}(B | A^C)\\cdot \\mathbb{P}(A^C)\n\\end{array}\n%\\right)\\]"
  },
  {
    "objectID": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#general-law-of-total-proability",
    "href": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#general-law-of-total-proability",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "General Law of Total Proability",
    "text": "General Law of Total Proability\n\n\nLaw of Total Probability (general)\n\n\nIf \\(\\{A_i\\}_{i=1}^{n} = \\{A_1, A_2, \\ldots, A_n\\}\\) form a partition of the sample space, then for event \\(B\\),\n\\[%\\left(\n\\begin{array}{ccl}\n\\mathbb{P}(B)&=& \\sum_{i=1}^{n} \\mathbb{P}(B \\cap A_i)\\\\\n           &=& \\sum_{i=1}^{n} \\mathbb{P}(B|A_i) \\cdot \\mathbb{P}(A_i)\n\\end{array}\n%\\right)\\]"
  },
  {
    "objectID": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability",
    "href": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with generalized Law of Total Probability",
    "text": "Calculating probability with generalized Law of Total Probability"
  },
  {
    "objectID": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability-1",
    "href": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability-1",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with generalized Law of Total Probability",
    "text": "Calculating probability with generalized Law of Total Probability\n\n\n\n\nExample 3\n\n\nIndividuals are diagnosed with a particular type of cancer that can take on three different disease forms,* \\(D_1\\), \\(D_2\\), and \\(D_3\\). It is known that amongst people diagnosed with this particular type of cancer,\n\n20% of people will eventually be diagnosed with form \\(D_1\\),\n30% with form \\(D_2\\), and\n50% with form \\(D_3\\).\n\nThe probability of requiring chemotherapy (\\(C\\)) differs among the three forms of disease:\n\n80% with \\(D_1\\),\n30% with \\(D_2\\), and\n10% with \\(D_3\\).\n\nBased solely on the preliminary test of being diagnosed with the cancer, what is the probability of requiring chemotherapy (the event C)?\n\n\n\nSkipping in class! Let me know if you would like me to post solutions to this if you work through it!"
  },
  {
    "objectID": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#lets-revisit-the-color-blind-example",
    "href": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#lets-revisit-the-color-blind-example",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Let’s revisit the color-blind example",
    "text": "Let’s revisit the color-blind example\n\n\n\n\nExample 4\n\n\nRecall the color-blind example (Example 2), where\n\na person is AMAB with probability 0.5,\nAMAB people are color-blind with probability 0.05, and\nall people are color-blind with probability 0.03.\n\nAssuming people are AMAB or AFAB, find the probability that a color-blind person is AMAB."
  },
  {
    "objectID": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#calculate-probability-with-both-rules",
    "href": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#calculate-probability-with-both-rules",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculate probability with both rules",
    "text": "Calculate probability with both rules\n\n\n\n\nExample 5\n\n\nSuppose\n\n1% of people who are AFAB aged 40-50 years have breast cancer,\nan AFAB person with breast cancer has a 90% chance of a positive test from a mammogram, and\nan AFAB person has a 10% chance of a false-positive result from a mammogram.\n\nWhat is the probability that an AFAB person has breast cancer given that they just had a positive test?"
  },
  {
    "objectID": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#bayes-rule",
    "href": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#bayes-rule",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Bayes’ Rule",
    "text": "Bayes’ Rule\n\n\nTheorem: Bayes’ Rule\n\n\nIf \\(\\{A_i\\}_{i=1}^{n}\\) form a partition of the sample space \\(S\\), with \\(\\mathbb{P}(A_i)&gt;0\\) for \\(i=1\\ldots n\\) and \\(\\mathbb{P}(B)&gt;0\\), then\n\\[\\mathbb{P}(A_j | B) =\n\\frac{\\mathbb{P}(B|A_j) \\cdot \\mathbb{P}(A_j)}\n{\\sum_{i=1}^{n} \\mathbb{P}(B|A_i) \\cdot \\mathbb{P}(A_i)}\\]\n\n\n\n\nChapter 5 Slides"
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_Moment_Generating_Functions_Part1.html",
    "href": "lessons/43_01_Moment_Generating_Functions/43_Moment_Generating_Functions_Part1.html",
    "title": "Chapter 43: Moment Generating Functions Part 1",
    "section": "",
    "text": "Chapter 43: Moment Generating Functions Part 1\n\nWhat are moments?\n\n\nDefinition 1.   The \\(j^{th}\\) moment of a r.v. \\(X\\) is \\(\\mathbb{E}[X^j]\\).\n\n\nExample 2.   \\(1^{st}-4^{th}\\) moments.\n\n\n\nWhat is a moment generating function (mgf)?\n\n\nDefinition 3.   If \\(X\\) is a r.v., then \\[M_X(t)= \\mathbb{E}[e^{tX}]\\] is the moment generating function (mgf) associated with \\(X\\).\n\nRemarks\n\nFor a discrete r.v., the mgf of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\sum_{all \\ x}e^{tx}p_X(x)\\]\nFor a continuous r.v., the mgf of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\int_{-\\infty}^{\\infty}e^{tx}f_X(x)dx\\]\nThe mgf \\(M_X(t)\\) is a function of \\(t\\), not of \\(X\\), and it might not be defined (i.e. finite) for all values of \\(t\\). We just need it to be defined for \\(t=0\\).\n\n\nExample 4.   What is \\(M_X(t)\\) for \\(t=0\\)?\n\n\n\nTheorem 5.   The moment generating function uniquely specifies a probability distribution.\n\n\nTheorem 6.   \\[\\mathbb{E}[X^r] = M_X^{(r)}(0)\\]\n\n\nProof. Proof. ◻\n\n\nExample 7.   Let \\(X \\sim Poisson(\\lambda)\\).\n\nFind the mgf of \\(X\\).\nFind \\(\\mathbb{E}[X]\\).\nFind \\(Var(X)\\).\n\n\nRemark\nFinding the mean and variance is sometimes easier with the following trick.\n\nTheorem 8. Let \\[R_X(t) = \\ln[M_X(t)]\\]\nThen,\n\\[\\mu = \\mathbb{E}[X] = R_X'(0)\\] and \\[\\sigma^2 = Var(X) = R_X''(0)\\]\n\n\nProof. Proof. ◻\n\n\n\nExample 9.   Let \\(X \\sim Poisson(\\lambda)\\).\n\nFind \\(\\mathbb{E}[X]\\) using \\(R_X(t)\\).\nFind \\(Var(X)\\) using \\(R_X(t)\\).\n\n\n\nExample 10.   Let \\(Z\\) be a standard normal random variable, i.e. \\(Z \\sim N(0,1)\\).\n\nFind the mgf of \\(Z\\).\nFind \\(\\mathbb{E}[Z]\\).\nFind \\(Var(Z)\\)."
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html",
    "title": "Calculus Review",
    "section": "",
    "text": "Find derivatives of continuous functions with one variable\nFind antiderivatives and integrals of functions with one variable"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#learning-objectives",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#learning-objectives",
    "title": "Calculus Review",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nFind derivatives of continuous functions with one variable\nFind antiderivatives and integrals of functions with one variable"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-derivative-of-the-following-function",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-derivative-of-the-following-function",
    "title": "Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.1\n\n\n\\(f(x) = 2\\)\n\n\n\n\nDerivative of a constant\n\n\n\\[\\dfrac{d}{dx} c = 0\\]"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-derivative-of-the-following-function-1",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-derivative-of-the-following-function-1",
    "title": "Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.2\n\n\n\\(f(x) = 2x\\)"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-derivative-of-the-following-function-2",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-derivative-of-the-following-function-2",
    "title": "Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.3\n\n\n\\(f(x) = 2x+2\\)"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-derivative-of-the-following-function-3",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-derivative-of-the-following-function-3",
    "title": "Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.4\n\n\n\\(f(x) = x^2\\)\n\n\n\n\nDerivative of \\(x\\) to a constant\n\n\n\\[\\dfrac{d}{dx} x^n = nx^{n-1}\\]"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-derivative-of-the-following-function-4",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-derivative-of-the-following-function-4",
    "title": "Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.5\n\n\n\\(f(x) = 3\\sqrt{x}+\\frac2x+5\\)"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-derivative-of-the-following-function-5",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-derivative-of-the-following-function-5",
    "title": "Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.6\n\n\n\\(f(x) = e^x\\)\n\n\n\n\nDerivative of exponential function\n\n\n\\(\\dfrac{d}{dx} e^x = e^x\\)"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-derivative-of-the-following-function-6",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-derivative-of-the-following-function-6",
    "title": "Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.7\n\n\n\\(f(x) = \\ln(x)\\)\n\n\n\n\nDerivative of logarithm\n\n\n\\(\\dfrac{d}{dx} ln(x) = \\dfrac{1}{x}\\)"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-derivative-of-the-following-function-7",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-derivative-of-the-following-function-7",
    "title": "Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.8\n\n\n\\(f(x) = x^2 e^x\\)\n\n\n\n\nProduct Rule\n\n\n\\(\\dfrac{d}{dx} f(x)g(x) = f'(x)g(x) + f(x)g'(x)\\)"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-derivative-of-the-following-function-8",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-derivative-of-the-following-function-8",
    "title": "Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.9\n\n\n\\(f(x) = \\frac{x^5}{2x+7}\\)\n\n\n\n\nQuotient Rule\n\n\n\\(\\dfrac{d}{dx} \\dfrac{f(x)}{g(x)} = \\dfrac{g(x)f'(x) - f(x)g'(x)}{\\big(g(x)\\big)^2}\\)"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-derivative-of-the-following-function-9",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-derivative-of-the-following-function-9",
    "title": "Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.10\n\n\n\\(f(x) = e^{-2x+7}\\)\n\n\n\n\nChain Rule\n\n\n\\(\\dfrac{d}{dx} f\\big(g(x)\\big)= f'\\big(g(x)\\big)g'(x)\\)"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-derivative-of-the-following-function-10",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-derivative-of-the-following-function-10",
    "title": "Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.11\n\n\n\\(f(x) = \\ln(x^2)\\)"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-antiderivative-of-the-following-function",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-antiderivative-of-the-following-function",
    "title": "Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.1\n\n\n\\(f(x) = 2\\)"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-antiderivative-of-the-following-function-1",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-antiderivative-of-the-following-function-1",
    "title": "Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.2\n\n\n\\(f(x) = x\\)\n\n\n\n\nIntegration of x to a constant\n\n\n\\(\\displaystyle\\int x^n dx = \\dfrac{x^{n+1}}{n+1} + c\\)"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-antiderivative-of-the-following-function-2",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-antiderivative-of-the-following-function-2",
    "title": "Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.3\n\n\n\\(f(x) = \\frac1x\\)"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-antiderivative-of-the-following-function-3",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-antiderivative-of-the-following-function-3",
    "title": "Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.4\n\n\n\\(f(x) = x^{3/2}\\)"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-antiderivative-of-the-following-function-4",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-antiderivative-of-the-following-function-4",
    "title": "Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.5\n\n\n\\(f(x) = e^x\\)"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-antiderivative-of-the-following-function-5",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-antiderivative-of-the-following-function-5",
    "title": "Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.6\n\n\n\\(f(x) = e^{-x}\\)"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-antiderivative-of-the-following-function-6",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#find-the-antiderivative-of-the-following-function-6",
    "title": "Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.7\n\n\n\\(f(x) = e^{-2x}\\)"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#solve-the-following-integral",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#solve-the-following-integral",
    "title": "Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.1\n\n\n\\(\\displaystyle\\int_0^1 (2x+x^5)dx\\)"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#solve-the-following-integral-1",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#solve-the-following-integral-1",
    "title": "Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.2\n\n\n\\(\\displaystyle\\int_2^3 e^{-x}dx\\)\n\n\n\n\nU-substitution\n\n\n\\(\\displaystyle\\int f\\big(g(x)\\big) g'(x) dx = \\displaystyle\\int f(u) dx\\)"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#solve-the-following-integral-2",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#solve-the-following-integral-2",
    "title": "Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.3\n\n\n\\(\\displaystyle\\int_2^3 x e^{x^2}dx\\)"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#solve-the-following-integral-3",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#solve-the-following-integral-3",
    "title": "Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.4\n\n\n\\(\\displaystyle\\int_0^{\\infty} x e^{-x}dx\\)\n\n\n\n\nIntegrating by Parts\n\n\n\\(\\displaystyle\\int f(x) g'(x) dx = f(x)g(x) - \\\\ \\displaystyle\\int f'(x) g(x) dx\\)\nOR\n\\(\\displaystyle\\int_a^b u dv = uv\\bigg|^b_a - \\displaystyle\\int_a^b vdu\\)"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#solve-the-following-integral-4",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#solve-the-following-integral-4",
    "title": "Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.5\n\n\n\\(\\displaystyle\\int_1^2 x^2 \\ln(x)dx\\)"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#solve-the-following-integral-5",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#solve-the-following-integral-5",
    "title": "Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.6\n\n\n\\(\\displaystyle\\int_1^2 \\ln(x)dx\\)"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#solve-the-following-integral-6",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#solve-the-following-integral-6",
    "title": "Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.7\n\n\n\\(\\displaystyle\\int_1^2 x^2 e^{x}dx\\)\n\n\n\n\n\n\nChapter 24 Slides"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html",
    "href": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html",
    "title": "Chapter 14, 15, 16, 19, 20: Some Important Discrete RVs",
    "section": "",
    "text": "Distinguish between Bernoulli, Binomial, Geometric, Hypergeometric, and Discrete Uniform distributions when reading a story.\nIdentify the variable and the parameters in a story, and state what the variable and parameters mean.\nUse the formulas for the pmf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#learning-objectives",
    "href": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#learning-objectives",
    "title": "Chapter 14, 15, 16, 19, 20: Some Important Discrete RVs",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDistinguish between Bernoulli, Binomial, Geometric, Hypergeometric, and Discrete Uniform distributions when reading a story.\nIdentify the variable and the parameters in a story, and state what the variable and parameters mean.\nUse the formulas for the pmf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#properties-of-bernoulli-rvs",
    "href": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#properties-of-bernoulli-rvs",
    "title": "Chapter 14, 15, 16, 19, 20: Some Important Discrete RVs",
    "section": "Properties of Bernoulli RVs",
    "text": "Properties of Bernoulli RVs\n\nScenario: One trial, with outcome success or failure\nShorthand: \\(X \\sim \\text{Bernoulli}(p)\\)\n\n\\[\nX = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\quad \\\\\n            0 & \\quad \\mathrm{with\\ probability}\\ 1-p \\quad\n        \\end{array}\n    \\right.\n\\]\n\\[\np_X(x) = P(X=x) = p^x(1-p)^{1-x} \\text{ for } x=0,1\n\\]\n\\[\\text{E}(X) = p\\]\n\\[\\text{Var}(X) = pq = p(1-p)\\]"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#bernoulli-example-1",
    "href": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#bernoulli-example-1",
    "title": "Chapter 14, 15, 16, 19, 20: Some Important Discrete RVs",
    "section": "Bernoulli Example 1",
    "text": "Bernoulli Example 1\n\n\n\n\nExample 1\n\n\n\nWe roll a fair 6-sided die.\nWe get $1 if we roll a 5, and nothing otherwise.\nLet \\(X\\) be how much money we get.\nFind the mean and variance of \\(X\\)."
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#properties-of-binomial-rvs",
    "href": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#properties-of-binomial-rvs",
    "title": "Chapter 14, 15, 16, 19, 20: Some Important Discrete RVs",
    "section": "Properties of Binomial RVs",
    "text": "Properties of Binomial RVs\n\nScenario: There are \\(n\\) independent trials, each resulting in a success or failure, with constant probability, \\(p\\), in each trial. We are counting the number of successes (or failures).\nShorthand: \\(X \\sim \\text{Binomial}(n, p)\\)\n\n\\[\nX = \\text{Number of successes of } n \\text{ independent trials}\n\\]\n\\[\np_X(x) = P(X=x) = {n \\choose x}p^x(1-p)^{n-x} \\text{ for } x=0,1,2,  ..., n\n\\]\n\\[\\text{E}(X) = np\\] \\[\\text{Var}(X) = npq = np(1-p)\\]"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#bernoulli-to-binomial",
    "href": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#bernoulli-to-binomial",
    "title": "Chapter 14, 15, 16, 19, 20: Some Important Discrete RVs",
    "section": "Bernoulli to Binomial",
    "text": "Bernoulli to Binomial\n\n\n\n\nExample 2\n\n\n\nSuppose we roll a fair 6-sided die 50 times.\nWe get $1 every time we roll a 5, and nothing otherwise.\nLet \\(X\\) be how much money we get on the 50 rolls.\nFind the mean and variance of \\(X\\)."
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#geometric-rvs",
    "href": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#geometric-rvs",
    "title": "Chapter 14, 15, 16, 19, 20: Some Important Discrete RVs",
    "section": "Geometric RVs",
    "text": "Geometric RVs\n\nScenario: There are repeated independent trials, each resulting in a success or failure, with constant probability of success for each trial. We are counting the number of trials until the first success.\nShorthand: \\(X \\sim \\text{Geo}(p)\\) or \\(X \\sim \\text{Geometric}(p)\\) or \\(X \\sim \\text{G}(p)\\)\n\n\n\n\n\n\n\n\n\\(X =\\) Number of trials needed for first success (count \\(x\\) includes the success)\n\\(X =\\) Number of failures before first success (count \\(x\\) does not include the success)\n\n\n\n\n\\(p _ X  ( x ) = P(X=x) = (1-p)^{x-1}p\\)\nfor \\(x=1,2, 3,...\\)\n\\(F_ X ( x ) = P(X\\leq x) = 1-(1-p)^x\\)\nfor \\(x=1,2, 3,...\\)\n\\(p _X (x)= P(X=x) = (1-p)^{x}p\\)\nfor \\(x=0, 1,2,...\\)\n\\(F_X ( x ) = P(X\\leq x) = 1-(1-p)^{x+1}\\)\nfor \\(x=0, 1,2,...\\)\n\n\n\\(E(X)=\\dfrac{1-p}{p}\\)\n\\(Var(X)= \\dfrac{1-p}{p^2}\\)\n\\(E(X)=\\dfrac{1-p}{p}\\)\n\\(Var(X) = \\dfrac{1-p}{p^2}\\)"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#bullseye-16",
    "href": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#bullseye-16",
    "title": "Chapter 14, 15, 16, 19, 20: Some Important Discrete RVs",
    "section": "Bullseye (1/6)",
    "text": "Bullseye (1/6)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the pmf for the number of throws needed to hit the bullseye?\nWhat are the mean and variance for the number of throws needed to hit the bullseye?\nFind the probability that our first bullseye:\n\nis on the fourth try\nis on one of the first four tries\nis after the fifth try\nis on one of the first fifty tries\nis after the \\(50^{th}\\) try, given that it did not happen on the first 20 tries\n\nFind the expected number of misses until we hit the bullseye."
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#bullseye-26",
    "href": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#bullseye-26",
    "title": "Chapter 14, 15, 16, 19, 20: Some Important Discrete RVs",
    "section": "Bullseye (2/6)",
    "text": "Bullseye (2/6)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the pmf for the number of throws needed to hit the bullseye?"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#bullseye-36",
    "href": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#bullseye-36",
    "title": "Chapter 14, 15, 16, 19, 20: Some Important Discrete RVs",
    "section": "Bullseye (3/6)",
    "text": "Bullseye (3/6)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat are the mean and variance for the number of throws needed to hit the bullseye?"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#bullseye-46",
    "href": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#bullseye-46",
    "title": "Chapter 14, 15, 16, 19, 20: Some Important Discrete RVs",
    "section": "Bullseye (4/6)",
    "text": "Bullseye (4/6)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nFind the probability that our first bullseye:\n\nis on the fourth try\nis on one of the first four tries\nis after the fourth try"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#bullseye-56",
    "href": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#bullseye-56",
    "title": "Chapter 14, 15, 16, 19, 20: Some Important Discrete RVs",
    "section": "Bullseye (5/6)",
    "text": "Bullseye (5/6)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nFind the probability that our first bullseye:\n\nis on one of the first fifty tries\nis after the \\(50^{th}\\) try, given that it did not happen on the first 20 tries"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#memoryless-property-for-geometric-rvs",
    "href": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#memoryless-property-for-geometric-rvs",
    "title": "Chapter 14, 15, 16, 19, 20: Some Important Discrete RVs",
    "section": "Memoryless property for Geometric RVs",
    "text": "Memoryless property for Geometric RVs\nIf we know \\(X\\) is greater than some number (aka given \\(X &gt;j\\)), then the probability of \\(X &gt; k+j\\) is just the probability that \\(X&gt;k\\).\n \n\\(P(X &gt; k+j |X &gt; j) = P(X &gt; k)\\) \\[ P(X &gt; k+j |X &gt; j) = \\dfrac{P(X&gt;k+j \\text{ and } X&gt;j)}{P(X&gt;j)} = \\dfrac{P(X&gt;k+j)}{P(X&gt;j)} = \\dfrac{(1-p)^{k+j}}{(1-p)^{j}} = (1-p)^{k} \\]"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#hypergeometric-rvs",
    "href": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#hypergeometric-rvs",
    "title": "Chapter 14, 15, 16, 19, 20: Some Important Discrete RVs",
    "section": "Hypergeometric RVs",
    "text": "Hypergeometric RVs\n\nScenario: There are a fixed number of successes and failures (which are known in advance), from which we make \\(n\\) draws without replacement. We are counting the number of successes from the \\(n\\) trials.\n\nThere is a finite population of \\(N\\) items\nEach item in the population is either a success or a failure, and there are \\(M\\) successes total.\nWe randomly select (sample) \\(n\\) items from the population.\n\nShorthand: \\(X \\sim \\text{Hypergeo}(M, N, n)\\)\n\n\n\n\\[\nX = \\text{Number of successes in } n \\text{ draws}\n\\]\n\\[\np_X(x) = P(X=x) = \\dfrac{{M \\choose x}{N-M \\choose n-x}}{{N \\choose n}}\n\\] \\[\\text{ for } x \\text{ integer-valued } \\\\ \\max(0, n-(N-M)) \\leq x \\leq \\min(n, M)\\]\n\n\\[\\text{E}(X) =\\dfrac{nM}{N}\\]\n\\[\\text{Var}(X) = n \\dfrac{M}{N} \\bigg(1- \\dfrac{M}{N} \\bigg)\\bigg(\\dfrac{N-n}{N-1} \\bigg)\\]"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#wolf-population",
    "href": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#wolf-population",
    "title": "Chapter 14, 15, 16, 19, 20: Some Important Discrete RVs",
    "section": "Wolf population",
    "text": "Wolf population\n\n\n\n\nExample 4\n\n\nA wildlife biologist is using mark-recapture to research a wolf population. Suppose a specific study region is known to have 24 wolves, of which 11 have already been tagged. If 5 wolves are randomly captured, what is the probability that 3 of them have already been tagged?"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#hypergeometric-vs.-binomial-rvs",
    "href": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#hypergeometric-vs.-binomial-rvs",
    "title": "Chapter 14, 15, 16, 19, 20: Some Important Discrete RVs",
    "section": "Hypergeometric vs. Binomial RVs",
    "text": "Hypergeometric vs. Binomial RVs\nSuppose a hypergeometric RV \\(X\\) has the following properties:\n\nthe population size \\(N\\) is really big,\nthe number of successes \\(M\\) in the population is relatively large,\n\n\\(\\frac{M}{N}\\) shouldn’t be close to 0 or 1\n\nand the number of items \\(n\\) selected is small.\n\nThen, in this case, making \\(n\\) draws from the population doesn’t change the probability of success much, and the hypergeometric r.v. can be approximated by a binomial r.v."
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#wolf-population-revisited",
    "href": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#wolf-population-revisited",
    "title": "Chapter 14, 15, 16, 19, 20: Some Important Discrete RVs",
    "section": "Wolf population revisited",
    "text": "Wolf population revisited\n\n\n\n\nExample 5\n\n\nSuppose a specific study region is known to have 2400 wolves, of which 1100 have already been tagged.\n\nIf 50 wolves are randomly captured, what is the probability that 20 of them have already been tagged?\nApproximate the probability in part (1) using the binomial distribution."
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#discrete-uniform-rvs",
    "href": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#discrete-uniform-rvs",
    "title": "Chapter 14, 15, 16, 19, 20: Some Important Discrete RVs",
    "section": "Discrete Uniform RVs",
    "text": "Discrete Uniform RVs\n\nScenario: There are \\(N\\) possible outcomes, which are all equally likely.\nShorthand: \\(X \\sim \\text{Uniform}(N)\\)\n\n\\[\nX = \\text{Outcome of interest, with } x=1, 2, ..., N\n\\]\n\\[\np_X(x) = P(X=x) = \\dfrac{1}{N} \\text{ for } x=1, 2, 3, ..., N\n\\]\n\\[\\text{E}(X) =\\dfrac{N+1}{2}\\]\n\\[\\text{Var}(X) = \\dfrac{N^2 -1}{12}\\]"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#what-discrete-uniform-rvs-have-we-seen-already",
    "href": "lessons/14_20_Discrete_RVs/14_18_Discrete_RVs.html#what-discrete-uniform-rvs-have-we-seen-already",
    "title": "Chapter 14, 15, 16, 19, 20: Some Important Discrete RVs",
    "section": "What discrete uniform RVs have we seen already?",
    "text": "What discrete uniform RVs have we seen already?\n\n\n\n\nExample 6\n\n\nExamples of discrete uniform RVs\n\n\n\n\n\n\nChapter 14-20 Slides"
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "",
    "text": "Distinguish between discrete and continuous random variables.\nCalculate probabilities for continuous random variables.\nCalculate and graph a density (i.e., probability density function, PDF).\nCalculate and graph a CDF (i.e., a cumulative distribution function)"
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#learning-objectives",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#learning-objectives",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDistinguish between discrete and continuous random variables.\nCalculate probabilities for continuous random variables.\nCalculate and graph a density (i.e., probability density function, PDF).\nCalculate and graph a CDF (i.e., a cumulative distribution function)"
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#discrete-vs.-continuous-rvs",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#discrete-vs.-continuous-rvs",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Discrete vs. Continuous RVs",
    "text": "Discrete vs. Continuous RVs\n\n\n\nFor a discrete RV, the set of possible values is either finite or can be put into a countably infinite list.\n \nContinuous RVs take on values from continuous intervals, or unions of continuous intervals\n\n\n\n\n\nFigure from Introduction to Probability TB (pg. 301)"
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#how-to-define-probabilities-for-continuous-rvs",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#how-to-define-probabilities-for-continuous-rvs",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "How to define probabilities for continuous RVs?",
    "text": "How to define probabilities for continuous RVs?\n\n\nDiscrete RV \\(X\\):\n\n\n\n\n\n\n\n\n\n\npmf: \\(p_X(x) = P(X=x)\\)\n\n\nContinuous RV \\(X\\):\n\n\n\n\n\n\n\n\n\n\ndensity: \\(f_X(x)\\)\nprobability: \\(P(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\)"
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#what-is-a-probability-density-function",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#what-is-a-probability-density-function",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "What is a probability density function?",
    "text": "What is a probability density function?\n\n\nProbability density function\n\n\nThe probability distribution, or probability density function (pdf), of a continuous random variable \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\),\n\\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\]\n\n\nRemarks:\n\nNote that \\(f_X(x) \\neq \\mathbb{P}(X=x)\\)!!!\nIn order for \\(f_X(x)\\) to be a pdf, it needs to satisfy the properties\n\n\\(f_X(x) \\geq 0\\) for all \\(x\\)\n\\(\\int_{-\\infty}^{\\infty} f_X(x)dx=1\\)"
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-15",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-15",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (1/5)",
    "text": "Let’s demonstrate the PDF with an example (1/5)\n\n\n\n\nExample 1.1\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind the value of \\(a\\) so that \\(f_X(x)\\) is a pdf."
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-25",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-25",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (2/5)",
    "text": "Let’s demonstrate the PDF with an example (2/5)\n\n\n\n\nExample 1.2\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(2.7 \\leq X \\leq 2.9)\\)."
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-35",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-35",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (3/5)",
    "text": "Let’s demonstrate the PDF with an example (3/5)\n\n\n\n\nExample 1.3\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(2.7 &lt; X \\leq 2.9)\\)."
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-45",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-45",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (4/5)",
    "text": "Let’s demonstrate the PDF with an example (4/5)\n\n\n\n\nExample 1.4\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(X = 2.9)\\)."
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-55",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-55",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (5/5)",
    "text": "Let’s demonstrate the PDF with an example (5/5)\n\n\n\n\nExample 1.5\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(X \\leq 2.8)\\)."
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#what-is-a-cumulative-distribution-function",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#what-is-a-cumulative-distribution-function",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "What is a cumulative distribution function?",
    "text": "What is a cumulative distribution function?\n\n\nCumulative distribution function\n\n\nThe cumulative distribution function (cdf) of a continuous random variable \\(X\\), is the function \\(F_X(x)\\), such that for all real values of \\(x\\), \\[F_X(x)= \\mathbb{P}(X \\leq x) = \\int_{-\\infty}^x f_X(s)ds\\]\n\n\nRemarks: In general, \\(F_X(x)\\) is increasing and\n\n\\(\\lim_{x\\rightarrow -\\infty} F_X(x)= 0\\)\n\\(\\lim_{x\\rightarrow \\infty} F_X(x)= 1\\)\n\\(P(X &gt; a) = 1 - P(X \\leq a) = 1 - F_X(a)\\)\n\\(P(a \\leq X \\leq b) = F_X(b) - F_X(a)\\)"
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-cdf-with-an-example",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-cdf-with-an-example",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the CDF with an example",
    "text": "Let’s demonstrate the CDF with an example\n\n\n\n\nExample 2\n\n\nLet \\(f_X(x)= 2\\), for \\(2.5 \\leq x \\leq 3\\). Find \\(F_X(x)\\)."
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#derivatives-of-the-cdf",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#derivatives-of-the-cdf",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Derivatives of the CDF",
    "text": "Derivatives of the CDF\n\n\nTheorem 1\n\n\nIf \\(X\\) is a continuous random variable with pdf \\(f_X(x)\\) and cdf \\(F_X(x)\\), then for all real values of \\(x\\) at which \\(F'_X(x)\\) exists, \\[\\frac{d}{dx} F_X(x)= F'_X(x) = f_X(x)\\]"
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#finding-the-pdf-from-a-cdf",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#finding-the-pdf-from-a-cdf",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Finding the PDF from a CDF",
    "text": "Finding the PDF from a CDF\n\n\n\n\nExample 3\n\n\nLet \\(X\\) be a RV with cdf \\[F_X(x)= \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x &lt; 2.5 \\\\\n            2x-5 & \\quad 2.5 \\leq x \\leq 3 \\\\\n            1 & \\quad x &gt; 3\n        \\end{array}\n    \\right.\\] Find the pdf \\(f_X(x)\\)."
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-17",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-17",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (1/7)",
    "text": "Let’s go through another example (1/7)\n\n\n\n\nExample 4\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nShow \\(f_X(x)\\) is a pdf.\nFind \\(\\mathbb{P}(1 \\leq X \\leq 3)\\).\nFind \\(F_X(x)\\).\nGiven \\(F_X(x)\\), find \\(f_X(x)\\).\nFind \\(\\mathbb{P}(X \\geq 1 | X \\leq 3)\\).\nFind the median of the distribution of \\(X\\)."
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-27",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-27",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (2/7)",
    "text": "Let’s go through another example (2/7)\n\n\n\n\nExample 4.1\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nShow \\(f_X(x)\\) is a pdf."
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-37",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-37",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (3/7)",
    "text": "Let’s go through another example (3/7)\n\n\n\nDo this problem at home for extra practice.\n\n\n\n\n\n\n\nExample 4.2\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nFind \\(\\mathbb{P}(1 \\leq X \\leq 3)\\)."
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-47",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-47",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (4/7)",
    "text": "Let’s go through another example (4/7)\n\n\n\n\nExample 4.3\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nFind \\(F_X(x)\\)."
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-57",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-57",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (5/7)",
    "text": "Let’s go through another example (5/7)\n\n\n\nDo this problem at home for extra practice.\n\n\n\n\n\n\n\nExample 4.4\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nGiven \\(F_X(x)\\), find \\(f_X(x)\\)."
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-67",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-67",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (6/7)",
    "text": "Let’s go through another example (6/7)\n\n\n\n\nExample 4.5\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nFind \\(\\mathbb{P}(X \\geq 1 | X \\leq 3)\\)."
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-77",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-77",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (7/7)",
    "text": "Let’s go through another example (7/7)\n\n\n\n\nExample 4.6\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nFind the median of the distribution of \\(X\\).\n\n\n\n\n\n\n\nChapter 24 Slides"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability.html",
    "href": "lessons/02_Probability/02_Probability.html",
    "title": "Chapter 2: Introduction to Probability",
    "section": "",
    "text": "Define basic axioms and propositions in probability\nAssign probabilities to events, and perform manipulations on probabilities to make calculations easier"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability.html#learning-objectives",
    "href": "lessons/02_Probability/02_Probability.html#learning-objectives",
    "title": "Chapter 2: Introduction to Probability",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDefine basic axioms and propositions in probability\nAssign probabilities to events, and perform manipulations on probabilities to make calculations easier"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability.html#probabilities-of-equally-likely-events-1",
    "href": "lessons/02_Probability/02_Probability.html#probabilities-of-equally-likely-events-1",
    "title": "Chapter 2: Introduction to Probability",
    "section": "Probabilities of equally likely events",
    "text": "Probabilities of equally likely events\n\n“Equally likely” means the probability of any possible outcome is the same\n\nThink: each side of die is equally likely or picking a card in a deck is equally likely"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability.html#pick-an-equally-likely-card-any-equally-likely-card",
    "href": "lessons/02_Probability/02_Probability.html#pick-an-equally-likely-card-any-equally-likely-card",
    "title": "Chapter 2: Introduction to Probability",
    "section": "Pick an equally likely card, any equally likely card",
    "text": "Pick an equally likely card, any equally likely card\n\n\nExample 1\n\n\nSuppose you have a regular well-shuffled deck of cards. What’s the probability of drawing:\n\nany heart\nthe queen of hearts\nany queen"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability.html#lets-break-down-this-probability",
    "href": "lessons/02_Probability/02_Probability.html#lets-break-down-this-probability",
    "title": "Chapter 2: Introduction to Probability",
    "section": "Let’s break down this probability",
    "text": "Let’s break down this probability\nIf \\(S\\) is a finite sample space, with equally likely outcomes, then\n\\[\\mathbb{P}(A) = \\frac{|A|}{|S|}\\]\nIn human speak:\n\nFor equally likely outcomes, the probability that a certain event occurs is: the number of outcomes within the event of interest (\\(|A|\\)) divided by the total number of possible outcomes (\\(|S|\\))\n\n\\[\\mathbb{P}(A) = \\frac{\\text{total number of outcomes in event A}}{\\text{total number of outcomes in sample space}}\\]\n\nThus, it is important to be able to count the outcomes within an event"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability.html#a-probability-is-a-function",
    "href": "lessons/02_Probability/02_Probability.html#a-probability-is-a-function",
    "title": "Chapter 2: Introduction to Probability",
    "section": "A probability is a function…",
    "text": "A probability is a function…\n\n\\(\\mathbb{P}(A)\\) is a function with\n\nInput: event \\(A\\) from the sample space \\(S\\), (\\(A \\subseteq S\\))\n\n\\(A \\subseteq S\\) means “A contained within S” or “A is a subset of S”\n\nOutput: a number between 0 and 1 (inclusive)\n\n\n \n\nThe probability function maps an event (input) to value between 0 and 1 (output)\n\nWhen we speak of the probability function, we often call the values between 0 and 1 “probabilities”\n\nExample: “The probability of drawing a heart is 0.25” for \\(P(\\text{heart}) = 0.25\\)\n\n\n\n \n\nThe probability function needs to follow some specific rules!\n\n \nSee Probability Axioms on next slide."
  },
  {
    "objectID": "lessons/02_Probability/02_Probability.html#probability-axioms-1",
    "href": "lessons/02_Probability/02_Probability.html#probability-axioms-1",
    "title": "Chapter 2: Introduction to Probability",
    "section": "Probability Axioms",
    "text": "Probability Axioms\n\n\n\n\nAxiom 1\n\n\nFor every event \\(A\\), \\(0\\leq\\mathbb{P}(A)\\leq 1\\). Probability is between 0 and 1.\n\n\n\n\nAxiom 2\n\n\nFor the sample space \\(S\\), \\(\\mathbb{P}(S)=1\\).\n\n\n\n\nAxiom 3\n\n\nIf \\(A_1, A_2, A_3, \\ldots\\), is a collection of disjoint events, then \\[\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i).\\] The probability of at least one \\(A_i\\) is the sum of the individual probabilities of each."
  },
  {
    "objectID": "lessons/02_Probability/02_Probability.html#some-probability-properties-1",
    "href": "lessons/02_Probability/02_Probability.html#some-probability-properties-1",
    "title": "Chapter 2: Introduction to Probability",
    "section": "Some probability properties",
    "text": "Some probability properties\nUsing the Axioms, we can prove all other probability properties! Events A, B, and C are not necessarily disjoint!\n\n\n\n\nProposition 1\n\n\nFor any event \\(A\\), \\(\\mathbb{P}(A)= 1 - \\mathbb{P}(A^C)\\)\n\n\n\n\nProposition 2\n\n\n\\(\\mathbb{P}(\\emptyset)=0\\)\n\n\n\n\nProposition 3\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\n\n\n\n\n\nProposition 4\n\n\n\\[\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\] where \\(A\\) and \\(B\\) are not necessarily disjoint\n\n\n\n\nProposition 5\n\n\n\\(\\begin{aligned} \\mathbb{P}(A \\cup B & \\cup C) = \\mathbb{P}(A) + \\mathbb{P}(B) + \\\\ & \\mathbb{P}(C) - \\mathbb{P}(A \\cap B) - \\mathbb{P}(A \\cap C) - \\\\ & \\mathbb{P}(B \\cap C) + \\mathbb{P}(A \\cap B \\cap C) \\end{aligned}\\)"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability.html#proposition-1-proof",
    "href": "lessons/02_Probability/02_Probability.html#proposition-1-proof",
    "title": "Chapter 2: Introduction to Probability",
    "section": "Proposition 1 Proof",
    "text": "Proposition 1 Proof\n\n\n\n\nProposition 1\n\n\nFor any event \\(A\\), \\(\\mathbb{P}(A)= 1 - \\mathbb{P}(A^C)\\)\n\n\n\n\n\nUse Axioms!\n\n\nA1: \\(0\\leq\\mathbb{P}(A)\\leq 1\\)\nA2: \\(\\mathbb{P}(S)=1\\)\nA3: For disjoint \\(A_i\\),\n\\(\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i)\\)"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability.html#proposition-2-proof",
    "href": "lessons/02_Probability/02_Probability.html#proposition-2-proof",
    "title": "Chapter 2: Introduction to Probability",
    "section": "Proposition 2 Proof",
    "text": "Proposition 2 Proof\n\n\n\n\nProposition 2\n\n\n\\(\\mathbb{P}(\\emptyset)=0\\)\n\n\n\n\n\nUse Axioms!\n\n\nA1: \\(0\\leq\\mathbb{P}(A)\\leq 1\\)\nA2: \\(\\mathbb{P}(S)=1\\)\nA3: For disjoint \\(A_i\\),\n\\(\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i)\\)"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability.html#proposition-3-proof",
    "href": "lessons/02_Probability/02_Probability.html#proposition-3-proof",
    "title": "Chapter 2: Introduction to Probability",
    "section": "Proposition 3 Proof",
    "text": "Proposition 3 Proof\n\n\n\n\nProposition 3\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\n\n\n\n\n\nUse Axioms!\n\n\nA1: \\(0\\leq\\mathbb{P}(A)\\leq 1\\)\nA2: \\(\\mathbb{P}(S)=1\\)\nA3: For disjoint \\(A_i\\),\n\\(\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i)\\)"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability.html#proposition-4-visual-proof",
    "href": "lessons/02_Probability/02_Probability.html#proposition-4-visual-proof",
    "title": "Chapter 2: Introduction to Probability",
    "section": "Proposition 4 Visual Proof",
    "text": "Proposition 4 Visual Proof\n\n\nProposition 4\n\n\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability.html#proposition-5-visual-proof",
    "href": "lessons/02_Probability/02_Probability.html#proposition-5-visual-proof",
    "title": "Chapter 2: Introduction to Probability",
    "section": "Proposition 5 Visual Proof",
    "text": "Proposition 5 Visual Proof\n\n\nProposition 5\n\n\n\\(\\mathbb{P}(A \\cup B \\cup C) = \\mathbb{P}(A) + \\mathbb{P}(B) + \\mathbb{P}(C) - \\mathbb{P}(A \\cap B) - \\mathbb{P}(A \\cap C) - \\mathbb{P}(B \\cap C) + \\mathbb{P}(A \\cap B \\cap C)\\)"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability.html#partitions-1",
    "href": "lessons/02_Probability/02_Probability.html#partitions-1",
    "title": "Chapter 2: Introduction to Probability",
    "section": "Partitions",
    "text": "Partitions\n\n\n\n\nDefinition: Partition\n\n\nA set of events \\(\\{A_i\\}_{i=1}^{n}\\) create a partition of \\(A\\), if\n\nthe \\(A_i\\)’s are disjoint (mutually exclusive) and\n\\(\\bigcup \\limits_{i=1}^n A_i = A\\)\n\n\n\n\n\nExample 2\n\n\n\nIf \\(A \\subset B\\), then \\(\\{A, B \\cap A^C\\}\\) is a partition of \\(B\\).\nIf \\(S = \\bigcup \\limits_{i=1}^n A_i\\), and the \\(A_i\\)’s are disjoint, then the \\(A_i\\)’s are a partition of the sample space.\n\n\n\n\n\n\nCreating partitions is sometimes used to help calculate probabilities, since by Axiom 3 we can add the probabilities of disjoint events."
  },
  {
    "objectID": "lessons/02_Probability/02_Probability.html#weekly-medications",
    "href": "lessons/02_Probability/02_Probability.html#weekly-medications",
    "title": "Chapter 2: Introduction to Probability",
    "section": "Weekly medications",
    "text": "Weekly medications\n\n\n\n\nExample 3\n\n\nIf a subject has an\n\n80% chance of taking their medication this week,\n70% chance of taking their medication next week, and\n10% chance of not taking their medication either week,\n\nthen find the probability of them taking their medication exactly one of the two weeks.\n\n\n\nHint: Draw a Venn diagram labelling each of the parts to find the probability."
  },
  {
    "objectID": "lessons/33_Gamma_rv/33_Gamma_rv.html",
    "href": "lessons/33_Gamma_rv/33_Gamma_rv.html",
    "title": "Chapter 33: Gamma Random Variables",
    "section": "",
    "text": "Identify the variable and the parameters in a story, and state in English what the variable and its parameters mean.\n\n\ncode.sourceCode {\n  font-size: 1.5em;\n  /* or try font-size: xx-large; */\n}"
  },
  {
    "objectID": "lessons/33_Gamma_rv/33_Gamma_rv.html#learning-objectives",
    "href": "lessons/33_Gamma_rv/33_Gamma_rv.html#learning-objectives",
    "title": "Chapter 33: Gamma Random Variables",
    "section": "",
    "text": "Identify the variable and the parameters in a story, and state in English what the variable and its parameters mean.\n\n\ncode.sourceCode {\n  font-size: 1.5em;\n  /* or try font-size: xx-large; */\n}"
  },
  {
    "objectID": "lessons/33_Gamma_rv/33_Gamma_rv.html#properties-of-gamma-rvs",
    "href": "lessons/33_Gamma_rv/33_Gamma_rv.html#properties-of-gamma-rvs",
    "title": "Chapter 33: Gamma Random Variables",
    "section": "Properties of gamma RVs",
    "text": "Properties of gamma RVs\n\nScenario: Modeling the time until the \\(r^{th}\\) event.\nContinuous analog to the Negative Binomial distribution\nShorthand: \\(X \\sim \\text{Gamma}(r, \\lambda)\\)\n\n\\[\nf_X(x) = \\dfrac{\\lambda^r}{\\Gamma(r)}x^{r-1} e^{-\\lambda x}\\text{ for } x&gt;0, \\lambda&gt;0, \\Gamma(r) = (r-1)!\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;0 \\quad \\\\\n            1 - e^{-\\lambda x}\\displaystyle\\sum_{j=0}^{r-1}\\dfrac{(\\lambda x)^j}{j!}  & \\quad x\\geq0 \\\\\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{r}{\\lambda}\\text{, }\\text{ Var}(X) = \\dfrac{r}{\\lambda^2}\\]\nCommon to see \\(\\alpha = r\\) and \\(\\beta = \\lambda\\)"
  },
  {
    "objectID": "lessons/33_Gamma_rv/33_Gamma_rv.html#identifying-gamma-rv-from-word-problems",
    "href": "lessons/33_Gamma_rv/33_Gamma_rv.html#identifying-gamma-rv-from-word-problems",
    "title": "Chapter 33: Gamma Random Variables",
    "section": "Identifying gamma RV from word problems",
    "text": "Identifying gamma RV from word problems\n\nGamma distribution with \\(r=1\\) is same as exponential\n\nJust like Negative Binomial with \\(r=1\\) is same as the geometric distribution\n\nSimilar to exponential\n\nLook for time between or until events/successes\n\nBUT now we are measuring time until more than 1 success\n\nLook for a rate of the events over time period"
  },
  {
    "objectID": "lessons/33_Gamma_rv/33_Gamma_rv.html#helpful-r-code",
    "href": "lessons/33_Gamma_rv/33_Gamma_rv.html#helpful-r-code",
    "title": "Chapter 33: Gamma Random Variables",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re sitting at the bus stop, measuring the time until 4 buses arrive. We know the bus comes every 10 minutes on average.\n\nIf we want to know the probability that the 4 buses arrive in the next 50 minutes:\n\npgamma(q = 50, rate = 1/10, shape = 4)\n\n[1] 0.7349741\n\npgamma(q = 50, scale = 10, shape = 4)\n\n[1] 0.7349741\n\n\nIf we want to know the time, say \\(t\\), where the probability of the 4 buses arriving at \\(t\\) or earlier is 0.35:\n\nqgamma(p = 0.35, rate = 1/10, shape = 4)\n\n[1] 29.87645\n\n\nIf we want to know the probability that the 4 buses arrives between 30 and 50 minutes:\n\npgamma(q = 50, scale = 10, shape = 4) - pgamma(q = 30, scale = 10, shape = 4)\n\n[1] 0.382206\n\n\nIf we want to sample 20 arrival times for the 4 buses:\n\nrgamma(n = 20, scale = 10, shape = 4)\n\n [1] 65.82893 51.24661 30.37140 11.98719 16.44844 23.40988 36.99517 62.94100\n [9] 22.53064 32.98528 12.91307 11.69527 18.97205 20.61454 54.13300 44.59991\n[17] 27.24499 28.42798 75.36846 80.59334"
  },
  {
    "objectID": "lessons/33_Gamma_rv/33_Gamma_rv.html#remarks",
    "href": "lessons/33_Gamma_rv/33_Gamma_rv.html#remarks",
    "title": "Chapter 33: Gamma Random Variables",
    "section": "Remarks",
    "text": "Remarks\n\nThe parameter \\(r\\) in a Gamma(\\(r\\),\\(\\lambda\\)) distribution does NOT need to be a positive integer\n\n\\(r\\) is usually a positive integer\n\nWhen \\(r\\) is a positive integer, the distribution is sometimes called an Erlang(\\(r\\),\\(\\lambda\\)) distribution\n \n \nWhen \\(r\\) is any positive real number, we have a general gamma distribution that is usually instead parameterized by \\(\\alpha&gt;0\\) and \\(\\beta&gt;0\\), where:\n\n\\(\\alpha = \\text{shape parameter}\\) : same as \\(k\\), the total number of events we must witness\n\nIn R code example: 4 buses to wait for\n\n\\(\\beta = \\text{scale parameter}\\) : same as \\(\\lambda\\), the rate parameter\n\nIn R code example: 1 bus per 10 minutes (1/10)"
  },
  {
    "objectID": "lessons/33_Gamma_rv/33_Gamma_rv.html#sending-money-orders",
    "href": "lessons/33_Gamma_rv/33_Gamma_rv.html#sending-money-orders",
    "title": "Chapter 33: Gamma Random Variables",
    "section": "Sending money orders",
    "text": "Sending money orders\n\n\n\n\nExample 1\n\n\nOn average, someone sends a money order once per 15 minutes. What is the probability someone sends 10 money orders in less than 3 hours?"
  },
  {
    "objectID": "lessons/33_Gamma_rv/33_Gamma_rv.html#additional-resource",
    "href": "lessons/33_Gamma_rv/33_Gamma_rv.html#additional-resource",
    "title": "Chapter 33: Gamma Random Variables",
    "section": "Additional Resource",
    "text": "Additional Resource\n\nAnother helpful site with R code: https://rpubs.com/mpfoley73/459051"
  },
  {
    "objectID": "lessons/12_Variance/12_Variance.html",
    "href": "lessons/12_Variance/12_Variance.html",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "",
    "text": "Calculate the variance and standard deviation of discrete random variables\nCalculate the variance of sums of discrete random variables\nCalculate the variance of functions of discrete random variables"
  },
  {
    "objectID": "lessons/12_Variance/12_Variance.html#learning-objectives",
    "href": "lessons/12_Variance/12_Variance.html#learning-objectives",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate the variance and standard deviation of discrete random variables\nCalculate the variance of sums of discrete random variables\nCalculate the variance of functions of discrete random variables"
  },
  {
    "objectID": "lessons/12_Variance/12_Variance.html#lets-start-building-the-variance-through-expected-values-of-functions",
    "href": "lessons/12_Variance/12_Variance.html#lets-start-building-the-variance-through-expected-values-of-functions",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Let’s start building the variance through expected values of functions",
    "text": "Let’s start building the variance through expected values of functions\n\n\n\n\nExample 1\n\n\nLet \\(g\\) be a function and let \\(g(x) = ax+b\\), for real-valued constants \\(a\\) and \\(b\\). What is \\(\\mathbb{E}[g(X)]\\)?"
  },
  {
    "objectID": "lessons/12_Variance/12_Variance.html#what-is-the-expected-value-of-a-function",
    "href": "lessons/12_Variance/12_Variance.html#what-is-the-expected-value-of-a-function",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "What is the expected value of a function?",
    "text": "What is the expected value of a function?\n\n\nDefinition: Expected value of function of RV\n\n\nFor any function \\(g\\) and discrete r.v. \\(X\\), the expected value of \\(g(X)\\) is \\[\\mathbb{E}[g(X)] = \\sum_{\\{all\\ x\\}}\\ g(x) p_X(x).\\]"
  },
  {
    "objectID": "lessons/12_Variance/12_Variance.html#lets-revisit-the-card-example-12",
    "href": "lessons/12_Variance/12_Variance.html#lets-revisit-the-card-example-12",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Let’s revisit the card example (1/2)",
    "text": "Let’s revisit the card example (1/2)\n\n\n\n\nExample 2\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw.\n\nFind \\(\\mathbb{E}[X^2]\\).\n\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "lessons/12_Variance/12_Variance.html#lets-revisit-the-card-example-22",
    "href": "lessons/12_Variance/12_Variance.html#lets-revisit-the-card-example-22",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Let’s revisit the card example (2/2)",
    "text": "Let’s revisit the card example (2/2)\n\n\n\n\nExample 2\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw.\n\nFind \\(\\mathbb{E}\\big[\\big(X-\\frac{1}{2}\\big)^2\\big]\\).\n\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "lessons/12_Variance/12_Variance.html#variance-of-a-rv",
    "href": "lessons/12_Variance/12_Variance.html#variance-of-a-rv",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Variance of a RV",
    "text": "Variance of a RV\n\n\nDefinition: Variance of RV\n\n\nThe variance of a r.v. \\(X\\), with (finite) expected value \\(\\mu_X=\\mathbb{E}[X]\\) is \\[\\sigma_X^2=Var(X)=\\mathbb{E}[(X-\\mu_X)^2] = \\mathbb{E}[(X-\\mathbb{E}[X])^2]\\]\n\n\n\n\nDefinition: Standard deviation of RV\n\n\nThe standard deviation of a r.v. \\(X\\) is \\[\\sigma_X = SD(X) = \\sqrt{\\sigma_X^2}=\\sqrt{Var(X)}.\\]"
  },
  {
    "objectID": "lessons/12_Variance/12_Variance.html#questions",
    "href": "lessons/12_Variance/12_Variance.html#questions",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Questions",
    "text": "Questions\nQuestions: Why do we square the difference in the variance definition? \\((X-\\mu_X)^2\\)\n\nWhy not define the measure of spread as \\(\\mathbb{E}[X-\\mu_X] = \\mathbb{E}[X-\\mathbb{E}[X]]\\)?\nWhy not use \\(\\mathbb{E}[|X-\\mu_X|]\\)?"
  },
  {
    "objectID": "lessons/12_Variance/12_Variance.html#lets-calculate-the-variance-and-prove-it",
    "href": "lessons/12_Variance/12_Variance.html#lets-calculate-the-variance-and-prove-it",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Let’s calculate the variance and prove it!",
    "text": "Let’s calculate the variance and prove it!\n\n\n\n\nLemma 6: “Computation formula” for Variance\n\n\nThe variance of a r.v. \\(X\\), can be computed as \\[\\begin{align}\n\\sigma_X^2 & =Var(X) \\\\ & = \\mathbb{E}[X^2]-\\mu_X^2 \\\\ & = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2\n\\end{align}\\]"
  },
  {
    "objectID": "lessons/12_Variance/12_Variance.html#variance-of-a-function-with-a-single-rv",
    "href": "lessons/12_Variance/12_Variance.html#variance-of-a-function-with-a-single-rv",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Variance of a function with a single RV",
    "text": "Variance of a function with a single RV\n\n\nLemma 7\n\n\nFor a r.v. \\(X\\) and constants \\(a\\) and \\(b\\), \\[Var(aX+b) = a^2Var(X).\\]\n\n\nProof will be exercise in homework. It’s fun! In a mathy kinda way."
  },
  {
    "objectID": "lessons/12_Variance/12_Variance.html#important-results-for-independent-rvs",
    "href": "lessons/12_Variance/12_Variance.html#important-results-for-independent-rvs",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Important results for independent RVs",
    "text": "Important results for independent RVs\n\n\nTheorem 8\n\n\nFor independent r.v.’s \\(X\\) and \\(Y\\), and functions \\(g\\) and \\(h\\), \\[\\mathbb{E}[g(X)h(Y)] = \\mathbb{E}[g(X)]\\mathbb{E}[h(Y)].\\]\n\n\n\n\nCorollary 1\n\n\nFor independent r.v.’s \\(X\\) and \\(Y\\), \\[\\mathbb{E}[XY] = \\mathbb{E}[X]\\mathbb{E}[Y].\\]"
  },
  {
    "objectID": "lessons/12_Variance/12_Variance.html#variance-of-sum-of-independent-discrete-rvs",
    "href": "lessons/12_Variance/12_Variance.html#variance-of-sum-of-independent-discrete-rvs",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Variance of sum of independent discrete RVs",
    "text": "Variance of sum of independent discrete RVs\n\n\nTheorem 9: Variance of sum of independent discrete r.v.’s\n\n\nFor independent discrete r.v.’s \\(X_i\\) and constants \\(a_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n a_iX_i\\Bigg) = \\sum_{i=1}^n a_i^2Var(X_i).\\]\n\n\nSimpler version:\n\\[Var(a_1 X + a_2 Y) = Var(a_1X) + Var(a_2 Y) = a_1^2 Var(X) + a_2^2 Var(Y)\\]"
  },
  {
    "objectID": "lessons/12_Variance/12_Variance.html#corollaries",
    "href": "lessons/12_Variance/12_Variance.html#corollaries",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Corollaries",
    "text": "Corollaries\n\n\nCorollary 2\n\n\nFor independent discrete r.v.’s \\(X_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n X_i\\Bigg) = \\sum_{i=1}^n Var(X_i).\\]\n\n\n\n\nCorollary 3\n\n\nFor independent identically distributed (i.i.d.) discrete r.v.’s \\(X_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n X_i\\Bigg) = n Var(X_1).\\]"
  },
  {
    "objectID": "lessons/12_Variance/12_Variance.html#lets-revisit-our-ghost-problems-without-replacement",
    "href": "lessons/12_Variance/12_Variance.html#lets-revisit-our-ghost-problems-without-replacement",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Let’s revisit our ghost problems without replacement",
    "text": "Let’s revisit our ghost problems without replacement\n\n\n\n\nExample 3.1\n\n\nThe ghost is trick-or-treating at a different house now. In this case it is known that the bag of candy has 10 chocolates, 20 lollipops, and 30 laffy taffies. The ghost grabs a handful of five pieces of candy. What is the variance for the number of chocolates the ghost takes? Let’s solve this for the cases without replacement.\n\n\n\n\nRecall probability without replacement:\n\\[p_X(x) = \\dfrac{{K \\choose x}{N-K \\choose n-x}}{{N \\choose n}}\n\\]"
  },
  {
    "objectID": "lessons/12_Variance/12_Variance.html#lets-revisit-our-ghost-problems-with-replacement",
    "href": "lessons/12_Variance/12_Variance.html#lets-revisit-our-ghost-problems-with-replacement",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Let’s revisit our ghost problems with replacement",
    "text": "Let’s revisit our ghost problems with replacement\n\n\n\n\nExample 3.2\n\n\nThe ghost is trick-or-treating at a different house now. In this case it is known that the bag of candy has 10 chocolates, 20 lollipops, and 30 laffy taffies. The ghost grabs a handful of five pieces of candy. What is the variance for the number of chocolates the ghost takes? Let’s solve this for the cases with replacement.\n\n\n\n\nRecall probability with replacement:\n\\[\np_X(x) = {n \\choose k}p^k(1-p)^{n-k}\n\\]"
  },
  {
    "objectID": "lessons/12_Variance/12_Variance.html#back-to-our-hotel-example-from-chapter-11",
    "href": "lessons/12_Variance/12_Variance.html#back-to-our-hotel-example-from-chapter-11",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Back to our hotel example from Chapter 11",
    "text": "Back to our hotel example from Chapter 11\n\n\n\n\nExample 4\n\n\nA tour group is planning a visit to the city of Minneapolis and needs to book 30 hotel rooms. The average price of a room is $200 with standard deviation $10. In addition, there is a 10% tourism tax for each room. What is the standard deviation of the cost for the 30 hotel rooms? Assume rooms are independent.\n\n\nProblem to do at home if we don’t have enough time.\n\n\n\n\nChapter 12 Slides"
  },
  {
    "objectID": "readings/Calc_review.html",
    "href": "readings/Calc_review.html",
    "title": "Calculus Review",
    "section": "",
    "text": "Calculus will be used in probability throughout the quarter, as well as in the following math stat classes. Below are topics and links from Paul’s Online Math Notes to help you review algebra and calculus skills that are essential to BSTA 550.\n\nYou can ignore all examples that use trigonometry.\nI listed the sections that you should be familiar with. The webpages have both notes and exercises for you to practice.\nI recommend first reviewing the italicized sections since we will be using series early in the course.\nWe will not use differentiation and integration until the second half of the course (Week 6), so you have some time to review."
  },
  {
    "objectID": "readings/Calc_review.html#introduction",
    "href": "readings/Calc_review.html#introduction",
    "title": "Calculus Review",
    "section": "",
    "text": "Calculus will be used in probability throughout the quarter, as well as in the following math stat classes. Below are topics and links from Paul’s Online Math Notes to help you review algebra and calculus skills that are essential to BSTA 550.\n\nYou can ignore all examples that use trigonometry.\nI listed the sections that you should be familiar with. The webpages have both notes and exercises for you to practice.\nI recommend first reviewing the italicized sections since we will be using series early in the course.\nWe will not use differentiation and integration until the second half of the course (Week 6), so you have some time to review."
  },
  {
    "objectID": "readings/Calc_review.html#topics",
    "href": "readings/Calc_review.html#topics",
    "title": "Calculus Review",
    "section": "Topics",
    "text": "Topics\n\nAlgebra\n\nPreliminaries\nSolving Equations And Inequalities\nGraphing And Functions\nExponential And Logarithm Functions\n\nCalculus 1   [Notes]   [Practice Problems]\n\nDerivatives\n\nDifferentiation Formulas\nProduct and Quotient Rule\nDerivatives of Exponential and Logarithm Functions (Only need exponential functions, and in particular only ex)\nChain Rule\n\nIntegrals\n\nIndefinite Integrals\nComputing Indefinite Integrals\nSubstitution Rule for Indefinite Integrals\nMore Substitution Rule\nArea Problem\n\nDon’t worry about the computations. Read through as a review for how integrals calculate area under the curve as the limit of areas of rectangles.\n\nThe Definition of the Definite Integral\nComputing Definite Integrals\nSubstitution Rule for Definite Integrals\n\nApplications of Integrals\n\nArea Between Curves\n\nExtras\n\nSummation Notation\n\n\nCalculus 2   [Notes]   [Practice Problems]\n\nIntegration Techniques\n\nIntegration by Parts\n\nSequences and Series\n\nSeries - The Basics\nSeries - Special Series (just Geometric Series)"
  },
  {
    "objectID": "homework/HW5.html",
    "href": "homework/HW5.html",
    "title": "Homework 5",
    "section": "",
    "text": "Midterm Survey\n\n\n\nWith this homework, you need to complete the midterm survey. This will help me evaluate how well I am teaching.\nThere are 13 total questions. Only one question is required, so if you do not feel strongly or do not have suggestions, don’t feel like you need to answer. I want to hear your opinion! I want to make meaningful changes in the classroom that will help you! \nDon’t forget that this is 2% of your grade. This survey is also due November 9th at 11pm."
  },
  {
    "objectID": "homework/HW5.html#directions",
    "href": "homework/HW5.html#directions",
    "title": "Homework 5",
    "section": "Directions",
    "text": "Directions\nPlease turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nThe more work you include that shows your thought process, the more I can give you feedback.\n\n\n\n\n\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n12\nNTB # 1-2\n# 1, 2, 7, 11, 12, 15, 19, 25, 27, NTB # 4\n\n\n13 (review)\n\n# 3, 4, 5, 6, 8, 9, 10, 17, 25\n\n\n14\n\n# 3, 7\n\n\n15\nNTB # 3\n# 1, 5, 11, 18, 23, NTB # 5\n\n\n16\nTB # 7\n# 3a-g, 8, 11, 21\n\n\n17\nTB # 9\n# 3a-g, 6, 11, 12a-c, NTB # 6\n\n\n18\nTB # 20\n# 1, 24, 26, 27\n\n\n19\nTB # 6\n# 1, 18, 19\n\n\n20\n\n# 2, 3, 4"
  },
  {
    "objectID": "homework/HW5.html#non-textbook-problems-ntb",
    "href": "homework/HW5.html#non-textbook-problems-ntb",
    "title": "Homework 5",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nProve that for a r.v. \\(X\\) and constants \\(a\\) and \\(b\\), that \\[\\mathrm{Var}[aX+b]=a^2\\mathrm{Var}[X].\\]\nLet \\(\\bar{X}\\) be the random variable for the sample mean, \\(\\bar{X}=\\frac{\\sum_{i=1}^nX_i}{n}\\), where the \\(X_i\\) are i.i.d. random variables with common mean \\(\\mu\\) and variance \\(\\sigma^2\\).\n\nFind \\(\\mathbb{E}[\\bar{X}]\\).\nFind \\(Var[\\bar{X}]\\).\n\nLet \\(X_i\\sim\\) Binomial(\\(n_i,p\\)) be independent r.v.’s for \\(i=1,\\ldots,m\\).\n\nWhat does the r.v. \\(X=\\sum_{i=1}^mX_i\\) count, and what is the distribution of \\(X\\)? Make sure to specify the parameters of \\(X\\)’s distribution.\nFind \\(\\mathbb{E}[X]\\). Make sure to show your work for (b) and (c). However, you may use without proof what you know about the mean and variance of each \\(X_i\\).\nFind \\(Var[X]\\).\n\nExtra Problems\n\nLet \\(\\hat{p}\\) be the random variable for the sample proportion, \\(\\hat{p}=\\frac{X}{n}\\), where \\(X\\) is the number of successes in a random sample of size \\(n\\). Assume the probability of success is \\(p\\).\n\nFind \\(\\mathbb{E}[\\hat{p}]\\).\nFind \\(Var[\\hat{p}]\\).\n\nRead the Washington Post article The amazing woman who can smell Parkinson’s disease - before symptoms appear (http://www.washingtonpost.com/news/morning-mix/wp/2015/10/23/scottish-woman-detects-a-musky-smell-that-could-radically-improve-how-parkinsons-disease-is-diagnosed/)\nAssuming Joy Milne does not have the ability to detect Parkinson’s disease via smell, answer the following questions:\n\nWhat is the probability of her correctly detecting Parkinson’s by smelling one t-shirt?\nWhat is the probability of her correctly detecting Parkinson’s in 12 out of 12 t-shirts?\n\nLet \\(X_i\\sim\\) Negative Binomial(\\(r_i,p\\)) be independent r.v.’s for \\(i=1,\\ldots,m\\).\n\nWhat does the r.v. \\(X=\\sum_{i=1}^mX_i\\) count, and what is the distribution of \\(X\\)? Make sure to specify the parameters of \\(X\\)’s distribution.\nFind \\(\\mathbb{E}[X]\\). Make sure to show your work for (b) and (c). However, you may use without proof what you know about the mean and variance of each \\(X_i\\).\nFind \\(Var[X]\\)."
  },
  {
    "objectID": "homework/HW5.html#some-select-answers",
    "href": "homework/HW5.html#some-select-answers",
    "title": "Homework 5",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 12\n\n# 2:  64.8\n# 12:  1,096,357\n\nChapter 13\n\n# 4:  (a) 260/9     (b) 2.833     (c) \\(2.679\\times 10^{-5}\\)     (d) Same idea as (c) Replace 10’s with 100.     \n# 6:  (a) \\(p_X(x)=\\binom{4}{x}.3^x .7^{4-x}\\), for \\(x=0,1,\\ldots,4\\)     (d) 0.3483     (e) 0.9163     (f) 0.0233     (g) 1\n# 8:  (a) T     (b) F     (c) F     (d) F     (e) T     (f) T    (g) T\n# 10:  (a) T     (b) T    (c) F     (d) T    (e) T     (f) F    (g) T     (h) T (nonnegative instead of positive)     (i) F\n\nChapter 15\n\n# 18  (a) Bin(21,0.65)     (b) 4.78     \n\nChapter 16\n\n# 8  (a) 14.28      (b) code below     (c) \\(1.03\\times 10^{-6}\\)    (d) 10 questions: 91.43 minutes    \n\n\n1-pgeom(q = 18, prob = 0.07)\n\n[1] 0.2518698\n\n## OR\npgeom(q = 18, prob = 0.07, lower.tail = F)\n\n[1] 0.2518698\n\n\nChapter 17\n\n# 6   (a) 400, 87.18     (b) No     \n# 12   (c) 0.8000\n\nChapter 18\n\n# 24  (c) 0.8571\n# 26  162,754.8\n\nChapter 19\n\n# 6:  (c) 15.625     (d) 0.0486     (f) 0.0488\n# 18:   100\n\nChapter 20\n\n# 2:  (a) 0.0001     (b) Discrete since \\(X\\) has a finite number of possible values. Uniform since each outcome is equally likely.     (c) \\(X\\) = randomly selected 4-digit ID#; \\(X=0000,0001,\\ldots,9999\\)     (d) 5000.5     (e) 8,333,333.25"
  },
  {
    "objectID": "homework/HW6.html",
    "href": "homework/HW6.html",
    "title": "Homework 6",
    "section": "",
    "text": "HW 6 Due Date\n\n\n\nYou can turn in the homework any time through Sunday, November 19th."
  },
  {
    "objectID": "homework/HW6.html#directions",
    "href": "homework/HW6.html#directions",
    "title": "Homework 6",
    "section": "Directions",
    "text": "Directions\nPlease turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nThe more work you include that shows your thought process, the more I can give you feedback.\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\nCalculus Review\n\nNTB # 1\n\n\n24\nTB # 19, 20*\n# 2, 3, 7, 17, 18, 22, 23\n\n\n\n\n*Also find the cdf \\(F_X(x)\\)"
  },
  {
    "objectID": "homework/HW6.html#non-textbook-problems-ntb",
    "href": "homework/HW6.html#non-textbook-problems-ntb",
    "title": "Homework 6",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nCalculus Review\n\n\\[\\int_0^yc(x+y)dx\\]\n\\[\\frac{d}{dx}\\bigg(\\frac{4}{9}x^2y^2+\\frac{5}{9}xy^4\\bigg)\\]\n\\[\\frac{d}{dy}\\bigg(\\frac{4}{9}x^2y^2+\\frac{5}{9}xy^4\\bigg)\\]\n\\[\\int_0^y2e^{-x}e^{-y}dx\\]\n\\[\\int_0^\\infty xye^{-(x+y)}dy\\]\n\\[\\int_x^{2x} 2e^{-(x+3y)}dy\\]\nFind the area of the region bounded by the graphs of \\(f(x)=2-x^2\\) and \\(g(x)=x\\) by integrating with respect to \\(x\\).\nFind the area of the region bounded by the graphs of \\(f(x)=2-x^2\\) and \\(g(x)=x\\) by integrating with respect to \\(y\\).\nFind the area of the region bounded by the graphs of \\(x=3-y^2\\) and \\(y=x-1\\) by integrating with respect to \\(x\\).\nFind the area of the region bounded by the graphs of \\(x=3-y^2\\) and \\(y=x-1\\) by integrating with respect to \\(y\\)."
  },
  {
    "objectID": "homework/HW6.html#some-select-answers",
    "href": "homework/HW6.html#some-select-answers",
    "title": "Homework 6",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nCalculus Review\n\n(a)  \\(c(\\frac{y^{2}}{2}+y^{2})\\)\n(b)  \\(\\frac{8}{9}xy^{2}+\\frac{5}{9}y^{4}\\)\n(c)  \\(\\frac{8}{9}x^{2}y+\\frac{20}{9}xy^{3}\\)\n(d)  \\(-2e^{-2y}+2e^{-y}\\)\n(e)  \\(xe^{-x}\\)\n(f)  \\(-\\frac{2}{3}(e^{-7x}-e^{-4x})\\)\n(g)  \\(\\frac{9}{2}\\)\n(h)  \\(\\frac{9}{2}\\)\n(i)  \\(\\frac{9}{2}\\)\n(j)  \\(\\frac{9}{2}\\)\n\nChapter 24\n\n# 2: (a) Discrete     (b) Discrete     (c) Continuous\n# 22: \\[f_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x &lt;0 \\\\\n            \\frac{7x}{4} & \\quad 0\\leq x\\leq 1 \\\\\n            0 & \\quad 1&lt; x&lt; 7 \\\\\n            \\frac{1}{8} & \\quad 7\\leq x\\leq 8 \\\\\n            0 & \\quad  x&gt;8 \\\\\n        \\end{array}\n    \\right.\\]\n\nChapter 25\n\n# 4:   7/16\n# 8:  (a) \\(\\frac{25}{228}\\)     (b) \\(f_X(x)=\\frac{1}{12}(x+1)\\), for \\(0\\leq x\\leq 4\\)     (c) \\(f_Y(y)=\\frac{3}{76}(y^2+1)\\), for \\(0\\leq y\\leq 4\\)\n# 18:  5/6\n# 24:  (a) \\(f_X(x)=-2e^{-2x}+2e^{-x}\\), for \\(x\\geq 0\\)     (b) \\(f_Y(y)=2e^{-2y}\\), for \\(y\\geq 0\\)\n\nChapter 26\n\n# 12:  (b) \\(\\frac{233}{256}\\)     (c) \\(\\frac{65}{256}\\)     (d) \\(\\frac{1}{512}\\)\n# 20:  (a) Yes.     (b) \\(\\frac{15}{16}\\)\nNTB # 3: (b) 0.09999546   (d) \\(f_Z(z) =\\Big(\\frac{11}{5} - \\frac{2z}{5}\\Big)e^{-2z}\\), for what values of \\(z\\)?\n\nChapter 27\n\n# 6: \\(f_{X|Y}(x|y)=\\frac{e^{-x/4-y/5}}{4(e^{-y/5}-e^{-9y/20})}\\), for \\(0&lt; x&lt; y\\)\n# 8: \\(f_{X|Y}(x|y)=\\frac{1-x^2}{1-y-\\frac{(1-y)^3}{3}}\\), for \\(0\\leq x, 0\\leq y, x+y\\leq 1\\)\n# 12: (a) \\(f_{X|Y}(x|y)=\\frac{1}{2}\\)    (c) \\(\\frac{4}{7}\\)"
  },
  {
    "objectID": "homework/HW3.html",
    "href": "homework/HW3.html",
    "title": "Homework 3",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nThe more work you include that shows your thought process, the more I can give you feedback.\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n5\nTB # 17, NTB # 1\n# 1, 9, 11\n\n\n7\n\n# 2, 10, 16, 17, 18\n\n\n8\nTB # 8*, 18*\n# 2, 5, 7, 10\n\n\n\n\n* In addition to the graphs, include piecewise defined functions for the pmf and cdf."
  },
  {
    "objectID": "homework/HW3.html#directions",
    "href": "homework/HW3.html#directions",
    "title": "Homework 3",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nThe more work you include that shows your thought process, the more I can give you feedback.\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n5\nTB # 17, NTB # 1\n# 1, 9, 11\n\n\n7\n\n# 2, 10, 16, 17, 18\n\n\n8\nTB # 8*, 18*\n# 2, 5, 7, 10\n\n\n\n\n* In addition to the graphs, include piecewise defined functions for the pmf and cdf."
  },
  {
    "objectID": "homework/HW3.html#non-textbook-problems-ntb",
    "href": "homework/HW3.html#non-textbook-problems-ntb",
    "title": "Homework 3",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nA new drug is packaged to contain 30 pills in a bottle. Suppose that 98% of all bottles contain no defective pills, 1.5% contain one defective pill, and 0.5% contain two defective pills. Two pills from a bottle are randomly selected and tested. What is the probability that there are 2 defective pills in the bottle given that one of the two tested pills is defective?"
  },
  {
    "objectID": "homework/HW3.html#some-select-answers",
    "href": "homework/HW3.html#some-select-answers",
    "title": "Homework 3",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 5\n\nNTB # 1: 0.3916\n\nChapter 7\n\n# 2: \\(X\\in(0,\\infty)\\), continuous; \\(Y\\in\\{0,1,2,\\ldots\\}\\), discrete\n# 10: \\(X_j\\in[0,\\infty),j=1,\\ldots,100\\); \\(Y\\in[0,\\infty)\\); both continuous\n# 16: \\(Y\\) could be 0\n# 18: Yes, a r.v. can be both. Give an example!\n\nChapter 8\n\n# 2: (a) \\(p(x)=\\binom{7}{x}(.5)^7\\) for \\(x=0,1,2,\\ldots,7\\)\n# 9: (a) \\(c = \\frac{1}{8}\\)\n# 10:\n\n\n\n\n\\(x\\)\n2\n4\n6\n8\n\n\n\n\n\\(p(x)\\)\n3/10\n1/2\n3/20\n1/20"
  },
  {
    "objectID": "homework/HW0.html",
    "href": "homework/HW0.html",
    "title": "Homework 0",
    "section": "",
    "text": "This homework does not need to be turned in on Sakai.\n\n\nThis homework is meant to introduce yourself to me and your peers. In the first class, we will all briefly introduce ourselves, but we don’t have enough time in-depth introductions. Thus, I’d like you to share some information with the class over Slack.\n\n\n\nGrading will be done as a check/no check for turning in your work. If you are stressed about time, please give yourself an extension."
  },
  {
    "objectID": "homework/HW0.html#directions",
    "href": "homework/HW0.html#directions",
    "title": "Homework 0",
    "section": "",
    "text": "This homework does not need to be turned in on Sakai.\n\n\nThis homework is meant to introduce yourself to me and your peers. In the first class, we will all briefly introduce ourselves, but we don’t have enough time in-depth introductions. Thus, I’d like you to share some information with the class over Slack.\n\n\n\nGrading will be done as a check/no check for turning in your work. If you are stressed about time, please give yourself an extension."
  },
  {
    "objectID": "homework/HW0.html#questions",
    "href": "homework/HW0.html#questions",
    "title": "Homework 0",
    "section": "Questions",
    "text": "Questions\n\nQuestion 1\nPlease upload a picture of yourself to Slack. Please follow the below steps to add a picture of yourself in Slack:\n\nGo to the top right corner in Slack and click your profile picture.\nClick “Profile.”\nIn the picture of the clip art person, click “Upload Photo” in top right corner.\nUpload a picture file of yourself.\n\n\n\nQuestion 2\nProvide a pronunciation of your name: Please follow the below steps to add an audio and written pronunciation of your name in Slack:\n\nGo to the top right corner in Slack and click your profile picture.\nClick “Profile.”\nTo the right of your name, click “Edit.”\nUnder “Name Recording,” click “Record Audio Clip.”\nPlease say your name once at a normal pace then once slowly. Please listen to my audio for an example.\nYou may also edit the written pronunciation of your name. This is optional! I realize that doing this is may require a lot of time researching phonetics.\n\n\n\nQuestion 3\nPlease complete the following whenisgood poll so that we can schedule office hours. Please use a unique identifier (does not have to be your name), so that I can make sure each student can attend at least one office hour.\n\n\nQuestion 4\nCompletion of this question is optional. If you are comfortable sharing your pronouns, please edit your name in Slack to include them. For example, I have changed my name to be “Nicky Wakim (she/her)”. If you prefer to not share your pronouns, then I will refer to you using they/them pronouns.\n\n\nQuestion 5\nPlease post an introduction in the #random channel on Slack. You do not need to include all of the below items, but your introduction may include information like:\n\nPreferred name\nPronouns\nAre you new to Portland?\nCareer interests\nHobbies\nFamily, children, and/or fur babies\nFavorite/recent adventures, restaurants, TV shows, books, podcasts, games, etc.\nWillingness to join a study group\nAnticipated Fall trip/activity\nAny resolutions/vibes/outlooks that you are thinking about as we start the new academic year/quarter\n\nPlease feel free to get creative with what you share! You don’t need to adhere to this list!\n\n\nQuestion 6\nCompletion of this question is only necessary if you have accommodations. If you have any learning accommodations, please email me about your needs. I should receive a direct email from the Office of Student Access, but it is important that we discuss how accommodations will translate to our class. If you plan to seek accomodations, but do not have the formal document yet, please let me know!\nI highly suggest that you make an appointment with a learning specialist through Student Academic Support Services! If you often need more time on a test, struggle to focus in class, or noticed a difference between your learning style and typical styles offered in school, talk to academic support services and see if you qualify for accommodations! Most professors should be working towards an inclusive classroom, but this is the best way to insure you get the learning environment you need!"
  },
  {
    "objectID": "homework/HW8.html",
    "href": "homework/HW8.html",
    "title": "Homework 8",
    "section": "",
    "text": "This homework is optional!!\n\n\n\nThis homework is completely optional!! These chapters will be on the test! I cannot stress enough how important these distributions and the CLT are!!\nSome questions that test material covered by exam: 32.10, 32.11"
  },
  {
    "objectID": "homework/HW8.html#directions",
    "href": "homework/HW8.html#directions",
    "title": "Homework 8",
    "section": "Directions",
    "text": "Directions\nPlease turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nThe more work you include that shows your thought process, the more I can give you feedback.\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n31\nTB # 18\nTB # 13, 14, 17\n\n\n32\nTB # 8\nTB # 3, 5, 101, 15\n\n\n33\nNTB # 1\nTB # 3, 9, 10\n\n\n35\nTB # 10, NTB # 2\nTB # 6, 9, 24\n\n\n36\nTB # 122, 14\nTB # 4, 11, 13, 15, 16\n\n\n37\nTB # 24, 30\nTB # 2, 4, 13, 20, 29\n\n\n\n\n* Although within Chapter 26, these exercises are primarily practicing the material from Chapter 25.\n** For Ch 27 # 12, in order to find the conditional densities in parts (a) and (b), you will need to calculate \\(f_Y(y)\\) for the specific regions of \\(y\\) specified. After finding the conditional densities in parts (a) and (b), also calculate the conditional probabilities below. Please submit these together with your other work in parts (a) and (b): Find \\(\\mathbb{P}[0.5 &lt; X &lt; 3 | Y = 4]\\). Find \\(\\mathbb{P}[0.5 &lt; X &lt; 3 | Y = 7]\\)."
  },
  {
    "objectID": "homework/HW8.html#non-textbook-problems-ntb",
    "href": "homework/HW8.html#non-textbook-problems-ntb",
    "title": "Homework 8",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nSuppose that voters arrive at a polling station at the rate of 120 per hour.For each of the following parts, give the name and parameter(s) of the distribution to be used to model the event and set up the expression to find the specified probability.You do not need to compute the probability.\n\nThe probability that the next voter will arrive in less than 30 seconds.\nThe probability that 200 voters will arrive within two hours of each other.\nThe probability that the \\(50^{th}\\) voter will arrive in between 15 and 30 minutes.\n\nThe automatic opening device of a military cargo parachute has been designed to open when the parachute is 200 m above the ground. Suppose opening altitude actually has a normal distribution with mean value 200 m and standard deviation 30 m. Equipment damage will occur if the parachute opens at an altitude of less than 100 m. What is the probability that there is equipment damage to the payload of at least one of the five independently dropped parachutes?"
  },
  {
    "objectID": "homework/HW8.html#some-select-answers",
    "href": "homework/HW8.html#some-select-answers",
    "title": "Homework 8",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 25\n\n# 4:   7/16\n# 8:  (a) \\(\\frac{25}{228}\\)     (b) \\(f_X(x)=\\frac{1}{12}(x+1)\\), for \\(0\\leq x\\leq 4\\)     (c) \\(f_Y(y)=\\frac{3}{76}(y^2+1)\\), for \\(0\\leq y\\leq 4\\)\n# 18:  5/6\n# 24:  (a) \\(f_X(x)=-2e^{-2x}+2e^{-x}\\), for \\(x\\geq 0\\)     (b) \\(f_Y(y)=2e^{-2y}\\), for \\(y\\geq 0\\)\n\nChapter 26\n\n# 12:  (b) \\(\\frac{233}{256}\\)     (c) \\(\\frac{65}{256}\\)     (d) \\(\\frac{1}{512}\\)\n# 20:  (a) Yes.     (b) \\(\\frac{15}{16}\\)\nNTB # 3: (b) 0.09999546   (d) \\(f_Z(z) =\\Big(\\frac{11}{5} - \\frac{2z}{5}\\Big)e^{-2z}\\), for what values of \\(z\\)?\n\nChapter 27\n\n# 6: \\(f_{X|Y}(x|y)=\\frac{e^{-x/4-y/5}}{4(e^{-y/5}-e^{-9y/20})}\\), for \\(0&lt; x&lt; y\\)\n# 8: \\(f_{X|Y}(x|y)=\\frac{1-x^2}{1-y-\\frac{(1-y)^3}{3}}\\), for \\(0\\leq x, 0\\leq y, x+y\\leq 1\\)\n# 12: (a) \\(f_{X|Y}(x|y)=\\frac{1}{2}\\)    (c) \\(\\frac{4}{7}\\)\n\nChapter 28\n\n# 10: (a) 8/9     (b) 14/3     \n# 18: 4/5\n\nChapter 29\n\n# 10: (a) 26/81     (b) 74/9\n# 14: (a) 67/3     (b) 1/14     (c) 25/12     (d) \\(\\sqrt{25/12}\\)\n# 26: 250\n# 32: See notes (or book) for the proof from the discrete random variables case. The proof doesn’t depend on what type of random variable (discrete vs. continuous) is being used.\nNTB # 3: (a) 63     (b) 287/3     (c) -1, 41/3     (d) -7, 287/3\n\nChapter 30\n\n# 4: \\(f_x(x)=1/2\\) for \\(2\\leq x\\leq 4\\)\n# 8: (a) T     (b) T     (c) F\n# 10: (a) F     (b) T\n# 12: (a) T     (b) T     (c) F     (d) T\n\nChapter 31\n\n# 14: (a) 0.25     (b) 0.02887     (c) 0.063     (d) 0.0145     (e) 0.01625     (f) 0.0055     (f) 6.195    (g) 0.00433     (h) 61.95     (i) 0.0433\n# 17: 2.25\n# 18: 7/15\n\nChapter 32\n\n# 8: 0.2526\n# 5: 0.8047\n# 10: 0.4323\n\nChapter 33\n\n#10: (a) \\(f_x(x)=\\frac{x}{9}e^{-x/3}\\) for \\(x&gt; 0\\)     (b) 0.4963\n\nChapter 35\n\n# 6: (a) 0     (b) -1.13     (c) \\(\\pm 0.32\\)\n# 10: (a) 0.0475     (b) 0.0475     (c) 0.2283     (d) 68.97 to 81.03     (e) 48 to 102     (f) 68.97\n# 24: (a) 0.2119     (b) 0.0011\nNTB # 5:   0.002\n\nChapter 36\n\n# 4: 0.0044\n# 12: (a) 0.9525     (b) 0.7939     (c) 0.7939\n# 14: 0.5911\n# 16: (a) \\(R=8.225\\sigma+25\\mu\\)     (b) \\(R=16.45\\sigma+100\\mu\\)     (c) \\(R=164.5\\sigma+10,000\\mu\\)     (d) \\(R=1.645\\sqrt{n}\\sigma+n\\mu\\)\n\nChapter 37\n\n# 2: 0.8869\n# 4: 0.0023\n# 20: 0.3936\n# 24: 0.4562\n# 30: (b) 0.0022     (c) \\(478.696\\approx 479\\)"
  },
  {
    "objectID": "homework/HW8.html#footnotes",
    "href": "homework/HW8.html#footnotes",
    "title": "Homework 8",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAssume \\(X\\) and \\(Y\\) are independent.↩︎\nAssume the distances between the cars are independent.↩︎"
  },
  {
    "objectID": "homeworks.html",
    "href": "homeworks.html",
    "title": "Homework",
    "section": "",
    "text": "Homework\nAssignment\nAssignment due (@11pm)\nAnswers\nSolutions & videos\n\n\n\n\n0\n\n10/02\n\n\n\n\n1\n\n10/12\n\n\n\n\n2\n\n10/19\n\n\n\n\n3\n\n10/26\n\n\n\n\n4\n\n11/02\n\n\n\n\n5\n\n11/09\n\n\n\n\n6\n\n11/16\n\n\n\n\n7\n\n11/23\n\n\n\n\n8\n\n12/07\n\n\n\n\n9 (optional)\n\n12/11"
  },
  {
    "objectID": "homeworks.html#assignments",
    "href": "homeworks.html#assignments",
    "title": "Homework Assignments and Solutions",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nReading Time\n\n\n\n\n\n\n9/28/23\n\n\nHomework 0\n\n\n4 min\n\n\n\n\n10/5/23\n\n\nHomework 1\n\n\n3 min\n\n\n\n\n10/12/23\n\n\nHomework 2\n\n\n5 min\n\n\n\n\n10/19/23\n\n\nHomework 3\n\n\n3 min\n\n\n\n\n10/26/23\n\n\nHomework 4\n\n\n6 min\n\n\n\n\n11/9/23\n\n\nHomework 5\n\n\n7 min\n\n\n\n\n11/16/23\n\n\nHomework 6\n\n\n5 min\n\n\n\n\n11/30/23\n\n\nHomework 7\n\n\n10 min\n\n\n\n\n12/7/23\n\n\nHomework 8\n\n\n7 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "homeworks.html#solutions",
    "href": "homeworks.html#solutions",
    "title": "Homework Assignments and Solutions",
    "section": "Solutions",
    "text": "Solutions\n\n\n\nHomework\nWritten Solutions\nVideos\n\n\n\n\n0\n\n\n\n\n1\n\n NTB 1a\n NTB 1b\n TB 2.30\n\n\n2\n\n NTB 1\n TB 22.1\n TB 3.10\n TB 4.5\n\n\n3\n\n NTB 1\n TB 5.17\n TB 8.8\n TB 8.18\n\n\n4\n\n NTB 1\n NTB 2\n TB 10.6\n NTB 3\n NTB 4\n\n\n5\n\n NTB 1\n NTB 2\n NTB 3\n TB 16.7\n TB 17.9\n TB 18.20\n TB 19.6\n\n\n6\n\n TB 24.19\n TB 24.20\n\n\n7\n\n TB 25.18\n NTB 1\n  TB 26.12\n NTB 2\n  NTB 3\n TB 27.12\n TB 28.18\n NTB 4\n NTB 5\n NTB 6\n\n\n8\nFolder of old solutions"
  },
  {
    "objectID": "instructors.html",
    "href": "instructors.html",
    "title": "Instructor: Nicole (Nicky) Wakim, PhD",
    "section": "",
    "text": "Email: wakim@ohsu.edu\nOffice: VPT 622A\n\nPronouns: she/her/hers\nYou are welcome to address me as Nicky (pronounced “nik-EE”), Dr. Wakim (pronounced “wah-KEEM”), Dr. W, Dr. Nicky, Professor, Professor Wakim, or any combination of the prior.\nBest method to contact: Office hours or email for general course questions.\n\n\n\n\n\n\n\n\n\n\nBrief professor statement: As a professor, my main goal is to instill a growth mindset into my students. Growth mindset means we are NOT stuck in our abilities or knowledge, and that we all can grow with effort, feedback, and learning from mistakes! This course aims to be as transparent as possible. I want you to understand my motivation for assessments, questions, and lessons. I also want those assessments to be clear, so please ask for clarification whenever needed."
  },
  {
    "objectID": "instructors.html#instructor-nicole-nicky-wakim-phd",
    "href": "instructors.html#instructor-nicole-nicky-wakim-phd",
    "title": "Instructors",
    "section": "",
    "text": "Email: wakim@ohsu.edu\nOffice: VPT 622A\n\nPronouns: she/her/hers\nYou are welcome to address me as Nicky (pronounced “nik-EE”), Dr. Wakim (pronounced “wah-KEEM”), Dr. W, Dr. Nicky, Professor, Professor Wakim, or any combination of the prior.\nBest method to contact: Office hours or Slack for general course questions or E-mail/Calendly appointments for private communication.\n\n\n\n\n\n\n\n\n\n\nBrief professor statement: As a professor, my main goal is to instill a growth mindset into my students. Growth mindset means we are NOT stuck in our abilities or knowledge, and that we all can and will grow! This course aims to be as transparent as possible. I want you to understand my motivation for assessments, questions, and lessons. I also want those assessments to be clear, so please ask for clarification whenever needed.\n\n\nLink to Webex!!\nTBD\nKnown exceptions:\n\nCancelled:"
  },
  {
    "objectID": "homework/HW1.html",
    "href": "homework/HW1.html",
    "title": "Homework 1",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nComplete all of the problems listed below. Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nYou must show all of your work to receive credit.\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n1\n\n# 3, 7, 9, 11\n\n\n2\nNTB # 1, TB # 30\n# 1, 4, 8, 16, 19, 23"
  },
  {
    "objectID": "homework/HW1.html#directions",
    "href": "homework/HW1.html#directions",
    "title": "Homework 1",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nComplete all of the problems listed below. Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nYou must show all of your work to receive credit.\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n1\n\n# 3, 7, 9, 11\n\n\n2\nNTB # 1, TB # 30\n# 1, 4, 8, 16, 19, 23"
  },
  {
    "objectID": "homework/HW1.html#non-textbook-problems-ntb",
    "href": "homework/HW1.html#non-textbook-problems-ntb",
    "title": "Homework 1",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nSuppose the following are the percentage of US adults with the following conditions:\n\n\\(A\\): Hypertension 33%\n\\(B\\): Diabetes 9%\n\\(C\\): Metabolic syndrome 24%\n\\(A\\) or \\(B\\): 39%\n\\(A\\) or \\(C\\): 45%\n\\(B\\) or \\(C\\): 28%\n\\(A\\) or \\(B\\) or \\(C\\): 48%\n\n\nMake a Venn diagram of the 3 conditions labeling the percentage (or probability) for ALL of the 8 “sections”. Hint: Start from the last condition and work your way up!\nFor each of the following (1. - 7. below), (\\(i\\)) write out the event using unions, intersections, and/or complements of the events \\(A\\), \\(B\\), and \\(C\\) (this is NOT finding the probability, that’s in \\(ii\\)); (\\(ii\\)) find the probability of the event; and (\\(iii\\)) write a sentence explaining what the probability is of in terms of the context of the problem.\n\n\\(\\mathbb{P}\\)(event at least one of the 3)\n\\(\\mathbb{P}\\)(event none)\n\\(\\mathbb{P}\\)(event \\(A\\) only)\n\\(\\mathbb{P}\\)(event exactly one)\n\\(\\mathbb{P}\\)(event \\(A\\) and \\(B\\))\n\\(\\mathbb{P}\\)(event \\(A\\) and \\(B\\) but not \\(C\\))\n\\(\\mathbb{P}\\)(event all 3)"
  },
  {
    "objectID": "homework/HW1.html#some-select-answers",
    "href": "homework/HW1.html#some-select-answers",
    "title": "Homework 1",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 2\n\n# 4: 0.35\n# 8: 0.03125\n# 16: 0.48\n# 30: (a) 0.189     (b) 0.811     (c) 0.189"
  },
  {
    "objectID": "homework/HW2.html",
    "href": "homework/HW2.html",
    "title": "Homework 2",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nThe more work you include that shows your thought process, the more I can give you feedback.\n\n\n\n\n\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n22*\nTB # 1\n# 3, 5, 7, 25, 27, 30, 31, 39-41, 43-48\n\n\n3\nTB # 10, NTB # 1\n# 4, 9, 12, 13**\n\n\n4\nTB # 5\n# 1, 4, 11, 13\n\n\n\n\nSee also the handout Conditional Probability Practice posted in Week 2 Course Materials on Sakai for more practice.\n* Please note the following for Chapter 22:\n\nSee the table on pg. 277, which summarizes some key combinatorics concepts.\nProblems 39-48 are a set that build on one another and more advanced than the other problems. It’ll be much easier to do #42 after doing 39-41.\nI highly recommend reading Chapter 23, which is a series of case studies in counting: poker hands and Yahtzee.\n\n**For #3.13, mathematically solve for the sample size instead of plugging in numbers and guessing."
  },
  {
    "objectID": "homework/HW2.html#directions",
    "href": "homework/HW2.html#directions",
    "title": "Homework 2",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nThe more work you include that shows your thought process, the more I can give you feedback.\n\n\n\n\n\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n22*\nTB # 1\n# 3, 5, 7, 25, 27, 30, 31, 39-41, 43-48\n\n\n3\nTB # 10, NTB # 1\n# 4, 9, 12, 13**\n\n\n4\nTB # 5\n# 1, 4, 11, 13\n\n\n\n\nSee also the handout Conditional Probability Practice posted in Week 2 Course Materials on Sakai for more practice.\n* Please note the following for Chapter 22:\n\nSee the table on pg. 277, which summarizes some key combinatorics concepts.\nProblems 39-48 are a set that build on one another and more advanced than the other problems. It’ll be much easier to do #42 after doing 39-41.\nI highly recommend reading Chapter 23, which is a series of case studies in counting: poker hands and Yahtzee.\n\n**For #3.13, mathematically solve for the sample size instead of plugging in numbers and guessing."
  },
  {
    "objectID": "homework/HW2.html#non-textbook-problems-ntb",
    "href": "homework/HW2.html#non-textbook-problems-ntb",
    "title": "Homework 2",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nRecall from class, that we defined events \\(A,B,\\) and \\(C\\) to mutually independent if both (1) and (2) below hold. This point of this exercise is to show that \\((1)\\nRightarrow (2),\\) and \\((2)\\nRightarrow (1).\\) \\[\\begin{array}{cc}\n    (1) & \\mathbb{P}(A\\cap B\\cap C)=\\mathbb{P}(A)\\mathbb{P(}B)\\mathbb{P(}C) \\\\\n    (2) & \\mathbb{P}(A\\cap B)=\\mathbb{P}(A)\\mathbb{P(}B) \\\\\n    & \\mathbb{P}(A\\cap C)=\\mathbb{P}(A)\\mathbb{P(}C) \\\\\n    & \\mathbb{P}(B\\cap C)=\\mathbb{P}(B)\\mathbb{P(}C)%\n    \\end{array}%\\]\n\nSuppose two different fair dice are rolled. Let events \\(A,B,\\) and \\(C\\) be defined in the following way: \\[\\begin{array}{cl}\nA: & \\text{Roll a total of 7} \\\\\nB: & \\text{First die is a 6} \\\\\nC: & \\text{Second die is a 2}%\n\\end{array}%\\]\nShow that condition \\((2)\\) holds, but that condition \\((1)\\) does not.\nSuppose two different fair dice are rolled. Let events \\(A,B,\\) and \\(C\\) be defined in the following way: \\[\\begin{array}{cl}\nA: & \\text{Roll a 1 or 2 on the first die} \\\\\nB: & \\text{Roll a 3, 4, or 5 on the second die} \\\\\nC: & \\text{Roll a total of 4, 11, or 12}%\n\\end{array}%\\]\nShow that condition \\((1)\\) holds, but that condition \\((2)\\) does not."
  },
  {
    "objectID": "homework/HW2.html#some-select-answers",
    "href": "homework/HW2.html#some-select-answers",
    "title": "Homework 2",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 22\n\n# 30: (a) 2,835     (b) 405     (c) 10,780     (d) 7,980\n# 40: 0.6666667\n# 42: 0.002116402 (This is the answer when \\(n=5\\). Your answer needs to be in terms of \\(n\\).)\n# 44: 0.3\n# 46: 0.3333333\n# 48: 0.007936508 (This is the answer when \\(n=5\\). Your answer needs to be in terms of \\(n\\).)\n\nChapter 3\n\n# 4: (a) 0.111328    (b) 0.004872    0.995128\n# 10: (c) 0.384 If you have the right answer to (c), then you should be able to figure out the rest (see (e)).\n# 12: No.\nNTB #1: (a) 0.0799     (b) 0.07553     (c) 0.0655\n\nChapter 4\n\n#4: 0.25\n# 12: (a) 0.4285714     (b) 0.4285714     (c) 0.1428571"
  },
  {
    "objectID": "homework/HW7.html",
    "href": "homework/HW7.html",
    "title": "Homework 7",
    "section": "",
    "text": "Split up this homework over the 2 weeks!\n\n\n\nThis homework is extra long! While I don’t want you to worry about turning something in over your break, I do not recommend saving it all for after the break. I recommend having Chapter 25-27 problems completed when you get back from your break."
  },
  {
    "objectID": "homework/HW7.html#directions",
    "href": "homework/HW7.html#directions",
    "title": "Homework 7",
    "section": "Directions",
    "text": "Directions\nPlease turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nThe more work you include that shows your thought process, the more I can give you feedback.\n\n\n\n\n\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n25\nTB # 18, NTB # 1\n# 1, 4, 8, 17, 23, 24\nSlide examples: 2, 3.3, 4\n\n\n26*\nTB # 12**, NTB # 2, 3\n# 7, 9, 19, 20\nSlide examples: 3\n\n\n27\nTB # 12***\n# 6, 8, 13, 17\nSlide examples: 1.2\n\n\n28\nTB # 18\nTB # 1, 10\n\n\n291\nNTB # 4-6\nTB # 10, 14, 23, 26, 11, 13, 32\n\n\n30\n\nTB # 4, 7-12\n\n\n\n\n* Although within Chapter 26, these exercises are primarily practicing the material from Chapter 25.\n** For this problem, you only need to set up the integrals!!\n*** For Ch 27 # 12, in order to find the conditional densities in parts (a) and (b), you will need to calculate \\(f_Y(y)\\) for the specific regions of \\(y\\) specified. After finding the conditional densities in parts (a) and (b), also calculate the conditional probabilities below. Please submit these together with your other work in parts (a) and (b): Find \\(\\mathbb{P}[0.5 &lt; X &lt; 3 | Y = 4]\\). Find \\(\\mathbb{P}[0.5 &lt; X &lt; 3 | Y = 7]\\)."
  },
  {
    "objectID": "homework/HW7.html#non-textbook-problems-ntb",
    "href": "homework/HW7.html#non-textbook-problems-ntb",
    "title": "Homework 7",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nLet \\(X_1, X_2, \\ldots, X_n\\) be i.i.d. random variables with common pdf \\(f_X(x)\\) and cdf \\(F_X(x)\\). Find the pdf for the random variable \\(Z\\), where \\(Z = max(X_1, X_2, \\ldots, X_n)\\).\nLet \\(X\\) and \\(Y\\) be independent random variables with respective pdf’s \\(f_X(x)=\\frac{1}{5}\\), for \\(0\\leq x\\leq 5\\), and \\(f_Y(y)=2e^{-2y}\\), for \\(y&gt;0\\).\n\nFind the joint distribution \\(f_{X,Y}(x,y)\\).\nFind the probability that \\(X\\) is less than \\(Y\\).\nLet \\(Z\\) be the random variable that is the smaller of \\(X\\) and \\(Y\\). Find the cumulative distribution function for \\(Z\\).\nFind the pdf for Z.\n\nSuppose that the random variables \\(X\\) and \\(Y\\) have joint density \\(f_{X,Y}(x,y)\\), for \\(0&lt;x&lt;1\\), and \\(\\frac{1}{2}&lt;y&lt;1\\). Set up the equation for the cdf of \\(Z\\), where \\(Z=X/Y\\).\nHint: First determine what the possible values for \\(Z\\) are. Then make a sketch of the domain of the joint pdf and shade in the region representing the cdf of Z for different values of \\(z\\). Make sure to pay close attention to how the region we need to integrate over changes as \\(z\\) changes. The cdf has two different cases depending on the value of \\(z\\). Plug in specific values of \\(z\\) and shade in the region representing the cdf to see why two different cases are needed.\nLet \\(f_X(x)=\\lambda e^{-\\lambda x}\\) for \\(x&gt;0\\), where \\(\\lambda&gt;0\\).\n\nShow \\(Var[X]=\\frac{1}{\\lambda^2}\\). You may use the result from class for \\(\\mathbb{E}[X]\\) without first proving it.\n\nA shipping company handles containers in three different sizes: (1) 27 \\(ft^3\\) (3 x 3 x 3), (2) 125 \\(ft^3\\), and (3) 512 \\(ft^3\\). Let \\(X_i\\) (\\(i = 1, 2, 3\\)) denote the number of type \\(i\\) containers shipped during a given week. Suppose that \\(\\mu_1 =200,\\sigma_1=10,\\mu_2 =250,\\sigma_2=12,\\mu_3 =100,\\sigma_3=8\\).\n\nAssuming that \\(X_1,X_2,X_3\\) are independent, calculate the expected value and variance of the total volume shipped.\nWould your calculations necessarily be correct if the \\(X_i\\)’s were not independent? Explain.\n\nSuppose your waiting time for a bus in the morning is uniformly distributed on [0, 8] (minutes), whereas waiting time in the evening is uniformly distributed on [0, 10] (minutes) independent of morning waiting time. Make sure to FIRST set up an equation for calculating the total waiting time in each question before calculating the mean and variance of the total waiting time. You may use results from class for the expected value and variance of uniform r.v.’s without proving them.\n\nIf you take the bus each morning and evening for a week (7 days), what is your total expected waiting time?\nWhat is the variance of your total waiting time?\nWhat are the expected value and variance of the difference between morning and evening waiting times on a given day?\nWhat are the expected value and variance of the difference between total morning waiting time and total evening waiting time for a particular week?"
  },
  {
    "objectID": "homework/HW7.html#some-select-answers",
    "href": "homework/HW7.html#some-select-answers",
    "title": "Homework 7",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 25\n\n# 4:   7/16\n# 8:  (a) \\(\\frac{25}{228}\\)     (b) \\(f_X(x)=\\frac{1}{12}(x+1)\\), for \\(0\\leq x\\leq 4\\)     (c) \\(f_Y(y)=\\frac{3}{76}(y^2+1)\\), for \\(0\\leq y\\leq 4\\)\n# 18:  5/6\n# 24:  (a) \\(f_X(x)=-2e^{-2x}+2e^{-x}\\), for \\(x\\geq 0\\)     (b) \\(f_Y(y)=2e^{-2y}\\), for \\(y\\geq 0\\)\n\nChapter 26\n\n# 12:  (b) \\(\\frac{233}{256}\\)     (c) \\(\\frac{65}{256}\\)     (d) \\(\\frac{1}{512}\\)\n# 20:  (a) Yes.     (b) \\(\\frac{15}{16}\\)\nNTB # 3: (b) 0.09999546   (d) \\(f_Z(z) =\\Big(\\frac{11}{5} - \\frac{2z}{5}\\Big)e^{-2z}\\), for what values of \\(z\\)?\n\nChapter 27\n\n# 6: \\(f_{X|Y}(x|y)=\\frac{e^{-x/4-y/5}}{4(e^{-y/5}-e^{-9y/20})}\\), for \\(0&lt; x&lt; y\\)\n# 8: \\(f_{X|Y}(x|y)=\\frac{1-x^2}{1-y-\\frac{(1-y)^3}{3}}\\), for \\(0\\leq x, 0\\leq y, x+y\\leq 1\\)\n# 12: (a) \\(f_{X|Y}(x|y)=\\frac{1}{2}\\)    (c) \\(\\frac{4}{7}\\)\n\nChapter 28\n\n# 10: (a) 8/9     (b) 14/3     \n# 18: 4/5\n\nChapter 29\n\n# 10: (a) 26/81     (b) 74/9\n# 14: (a) 67/3     (b) 1/14     (c) 25/12     (d) \\(\\sqrt{25/12}\\)\n# 26: 250\n# 32: See notes (or book) for the proof from the discrete random variables case. The proof doesn’t depend on what type of random variable (discrete vs. continuous) is being used.\nNTB # 6: (a) 63     (b) 287/3     (c) -1, 41/3     (d) -7, 287/3\n\nChapter 30\n\n# 4: \\(f_x(x)=1/2\\) for \\(2\\leq x\\leq 4\\)\n# 8: (a) T     (b) T     (c) F\n# 10: (a) F     (b) T\n# 12: (a) T     (b) T     (c) F     (d) T"
  },
  {
    "objectID": "homework/HW7.html#footnotes",
    "href": "homework/HW7.html#footnotes",
    "title": "Homework 7",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI recommend doing the Chapter 29 Extra Problems in the order listed.↩︎"
  },
  {
    "objectID": "homework/HW4.html",
    "href": "homework/HW4.html",
    "title": "Homework 4",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nThe more work you include that shows your thought process, the more I can give you feedback.\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n9\nNTB # 1, 2\n# 1, 2, 4, \\(8^{\\#}\\), 9, 10\n\n\n10*\nTB # 6\n# 1, 8, 10, 11, 14, 17\n\n\n11**\nNTB # 3, 4\n# 1, 2, 9***, 17***, 18***, 20\n\n\n\n\n\\(^\\#\\) Break up your solution to Chapter 9 #8 into the following 5 parts:\n\nMake a table of the joint probabilities for \\(X\\) and \\(Y\\).\nUsing the table in the previous part, write down the piecewise-defined equation for \\(p_{X,Y}(x,y)\\). There should be only 3 pieces (cases) for \\(p_{X,Y}(x,y)\\).\nExpress \\(p_Y(y)\\) as a formula (i.e. a function in terms of \\(y\\)).\nFind the conditional pmf \\(p_{X|Y}(x|y)\\) and express your answer as a piecewise-defined equation. There should be only 3 pieces (cases) for \\(p_{X|Y}(x|y)\\).\nMake a table of the joint cdf \\(F_{X,Y}(x,y)\\) values.\n\n* Use Chapter 10 techniques when computing expected values for Chapter 10 problems, i.e. computing the expected value directly using the definition of \\(\\mathbb{E}[X]\\).\n** Use Chapter 11 techniques when computing expected values for Chapter 11 problems, i.e. expressing the r.v. as a sum of other r.v.’s and calculating the expected value of the sum of r.v.’s. Also, as I mentioned in class and posted on Sakai, we will be skipping the more complex examples of finding expected values using indicator r.v.’s. You can skip Examples 11.5, 11.10, and 11.11. We will not be covering these techniques.\n*** Although Chapter 11 exercises, these are to be done using Chapter 10 techniques since we aren’t covering the more complex examples of finding expected values using indicator r.v.’s."
  },
  {
    "objectID": "homework/HW4.html#directions",
    "href": "homework/HW4.html#directions",
    "title": "Homework 4",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nThe more work you include that shows your thought process, the more I can give you feedback.\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n9\nNTB # 1, 2\n# 1, 2, 4, \\(8^{\\#}\\), 9, 10\n\n\n10*\nTB # 6\n# 1, 8, 10, 11, 14, 17\n\n\n11**\nNTB # 3, 4\n# 1, 2, 9***, 17***, 18***, 20\n\n\n\n\n\\(^\\#\\) Break up your solution to Chapter 9 #8 into the following 5 parts:\n\nMake a table of the joint probabilities for \\(X\\) and \\(Y\\).\nUsing the table in the previous part, write down the piecewise-defined equation for \\(p_{X,Y}(x,y)\\). There should be only 3 pieces (cases) for \\(p_{X,Y}(x,y)\\).\nExpress \\(p_Y(y)\\) as a formula (i.e. a function in terms of \\(y\\)).\nFind the conditional pmf \\(p_{X|Y}(x|y)\\) and express your answer as a piecewise-defined equation. There should be only 3 pieces (cases) for \\(p_{X|Y}(x|y)\\).\nMake a table of the joint cdf \\(F_{X,Y}(x,y)\\) values.\n\n* Use Chapter 10 techniques when computing expected values for Chapter 10 problems, i.e. computing the expected value directly using the definition of \\(\\mathbb{E}[X]\\).\n** Use Chapter 11 techniques when computing expected values for Chapter 11 problems, i.e. expressing the r.v. as a sum of other r.v.’s and calculating the expected value of the sum of r.v.’s. Also, as I mentioned in class and posted on Sakai, we will be skipping the more complex examples of finding expected values using indicator r.v.’s. You can skip Examples 11.5, 11.10, and 11.11. We will not be covering these techniques.\n*** Although Chapter 11 exercises, these are to be done using Chapter 10 techniques since we aren’t covering the more complex examples of finding expected values using indicator r.v.’s."
  },
  {
    "objectID": "homework/HW4.html#non-textbook-problems-ntb",
    "href": "homework/HW4.html#non-textbook-problems-ntb",
    "title": "Homework 4",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nThe following table shows the results of a survey in which the subjects were a sample of 300 adults residing in a certain metropolitan area. Each subject was asked to indicate which of three policies they favored with respect to smoking in public places. (Table is from Biostatistics: A Foundation for Analysis in the Health Sciences, 10th Edition, Daniel, Wayne W.; Cross, Chad L., pg. 630)\n\n\n\n\n\nLet \\(X=\\) highest education level and \\(Y=\\) policy favored. We can let \\(X=1\\) for college graduate, \\(X=2\\) for high-school graduate, etc., and similarly for \\(Y\\), or just keep the category names for the different levels of \\(X\\) and \\(Y\\)\n\nMake a table for the joint pmf \\(p_{X,Y}(x,y)\\) and briefly describe in words what the values are the probability of.\nFind the marginal pmf \\(p_{X}(x)\\) and briefly describe in words what the values are the probability of.\nFind the marginal pmf \\(p_{Y}(y)\\) and briefly describe in words what the values are the probability of.\nMake a table for the joint cdf \\(F_{X,Y}(x,y)\\) and briefly describe in words what the values are the probability of.\nFind the marginal cdf \\(F_{X}(x)\\) and briefly describe in words what the values are the probability of.\nFind the marginal cdf \\(F_{Y}(y)\\) and briefly describe in words what the values are the probability of.\nMake a table for the conditional pmf \\(p_{X|Y}(x|y)\\) and briefly describe in words what the values are the probability of.\nMake a table for the conditional pmf \\(p_{Y|X}(y|x)\\) and briefly describe in words what the values are the probability of.\n\nEach day, Maude has a 1% chance of losing her cell phone (her behavior on different days is independent). Each day, Maude has a 3% chance of forgetting to eat breakfast (again, her behavior on different days is independent). Her breakfast and cell phone habits are independent. Let X be the number of days until she first loses her cell phone. Let Y be the number of days until she first forgets to eat breakfast. (Here, X and Y are independent.)\n\nFind the joint probability mass function of X and Y.\nFind the joint cdf of \\(X\\) and \\(Y\\) and briefly explain what \\(F_{X,Y}(x,y)\\) represents in the context of the problem.\nFind the conditional pmf \\(p_{Y|X}(y|x)\\).\n\nApproximately 10% of U.S. Veterans are women. Suppose an investigator plans a study with 4500 participants that are Veterans. How many women can they expect to be included? Your answer must be calculated by defining a random variable and showing how to calculate the expected value.\nThere is a bowl containing 30 cashews, 20 pecans, 25 almonds, and 25 walnuts. I am going to randomly pick and eat 3 nuts (without replacement). Find the expected value of the number of cashews by defining the number of cashews as a sum of random variables. (This one takes a little while if we don’t rely on the"
  },
  {
    "objectID": "homework/HW4.html#some-select-answers",
    "href": "homework/HW4.html#some-select-answers",
    "title": "Homework 4",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 9\n\nNTB # 1 Partial answers:\n\n\n\\(p_{X|Y}(X=\\text{high school}| Y=\\text{no smoking at all}) = 0.476\\)\n\n\n\\(p_{Y|X}( Y=\\text{no smoking at all}|X=\\text{high school}) = 0.200\\)\n\n\n\nChapter 10\n\n# 6:  750.5\n# 8:  0.9\n# 10:   201\n# 14:   (a) 1.875     (b) 3.125     \n\nChapter 11\n\n# 2:  1.6\n# 18:  a) 48.5     (b) 96     \n# 20:  \\(\\approx\\) 23.077"
  },
  {
    "objectID": "readings/Chapter_01.html",
    "href": "readings/Chapter_01.html",
    "title": "Outcomes, Events, and Sample Space",
    "section": "",
    "text": "Note that I will keep the example and definition numbering that is presented in the textbook, so it may seem like numbers are being skipped. This just means I may not have presented an example from the textbook here. Feel free to consult the textbook for more examples!"
  },
  {
    "objectID": "readings/Chapter_01.html#introduction",
    "href": "readings/Chapter_01.html#introduction",
    "title": "Outcomes, Events, and Sample Space",
    "section": "1.1 Introduction",
    "text": "1.1 Introduction\nThe introduction in this chapter starts with the following quote:\n\n\n\n\n\n\n“Probability theory is the study of randomness and all things associated with randomness.”\n\n\n\nI couldn’t say it better myself. There are examples with obvious hints at randomness (i.e. dice rolls, coins flips) and there are examples with not-so-obvious randomness involved (i.e. time until any given traffic light turns green).\n\n\n\n\n\n\nDefinition 1.1\n\n\n\nWhen something happens at random there are several potential outcomes. Exactly one of the outcomes occurs. An event is defined to be a collection of some outcomes.\n\n\nOur goal in probability and statistics is to characterize randomness. Then as statisticians, we can use what we know about randomness to see if certain features of the world is within randomness or outside the randomness. For example, according to a New York Times article published on July 25, 2023, the Education Department is investigating Harvard University’s legacy admissions policy. Here is an excerpt from that article:\n\nHarvard gives preference to applicants who are recruited athletes, legacies, relatives of donors and children of faculty and staff. As a group, they make up less than 5 percent of applicants, but around 30 percent of those admitted each year. About 67.8 percent of these applicants are white, according to court papers.\n\nUsing probability, we can start to see why this practice might be inequitable. If these applicants make up 5% of the total applicant pool, and we completely, randomly chose applicants to admit, then we would expect 5% of admitted students to be this group of recruited athletes, legacies, relatives of donors, and children of faculty and staff. We could argue that recruited athletes are more likely to be admitted since they are, in fact, recruited, or that children of faculty and staff might “game” high school succesfully because they live in a home that subscribes to the academic world. If we want to compare the acceptance rate of 30% for this group to the average acceptance rate, the article actually fails to present a crucial peice of information: the average acceptance rate. I looked it up, and it is ~4%. So now we can start to think about questions like: With an average acceptance rate of 4%, does an acceptance of 30% of this group of recruited athletes, legacies, relatives of donors and children of faculty and staff make sense? We will explore this example further as we progress through our class.\nBaaack to our definitions: When we have several potential outcomes, and an event is a collection of outcomes, then we can start thinking of the set of potential outcomes. When there are no outcomes, then we have the empty set \\(\\emptyset\\). When we look at all outcomes, we call it the sample space \\(S\\). For now, when we look at a single event, we will focus on the sample space. When we start thinking of multiple events, the empty set might come into play. And just to reiterate: The empty set is an event. It is an impossible event, but it is still considered an event. So when you consider all possible events, the empty set is included. When you consider all possible outcomes, this is the sample space.\nNow let’s look at at an example with an obvious hint at randomness:\n\n\n\n\n\n\nExample 1.2\n\n\n\nYou roll a 6-sided die.\n\n\n\n\n\n\n\n\nExample 1.2 Explanation\n\n\n\n\n\nA 6-sided die has sides labelled 1-6. Thus, the sample space is \\(S=\\{1,2,3,4,5,6\\}\\) since we can land on any of the 6 sides. For every roll, only one of these outcomes occur, and that outcome is random.\nAn event can be any subgroup (more formally, subset) of the sample space, but not necessarily. Events can technically be outside of the sample space, but we often only consider events within the sample space.\nIf we can say our event is if we roll a 6, then our event is defined mathematically as \\(\\{6\\}\\). We can define a different event as rolling an odd numbered side, then our event is defined mathematically as \\(\\{1,3,5\\}\\). See TB pg 4 for more event examples.\n\n\n\nWe introduced subset, but here’s the definition:\n\n\n\n\n\n\nDefinition 1.3\n\n\n\nEvent A is a subset of event B, written \\(A \\subset B\\). if every outcome in A is also an outcome in B.\n\n\n\nLet’s work on defining different types of events within sample spaces:\n\n\n\n\n\n\nExample 1.4\n\n\n\nA student buys a book and opens it to a random page. They note the number of typographical errors on the page. Let’s define the sample space and discuss one potential event.\n\n\n\n\n\n\n\n\nExample 1.4 Explanation\n\n\n\n\n\nSince there must be 0 or more errors, and errors are counted with whole numbers, the sample space will be the set of nonnegative integers: \\(S=\\mathbb{Z}^{&gt;=0}\\). More plainly, \\(S=\\{0, 1, 2, 3, 4, ...\\}\\).\nHere are a few possible events we can consider: (I invite you to think of others if you’d like)\n\nevent that a page contains 4 errors\nevent that a page contains at most 3 errors\nevent that a page contains more than 3 errors\nevent that a page contains an odd number of errors.\n\n\n\n\nDefinitions:\n\n\n\n\n\n\nDefinition 1.11\n\n\n\nThe union of events \\(A\\) and \\(B\\), denoted by \\(A \\cup B\\), contains all outcomes that are in \\(A\\) or \\(B\\).\n\n\n\n\n\n\n\n\nDefinition 1.12\n\n\n\nThe intersection of events \\(A\\) and \\(B\\), denoted by \\(A \\cap B\\), contains all outcomes that are both in \\(A\\) and \\(B\\)."
  },
  {
    "objectID": "readings/Chapter_01.html#complements-and-demorgans-laws",
    "href": "readings/Chapter_01.html#complements-and-demorgans-laws",
    "title": "Outcomes, Events, and Sample Space",
    "section": "1.2 Complements and DeMorgan’s Laws",
    "text": "1.2 Complements and DeMorgan’s Laws"
  },
  {
    "objectID": "readings/Chapter_01.html#notes",
    "href": "readings/Chapter_01.html#notes",
    "title": "Outcomes, Events, and Sample Space",
    "section": "Notes",
    "text": "Notes\nThere are a few things I’d like to address from the book:\n\nThere is a set of examples, 1.5 and 1.6, that talk about the birth of a baby. While this example is helpful for considering potential sample spaces, there is an oversight on the biology of births. The examples refer to the event of the sex assigned at birth (SAB). There are two issues in this example. First, SAB is considered binary in this example (I will get back to this). Second, the binary SAB is written as “boy” or “girl.” These labels have gender identity inherently attached to their meaning, and thus, the more accurate binary versions of these are “male” or “female,” respectively (“Assigned Sex at Birth,” n.d.). These are often denoted as “assigned male at birth” (AMAB) or “assigned female at birth” (AFAB). Going back the first issue, a binary representation of SAB does not cover all possible events. People can also be intersex, meaning their genitals, chromosomes, and/or reproductive organs are not exclusively AMAB or AFAB (“Intersex: What Is Intersex, Gender Identity, Intersex Surgery,” n.d.).\n\n\n\n\n\n\nExtension to Example 1.5 and 1.6\n\n\n\nYou can go back to these examples (TB pg. 5) and work through them with the more accurate representation of sex at birth. Please use the possible outcomes of AFAB, AMAB, or intersex."
  },
  {
    "objectID": "lessons/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html",
    "href": "lessons/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "",
    "text": "Calculate probability of a sample mean using a Normally distributed population"
  },
  {
    "objectID": "lessons/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#learning-objectives",
    "href": "lessons/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#learning-objectives",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate probability of a sample mean using a Normally distributed population"
  },
  {
    "objectID": "lessons/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#sum-of-normal-rvs",
    "href": "lessons/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#sum-of-normal-rvs",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "Sum of Normal RVs",
    "text": "Sum of Normal RVs\n\n\nTheorem 1\n\n\nLet \\(X\\sim N(\\mu, \\sigma^2)\\), and let \\(Y=aX+b\\), where \\(a\\) and \\(b\\) are constants. Then \\[Y \\sim N(a\\mu+b, a^2\\sigma^2)\\]\n\n\n\n\nTheorem 2\n\n\nLet \\(X_i \\sim N(\\mu_i, \\sigma_i^2)\\) be independent normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\sim N\\Bigg(\\sum_{i=1}^n \\mu_i , \\sum_{i=1}^n \\sigma^2_i\\Bigg)\\]"
  },
  {
    "objectID": "lessons/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#special-cases",
    "href": "lessons/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#special-cases",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "Special Cases",
    "text": "Special Cases\n\nLet \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\sim N\\big(n\\mu, n \\sigma^2\\big)\\]\nLet \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\bar{X}=\\frac{\\sum_{i=1}^n X_i}{n} \\sim N\\big(\\mu, \\sigma^2 / n\\big)\\]\nLet \\(X\\sim N(\\mu_X,\\sigma_X^2)\\), and \\(Y\\sim N(\\mu_Y,\\sigma_Y^2)\\). Then \\[X-Y \\sim N\\big(\\mu_X - \\mu_Y, \\sigma^2_X + \\sigma^2_Y \\big)\\]"
  },
  {
    "objectID": "lessons/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#detecting-and-solving-sums-of-normal-rvs-from-a-word-problem",
    "href": "lessons/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#detecting-and-solving-sums-of-normal-rvs-from-a-word-problem",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "Detecting and solving sums of Normal RVs from a word problem",
    "text": "Detecting and solving sums of Normal RVs from a word problem\n\n\n\n\nExample 1\n\n\nGlaucoma is an eye disease that is manifested by high intraocular pressure (IOP). The distribution of IOP in the general population is approximately normal with mean 16 mmHg and standard deviation 3 mmHg.\n\nSuppose a patient has 40 IOP readings. What is the probability that their average reading is greater than 20.32 mmHg, assuming their eyes are healthy?\nRepeat the previous question for a patient with 10 IOP readings.\n\n\n\n\n\n\n\nChapter 36 Slides"
  },
  {
    "objectID": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html",
    "href": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "",
    "text": "Calculate probabilities for discrete random variables\nCalculate and graph a probability mass function (pmf)\nCalculate and graph a cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#learning-objectives",
    "href": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#learning-objectives",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate probabilities for discrete random variables\nCalculate and graph a probability mass function (pmf)\nCalculate and graph a cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#what-is-a-probability-mass-function",
    "href": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#what-is-a-probability-mass-function",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "What is a probability mass function?",
    "text": "What is a probability mass function?\n\n\nDefinition: probability distribution or probability mass function (pmf)\n\n\nThe probability distribution or probability mass function (pmf) of a discrete r.v. \\(X\\) is defined for every number \\(x\\) by \\[p_X(x) = \\mathbb{P}(X=x) = \\mathbb{P}(\\mathrm{all }\\ \\omega\\in S:X(\\omega) = x)\\]"
  },
  {
    "objectID": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#lets-demonstrate-this-definition-with-our-coin-toss",
    "href": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#lets-demonstrate-this-definition-with-our-coin-toss",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Let’s demonstrate this definition with our coin toss",
    "text": "Let’s demonstrate this definition with our coin toss\n\n\n\n\nExample 1\n\n\nSuppose we toss 3 coins with probability of tails \\(p\\). If \\(X\\) is the random variable counting the number of tails, what are the probabilities of each value of \\(X\\)?"
  },
  {
    "objectID": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#remarks-on-the-pmf",
    "href": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#remarks-on-the-pmf",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Remarks on the pmf",
    "text": "Remarks on the pmf\n\n\nProperties of pmf\n\n\nA pmf \\(p_X(x)\\) must satisfy the following properties:\n\n\\(0 \\leq p_X(x) \\leq 1\\) for all \\(x\\).\n\\(\\sum \\limits_{\\{all\\ x\\}}p_X(x)=1\\).\n\n\n\n\nSome distributions depend on parameters\n\nEach value of a parameter gives a different pmf\nIn previous example, the number of coins tossed was a parameter\n\nWe tossed 3 coins\nIf we tossed 4 coins, we’d get a different pmf!\n\nThe collection of all pmf’s for different values of the parameters is called a family of pmf’s"
  },
  {
    "objectID": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#binomial-family-of-rvs",
    "href": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#binomial-family-of-rvs",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Binomial family of RVs",
    "text": "Binomial family of RVs\n\n\n\n\nExample 2\n\n\nSuppose you toss \\(n\\) coins, each with probability of tails \\(p\\). If \\(X\\) is the number of tails, what is the pmf of \\(X\\)?"
  },
  {
    "objectID": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#bernoulli-family-of-rvs",
    "href": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#bernoulli-family-of-rvs",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Bernoulli family of RVs",
    "text": "Bernoulli family of RVs\n\n\n\n\nExample 3\n\n\nSuppose you toss 1 coin, with probability of tails \\(p\\). If \\(X\\) is the number of tails, what is the pmf of \\(X\\)?"
  },
  {
    "objectID": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#household-size-15",
    "href": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#household-size-15",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (1/5)",
    "text": "Household size (1/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nWhat is the sample space for household sizes?\nDefine the random variable for household sizes.\nDo the values in the table create a pmf? Why or why not?\nMake a plot of the pmf.\nWrite the cdf as a function.\nGraph the cdf of household sizes in 2019."
  },
  {
    "objectID": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#household-size-25",
    "href": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#household-size-25",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (2/5)",
    "text": "Household size (2/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nWhat is the sample space for household sizes?\nDefine the random variable for household sizes."
  },
  {
    "objectID": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#household-size-35",
    "href": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#household-size-35",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (3/5)",
    "text": "Household size (3/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nDo the values in the table create a pmf? Why or why not?\nMake a plot of the pmf"
  },
  {
    "objectID": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#what-is-a-cumulative-distribution-function",
    "href": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#what-is-a-cumulative-distribution-function",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "What is a cumulative distribution function?",
    "text": "What is a cumulative distribution function?\n\n\nDefinition: cumulative distribution function (CDF)\n\n\nThe cumulative distribution function (cdf) of a discrete r.v. \\(X\\) with pmf \\(p_X(x)\\), is defined for every value \\(x\\) by \\[F_X(x) = \\mathbb{P}(X \\leq x) = \\sum \\limits_{\\{all\\ y:\\ y\\leq x\\}}p_X(y)\\]"
  },
  {
    "objectID": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#household-size-45",
    "href": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#household-size-45",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (4/5)",
    "text": "Household size (4/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nWrite the cdf as a function."
  },
  {
    "objectID": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#household-size-55",
    "href": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#household-size-55",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (5/5)",
    "text": "Household size (5/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nGraph the cdf of household sizes in 2019."
  },
  {
    "objectID": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#properties-of-discrete-cdfs",
    "href": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#properties-of-discrete-cdfs",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Properties of discrete CDFs",
    "text": "Properties of discrete CDFs\n\n\\(F(x)\\) is increasing or flat (never decreasing)\n\\(\\min\\limits_x F(x) = 0\\)\n\\(\\max\\limits_xF(x)=1\\)\nCDF is a step function\n\n\n\nChapter 8 Slides"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability_muddy_points.html",
    "href": "lessons/02_Probability/02_Probability_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "The muddy points from this year were a subset of the ones from last year, so I just decided to copy those below!"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability_muddy_points.html#from-fall-2023",
    "href": "lessons/02_Probability/02_Probability_muddy_points.html#from-fall-2023",
    "title": "Muddy Points",
    "section": "",
    "text": "In class, we were wondering why/if \\(2^{|S|}\\) is the general formula for calculating the total number of possible events. We were specifically wondering if the \\(2\\) came from the fact that we had two options (heads and tails) for our outcome. Let’s work through the example of a 6-sided die to explain this further. The sample space is \\(S=\\{1, 2, 3, 4, 5, 6\\}\\). So is the total number of possible events \\(2^6\\) or \\(6^6\\) or something else? We can actually think about an event by using an indicator variable for each outcome of the sample space. An indicator variable is just a way to give us a yes/no answer to a question. So in this case, we are wondering: is this outcome a part of our event? If our event is \\(\\{1\\}\\) then for the outcome \\(1\\), the answer is “yes, the outcome is part of the event. For outcomes \\(2-6\\), the answer is”no, the outcome is not apart of the event.”\n\nFor each outcome, we have a “yes” or “no” answer. We can look at another example of an event. Let’s say our event is rolling an even number:\n\nFor \\(2\\), \\(4\\), and \\(6\\), the answer is “yes.” We can define the indicator variable for whether an outcome is in an event or not. The indicator gives a 1 or 0 for yes and no respectively.\n\nAs stated above, the \\(2\\) in \\(2^6\\) comes from the \\(2\\) options from our indicator. Each side has two options, and there are \\(6\\) sides. Thus, \\(2^6\\) possible events.\n\n\n\nI think this will become clearer when we start thinking about events in the context of probability. When we think of events outside of probability, we may think of something we actually do or something that happens, like going to a concert or coming to class or missing the streetcar. In this case, we think of the event as the single thing (out of all the options) that actually occured. For example, if I’m taking the streetcar to class, I can think of two definitive options of what might occur: I miss the streetcar or I get on the streetcar. Only one of these things can occur, which I may call an event colloquially.\nIt is important to make the distinction with events defined within probability. Events are not necessarily a single thing that occurred. Instead it can be a collection of things that may occur. In the example of the streetcar, I can define my event to include both options. Thus, my event is that I make the streetcar or I miss it. Both of these things cannot happen simultaneously, but if I want to calculate the probability that I miss or make the streetcar, then it is helpful to have the event defined.\n\n\n\nThis is in reference to the Chapter 1 notes on “BP example variation (3/3)” slide. I explained the event that at least one subject does not have high blood pressure using a venn diagram. In this venn diagram, I assumed \\(n=4\\), and I wanted to show that the union of complements is equal to the complement of unions: \\(\\bigcup\\limits_{i=1}^{n}H_i^C = \\Big(\\bigcap\\limits_{i=1}^{n}H_i\\Big)^C\\).\n\n Now we can look at \\(\\bigcup\\limits_{i=1}^{4}H_i^C\\). We first need to define \\(H_i^c\\)\n\n\n\n\n\n\nFurther explanations of the propositions can be found in the textbook from pages 24-27. For many of the explanations in class, I was working to produce a union of disjoint events, so that the probability could easily be calculated. Proposition 3 and 4 were specifically mentioned, so I will include some writing notes on them here:\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\nIn this proposition, I want to define event \\(B\\) as a union of disjoint events so that I can show \\(P(B)\\) is the sum of \\(P(A)\\) and some greater-than-or-equal-to 0 probability event. If the following is my venn diagram of A and B:\n\n\n\n\n\nThen I can define B as the union of disjoint events: \nIf we then take the probability of each side of the equation \\(B = A \\cup (A^c \\cap B)\\), we get \\[P(B) = P\\big(A \\cup (A^c \\cap B)\\big)\\]\nSince events \\(A\\) and \\(A^c \\cap B\\) are disjoint, the probability of their union is just: \\[P(A) + P(A^c \\cap B)\\]\nThus, our equation is now \\[P(B) = P(A) + P(A^c \\cap B)\\]\nFrom Axiom 1, we know for event \\(A^c \\cap B\\), \\(P(A^c \\cap B) \\geq 0\\).\nSo the probability of event B is the sum of the probability of event A and an event that is \\(\\geq\\) 0. This means \\(P(B) \\geq P(A)\\).\n\n\n\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)\n\n\nFrom the pictures above, we can see some similar disjoint events.\nIf we look back at \\(A \\cup B\\), we can start manipulating the right side of the equation:\n\n \n\n\n\n\nI will post this in the previous week’s Muddy Points as well. Please follow this link for my work through of the example. And here is the PDF with my work.\nSub-question: why don’t we just multiply the probability of A and B to get the intersection? This is a specific property of probability when A and B are independent. Only when A and B are independent can we conclude that \\(P(A \\cap B) = P(A)P(B)\\).\n\n\n\nWe’ve been working with event partitions throughout Chapter 2, but we have not formally identified them. Partitions are advantageous to define for two reasons:\n\nThe partitions may be easier to calculate. We can then use the partitions to reconstruct other probabilities that may be more difficult to calculate\nPartitions have nice properties as a consequence of being disjoint. For example, the probability of the union of partitions is the sum of the probabilities across each partition: \\[P\\bigg(\\bigcup_{i=1}^n A_i\\bigg) = P(A_1)P(A_2)P(A_3) \\cdot \\cdot \\cdot P(A_n)\\]"
  },
  {
    "objectID": "lessons/35_Normal_rv/35_Normal_rv.html",
    "href": "lessons/35_Normal_rv/35_Normal_rv.html",
    "title": "Chapter 35: Normal Random Variables",
    "section": "",
    "text": "Translate a word problem into probability within Normal RV\nCalculate probabilities within Normal RV using R\n\n\ncode.sourceCode {\n  font-size: 1.5em;\n  /* or try font-size: xx-large; */\n}"
  },
  {
    "objectID": "lessons/35_Normal_rv/35_Normal_rv.html#learning-objectives",
    "href": "lessons/35_Normal_rv/35_Normal_rv.html#learning-objectives",
    "title": "Chapter 35: Normal Random Variables",
    "section": "",
    "text": "Translate a word problem into probability within Normal RV\nCalculate probabilities within Normal RV using R\n\n\ncode.sourceCode {\n  font-size: 1.5em;\n  /* or try font-size: xx-large; */\n}"
  },
  {
    "objectID": "lessons/35_Normal_rv/35_Normal_rv.html#properties-of-normal-rvs",
    "href": "lessons/35_Normal_rv/35_Normal_rv.html#properties-of-normal-rvs",
    "title": "Chapter 35: Normal Random Variables",
    "section": "Properties of Normal RVs",
    "text": "Properties of Normal RVs\n\nNo scenario description here because the Normal distribution is so universal\n\nCentral Limit Theorem (next class) makes it applicable to many types of events\n\nShorthand: \\(X \\sim \\text{Normal}(\\mu, \\sigma^2)\\)\n\n\\[\nf_X(x) = \\dfrac{1}{\\sqrt{2\\pi \\sigma^2}}e^{-(x-\\mu)^2/(2\\sigma^2)} \\text{, for} -inf &lt; x &lt; inf\n\\]\n\\[\\text{E}(X) = \\mu \\] \\[\\text{Var}(X) = \\sigma^2\\]"
  },
  {
    "objectID": "lessons/35_Normal_rv/35_Normal_rv.html#helpful-r-code",
    "href": "lessons/35_Normal_rv/35_Normal_rv.html#helpful-r-code",
    "title": "Chapter 35: Normal Random Variables",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re measuring the high temperature today. The average high temperature on this day across many, many years is 50 degrees with a standard deviation of 4 degrees.\n\nIf we want to know the probability that the high temperature is below 45 degrees:\n\npnorm(q = 45, mean = 50, sd = 4)\n\n[1] 0.1056498\n\n\nIf we want to know the temoerature, say \\(t\\), where the probability of that the temperature is at \\(t\\) or lower is 0.35:\n\nqnorm(p = 0.35, mean = 50, sd = 4)\n\n[1] 48.45872\n\n\nIf we want to know the probability that the temperature is between 45 and 50 degrees:\n\npnorm(q = 50, mean = 50, sd = 4) - pnorm(q = 45, mean = 50, sd = 4)\n\n[1] 0.3943502\n\n\nIf we want to sample 20 days’ temperature (over the years) from the distribution:\n\nrnorm(n = 20, mean = 50, sd = 4)\n\n [1] 47.56260 48.59404 49.76717 54.10255 51.58408 45.16936 50.34457 48.08105\n [9] 58.04966 53.99631 54.19038 55.50139 47.56506 49.85627 48.58170 46.35353\n[17] 49.60928 49.79414 50.90292 54.39493"
  },
  {
    "objectID": "lessons/35_Normal_rv/35_Normal_rv.html#movie-night-while-studying",
    "href": "lessons/35_Normal_rv/35_Normal_rv.html#movie-night-while-studying",
    "title": "Chapter 35: Normal Random Variables",
    "section": "Movie night while studying",
    "text": "Movie night while studying\n\n\n\n\nExample 1\n\n\nChildren’s movies run an average of 98 minutes with a standard deviation of 10 minutes. You check out a random movie from the library to entertain your kids so you can study for your test. Assume that your kids will be occupied for the entire length of the movie.\n\nWhat is the probability that your kids will be occupied for at least the 2 hours you would like to study?\nWhat is range for the bottom quartile (lowest 25%) of time they will be occupied?"
  },
  {
    "objectID": "lessons/35_Normal_rv/35_Normal_rv.html#standard-normal-distribution",
    "href": "lessons/35_Normal_rv/35_Normal_rv.html#standard-normal-distribution",
    "title": "Chapter 35: Normal Random Variables",
    "section": "Standard Normal Distribution",
    "text": "Standard Normal Distribution\n\\[ Z \\sim \\text{Normal}(\\mu = 0, \\sigma^2 = 1)\\]\n\nUsed to be more helpful when computing was not as advanced\n\nUse tables of the standard normal\nYou can convert any normal distribution to a standard normal through transformation\n\n\\(Z = \\dfrac{X - \\mu_X}{\\sigma_X}\\)\n\nComes from \\(X = \\sigma_X Z + \\mu_X\\)\nSince \\(\\sigma_X\\) and \\(\\mu_X\\) are constants, then \\(E(X) = \\mu_X\\) and \\(SD(X) = \\sigma_X SD(Z) = \\sigma_X\\)"
  },
  {
    "objectID": "lessons/31_Uniform_rv/31_Uniform_rv.html",
    "href": "lessons/31_Uniform_rv/31_Uniform_rv.html",
    "title": "Chapter 31: Continuous Uniform Random Variables",
    "section": "",
    "text": "Identify the variable and the parameters in a story, and state in English what the variable and its parameters mean.\n\n\ncode.sourceCode {\n  font-size: 1.5em;\n  /* or try font-size: xx-large; */\n}"
  },
  {
    "objectID": "lessons/31_Uniform_rv/31_Uniform_rv.html#learning-objectives",
    "href": "lessons/31_Uniform_rv/31_Uniform_rv.html#learning-objectives",
    "title": "Chapter 31: Continuous Uniform Random Variables",
    "section": "",
    "text": "Identify the variable and the parameters in a story, and state in English what the variable and its parameters mean.\n\n\ncode.sourceCode {\n  font-size: 1.5em;\n  /* or try font-size: xx-large; */\n}"
  },
  {
    "objectID": "lessons/31_Uniform_rv/31_Uniform_rv.html#properties-of-continuous-uniform-rvs",
    "href": "lessons/31_Uniform_rv/31_Uniform_rv.html#properties-of-continuous-uniform-rvs",
    "title": "Chapter 31: Continuous Uniform Random Variables",
    "section": "Properties of continuous uniform RVs",
    "text": "Properties of continuous uniform RVs\n\nScenario: Events are equally likely to happen anywhere or anytime in an interval of values\nShorthand: \\(X \\sim \\text{U}[a,b]\\)\n\n\\[\nf_X(x) = \\dfrac{1}{b-a}, \\text{ for }a \\leq x \\leq b\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;a \\quad \\\\\n            \\dfrac{x-a}{b-a} & \\quad a \\leq x \\leq b\\quad \\\\\n            1 & \\quad x&gt;b \\quad\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{a+b}{2} \\text{, } \\text{ Var}(X) = \\dfrac{(b-a)^2}{12}\\]"
  },
  {
    "objectID": "lessons/31_Uniform_rv/31_Uniform_rv.html#identifying-continuous-uniform-rv-from-word-problems",
    "href": "lessons/31_Uniform_rv/31_Uniform_rv.html#identifying-continuous-uniform-rv-from-word-problems",
    "title": "Chapter 31: Continuous Uniform Random Variables",
    "section": "Identifying continuous uniform RV from word problems",
    "text": "Identifying continuous uniform RV from word problems\n\nLook for some indication that all events are equally likely\n\nCould also say “uniformly distributed”\n\nLook for an interval\n\nTime example: Costumer in your store will approach the cash register in next 30 minutes. Approaching the register throughout the 30 minutes is equally likely.\nLength example: You have a 12 inch string that you need to cut. You are equally likely to cut anywhere on the string.\n\nDifferent than the discrete uniform\n\nDiscrete usually includes a countable number of events that are equally likely\nContinuous is not countable\n\nExact time and length can be measured with infinite decimal places"
  },
  {
    "objectID": "lessons/31_Uniform_rv/31_Uniform_rv.html#helpful-r-code",
    "href": "lessons/31_Uniform_rv/31_Uniform_rv.html#helpful-r-code",
    "title": "Chapter 31: Continuous Uniform Random Variables",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re looking at equally likely arrival times between 10 am and 11 am.\n\nIf we want to know the probability that someone arrives at 10:30am or earlier:\n\npunif(q = 30, min = 0, max = 60)\n\n[1] 0.5\n\n\nIf we want to know the time, say \\(t\\), where the probability of arriving at \\(t\\) or earlier is 0.35:\n\nqunif(p = 0.35, min = 0, max = 60)\n\n[1] 21\n\n\nIf we want to know the probability that someone arrives between 10:14 and 10:16 am:\n\npunif(q = 16, min = 0, max = 60) - punif(q = 14, min = 0, max = 60)\n\n[1] 0.03333333\n\n\nIf we want to sample 20 arrival times from the distribution:\n\nrunif(n = 20, min = 0, max = 60)\n\n [1] 15.8421963 30.9208834 51.4621062  1.3592105 45.0488349 26.8564578\n [7]  3.6293578 37.1408808 54.7248642 48.2275393 20.1948650 31.1724125\n[13]  9.2623312 28.4292918 20.6505294  8.1207222 44.6161605 57.5359158\n[19] 44.7060820  0.6027594"
  },
  {
    "objectID": "lessons/31_Uniform_rv/31_Uniform_rv.html#bird-on-a-wire-tb-31.5",
    "href": "lessons/31_Uniform_rv/31_Uniform_rv.html#bird-on-a-wire-tb-31.5",
    "title": "Chapter 31: Continuous Uniform Random Variables",
    "section": "Bird on a wire (TB 31.5)",
    "text": "Bird on a wire (TB 31.5)\n\n\n\n\nExample 1\n\n\nA bird lands at a location that is Uniformly distributed along an electrical wire of length 150 feet. The wire is stretched tightly between two poles. What is the probability that the bird is 20 feet or less from one or the other of the poles?"
  },
  {
    "objectID": "lessons/04_Conditional_Probability/04_Conditional_Probability.html",
    "href": "lessons/04_Conditional_Probability/04_Conditional_Probability.html",
    "title": "Chapter 4: Conditional Probability",
    "section": "",
    "text": "Use set process to calculate probability of event of interest\nCalculate the probability of an event occurring, given that another event occurred.\nDefine keys facts for conditional probabilities using notation."
  },
  {
    "objectID": "lessons/04_Conditional_Probability/04_Conditional_Probability.html#learning-objectives",
    "href": "lessons/04_Conditional_Probability/04_Conditional_Probability.html#learning-objectives",
    "title": "Chapter 4: Conditional Probability",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nUse set process to calculate probability of event of interest\nCalculate the probability of an event occurring, given that another event occurred.\nDefine keys facts for conditional probabilities using notation."
  },
  {
    "objectID": "lessons/04_Conditional_Probability/04_Conditional_Probability.html#general-process-for-probability-word-problems",
    "href": "lessons/04_Conditional_Probability/04_Conditional_Probability.html#general-process-for-probability-word-problems",
    "title": "Chapter 4: Conditional Probability",
    "section": "General Process for Probability Word Problems",
    "text": "General Process for Probability Word Problems\n\nClearly define your events of interest\nTranslate question to probability using defined events OR Venn Diagram\nAsk yourself:\n\nAre we sampling with or without replacement?\nDoes order matter?\n\nUse axioms, properties, partitions, facts, etc. to define the end probability calculation into smaller parts\n\nIf probabilities are given to you, Venn Diagrams may help you parse out the events and probability calculations\nIf you need to find probabilities with counting, pictures or diagrams might help here\n\nWrite out a concluding statement that gives the probability context\n(For own check) Make sure the calculated probability follows the axioms. Is is between 0 and 1?"
  },
  {
    "objectID": "lessons/04_Conditional_Probability/04_Conditional_Probability.html#lets-revisit-our-deck-of-cards",
    "href": "lessons/04_Conditional_Probability/04_Conditional_Probability.html#lets-revisit-our-deck-of-cards",
    "title": "Chapter 4: Conditional Probability",
    "section": "Let’s revisit our deck of cards",
    "text": "Let’s revisit our deck of cards\n\n\n\n\nExample 1\n\n\nSuppose we randomly draw 2 cards from a standard deck of cards. What is the probability that we draw a spade then a heart?\n\n\nLet\n\nLet \\(A =\\) event \\(1^{st}\\) card is spades\nLet \\(B =\\) event \\(2^{nd}\\) card is heart"
  },
  {
    "objectID": "lessons/04_Conditional_Probability/04_Conditional_Probability.html#conditional-probability-facts-12",
    "href": "lessons/04_Conditional_Probability/04_Conditional_Probability.html#conditional-probability-facts-12",
    "title": "Chapter 4: Conditional Probability",
    "section": "Conditional Probability facts (1/2)",
    "text": "Conditional Probability facts (1/2)\n\n\n\n\nFact 1: General Multiplication Rule\n\n\n\\[\\mathbb{P}(A\\cap B)=\\mathbb{P}(A)\\cdot\\mathbb{P}(B|A)\\]\n\n\n\n\n\nFact 2: Conditional Probability Definition\n\n\n\\[\\mathbb{P}(A|B)=\\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)}\\]"
  },
  {
    "objectID": "lessons/04_Conditional_Probability/04_Conditional_Probability.html#conditional-probability-facts-22",
    "href": "lessons/04_Conditional_Probability/04_Conditional_Probability.html#conditional-probability-facts-22",
    "title": "Chapter 4: Conditional Probability",
    "section": "Conditional Probability facts (2/2)",
    "text": "Conditional Probability facts (2/2)\n\n\n\n\nFact 3\n\n\nIf \\(A\\) and \\(B\\) are independent events (\\(A \\unicode{x2AEB}B\\)), then \\[\\mathbb{P}(A|B) = \\mathbb{P}(A)\\]\n\n\n\n\n\nFact 4\n\n\n\\(\\mathbb{P}(A|B)\\) is a probability, meaning that it satisfies the probability axioms. In particular, \\[\\mathbb{P}(A|B) + \\mathbb{P}(A^C|B) = 1\\]"
  },
  {
    "objectID": "lessons/04_Conditional_Probability/04_Conditional_Probability.html#conditional-probability-with-two-dice",
    "href": "lessons/04_Conditional_Probability/04_Conditional_Probability.html#conditional-probability-with-two-dice",
    "title": "Chapter 4: Conditional Probability",
    "section": "Conditional probability with two dice",
    "text": "Conditional probability with two dice\n\n\n\n\nExample 2\n\n\nTwo dice (red and blue) are rolled. If the dice do not show the same face, what is the probability that one of the dice is a 1?\n\n\n\n\n\n\nChapter 4 Slides"
  },
  {
    "objectID": "lessons/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html",
    "href": "lessons/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "",
    "text": "Calculate the mean (expected value) of sums of discrete random variables"
  },
  {
    "objectID": "lessons/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#learning-objectives",
    "href": "lessons/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#learning-objectives",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate the mean (expected value) of sums of discrete random variables"
  },
  {
    "objectID": "lessons/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#revisiting-our-two-card-draw",
    "href": "lessons/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#revisiting-our-two-card-draw",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Revisiting our two card draw",
    "text": "Revisiting our two card draw\n\n\n\n\nExample 1\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw. Find \\(\\mathbb{E}[X]\\).\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "lessons/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#what-if-we-draw-a-lot-of-cards",
    "href": "lessons/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#what-if-we-draw-a-lot-of-cards",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "What if we draw A LOT of cards?",
    "text": "What if we draw A LOT of cards?\n\n\n\n\nExample 2\n\n\nWhat is the expected number of hearts in Example 1 if you draw 200 cards?\n\n\n\n\nRecall Binomial RV with \\(n=200\\):\n\\[p_X(x) = {200 \\choose x}p^x(1-p)^{200-x}\\] \\[\\text{  for } x = 0, 1, 2, ..., 200\\]"
  },
  {
    "objectID": "lessons/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#sum-of-discrete-rvs",
    "href": "lessons/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#sum-of-discrete-rvs",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Sum of discrete RVs",
    "text": "Sum of discrete RVs\n\n\nTheorem 11.1: Sum of discrete RVs\n\n\nFor discrete r.v.’s \\(X_i\\) and constants \\(a_i\\), \\(i=1,2,\\dots, n\\), \\[\\mathbb{E}\\Bigg[\\sum_{i=1}^n a_iX_i\\Bigg] = \\sum_{i=1}^n a_i\\mathbb{E}[X_i] .\\] Remark: The theorem holds for infinitely r.v.’s \\(X_i\\) as well.\n\n\n\nFor two RVs, \\(X\\) and \\(Y\\):\n\nWe can say \\(E[X+Y] = E[X] + E[Y]\\)\n… and constant numbers \\(a\\) and \\(b\\), we can also say \\(E[aX+bY] = aE[X] + bE[Y]\\)\nWe can also also say \\(E[X-Y] = E[X] - E[Y]\\), since \\(b=-1\\)"
  },
  {
    "objectID": "lessons/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#corollaries-from-thm-11.1",
    "href": "lessons/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#corollaries-from-thm-11.1",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Corollaries from Thm 11.1",
    "text": "Corollaries from Thm 11.1\n\n\n\n\nCorollary 11.1.1\n\n\nFor a discrete r.v. \\(X\\), and constants \\(a\\) and \\(b\\), \\[\\mathbb{E}[aX+b] = a\\mathbb{E}[X] + b.\\]\n\n\n\n\n\nCorollary 11.1.2\n\n\nIf \\(X_i\\), \\(i=1,2,\\dots, n\\), are identically distributed r.v.’s, then \\[\\mathbb{E}\\bigg[\\sum_{i=1}^n X_i\\bigg] = n\\mathbb{E}[X_1] .\\]"
  },
  {
    "objectID": "lessons/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#revisiting-our-ghost",
    "href": "lessons/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#revisiting-our-ghost",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Revisiting our ghost! 👻",
    "text": "Revisiting our ghost! 👻\n\n\n\n\nExample 3\n\n\nThe ghost is trick-or-treating at a different house now. In this case it is known that the bag of candy has 10 chocolates, 20 lollipops, and 30 laffy taffies. The ghost grabs a handful of five pieces of candy. How many pieces of chocolate do we expect the ghost to take?"
  },
  {
    "objectID": "lessons/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#cost-of-hotel-rooms",
    "href": "lessons/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#cost-of-hotel-rooms",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Cost of hotel rooms",
    "text": "Cost of hotel rooms\n\n\n\n\nExample 4\n\n\nA tour group is planning a visit to the city of Minneapolis and needs to book 30 hotel rooms. The average price of a room is $200. In addition, there is a 10% tourism tax for each room. What is the expected cost for the 30 hotel rooms?\n\n\n\n\n\n\nChapter 11 Slides"
  },
  {
    "objectID": "lessons/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html",
    "href": "lessons/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "",
    "text": "Calculate expected value of functions of RVs\nCalculate variance of RVs"
  },
  {
    "objectID": "lessons/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#learning-objectives",
    "href": "lessons/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#learning-objectives",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate expected value of functions of RVs\nCalculate variance of RVs"
  },
  {
    "objectID": "lessons/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#expected-value-of-a-function-of-a-continuous-rv",
    "href": "lessons/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#expected-value-of-a-function-of-a-continuous-rv",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Expected value of a function of a continuous RV",
    "text": "Expected value of a function of a continuous RV\n\n\nHow do we calculate the expected value of a function of a discrete RV or joint RVs?\n   \nFor discrete RVs:\n\\[\\mathbb{E}[g(X)] = \\sum_{\\{all\\ x\\}}\\ g(x) p_X(x).\\] \\[\\mathbb{E}[g(X, Y)] = \\sum_{\\{all\\ x\\}}\\sum_{\\{all\\ y\\}}\\ g(x,y) p_{X,Y}(x,y).\\]\n\n\n\nHow do we calculate the expected value of a function of a continuous RV or joint RVs?\n   \nFor continuous RVs:"
  },
  {
    "objectID": "lessons/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#expected-value-from-a-joint-pdf",
    "href": "lessons/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#expected-value-from-a-joint-pdf",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Expected value from a joint pdf",
    "text": "Expected value from a joint pdf\n\n\n\n\nExample 1\n\n\nLet \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#remark-on-expected-value-of-one-rv-from-joint-pdf",
    "href": "lessons/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#remark-on-expected-value-of-one-rv-from-joint-pdf",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Remark on expected value of one RV from joint pdf",
    "text": "Remark on expected value of one RV from joint pdf\nIf you are given \\(f_{X,Y}(x,y)\\) and want to calculate \\(\\mathbb{E}[X]\\), you have two options:\n\nFind \\(f_X(x)\\) and use it to calculate \\(\\mathbb{E}[X]\\).\nOr, calculate \\(\\mathbb{E}[X]\\) using the joint density: \\[\\mathbb{E}[X] = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}x f_{X,Y}(x,y)dydx.\\]"
  },
  {
    "objectID": "lessons/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#important-properties-of-expected-values-of-functions-of-continuous-rvs",
    "href": "lessons/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#important-properties-of-expected-values-of-functions-of-continuous-rvs",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Important properties of expected values of functions of continuous RVs",
    "text": "Important properties of expected values of functions of continuous RVs\n\n\n\n\nFunction of RV with two constants\n\n\n\\(\\mathbb{E}[aX+b] =a\\mathbb{E}[X]+b\\)\n\n\n\n\nFunction of two RVs added\n\n\n\\(\\mathbb{E}[X+Y] =\\mathbb{E}[X]+\\mathbb{E}[Y]\\)\n\n\n\n\nExpected value of sum of independent RVs pt 1\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are continuous RVs and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\[\\mathbb{E}\\Bigg[\\sum_{i=1}^{n} a_i X_i\\Bigg] = \\sum_{i=1}^{n}a_i\\mathbb{E}[X_i]\\]\n\n\n\n\n\nExpected value of multiplication of function of independent RVs\n\n\nIf \\(X\\) and \\(Y\\) are independent continuous RVs, and \\(g\\) and \\(h\\) are functions, then \\[\\mathbb{E}[g(X)h(Y)] =\\mathbb{E}[g(X)]\\mathbb{E}[h(Y)]\\]\n\n\n\n\nExpected value of multiplication of independent RVs\n\n\nIf \\(X\\) and \\(Y\\) are independent continuous RVs, then \\[\\mathbb{E}[XY] = \\mathbb{E}[X] \\mathbb{E}[Y] \\]"
  },
  {
    "objectID": "lessons/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-continuous-rvs",
    "href": "lessons/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-continuous-rvs",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Variance of continuous RVs",
    "text": "Variance of continuous RVs\n\n\nHow do we calculate the variance of a discrete RV?\n   \nFor discrete RVs:\n\\[\n\\begin{align}\nVar(X) & =\n\\mathbb{E}[(X-\\mu_X)^2] \\\\ & = \\mathbb{E}[(X-\\mathbb{E}[X])^2] \\\\ &= \\mathbb{E}[X^2]-(\\mathbb{E}[X])^2 \\\\ & = \\sum_{\\{all\\ x\\}}(x-\\mu_x)^2 p_{X}(x)\n\\end{align}\n\\]\n\n\n\nHow do we calculate the variance of a continuous RV?\n    \nFor continuous RVs:"
  },
  {
    "objectID": "lessons/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-an-uniform-distribution",
    "href": "lessons/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-an-uniform-distribution",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Variance of an Uniform distribution",
    "text": "Variance of an Uniform distribution\n\n\n\n\nExample 2\n\n\nLet \\(f_X(x)= \\frac{1}{b-a}\\), for \\(a \\leq x \\leq b\\). Find \\(Var[X]\\)."
  },
  {
    "objectID": "lessons/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-exponential-distribution",
    "href": "lessons/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-exponential-distribution",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Variance of exponential distribution",
    "text": "Variance of exponential distribution\n\n\nIn the homework:\n\n\nExample 3\n\n\nLet \\(f_X(x)= \\lambda e^{-\\lambda x}\\), for \\(x &gt; 0\\) and \\(\\lambda&gt; 0\\). Find \\(Var[X]\\)."
  },
  {
    "objectID": "lessons/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#important-properties-of-variances-of-continuous-rvs",
    "href": "lessons/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#important-properties-of-variances-of-continuous-rvs",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Important properties of variances of continuous RVs",
    "text": "Important properties of variances of continuous RVs\n\n\n\n\nFunction of RV with two constants\n\n\n\\[Var[aX+b] = a^2Var[X]\\]\n\n\n\n\n\nVariance of sum of independent RVs pt 1\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous RVs and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\[Var\\Bigg(\\sum_{i=1}^{n} a_i X_i\\Bigg) =\\sum_{i=1}^{n} a^2_i Var(X_i)\\]\n\n\n\n\nVariance of sum of independent RVs pt 2\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous RVs, then \\[Var\\Bigg(\\sum_{i=1}^{n} X_i\\Bigg) = \\sum_{i=1}^{n} Var(X_i)\\]"
  },
  {
    "objectID": "lessons/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#find-the-mean-and-sd-from-word-problem",
    "href": "lessons/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#find-the-mean-and-sd-from-word-problem",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Find the mean and sd from word problem",
    "text": "Find the mean and sd from word problem\n\n\n\n\nExample 4\n\n\nA machine manufactures cubes with a side length that varies uniformly from 1 to 2 inches. Assume the sides of the base and height are equal. The cost to make a cube is 10 ¢ per cubic inch, and 5 ¢ cents for the general cost per cube. Find the mean and standard deviation of the cost to make 10 cubes.\n\n\n\n\n\n\nChapter 29 Slides"
  },
  {
    "objectID": "lessons/00_Intro/00_Intro.html",
    "href": "lessons/00_Intro/00_Intro.html",
    "title": "Welcome to BSTA 550!",
    "section": "",
    "text": "Call me “Nicky,” “Dr. W,” “Professor Wakim,” or any combo!\nAssistant Professor of Biostatistics\n \nGrew up in DC area (Virginia side!)\nMoved here from Michigan around 2 years ago\nTwo sweet kitties\nVolleyball, pickleball, ceramics, strolling around my neighborhood\nBut also sleeping, TV, and reading\nProud plant mamma\nA few other things about myself that I will share non-publicly\n\n\n\n\n Video"
  },
  {
    "objectID": "lessons/00_Intro/00_Intro.html#nicky-wakim-sheher",
    "href": "lessons/00_Intro/00_Intro.html#nicky-wakim-sheher",
    "title": "Welcome to BSTA 550!",
    "section": "Nicky Wakim (she/her)",
    "text": "Nicky Wakim (she/her)\n\n\n\nCall me “Nicky,” “Dr. W,” “Professor Wakim,” or any combo!\nAssistant Professor of Biostatistics\n \nGrew up in DC area (Virginia side!)\nMoved here from Michigan around 2 years ago\nTwo sweet kitties\nVolleyball, pickleball, ceramics, strolling around my neighborhood\nBut also sleeping, TV, and reading\nProud plant mamma\nA few other things about myself that I will share non-publicly\n\n\n\n\n Video"
  },
  {
    "objectID": "lessons/00_Intro/00_Intro.html#some-important-tasks",
    "href": "lessons/00_Intro/00_Intro.html#some-important-tasks",
    "title": "Welcome to BSTA 550!",
    "section": "Some important tasks",
    "text": "Some important tasks\n\nStar the class website: https://nwakim.github.io/BSTA_550_25F/\n\n \n\nComplete Homework 0 by this Thursday at 11pm!\n\nIncludes office hours set up, attendance prefereance, and homework due date decision\nThink about what day of the week you would like your homeworks due\n\n\n \n\nHighly suggest that you make an appointment with a learning specialist through Student Academic Success Center!"
  },
  {
    "objectID": "lessons/00_Intro/00_Intro.html#lets-visit-the-website",
    "href": "lessons/00_Intro/00_Intro.html#lets-visit-the-website",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website",
    "text": "Let’s visit the website\n\nHomepage\nSyllabus\nSchedule\n\nWeeks, class info, exams, homeworks\n\nSearch"
  },
  {
    "objectID": "lessons/00_Intro/00_Intro.html#lets-go-through-the-syllabus",
    "href": "lessons/00_Intro/00_Intro.html#lets-go-through-the-syllabus",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s go through the syllabus!",
    "text": "Let’s go through the syllabus!\nSyllabus page"
  },
  {
    "objectID": "lessons/00_Intro/00_Intro.html#structure-for-this-course",
    "href": "lessons/00_Intro/00_Intro.html#structure-for-this-course",
    "title": "Welcome to BSTA 550!",
    "section": "Structure for this course",
    "text": "Structure for this course\n\nLearning the basic tools to understand statistics\n\nThis is the first quarter that I am adding simulations\nSo I rearranged a lot of the topics!\n\n\n \n\nIt is going to feel useless at times, but I swear it is not!\n\n \n\nThis class will help you build a toolbox that allows you to analyze data while understanding the inner theory at play\nYou can use probability and simulations to change your analysis as you need"
  },
  {
    "objectID": "lessons/28_Expected_Values/28_Expected_Values.html",
    "href": "lessons/28_Expected_Values/28_Expected_Values.html",
    "title": "Chapter 28: Expected Values of Continuous Random Variables",
    "section": "",
    "text": "Calculated mean (expected value) of a continuous RV"
  },
  {
    "objectID": "lessons/28_Expected_Values/28_Expected_Values.html#learning-objectives",
    "href": "lessons/28_Expected_Values/28_Expected_Values.html#learning-objectives",
    "title": "Chapter 28: Expected Values of Continuous Random Variables",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate the mean (expected value) of a continuous RV"
  },
  {
    "objectID": "lessons/28_Expected_Values/28_Expected_Values.html#expected-value-of-a-function-of-a-continuous-rv",
    "href": "lessons/28_Expected_Values/28_Expected_Values.html#expected-value-of-a-function-of-a-continuous-rv",
    "title": "Chapter 28: Expected Values of Continuous Random Variables",
    "section": "Expected value of a function of a continuous RV",
    "text": "Expected value of a function of a continuous RV\n\n\nHow do we calculate expected values of discrete RVs?\n       \nFor discrete RVs: weight average \\[\\mathbb{E}[X] = \\sum_{i=1}^n x_ip_X(x_i).\\]\n\n\n\nHow do we calculate expected values of continuous RVs?\n       \nFor continuous RVs:"
  },
  {
    "objectID": "lessons/28_Expected_Values/28_Expected_Values.html#expected-value-of-the-uniform-distribution",
    "href": "lessons/28_Expected_Values/28_Expected_Values.html#expected-value-of-the-uniform-distribution",
    "title": "Chapter 28: Expected Values of Continuous Random Variables",
    "section": "Expected Value of the Uniform Distribution",
    "text": "Expected Value of the Uniform Distribution\n\n\n\n\nExample 1\n\n\nLet \\(f_X(x)= \\frac{1}{b-a}\\), for \\(a \\leq x \\leq b\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons/28_Expected_Values/28_Expected_Values.html#expected-value-of-the-exponential-distribution",
    "href": "lessons/28_Expected_Values/28_Expected_Values.html#expected-value-of-the-exponential-distribution",
    "title": "Chapter 28: Expected Values of Continuous Random Variables",
    "section": "Expected Value of the Exponential Distribution",
    "text": "Expected Value of the Exponential Distribution\n\n\n\n\nExample 2\n\n\nLet \\(f_X(x)= \\lambda e^{-\\lambda x}\\), for \\(x &gt; 0\\) and \\(\\lambda&gt; 0\\). Find \\(\\mathbb{E}[X]\\).\n\n\n\n\nIntegrating by Parts\n\n\n\\(\\displaystyle\\int_a^b u dv = uv\\bigg|^b_a - \\displaystyle\\int_a^b vdu\\)\n\n\n\n\n\n\nChapter 28 Slides"
  },
  {
    "objectID": "lessons/28_Expected_Values/28_Expected_Values.html#expected-value-from-a-joint-distribution",
    "href": "lessons/28_Expected_Values/28_Expected_Values.html#expected-value-from-a-joint-distribution",
    "title": "Chapter 28: Expected Values of Continuous Random Variables",
    "section": "Expected value from a joint distribution",
    "text": "Expected value from a joint distribution\n\n\n\n\nExample 3\n\n\nLet \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\).\n\n\n\n\n\n\nChapter 28 Slides"
  },
  {
    "objectID": "lessons/43_02_Moment_Generating_Functions/43_Moment_Generating_Functions_Part2.html",
    "href": "lessons/43_02_Moment_Generating_Functions/43_Moment_Generating_Functions_Part2.html",
    "title": "Chapter 43: Moment Generating Functions Part 2",
    "section": "",
    "text": "Chapter 43: Moment Generating Functions Part 2\nRecap: What is an mgf?\n\nExample 1.   Let \\(X\\) be a random variable with mgf \\[M_X(t)= \\frac{1}{5}e^t + \\frac{3}{10}e^{2t} + \\frac{1}{2}e^{3t}.\\] Find the pmf or pdf of \\(X\\).\n\n\nExample 2.   Let \\(X\\) be a normal random variable with mean \\(\\mu\\) and variance \\(\\sigma^2\\), i.e. \\(X \\sim N(\\mu,\\sigma^2)\\).\n\nFind the mgf of \\(X\\).\nFind \\(\\mathbb{E}[X]\\).\nFind \\(Var(X)\\).\n\n\n\n\nTheorem 3.   Let \\(X\\) have mgf \\(M_X(t)\\), and let \\(Y=aX+b\\), where \\(a\\) and \\(b\\) are constants. Then \\[M_Y(t)=\\]\n\n\nProof. Proof. ◻\n\nQuestion: Do linear transformations always preserve the distribution type?\nI.e., if \\(X\\) has a certain probability distribution, does \\(aX+b\\) always have the same distribution type?\n\n\nExample 4.   Let \\(X \\sim U[0,1]\\), and \\(Y = 2X+3\\). Is \\(Y\\) also a uniform rv? If so, what are its parameters?\n\n\nExample 5.   Let \\(X \\sim Exp(\\lambda=5)\\), and \\(Y = 2X+3\\). Is \\(Y\\) also an exponential rv? If so, what is its parameter?\n\nMgf’s of Sums of Independent rv’s\n\n\nTheorem 6.   Let \\(X_1, X_2, \\ldots, X_n\\) be independent rv’s with respective mgf’s \\(M_{X_i}(t)\\), for \\(i=1,2,\\ldots,n\\). Let \\(Y=\\sum_{i=1}^n a_iX_i\\), where \\(a_i\\) are constants. Then \\[M_Y(t)= %\\Pi_{i=1}^n M_{X_i}(a_it).\\]\n\n\nProof. Proof. ◻\n\n\n\nExample 7.   Let \\(X_i \\sim N(\\mu_i, \\sigma_i^2)\\) be independent normal rv’s. What is the distribution of  \\(Y=\\sum_{i=1}^n X_i\\)?\n\n\n\nExample 8.   Let \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). What is the distribution of  \\(\\bar{X}=\\frac{\\sum_{i=1}^n X_i}{n}\\)?\n\n\nExample 9.   Let \\(Z\\) be a standard normal random variable, i.e. \\(Z \\sim N(0,1)\\). Show that \\(Z^2 \\sim \\chi_1^2\\), i.e. is a chi-squared rv with 1 degree of freedom."
  },
  {
    "objectID": "lessons/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html",
    "href": "lessons/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "",
    "text": "Calculate probability of a sample mean using a population mean and variance with unknown distribution\nUse the Central Limit Theorem to construct the Normal approximation of the Binomial and Poisson distributions"
  },
  {
    "objectID": "lessons/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#learning-objectives",
    "href": "lessons/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#learning-objectives",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate probability of a sample mean using a population mean and variance with unknown distribution\nUse the Central Limit Theorem to construct the Normal approximation of the Binomial and Poisson distributions"
  },
  {
    "objectID": "lessons/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#the-central-limit-theorem",
    "href": "lessons/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#the-central-limit-theorem",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\n\n\nTheorem 1: Central Limit Theorem (CLT)\n\n\nLet \\(X_i\\) be iid rv’s with common mean \\(\\mu\\) and variance \\(\\sigma^2\\), for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\rightarrow \\text{N}(n\\mu, n\\sigma^2)\\]"
  },
  {
    "objectID": "lessons/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#extension-of-the-clt",
    "href": "lessons/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#extension-of-the-clt",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "Extension of the CLT",
    "text": "Extension of the CLT\n\n\nCorollary 1\n\n\nLet \\(X_i\\) be iid rv’s with common mean \\(\\mu\\) and variance \\(\\sigma^2\\), for \\(i=1,2,\\ldots,n\\). Then \\[\\overline{X}=\\frac{\\sum_{i=1}^n X_i}{n}  \\rightarrow \\text{N}\\Bigg(\\mu, \\dfrac{\\sigma^2}{n}\\Bigg)\\]"
  },
  {
    "objectID": "lessons/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#example-of-corollary-in-use",
    "href": "lessons/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#example-of-corollary-in-use",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "Example of Corollary in use",
    "text": "Example of Corollary in use\n\n\n\n\nExample 1\n\n\nAccording to a large US study, the mean resting heart rate of adult women is about 74 beats per minutes (bpm), with standard deviation 13 bpm (NHANES 2003-2004).\n\nFind the probability that the average resting heart rate for a random sample of 36 adult women is more than 3 bpm away from the mean.\nRepeat the previous question for a single adult woman."
  },
  {
    "objectID": "lessons/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#example-of-clt-for-exponential-distribution",
    "href": "lessons/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#example-of-clt-for-exponential-distribution",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "Example of CLT for exponential distribution",
    "text": "Example of CLT for exponential distribution\n\n\n\n\nExample 2\n\n\nLet \\(X_i \\sim Exp(\\lambda)\\) be iid RVs for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\rightarrow\\]"
  },
  {
    "objectID": "lessons/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#clt-for-discrete-rvs",
    "href": "lessons/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#clt-for-discrete-rvs",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "CLT for Discrete RVs",
    "text": "CLT for Discrete RVs\n\n\n\nBinomial rv’s: Let \\(X \\sim Bin(n,p)\\)\n\n\\(X = \\displaystyle\\sum_{i=1}^n X_i\\), where \\(X_i\\) are iid \\(\\text{Bernoulli}(p)\\)\nRule of thumb: \\(np\\geq10\\) and \\(n(1-p)\\geq 10\\) to use Normal approximation\n\n\n\n\n\n\nPoisson rv’s: Let \\(X \\sim Poisson(\\lambda)\\)\n\n\\(X = \\displaystyle\\sum_{i=1}^n X_i\\), where \\(X_i\\) are iid \\(\\text{Poiss}(1)\\)\nRecall from Chapter 18 that if \\(X_i \\sim Poiss(\\lambda_i)\\) and \\(X_i\\) independent, then \\(\\sum_{i=1}^n X_i \\sim Poiss(\\sum_{i=1}^n \\lambda_i)\\)\nRule of thumb: \\(\\lambda \\geq10\\) to use Normal approximation"
  },
  {
    "objectID": "lessons/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#at-home-example",
    "href": "lessons/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#at-home-example",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "At home example",
    "text": "At home example\n\n\nExample 3\n\n\nSuppose that the probability of developing a specific type of breast cancer in women aged 40-49 is 0.001. Assume the occurrences of cancer are independent. Suppose you have data from a random sample of 20,000 women aged 40-49.\n\nHow many of the 20,000 women would you expect to develop this type of breast cancer, and what is the standard deviation?\nFind the exact probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to find the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to approximate the following probabilities, where \\(X\\) is the number of women that will develop this type of breast cancer.\n\n\\(\\mathbb{P}(15 \\leq X \\leq 22)\\)\n\\(\\mathbb{P}(X &gt; 20)\\)\n\\(\\mathbb{P}(X &lt; 20)\\)\n\nFind the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer - not using the CLT!\nUse the CLT to approximate the approximate probability in the previous question!\n\n\n\n\n\nChapter 37 Slides"
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rv.html",
    "href": "lessons/26_Independent_rvs/26_Independent_rv.html",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "",
    "text": "Show that a joint pdf consists of two independent, continuous RVs.\nCombine two independent RVs into one joint pdf or CDF."
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rv.html#learning-objectives",
    "href": "lessons/26_Independent_rvs/26_Independent_rv.html#learning-objectives",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nShow that a joint pdf consists of two independent, continuous RVs.\nCombine two independent RVs into one joint pdf or CDF."
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rv.html#how-do-we-represent-independent-continuous-rvs-in-a-joint-pdf",
    "href": "lessons/26_Independent_rvs/26_Independent_rv.html#how-do-we-represent-independent-continuous-rvs-in-a-joint-pdf",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "How do we represent independent continuous RVs in a joint pdf?",
    "text": "How do we represent independent continuous RVs in a joint pdf?\n\n\nWhat do we know about independence for events and discrete RVs?\nFor events: If \\(A \\perp B\\)\n\\[P(A \\cap B) = P(A)P(B)\\] \\[P(A|B) = P(A)\\]\nFor discrete RVs: If \\(X \\perp Y\\) \\[p_{X,Y}(x,y) = p_{X}(x)p_{Y}(y)\\] \\[F_{X,Y}(x,y) = F_{X}(x)F_{Y}(y)\\] \\[p_{X|Y}(x|y) = p_{X}(x)\\] \\[p_{Y|X}(y|x) = p_{Y}(y)\\]\n\n\n\nWhat does it mean for continuous r.v.’s to be independent?\nFor continuous RVs: If \\(X \\perp Y\\)"
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rv.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs",
    "href": "lessons/26_Independent_rvs/26_Independent_rv.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Constructing a joint pdf from two independent, continuous RVs",
    "text": "Constructing a joint pdf from two independent, continuous RVs\n\n\n\n\nExample 1.1\n\n\nLet \\(X\\) and \\(Y\\) be independent r.v.’s with \\(f_X(x)= \\frac12\\), for \\(0 \\leq x \\leq 2\\) and \\(f_Y(y)= 3y^2\\), for \\(0 \\leq y \\leq 1\\).\n\nFind \\(f_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rv.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs-1",
    "href": "lessons/26_Independent_rvs/26_Independent_rv.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs-1",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Constructing a joint pdf from two independent, continuous RVs",
    "text": "Constructing a joint pdf from two independent, continuous RVs\n\n\n\n\nExample 1.2\n\n\nLet \\(X\\) and \\(Y\\) be independent r.v.’s with \\(f_X(x)= \\frac12\\), for \\(0 \\leq x \\leq 2\\) and \\(f_Y(y)= 3y^2\\), for \\(0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)."
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rv.html#showing-independence-from-joint-pdf",
    "href": "lessons/26_Independent_rvs/26_Independent_rv.html#showing-independence-from-joint-pdf",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Showing independence from joint pdf",
    "text": "Showing independence from joint pdf\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for \\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\).\n\nAre \\(X\\) and \\(Y\\) independent?"
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rv.html#showing-independence-from-joint-pdf-1",
    "href": "lessons/26_Independent_rvs/26_Independent_rv.html#showing-independence-from-joint-pdf-1",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Showing independence from joint pdf",
    "text": "Showing independence from joint pdf\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 3\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Are \\(X\\) and \\(Y\\) independent?"
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rv.html#example",
    "href": "lessons/26_Independent_rvs/26_Independent_rv.html#example",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Example",
    "text": "Example\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 3\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Are \\(X\\) and \\(Y\\) independent?"
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rv.html#final-statement-on-independence",
    "href": "lessons/26_Independent_rvs/26_Independent_rv.html#final-statement-on-independence",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Final statement on independence",
    "text": "Final statement on independence\n\nIf \\(f_{X,Y}(x,y)= g(x)h(y)\\), where \\(g(x)\\) and \\(h(y)\\) are pdf’s, then \\(X\\) and \\(Y\\) are independent.\n\nThe domain of the joint pdf needs to be independent as well!!\n\n\n       \n\nIf \\(F_{X,Y}(x,y)= G(x)H(y)\\), where \\(G(x)\\) and \\(H(y)\\) are cdf’s, then \\(X\\) and \\(Y\\) are independent.\n\nThe domain of the joint CDF needs to be independent as well!!\n\n\n\n\nChapter 26 Slides"
  },
  {
    "objectID": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample_muddy_points.html",
    "href": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "1. Why is the number of possible events \\(2^{|S|}\\)?\nIn class, we were wondering why/if \\(2^{|S|}\\) is the general formula for calculating the total number of possible events. We were specifically wondering if the \\(2\\) came from the fact that we had two options (heads and tails) for our outcome. Let’s work through the example of a 6-sided die to explain this further. The sample space is \\(S=\\{1, 2, 3, 4, 5, 6\\}\\). So is the total number of possible events \\(2^6\\) or \\(6^6\\) or something else? We can actually think about an event by using an indicator variable for each outcome of the sample space. An indicator variable is just a way to give us a yes/no answer to a question. So in this case, we are wondering: is this outcome a part of our event? If our event is \\(\\{1\\}\\) then for the outcome \\(1\\), the answer is “yes, the outcome is part of the event. For outcomes \\(2-6\\), the answer is”no, the outcome is not apart of the event.”\n\nFor each outcome, we have a “yes” or “no” answer. We can look at another example of an event. Let’s say our event is rolling an even number:\n\nFor \\(2\\), \\(4\\), and \\(6\\), the answer is “yes.” We can define the indicator variable for whether an outcome is in an event or not. The indicator gives a 1 or 0 for yes and no respectively.\n\nAs stated above, the \\(2\\) in \\(2^6\\) comes from the \\(2\\) options from our indicator. Each side has two options, and there are \\(6\\) sides. Thus, \\(2^6\\) possible events.\n\n\n2. What is an event??\nI think this will become clearer when we start thinking about events in the context of probability. When we think of events outside of probability, we may think of something we actually do or something that happens, like going to a concert or coming to class or missing the streetcar. In this case, we think of the event as the single thing (out of all the options) that actually occured. For example, if I’m taking the streetcar to class, I can think of two definitive options of what might occur: I miss the streetcar or I get on the streetcar. Only one of these things can occur, which I may call an event colloquially.\nIt is important to make the distinction with events defined within probability. Events are not necessarily a single thing that occurred. Instead it can be a collection of things that may occur. In the example of the streetcar, I can define my event to include both options. Thus, my event is that I make the streetcar or I miss it. Both of these things cannot happen simultaneously, but if I want to calculate the probability that I miss or make the streetcar, then it is helpful to have the event defined.\n\nAnd what is the difference between event and outcome?\nAn outcome is a single result. The two options in the above example, missing the streetcar or getting on the streetcar, are two potential outcomes. Events are the collection of 0, 1, or more outcomes. So the possible events are: the empty set, missing the streetcar, getting on the streetcar, or the set of missing the streetcar and getting on the streetcar.\n\n\n\n3. Confusion on the Venn Diagram for the high blood pressure example\nThis is in reference to the Chapter 1 notes on “BP example variation (3/3)” slide. I explained the event that at least one subject does not have high blood pressure using a venn diagram. In this venn diagram, I assumed \\(n=4\\), and I wanted to show that the union of complements is equal to the complement of unions: \\(\\bigcup\\limits_{i=1}^{n}H_i^C = \\Big(\\bigcap\\limits_{i=1}^{n}H_i\\Big)^C\\).\n\n Now we can look at \\(\\bigcup\\limits_{i=1}^{4}H_i^C\\). We first need to define \\(H_i^c\\)\n\n\n\n\n\n4. Proofs of propositions\nFurther explanations of the propositions can be found in the textbook from pages 24-27. For many of the explanations in class, I was working to produce a union of disjoint events, so that the probability could easily be calculated. Proposition 3 and 4 were specifically mentioned, so I will include some writing notes on them here:\n\nProposition 3\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\nIn this proposition, I want to define event \\(B\\) as a union of disjoint events so that I can show \\(P(B)\\) is the sum of \\(P(A)\\) and some greater-than-or-equal-to 0 probability event. If the following is my venn diagram of A and B:\n\n\n\n\n\nThen I can define B as the union of disjoint events: \nIf we then take the probability of each side of the equation \\(B = A \\cup (A^c \\cap B)\\), we get \\[P(B) = P\\big(A \\cup (A^c \\cap B)\\big)\\]\nSince events \\(A\\) and \\(A^c \\cap B\\) are disjoint, the probability of their union is just: \\[P(A) + P(A^c \\cap B)\\]\nThus, our equation is now \\[P(B) = P(A) + P(A^c \\cap B)\\]\nFrom Axiom 1, we know for event \\(A^c \\cap B\\), \\(P(A^c \\cap B) \\geq 0\\).\nSo the probability of event B is the sum of the probability of event A and an event that is \\(\\geq\\) 0. This means \\(P(B) \\geq P(A)\\).\n\n\nProposition 4\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)\n\n\nFrom the pictures above, we can see some similar disjoint events.\nIf we look back at \\(A \\cup B\\), we can start manipulating the right side of the equation:\n\n \n\n\n\n5. Example at end of Chapter 2 slides (Venn Diagram)\nI will post this in the previous week’s Muddy Points as well. Please follow this link for my work through of the example. And here is the PDF with my work.\nSub-question: why don’t we just multiply the probability of A and B to get the intersection? This is a specific property of probability when A and B are independent. Only when A and B are independent can we conclude that \\(P(A \\cap B) = P(A)P(B)\\).\n\n\n6. Partition of events\nWe’ve been working with event partitions throughout Chapter 2, but we have not formally identified them. Partitions are advantageous to define for two reasons:\n\nThe partitions may be easier to calculate. We can then use the partitions to reconstruct other probabilities that may be more difficult to calculate\nPartitions have nice properties as a consequence of being disjoint. For example, the probability of the union of partitions is the sum of the probabilities across each partition: \\[P\\bigg(\\bigcup_{i=1}^n A_i\\bigg) = P(A_1)P(A_2)P(A_3) \\cdot \\cdot \\cdot P(A_n)\\]"
  },
  {
    "objectID": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample_muddy_points.html#from-fall-2023",
    "href": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample_muddy_points.html#from-fall-2023",
    "title": "Muddy Points",
    "section": "",
    "text": "In class, we were wondering why/if \\(2^{|S|}\\) is the general formula for calculating the total number of possible events. We were specifically wondering if the \\(2\\) came from the fact that we had two options (heads and tails) for our outcome. Let’s work through the example of a 6-sided die to explain this further. The sample space is \\(S=\\{1, 2, 3, 4, 5, 6\\}\\). So is the total number of possible events \\(2^6\\) or \\(6^6\\) or something else? We can actually think about an event by using an indicator variable for each outcome of the sample space. An indicator variable is just a way to give us a yes/no answer to a question. So in this case, we are wondering: is this outcome a part of our event? If our event is \\(\\{1\\}\\) then for the outcome \\(1\\), the answer is “yes, the outcome is part of the event. For outcomes \\(2-6\\), the answer is”no, the outcome is not apart of the event.”\n\nFor each outcome, we have a “yes” or “no” answer. We can look at another example of an event. Let’s say our event is rolling an even number:\n\nFor \\(2\\), \\(4\\), and \\(6\\), the answer is “yes.” We can define the indicator variable for whether an outcome is in an event or not. The indicator gives a 1 or 0 for yes and no respectively.\n\nAs stated above, the \\(2\\) in \\(2^6\\) comes from the \\(2\\) options from our indicator. Each side has two options, and there are \\(6\\) sides. Thus, \\(2^6\\) possible events.\n\n\n\nI think this will become clearer when we start thinking about events in the context of probability. When we think of events outside of probability, we may think of something we actually do or something that happens, like going to a concert or coming to class or missing the streetcar. In this case, we think of the event as the single thing (out of all the options) that actually occured. For example, if I’m taking the streetcar to class, I can think of two definitive options of what might occur: I miss the streetcar or I get on the streetcar. Only one of these things can occur, which I may call an event colloquially.\nIt is important to make the distinction with events defined within probability. Events are not necessarily a single thing that occurred. Instead it can be a collection of things that may occur. In the example of the streetcar, I can define my event to include both options. Thus, my event is that I make the streetcar or I miss it. Both of these things cannot happen simultaneously, but if I want to calculate the probability that I miss or make the streetcar, then it is helpful to have the event defined.\n\n\n\nThis is in reference to the Chapter 1 notes on “BP example variation (3/3)” slide. I explained the event that at least one subject does not have high blood pressure using a venn diagram. In this venn diagram, I assumed \\(n=4\\), and I wanted to show that the union of complements is equal to the complement of unions: \\(\\bigcup\\limits_{i=1}^{n}H_i^C = \\Big(\\bigcap\\limits_{i=1}^{n}H_i\\Big)^C\\).\n\n Now we can look at \\(\\bigcup\\limits_{i=1}^{4}H_i^C\\). We first need to define \\(H_i^c\\)\n\n\n\n\n\n\nFurther explanations of the propositions can be found in the textbook from pages 24-27. For many of the explanations in class, I was working to produce a union of disjoint events, so that the probability could easily be calculated. Proposition 3 and 4 were specifically mentioned, so I will include some writing notes on them here:\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\nIn this proposition, I want to define event \\(B\\) as a union of disjoint events so that I can show \\(P(B)\\) is the sum of \\(P(A)\\) and some greater-than-or-equal-to 0 probability event. If the following is my venn diagram of A and B:\n\n\n\n\n\nThen I can define B as the union of disjoint events: \nIf we then take the probability of each side of the equation \\(B = A \\cup (A^c \\cap B)\\), we get \\[P(B) = P\\big(A \\cup (A^c \\cap B)\\big)\\]\nSince events \\(A\\) and \\(A^c \\cap B\\) are disjoint, the probability of their union is just: \\[P(A) + P(A^c \\cap B)\\]\nThus, our equation is now \\[P(B) = P(A) + P(A^c \\cap B)\\]\nFrom Axiom 1, we know for event \\(A^c \\cap B\\), \\(P(A^c \\cap B) \\geq 0\\).\nSo the probability of event B is the sum of the probability of event A and an event that is \\(\\geq\\) 0. This means \\(P(B) \\geq P(A)\\).\n\n\n\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)\n\n\nFrom the pictures above, we can see some similar disjoint events.\nIf we look back at \\(A \\cup B\\), we can start manipulating the right side of the equation:\n\n \n\n\n\n\nI will post this in the previous week’s Muddy Points as well. Please follow this link for my work through of the example. And here is the PDF with my work.\nSub-question: why don’t we just multiply the probability of A and B to get the intersection? This is a specific property of probability when A and B are independent. Only when A and B are independent can we conclude that \\(P(A \\cap B) = P(A)P(B)\\).\n\n\n\nWe’ve been working with event partitions throughout Chapter 2, but we have not formally identified them. Partitions are advantageous to define for two reasons:\n\nThe partitions may be easier to calculate. We can then use the partitions to reconstruct other probabilities that may be more difficult to calculate\nPartitions have nice properties as a consequence of being disjoint. For example, the probability of the union of partitions is the sum of the probabilities across each partition: \\[P\\bigg(\\bigcup_{i=1}^n A_i\\bigg) = P(A_1)P(A_2)P(A_3) \\cdot \\cdot \\cdot P(A_n)\\]"
  },
  {
    "objectID": "lessons/22_Counting_Intro/22_Counting_Intro.html",
    "href": "lessons/22_Counting_Intro/22_Counting_Intro.html",
    "title": "Chapter 22: Introduction to Counting",
    "section": "",
    "text": "Define permutations and combinations\nCharacterize difference between sampling with and without replacement\nCharacterize difference between sampling when order matters and when order does not matter\nCalculate the probability of sampling any combination of the following: with or without replacement and order does or does not matter"
  },
  {
    "objectID": "lessons/22_Counting_Intro/22_Counting_Intro.html#learning-objectives",
    "href": "lessons/22_Counting_Intro/22_Counting_Intro.html#learning-objectives",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDefine permutations and combinations\nCharacterize difference between sampling with and without replacement\nCharacterize difference between sampling when order matters and when order does not matter\nCalculate the probability of sampling any combination of the following: with or without replacement and order does or does not matter"
  },
  {
    "objectID": "lessons/22_Counting_Intro/22_Counting_Intro.html#basic-counting-examples-13",
    "href": "lessons/22_Counting_Intro/22_Counting_Intro.html#basic-counting-examples-13",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Basic Counting Examples (1/3)",
    "text": "Basic Counting Examples (1/3)\n\n\nExample 1\n\n\nSuppose we have 10 (distinguishable) subjects for study.\n\nHow many possible ways are there to order them?\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?\n\nHow many ways to order them without replacement and only need 6?\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?"
  },
  {
    "objectID": "lessons/22_Counting_Intro/22_Counting_Intro.html#basic-counting-examples-23",
    "href": "lessons/22_Counting_Intro/22_Counting_Intro.html#basic-counting-examples-23",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Basic Counting Examples (2/3)",
    "text": "Basic Counting Examples (2/3)\nSuppose we have 10 (distinguishable) subjects for study.\n\n\n\n\nExample 1.1\n\n\nHow many possible ways are there to order them?\n\n\n \n\n\nExample 1.2\n\n\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?"
  },
  {
    "objectID": "lessons/22_Counting_Intro/22_Counting_Intro.html#basic-counting-examples-33",
    "href": "lessons/22_Counting_Intro/22_Counting_Intro.html#basic-counting-examples-33",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Basic Counting Examples (3/3)",
    "text": "Basic Counting Examples (3/3)\nSuppose we have 10 (distinguishable) subjects for study.\n\n\n\n\nExample 1.3\n\n\nHow many ways to order them without replacement and only need 6?\n\n\n \n\n\nExample 1.4\n\n\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?"
  },
  {
    "objectID": "lessons/22_Counting_Intro/22_Counting_Intro.html#permutations-and-combinations-1",
    "href": "lessons/22_Counting_Intro/22_Counting_Intro.html#permutations-and-combinations-1",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Permutations and Combinations",
    "text": "Permutations and Combinations\n\n\nDefinition: Permutations\n\n\nPermutations are the number of ways to arrange in order \\(r\\) distinct objects when there are \\(n\\) total.\n\\[nPr = \\frac{n!}{(n-r)!}\\]\n\n\n\n\nDefinition: Combinations\n\n\nCombinations are the number of ways to choose (order doesn’t matter) \\(r\\) objects from \\(n\\) without replacement.\n\\[nCr = \\textrm{\"n choose r\"} = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "lessons/22_Counting_Intro/22_Counting_Intro.html#some-combinations-properties",
    "href": "lessons/22_Counting_Intro/22_Counting_Intro.html#some-combinations-properties",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Some combinations properties",
    "text": "Some combinations properties\n\n\n\n\n\n\n\nProperty\nProof\n\n\n\n\n\\[\\binom{n}{r} = \\binom{n}{n-r}\\]\n\\(\\binom{n}{r} = \\dfrac{n!}{r!(n-r)!}\\) and \\(\\binom{n}{n-r} = \\dfrac{n!}{(n-r)!(n-(n-r))!} = \\dfrac{n!}{(n-r)!r!}\\)\n\n\n\\[\\binom{n}{1} = n\\]\n\\[\\binom{n}{1} = \\dfrac{n!}{1!(n-1)!}=\\dfrac{n\\cdot(n-1)\\cdot(n-2)\\cdots1}{1! \\cdot (n-1)\\cdot(n-2)\\cdots1} = \\dfrac{n\\cdot(n-1)!}{1\\cdot (n-1)!} = \\dfrac{n}{1}=n\\]\n\n\n\\[\\binom{n}{0} = 1\\]\n\\[\\binom{n}{0} = \\dfrac{n!}{0!(n-0)!}=\\dfrac{n!}{1\\cdot n!} = 1\\]"
  },
  {
    "objectID": "lessons/22_Counting_Intro/22_Counting_Intro.html#more-examples-order-matters-vs.-not-12",
    "href": "lessons/22_Counting_Intro/22_Counting_Intro.html#more-examples-order-matters-vs.-not-12",
    "title": "Chapter 22: Introduction to Counting",
    "section": "More examples: order matters vs. not (1/2)",
    "text": "More examples: order matters vs. not (1/2)\n\n\n\n\nExample 2\n\n\nSuppose we draw 2 cards from a standard deck without replacement. What is the probability that both are spades when\n\norder matters?\norder doesn’t matter?\n\n\n\n\n\n\n\nChapter 22 Slides"
  },
  {
    "objectID": "lessons/22_Counting_Intro/22_Counting_Intro.html#table-of-different-cases",
    "href": "lessons/22_Counting_Intro/22_Counting_Intro.html#table-of-different-cases",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Table of different cases",
    "text": "Table of different cases\nSee table on pg. 277 of textbook\n\n\\(n\\) = total number of objects\n\\(r\\) = number objects needed\n\n\n\n\n\n\n\n\n\nwith replacement\nwithout replacement\n\n\n\n\norder matters\n\\[n^r\\]\n\\[n\\text{P}r = \\frac{n!}{(n-r)!}\\]\n\n\norder doesn’t matter\n\\[ \\binom{n+r-1}{r}\\]\n\\[n\\text{C}r = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "lessons/22_Counting_Intro/22_Counting_Intro.html#enumerating-events-and-sample-space",
    "href": "lessons/22_Counting_Intro/22_Counting_Intro.html#enumerating-events-and-sample-space",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Enumerating Events and Sample Space",
    "text": "Enumerating Events and Sample Space\n\nRecall, \\(P(A) = \\dfrac{|A|}{|S|}\\)\n\nWithin combinatorics, we can use the previous equations to help enumerate the event and sample space\nBut \\(A\\) might be a combination of enumerations\n\n\n \n\nFor example in the following example drawing 2 spades when order does not matter, we actually need to enumerate the other cards that are NOT spades. So the event is choosing 2 spades out of 13 AND choosing 0 other cards of 39 cards (13 hearts + 13 clubs + 13 diamonds).\nThus the probability is actually:\n\n\\[ P(\\text{two spades}) = \\dfrac{{13 \\choose 2}{39 \\choose 0}}{{52 \\choose 2}} \\]\n\nNote that \\(13 + 39 = 52\\) and \\(2+ 0 = 2\\). So the numerator’s \\(n\\)’s add up to the denominator’s \\(n\\) and the numerator’s \\(r\\)’s add up to the denominator’s \\(r\\)’s"
  },
  {
    "objectID": "lessons/07_Random_Variables/07_Random_Variables.html",
    "href": "lessons/07_Random_Variables/07_Random_Variables.html",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "",
    "text": "Map the sample space to the set of real numbers using a discrete and continuous random variable\nDistinguish between discrete and continuous random variables from a written description"
  },
  {
    "objectID": "lessons/07_Random_Variables/07_Random_Variables.html#learning-objectives",
    "href": "lessons/07_Random_Variables/07_Random_Variables.html#learning-objectives",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nMap the sample space to the set of real numbers using a discrete and continuous random variable\nDistinguish between discrete and continuous random variables from a written description"
  },
  {
    "objectID": "lessons/07_Random_Variables/07_Random_Variables.html#what-is-a-random-variable",
    "href": "lessons/07_Random_Variables/07_Random_Variables.html#what-is-a-random-variable",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "What is a random variable?",
    "text": "What is a random variable?\n\n\nDefinition: Random Variable\n\n\nFor a given sample space \\(S\\), a random variable (r.v.) is a function whose domain is \\(S\\) and whose range is the set of real numbers \\(\\mathbb{R}\\). A random variable assigns a real number to each outcome in the sample space."
  },
  {
    "objectID": "lessons/07_Random_Variables/07_Random_Variables.html#lets-demonstrate-this-definition-with-our-coin-toss",
    "href": "lessons/07_Random_Variables/07_Random_Variables.html#lets-demonstrate-this-definition-with-our-coin-toss",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Let’s demonstrate this definition with our coin toss",
    "text": "Let’s demonstrate this definition with our coin toss\n\n\n\n\nExample 1\n\n\nSuppose we toss 3 fair coins.\n\nWhat is the sample space?\nWhat are the probabilities for each of the elements in the sample space?\nWhat are the probabilities that you get 0, 1, 2, or 3 tails?"
  },
  {
    "objectID": "lessons/07_Random_Variables/07_Random_Variables.html#lets-stretch-our-definition-of-random-variables",
    "href": "lessons/07_Random_Variables/07_Random_Variables.html#lets-stretch-our-definition-of-random-variables",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Let’s stretch our definition of random variables",
    "text": "Let’s stretch our definition of random variables\n\n\n\n\nExample 2\n\n\nWhat are some other random variables we could consider in Example 1?"
  },
  {
    "objectID": "lessons/07_Random_Variables/07_Random_Variables.html#some-remarks-on-random-variables",
    "href": "lessons/07_Random_Variables/07_Random_Variables.html#some-remarks-on-random-variables",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Some remarks on random variables",
    "text": "Some remarks on random variables\n\nA random variable’s value is completely determined by the outcome \\(\\omega\\), where \\(\\omega \\in S\\)\n\nWhat is random is the outcome \\(\\omega\\)\n\nA random variable is a function from the sample space (with outcomes \\(\\omega\\)) to the set of real numbers\n\nWe typically write \\(X\\) instead of \\(X(\\omega)\\), where \\(X\\) is our random variable\n\nFor example, if we roll three dice, there are \\(6^3 = 216\\) possible outcomes (which is \\(\\omega\\))\n\nWe can define a random variable as the sum of the of the three dice\nIf our outcome is the set of numbers the dice landed on ( \\(\\omega=(a,b,c)\\) ), then \\[ X(\\omega) = X = a + b + c \\]"
  },
  {
    "objectID": "lessons/07_Random_Variables/07_Random_Variables.html#lets-look-at-a-continuous-r.v.",
    "href": "lessons/07_Random_Variables/07_Random_Variables.html#lets-look-at-a-continuous-r.v.",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Let’s look at a continuous R.V.",
    "text": "Let’s look at a continuous R.V.\n\n\n\n\nExample 3\n\n\nLet \\(X =\\) how many hours you slept last night.\n\nWhat is the sample space \\(S\\)?\nWhat is the range of possible values for \\(X\\)?\nWhat is \\(X(\\omega)\\)?"
  },
  {
    "objectID": "lessons/07_Random_Variables/07_Random_Variables.html#discrete-vs.-continuous-r.v.s",
    "href": "lessons/07_Random_Variables/07_Random_Variables.html#discrete-vs.-continuous-r.v.s",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Discrete vs. Continuous r.v.’s",
    "text": "Discrete vs. Continuous r.v.’s\n\nFor a discrete r.v., the set of possible values is either finite or can be put into a countably infinite list\n\nYou could theoretically list the specific possible outcomes that the variable can take\nIf you sum the rolls of three dice, you must get a whole number. For example, you can’t get any number between 3 and 4.\n\n\n   \n\nContinuous r.v.’s take on values from continuous intervals, or unions of continuous intervals\n\nVariable takes on a range of values, but there are infinitely possible values within the range\nIf you keep track of the time you sleep, you can sleep for 8 hours or 7.9 hours or 7.99 hours or 7.999 hours …"
  },
  {
    "objectID": "lessons/17_Negative_binomial_rv/17_Negative_Binomial_rv.html",
    "href": "lessons/17_Negative_binomial_rv/17_Negative_Binomial_rv.html",
    "title": "Chapter 17: Negative Binomial RVs",
    "section": "",
    "text": "Identify the variable and the parameters of a Negative Binomial distribution in a word problem, and state what the variable and parameters mean.\nUse the formulas for the pmf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons/17_Negative_binomial_rv/17_Negative_Binomial_rv.html#learning-objectives",
    "href": "lessons/17_Negative_binomial_rv/17_Negative_Binomial_rv.html#learning-objectives",
    "title": "Chapter 17: Negative Binomial RVs",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nIdentify the variable and the parameters of a Negative Binomial distribution in a word problem, and state what the variable and parameters mean.\nUse the formulas for the pmf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons/17_Negative_binomial_rv/17_Negative_Binomial_rv.html#properties-of-negative-binomial-rvs",
    "href": "lessons/17_Negative_binomial_rv/17_Negative_Binomial_rv.html#properties-of-negative-binomial-rvs",
    "title": "Chapter 17: Negative Binomial RVs",
    "section": "Properties of Negative Binomial RVs",
    "text": "Properties of Negative Binomial RVs\n\nScenario: There are repeated independent trials, each resulting in a success or failure, with constant probability of success for each trial. We are counting the number of trials until the \\(r^{th}\\) success.\nShorthand: \\(X \\sim \\text{NegBin}(p, r)\\) or \\(X \\sim \\text{NB}(p, r)\\)\nNegative binomial is sum of \\(r\\) geometric distributions\n\n\\[\nX = \\text{Number of independent trials until } r^{th} \\text{ success}\n\\]\n\\[ p_X(x) = P(X=x) = {x-1 \\choose r-1}(1-p)^{x-r}p^r \\text{ for } x = r, r+1, r+2, ...\\]\n\\[ E(X) = \\dfrac{r}{p}\\]\n\\[Var(X) = \\dfrac{rq}{p^2} = \\dfrac{r(1-p)}{p^2}\\]"
  },
  {
    "objectID": "lessons/17_Negative_binomial_rv/17_Negative_Binomial_rv.html#hitting-more-than-1-bullseye",
    "href": "lessons/17_Negative_binomial_rv/17_Negative_Binomial_rv.html#hitting-more-than-1-bullseye",
    "title": "Chapter 17: Negative Binomial RVs",
    "section": "Hitting more than 1 bullseye",
    "text": "Hitting more than 1 bullseye\n\n\n\n\nExample 1\n\n\nConsider again the bullseye example, where we throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the expected value and variance of the number of throws needed to hit 5 bullseyes?"
  },
  {
    "objectID": "lessons/17_Negative_binomial_rv/17_Negative_Binomial_rv.html#hitting-more-than-1-bullseye-1",
    "href": "lessons/17_Negative_binomial_rv/17_Negative_Binomial_rv.html#hitting-more-than-1-bullseye-1",
    "title": "Chapter 17: Negative Binomial RVs",
    "section": "Hitting more than 1 bullseye",
    "text": "Hitting more than 1 bullseye\n\n\n\n\nExample 1\n\n\nConsider again the bullseye example, where we throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the probability that the \\(5^{th}\\) bullseye is on the \\(20^{th}\\) throw?\n\n\n\n\n\n\n\nChapter 17 Slides"
  },
  {
    "objectID": "syllabus.html#description",
    "href": "syllabus.html#description",
    "title": "BSTA 550 Syllabus",
    "section": "Description",
    "text": "Description\nWelcome to BSTA 550! In this course, we will establish foundational knowledge in probability in which more statistics knowledge can be built! This course is designed to introduce history, concepts and distributions in probability, Monte Carlo simulation techniques, and Markov chains. Students will also learn how to write R codes for various statistical computations and plots. Previous experience in R is not required. R is free software available from http://www.r-project.org.\n\nCourse Learning Objectives\nAt the end of this course, students should be able to…\n\nAssign probability to a chance event using concepts of probability (including fundamental axioms, properties, and counting)\nCompute probabilities for discrete random variables (including random variables following Bernoulli, binomial, geometric, and Poisson distributions)\nCompute probabilities for continuous random variables (including random variables following Normal, Gamma, and Beta distributions)\nPerform statistical computations and simulations using R"
  },
  {
    "objectID": "syllabus.html#instructors",
    "href": "syllabus.html#instructors",
    "title": "BSTA 550 Syllabus",
    "section": "Instructors",
    "text": "Instructors\nHere is the instructor page. This also has office hours!"
  },
  {
    "objectID": "syllabus.html#meeting-times",
    "href": "syllabus.html#meeting-times",
    "title": "BSTA 550 Syllabus",
    "section": "Meeting Times",
    "text": "Meeting Times\nMondays          10:30 AM – 12:00 PM PST in room VPT 620M\nWednesdays    10:30 AM – 12:00 PM PST in room VPT 620M\n\nKnown Exceptions\n\nWednesday, November 26: No class\nMonday, December 1: Virtual class"
  },
  {
    "objectID": "syllabus.html#materials",
    "href": "syllabus.html#materials",
    "title": "BSTA 550 Syllabus",
    "section": "Materials",
    "text": "Materials\n\nTextbook\n\nAn Introduction to Probability and Simulation\n\nAuthor: Kevin Ross\nUpdated: 8/11/2022\nTextbook available online\n\n\n\nSupplemental Readings (Optional)\n\nIntroduction to Probability, Mark Daniel Ward and Ellen Gundlach, 1st edition\n\nSee shared folder for textbook access\n\nStatistical Inference, Casella and Berger, 2nd ed. (This will be the textbook for BSTA 551-552 Math Stat.)\nIntroduction to Probability, Charles M. Grinstead and J. Laurie Snell\nProbability With Applications and R, Robert P. Dobrow, Wiley 2013 (eBook available from OHSU library)\nAn Introduction to R (free pdf available)\n\n\n\n\nOnline Resources\n\nSakai\nWhile most course materials will be delivered online through this website, assignments will be turned in through Sakai, OHSU’s course management system. I will include a link on this website to the Sakai assignment page. \n\n\nWebex\nWebex software will be used for virtual office hours. To give everyone the best possible experience with Webex, I recommend the following best practices:\n\nPlease stay muted until you want to participate\nDuring office hours, please send a message in chat with your question or with a statement like “I have a question.” This makes sure I or the TA can address everyone’s questions in order. \nI encourage you to attend office hours with your video on. This helps me recognize you, and keep mental notes on what techniques/concepts I emphasize to facilitate your specific understanding. \n\n\n\nPennState STAT 414 Website\nPennState has a class offered to advanced undergraduates that has some overlap with our class. They have all their course notes posted on this page. This is a great source if you would like to see class notes with different phrasing.\nNot all of our topics are covered in their notes, but the most important ones are. If you are having trouble finding our course’s concepts on their page, please make ask me at Office Hours, after class, or in a private meeting. I do not explicitly state corresponding sections under our schedule because I believe it is important for you to develop skills involving resources and learning key words that can help you find answers. \n\n\nR: Statistical Computing Software\nStudents will use statistical software to complete homework assignments. Students are required to use R/RStudio for this course. R can be freely downloaded. Helpful documentation on installing R is available. I encourage you to install R prior to attending our first lecture. Please email me if you need help installing R or RStudio.\nYou will need to download the following three things:\n\nR https://www.r-project.org/\nRstudio https://posit.co/download/rstudio-desktop/\nQuarto https://quarto.org/docs/get-started/\n\n\nAdditional R Resources\nYour learning and practicing of R will hopefully not be limited to this course. One of the best aspects of programming in R is that many resources are freely available online. Here are just a few additional resources you may explore beyond this class to continue your training in R.\n\n\nUseful online R resources\n\nR for the rest of us\nStatistical tools for high-throughput data analysis. ggplot2 essentials\nR-bloggers\nStack Overflow for troubleshooting\nR Graphical Manual\nQuick-R. Accessing the power of R\nR for SAS, STATA, and SPSS Users\nggplot2\nLearn R 4 free\nJoin a local R user groups\nLearning Machines\n\n\n\n\nOnline R courses to complement or refresh material from class\n\nR for the rest of us\nCoursera: R programming\nedX: R basics\nData Carpentry: For Biologists\nData Carpentry: For Ecologists\nPsychiatric R\nR coder"
  },
  {
    "objectID": "syllabus.html#assessment",
    "href": "syllabus.html#assessment",
    "title": "BSTA 550 Syllabus",
    "section": "Assessment",
    "text": "Assessment\nThe course is structured around the following four components:\n\n\n\n\n\n\n\n\n\nComponent\nModality\nFrequency\nDescription\n\n\nLecture\nIn person\nTwice, Weekly\nCourse content is provided through in-person lectures. Lectures will consist of didactic lessons, interactive examples, and PollEverywhere questions. Sessions will be recorded through Explain Everything and posted to Sakai. Attending or viewing the lecture within 7 days of the original lecture date is mandatory. Class attendance will be taken through an Exit Ticket. If viewing the lecture asynchronously, you must take the Exit Ticket to verify your attendance.\n\n\nHomework Assignment\nOnline\nWeekly\nThe course includes 9 homework assignments. They are an opportunity for you to engage with important concepts, practice some coding, and apply calculating skills. Homework assignments should be submitted online, and will be graded for completeness by the TAs. Students are encouraged to work in groups for homework assignments, but each person should do their own summary and hand in their work. Homework assignments will be due on Thursday at 11 PM.\n\n\nQuizzes\nOnline\nEvery 3 weeks\nThe purpose of the quizzes is to assess how well you have achieved the learning objectives through questions covering important concepts, conducting statistical processes, and interpreting output. We will have our quizzes online, over a few days, and it will be open book. Students must work on the quizzes independently.\n\n\n\n\nTypes of assessments\nThis class will use a combination of formative and summative assessments to build and test our knowledge. Below I define each of these types of assessments:\n\nFormative assessment: Activity or work meant to help students learn and practice. Feedback on these assessments are meant to help the instructor and student identify gaps in knowledge and highlight accomplishments.\nSummative assessment: Work meant to test how well students have achieved learning objectives. Grading of these assessments are meant to gauge how well a student grasps the learning objectives and will be able to use their knowledge outside of the classroom.\n\n\n\nBreakdown\n\nGrading & Requirements\nLetter grades will be assigned roughly according to the following scheme: A (&gt;=93%), A- (90-92%), B+ (88-89%), B(83-87%), B- (82-80%), C+(78-79%), C(73-77%), C- (70-72%), D (60 – 69%), F(&lt;60%).\nGrades will be based on homework assignments, midterm exam, class “attendance”, and final exam, as follows:\n\n\n\n\n\n\n\n\n\nCourse activity\nType of Assessment\nDue Dates\nPercentage of final grade\n\n\nHomework Assignments\nFormative\nEvery week\n50%\n\n\nQuizzes\nSummative\nEvery 3 weeks\n36%\n\n\nExit tickets (Attendance)\nN/A\nTwice Weekly\n12%\n\n\nMid-Quarter Feedback\nN/A\n11/02\n2%\n\n\n\n\n\nHomework grading\nNo student has the same amount of time available to dedicate to homework. This class may not be a priority to you, you may be taking several other courses, or you may need to dedicate time to other activities. Homework assignments are formative assessments, meaning its purpose is to help you learn and practice. To reduce the pressure on you to have perfect homework (the first time around), I have a very simple grading policy: Your homework will be given a check mark if you turn in 75% of the question parts completed (whether the 75% is correct or wrong). I highly encourage you to stay up-to-date with the homeworks and put in as much effort as you can. This will be the most helpful work in this class!\nIf you turn in the homework on time, I will give you feedback (on one or more complete problems). There is no penalty for turning in the homework late, but you will not get feedback on your work. Please make sure to check the solutions or go to office hours to assess your work.\n\n\nViewing Grades in Sakai\nPoints you receive for graded activities will be posted to the Sakai Gradebook. Click on the Gradebook link on the left navigation to view your points."
  },
  {
    "objectID": "syllabus.html#course-instructor-evaluations",
    "href": "syllabus.html#course-instructor-evaluations",
    "title": "BSTA 550 Syllabus",
    "section": "Course & Instructor Evaluations",
    "text": "Course & Instructor Evaluations\n\nOngoing Course Feedback\nThroughout the duration of the course, you are also welcome to informally and anonymously submit your feedback through this Microsoft Form or Class Exit Tickets. This form will be available on Sakai. Students can submit feedback at any time and this form will be reviewed regularly by me. Your responses will be anonymous unless you elect to leave your email address. If I have done anything to make you feel uncomfortable, please give me feedback so I can change my behavior. Ultimately, this class is for you, and my individual social identity/behavior should not inhibit your learning. Thank you for your help making BSTA 550 a more successful class! Examples of ongoing feedback are:\n\nNicky talks a little fast during lecture time. May you speak slower?\nDuring Office Hours, Dr. Wakim made a face when I asked a question. This face made me feel self-conscious about my question.\nDr. W asked me a question about my experience that made me feel like a monolith. Please do not assume I can speak on behalf of my social identity groups.\nThe in-class examples do not make me more interested in the material.\n\n\n\nMidterm Feedback\nDuring the middle of the quarter, I will ask you to submit guided, anonymous feedback. Completion of feedback will be count towards your grade. To insure anonymity, I will ask you to sign a separate, written statement that you completed the feedback.\n\n\nFinal Course Feedback\nAt the conclusion of the course, you will be asked to complete a formal online review of the course and the instructor. Your feedback on this University evaluation is critical to improving future student learning in this course as well as providing metrics relevant to the instructor’s career advancement (or lack of). Since our class is on the smaller side, everyone’s participation is needed for feedback to be released."
  },
  {
    "objectID": "syllabus.html#schedule",
    "href": "syllabus.html#schedule",
    "title": "BSTA 550 Syllabus",
    "section": "Schedule",
    "text": "Schedule\nPlease refer to the Schedule page. I will make changes to this schedule if we need more or less time on a concept. You do not need to read the corresponding chapters in the textbook for each class."
  },
  {
    "objectID": "syllabus.html#how-to-succeed-in-this-course",
    "href": "syllabus.html#how-to-succeed-in-this-course",
    "title": "BSTA 550 Syllabus",
    "section": "How to succeed in this course",
    "text": "How to succeed in this course\nEvery professor has different expectations when assigning certain work or providing certain resources. I want to walk through each class resource and assignment so that you know what you can do to succeed in this class. For resources, I want you to optimize the opportunities to learn. For assignments, I want you to know the strategies that students can use to learn the most and prepare for future exams.\n\nResources\n\n\n\n\n\n\n\n\nResource\nWhat is it?\nHow do I use it?\n\n\nOffice Hours\nBlocks of time a professor or TA dedicates for questions. The teaching staff will be located in a specific room. Several students may enter the space at a time and will ask specific or broad questions. If many students attend office hours, a queue will be created so that students can be served equally.\nThe main use of office hours is to ask questions about an assignment or lecture notes. You are welcome to sit and do homework in office hours. OH are also an informal way of meeting fellow students to collaborate with.\n\n\nLectures and lecture recordings\nTime shared between the professor and students where the professor conveys important class material. Material discussed in lectures include concepts, calculations, code, and examples. Lectures are a mix of presentation of information, working through examples together, interactive activities, and in-class polls.\nStudents should attend lectures in person if possible. You should attempt to understand new material presented by following the presentation slides, taking notes on additional details that may conveyed verbally, and working through examples with the professor. Students are encouraged to ask questions when you don’t understand the material at any point in the lecture.\n\n\nTextbooks\nWritten and published material that explains concepts, steps through calculations, provides examples, and provides practice problems. The listed textbooks is the basis for this course. While I am to cover all topics in class, the textbook provides alternative explanations and additional examples.\nWhile coming to class having read the accompanying textbook chapters helps understanding during class, I do not expect students to have read it. I see the textbook as a good resource if you are struggling with a specific topic after class, in need of an example while working on homework, or want additional practice when studying for the exam.\n\n\nWebsite\nThe course website is designed by me so that you have access to all the course materials in a more organized and flexible way. All resources delivered from me to you will be available on the website. Any assignments turned in will be through Sakai.\nYou can navigate through different course resources and information using the left-side tabs or top navigation bar. Course materials, like lecture notes, homework, data examples, and recordings, can be found under each week’s page under the schedule tab. You can also find the individual resources under the “Course Materials” tab on the left. Links to turn in assignments through Sakai will be given on the website. Please explore the tabs and get a sense of the organization.\n\n\nSakai\nSakai is a learning management system for higher ed. This is the university sanctioned LMS where we will submit assignments.\nYou will turn in assignments through Sakai under the “Submissions” tab. Generally, there will be a link to each assignment on the course website. You can also view your grades under “Gradebook” and links to Webex under “Webex.”\n\n\n\n\n\nAssignments\n\n\n\n\n\n\n\n\n\nAssignment\nType of assessment\nBefore you submit/take it\nAfter it is graded\n\n\nHomework\nassignment\nFormative\n\nWork out each problem on your own as much as you can\nTalk through problems with a peer\nGo to Office Hours for help\nWrite down work that shows your thought process\nSearch your issue on Stack Exchange/Stack Overflow\nAsk fellow students on Slack\n\n\nDiscuss problems with your group\nFor answers that involve writing sentences, check with me or a TA if your answer is sufficient\nGo to Office Hours to ask about your work\n\n\n\nQuizzes\nSummative\n\nIdentify and achieve learning objectives in each lecture\nUnderstand why certain statistics tools are used for certain cases\nPractice testing yourself and others on concepts\nCome to Office Hours for help with specific problems or concepts\n\n\nReview the solutions\nReview your mistakes\nFor solutions that involve writing sentences, check with me or a TA if your answer fits the solution\nGo to Office Hours to ask about your solutions\nDo not ask for a regrade unless you have viewed the solutions\n\n\n\nClass Exit Tickets\nN/A\n\nBring appropriate electronic device to participate in polls\nComplete the survey during the last 5 minutes of class or after class within 7 days\n\n\nReview muddiest and clearest points from the week\n\n\n\n\nIf you would like any other course resources explained in this format, please request it through the Ongoing Course Feedback."
  },
  {
    "objectID": "syllabus.html#course-policies-and-resources",
    "href": "syllabus.html#course-policies-and-resources",
    "title": "BSTA 550 Syllabus",
    "section": "Course Policies and Resources",
    "text": "Course Policies and Resources\n\nLate Work Policy\nI encourage you to make your best effort to submit all assignments on time, but I understand circumstances arise that are beyond our control. Please see this Swansea University’s page on extenuating circumstances for some examples. Not all circumstances are covered here, so please reach out if you have questions. \n\nThe class will end on December 10, 2025. All coursework is expected to be completed by December 12, 2025 at 11pm. If you have extenuating circumstances, and need additional time to complete class assignments, please contact me. Together, we will come up with a plan for completion and to sort out registrar logistics.\nIf you have extenuating circumstances that may jeopardize your ability to do work for several weeks, please contact me. We will come up with a plan to keep you on track in the course and prevent any delay in your education.\nFor homework, you will have TWO no-questions-asked, 3-day extensions: one for the first assignment part and one for either the solutions or presentation. Please use this wisely! You just need to send me a quick email saying “I am using my no-questions-asked extension for Homework __ assignment/solutions/presentation.”\nFor homework, I ask you to email me directly about any late submissions. You can explain your circumstances and may ask us for an extension. I am very likely to grant an extension, but I want to emphasize how important it will be to stay on track with your homework! Your group is depending on you, and delaying homework may only add stress on the next homework!\nIf you have a emergency involving your self, family, pet, friend, classmate, or anything/one deemed important to you, please do not worry about immediately contacting me. We can work something out after your emergency. If I contact you during an emergency, it is only because I am worried, and you do NOT need to respond until you are able. \n\n\n\nRegrade Policy\nIf you think a question was incorrectly graded, first compare your answer to the answer key. If you believe a re-grade would be appropriate, write an email to me containing the question and a short explanation as to why the question(s) was/were incorrectly graded. Deadline: One week after assignments were returned to class (late requests will not be considered).\n\n\nAttendance Policy\nYou are expected to attend class, participate in-class polls, and complete the exit ticket. For students who miss class or need a review, I will make video and audio recordings of lectures available. There are no guarantees against technical or other challenges for the recording availability or quality.\nYou will need to attend all classes. There are 19 classes total, so you are welcome to watch the recordings or come in-person. While I want attendance to be a flexible thing, I need to set certain requirements around in-person attendance to align with the school’s policy. Attendance is measured through exit tickets that will be due 7 days after each class.\nThis is meant to keep you on track within the course and prevent a pile up of material. Make sure to complete the exit ticket at the end of class to demonstrate attendance.\n\n\nPlagiarism and Attribution\nPlease note that this section has been motivated by Dr. Steven Bedrick’s Course Policies and Grading site for BMI 525. (Note that this is a good example of informal attribution of someone else’s work.)\nIn this class, it is easy to use ChatGPT or other AI tools to solve your homework for you. Many problems follow a basic structure that is especially easy for ChatGPT to solve. In this class, you may use ChatGPT to help with your homework. You may even ask for direct answers. However, there are a few things I do not want you to do:\n\nDo not copy ChatGPT’s answer directly into your homework. Your homework is graded for full credit if you turn it in, in any state, so turning in ChatGPT’s answers is unacceptable. I rather see half-written answers that show what you’re thinking than see a correct answer from ChatGPT.\nDo not stop once ChatGPT answered a question. If it gives an explanation, interact with it! Make sure you understand the thought process of ChatGPT. Try writing out the process to help cement it in your head. Check the answer with what we learn in class.\nDo not use ChatGPT on our exams! Hence, you need to really understand how to solve these problems even if you use ChatGPT on the homework.\n\nAt the end of the day, ChatGPT is a resource that will be available to you in a job and outside of school. Thus, we should use it as a tool in school as well! Let me know if ChatGPT helped you understand something! I would love to incorporate it into future classes!\n\n\n\n\n\n\nImportant\n\n\n\nYou can think of this class as assembling a toolbox. When a handyperson starts working for the first time, they need to buy their tools. For their first few jobs, they might need help finding their tools or remembering which tool is best used for what action. Eventually, they get to know their tools well, and using them appropriately becomes second nature.\nFor now, ChatGPT can help us find and use our tools, but we need to work towards using them as second nature!"
  },
  {
    "objectID": "syllabus.html#course-expectations",
    "href": "syllabus.html#course-expectations",
    "title": "BSTA 550 Syllabus",
    "section": "Course Expectations",
    "text": "Course Expectations\n\nInstructor Expectations\nCommitment to your learning and your success\nI believe that everyone has the ability to be successful in this course and I have put a lot of effort into designing the course in a way that maximizes your learning to ensure your success. Please talk to me before or after class or stop by my office if there is anything you want to discuss or about which you are unclear. I want to be supportive of your learning and growth.\nInclusive & supportive learning community\nI believe that learning happens best when we all learn together, as a community. This means creating a space characterized by generous listening, civility, humility, patience, and hospitality. I will attempt to promote a safe climate where we examine content from multiple perspectives. I will strive to create and maintain a classroom atmosphere in which you feel free to both listen to others and express your views and ask questions to increase your learning.\nOpenness to feedback\nI appreciate straightforward feedback from you regarding how well the class is meeting your needs. Let me know if material is not clear or when its relevance to the student learning outcomes for the course is not apparent. In particular, let me know if you identify bias or stereotyping in my teaching materials as I will seek to continuously improve. Please also let me know if there’s an aspect of the class you find particularly interesting, helpful, or enjoyable!\nResponsiveness\nI will monitor email as well as the discussion board daily and try respond to all messages within 24 hours Monday-Friday.\nClear guidelines and prompt feedback on assignments\nI will provide clear instructions for all assignments, and a grading rubric when applicable. The TAs and I will provide detailed feedback on your submissions and will update grades promptly in Sakai.\n\n\nStudent Expectations and Resources\nAttend class\nYou are expected to attend at least 12 scheduled class meetings in-person. Attendance is taken through exit tickets. If you have issues accessing the poll on a specific day, please let me know. \nParticipate\nI encourage you to participate actively in class and in Slack discussions. I will expect all students, and all instructors, to be respectful of each other’s contributions, whether I agree with them or not. Professional interactions are expected.\nBuild rapport\nIf you find that you have any trouble keeping up with assignments or other aspects of the course, make sure you let me know as early as possible. As you will find, building rapport and effective relationships are key to becoming an effective professional. Make sure that you are proactive in informing me when difficulties arise during the quarter so that I can help you find a solution in regards to coursework.\nComplete assignments\nAll assignments for this course will be submitted electronically through Sakai unless otherwise instructed. I encourage you to make your best effort to submit all assignments on time, but I understand that sometimes circumstances arise that are beyond our control. If you need an extension, please contact me in congruence with the Late Policy.\nSeek help if you need it\nI believe it is important to support the physical and emotional well‐being of my students. If you are experiencing physical and/or mental health issues, I encourage you to use the resources on campus such as those listed below. If you have a health issue that is affecting your performance or participation in the course, and/or if you need help connecting with these resources, please contact me.\n\nStudent Health and Wellness Center (SHW), Website, 503-494-8665 (OHSU Students only)\nStudent Health and Counseling (SHAC), Website, 503-725-2800\n\nInform your instructor of any accommodations needed\nYou should speak with or email me before or during the first week of classes regarding any special needs. Students seeking academic accommodations should register with the appropriate service under the School policies below.\nSome religious holidays may occur on regularly scheduled class days. Because available class hours are so limited in number, we will have to hold class on all such days. Class video recordings will be available and you are encouraged to engage with the material outside of the regular class time. Please email me about your absence. I will excuse the absece from your grade. You are also encouraged to come to office hours with questions from the session.\nCommit to integrity\nAs a student in this course (and at PSU or OHSU) you are expected to maintain high degrees of professionalism, commitment to active learning and participation in this class and also integrity in your behavior in and out of the classroom.\nCheating and other forms of academic misconduct will not be tolerated in this course and will be dealt with firmly. Student academic misconduct refers to behavior that includes plagiarism, cheating on assignments, fabrication of data, falsification of records or official documents, intentional misuse of equipment or materials (including library materials), or aiding and abetting the perpetration of such acts. Preparation of exams, assigned on an individual basis, must represent each student’s own individual effort. When used, resource materials should be cited in conventional reference format."
  },
  {
    "objectID": "syllabus.html#course-communications",
    "href": "syllabus.html#course-communications",
    "title": "BSTA 550 Syllabus",
    "section": "Course Communications",
    "text": "Course Communications\nSakai/Slack announcements\nFor important/urgent matters, I will communicate with you using announcements via Sakai that will be delivered to your OHSU Email account as well as displayed in the Sakai course site Announcements section. I will copy these announcements in Slack if they do not involve changes to the schedule. Unfortunately, there are certain announcements that OHSU requires I initiate behind the firewall.\nGeneral course questions\nIt is normal to have many questions about things that relate to the course, such as clarification about assignments, course materials, or assessments. Please post these on our Slack Workspace. Please use the channels that I created for questions. You are encouraged to give answers and help each other. I will monitor these threads, so I will endorse or correct responses as needed. Please give me 24 hours to respond to questions within Monday-Friday. Work-life balance is important for me as well, so I will try to respond as quickly as I can within my healthy limits. \nE-mail\nE-mail should be used only for messages that are private in nature. Please send private messages to my OHSU email address (wakim@ohsu.edu). Messages sent through Sakai Inbox will not be answered. Do not send messages asking general information about the class; please post those on Slack instead."
  },
  {
    "objectID": "syllabus.html#further-student-resources",
    "href": "syllabus.html#further-student-resources",
    "title": "BSTA 550 Syllabus",
    "section": "Further Student Resources",
    "text": "Further Student Resources\n\nAcademic Success Center\nOHSU houses an Academic Success Center for all students. Their mission is to create a center for learning support where ALL learners can discover the resources and community that they need for finding academic success at OHSU. They provide many services to students, including: learning skills support, writing support, English for speakers of other languages (ESOL) support, and individual and group content tutoring. Check out the SharePoint site for the Academic Success Center.\n\n\nStudent Wellness\nI am committed to supporting the physical and emotional well-being of my students. Both PSU and OHSU have designated centers for student health. For OHSU, students can visit the Behavioral Health site, where you can find more information including the number to make an appointment. All student visits are free. OHSU students also have access to PSU’s Counseling Services through the school’s Student Health & Counseling. Information on additional student resources for OHSU students are available on the OHSU Health and Wellness Resource page. \n\n\nSupport for Food Insecurity\nStudents across the country experience food insecurity at high rates. OHSU and PSU both provide a list of resources to help combat food insecurity. Of note, the Committee to Improve Student Food Security (CISFS) at PSU provides a Free Food Market on the second Monday of each month. OHSU also provides SNAP Enrollment Assistance. The Supplemental Nutrition Assistance Program (SNAP) allocates money towards food for individuals below a certain income level. If you make less than $2,430 monthly, you may wish to enroll.\n\n\nSupport for Students with Children\nStudents who have children can use the PSU resource: Resource Center for Students with Children. Resources are mostly focused on students with younger children. There are several great resources available, including: family-friendly study spaces, new baby starter packs, free kids clothing, and further information on financial resources for childcare."
  },
  {
    "objectID": "syllabus.html#school-policies-and-resources",
    "href": "syllabus.html#school-policies-and-resources",
    "title": "BSTA 550 Syllabus",
    "section": "School Policies and Resources",
    "text": "School Policies and Resources\n\nSchool of Public Health Handbook\nAll students are responsible for following the policies and expectations outlined in the student handbook for their program of study. Students are responsible for their own academic work and are expected to have read and practice principles of academic honesty, as presented in the handbook.\n\n\nStudent Access & Accommodations\nThe School of Public Health values diversity and inclusion; we are committed to fostering mutual respect and full participation for all students. My goal is to create a learning environment that is equitable, usable, inclusive, and welcoming. If any aspects of instruction or course design result in barriers to your inclusion or learning, please notify me. \n\nIf you are already registered with disability services at either OHSU or PSU and you are taking a course at the opposite institution, you need to contact the office you’re registered with to transfer your accommodations.\nIf you are not already registered with a disability services office, and you have, or think you may have, a disability that may affect your work in this class, and feel you need accommodations, use the following table for guidance about which office to contact to initiate accommodations.\n\nResource Table\n\n\n\nEnrollment University and Standing\nWhere to Seek Accommodations\n\n\nUndergraduate School of Public Health major\nPSU’s Disability Resource Center\n\n503-725-4150\nSmith Memorial Student Union, Room 116\ndrc@pdx.edu\n\n\n\nAll PSU-registering Dual Degree (MSW/MPH and MURP/MPH) Graduate School of Public Health Majors and all PSU-registering PhD students admitted prior to fall 2016.\nPSU’s Disability Resource Center\n\n503-725-4150\nSmith Memorial Student Union, Room 116\ndrc@pdx.edu\nwww.pdx.edu/drc\n\n\n\nGraduate School of Public Health major (irrespective of institution at which you register)\nOHSU’s Office for Student Access\n(503) 494-0082\nStudentAccess@OHSU.edu\nOHSU Auditorium Building 330\n\n\nNon-SPH major, PSU-enrolled student\nPSU’s Disability Resource Center\n503-725-4150\nSmith Memorial Student Union, Room 116\ndrc@pdx.edu\nwww.pdx.edu/drc\n\n\nNon-SPH major, OHSU-enrolled student\nOHSU’s Office for Student Access\n(503) 494-0082\nStudentAccess@OHSU.edu\nOHSU Auditorium Building 330\n\n\n\n \nFor more information related accessibility and accommodations, please see the “Statement Regarding Students with Disabilities” within the Institutional Policies section of this syllabus.\n\n\nTitle IX\nThe School of Public Health is committed to providing an environment free of all forms of prohibited discrimination and discriminatory harassment. The School of Public Health students who have questions about an incident related to Title IX are welcome to contact either the OHSU or PSU’s Title IX Coordinator and they will direct you to the appropriate resource or office. Title IX pertains to any form of sex/gender discrimination, discriminatory harassment, sexual harassment or sexual violence.\n\nPSU’s Title IX Coordinator is Julie Caron, she may be reached at titleixccordinator@pdx.edu or 503-725-4410. Julie’s office is located at 1600 SW 4th Ave, In the Richard and Maureen Neuberger Center RMNC - Suite 830.\nThe OHSU Title IX Coordinator’s may be reachedat 503-494-0258 or titleix@ohsu.edu and is located at 2525 SW 3rd St.\n\nPlease note that faculty and the Title IX Coordinators will keep the information you disclose private but are not confidential. If you would like to speak with a confidential advocate, who will not disclose the information to a university official without your written consent, you may contact an advocate at PSU or OHSU.\n\nPSU’s confidential advocates are available in Women’s Resource Center (serving all genders) in Smith Student Memorial Union 479. You may schedule an appointment by (503-725-5672) or schedule on line at https://psuwrc.youcanbook.me. For more information about resources at PSU, please see PSU’s Response to Sexual Misconduct website.\nOHSU’s advocates are available through the Confidential Advocacy Program (CAP) at 833-495-CAPS (2277) or by email CAPsupport@ohsu.edu, but please note, email is not a secure form of communication. Also visit www.ohsu.edu/CAP.\n\nAt OHSU, if you encounter any harassment, or discrimination based on race, color, religion, age, national origin or ancestry, veteran or military status, sex, marital status, pregnancy or parenting status, sexual orientation, gender identity or expression, disability or any other protected status, please contact the Affirmative Action and Equal Opportunity (AAEO) Department at 503-494-5148 or aaeo@ohsu.edu.\nAt PSU, you may contact the Office of Equity and Compliance if you experience any form of discrimination or discriminatory harassment as listed above at equityandcompliance@pdx.edu or by calling 503-725-5919.\n\n\nTechnical Support\nThe OHSU ITG Help Desk is available to assist students with email account or network account access issues between 6 a.m. and 6 p.m., Monday through Friday at 503-494-2222. For technical support in using the Sakai Course Management System, please contact the Sakai Help Desk at 877-972-5249 or email us at sakai@ohsu.edu"
  },
  {
    "objectID": "syllabus.html#ohsu-competencies",
    "href": "syllabus.html#ohsu-competencies",
    "title": "BSTA 550 Syllabus",
    "section": "OHSU Competencies",
    "text": "OHSU Competencies\n\nList of OHSU Graduation Core Competencies\n\nProfessional Knowledge and Skills\nProfessionalism\nInformation Literacy\nCommunication\nTeamwork\nCommunity Engagement, Social Justice and Equity\nPatient Centered Care\n\nTo access a descriptive list of OHSU Graducation Core Competencies: OHSU Graduation Core Competencies"
  },
  {
    "objectID": "syllabus.html#institutional-policies-and-resources",
    "href": "syllabus.html#institutional-policies-and-resources",
    "title": "BSTA 550 Syllabus",
    "section": "Institutional Policies and Resources",
    "text": "Institutional Policies and Resources\n\nStatement Regarding Students with Disabilities\nOHSU is committed to inclusive and accessible learning environments in compliance with federal and state law. If you have a disability or think you may have a disability (mental health, attention-related, learning, vision, hearing, physical or health impacts) contact the Office for Student Access at (503) 494-0082 or OHSU Student Access to have a confidential conversation about academic accommodations. Information is also available at Student Access Website. Because accommodations may take time to implement and cannot be applied retroactively, it is important to have this discussion as soon as possible.\nPortland State students also have similar resources available via the PSU Disability Resource Center (website http://www.pdx.edu/drc ). Please contact the DRC at tel. (503) 725-4150 or email at drc@pdx.edu\n\n\nStudent Evaluation of Courses\nCourse evaluation results are extremely important and used to help improve courses and the learning experience of future students. Responses will always remain anonymous and will only be available to instructors after grades have been posted. The results of scaled questions and comments go to both the instructor and their unit head/supervisor. Refer to Student Evaluation of Courses and Instructional Effectiveness, *Policy No. 02-50-035.\n*To access the OHSU Student Evaluation of Courses and Instructional Effectiveness Policy, you must log into the OHSU O2 website.\n\n\nCopyright Information\nCopyright laws and fair use policies protect the rights of those who have produced the material. The copy in this course has been provided for private study, scholarship, or research. Other uses may require permission from the copyright holder. The user of this work is responsible for adhering to copyright law of the U.S. (Title 17, U.S. Code). To help you familiarize yourself with copyright and fair use policies, the University encourages you to visit its Copyright Web Page\nSakai course web sites contain material protected by copyrights held by the instructor, other individuals or institutions. Such material is used for educational purposes in accord with copyright law and/or with permission given by the owners of the original material. You may download one copy of the materials on any single computer for non-commercial, personal, or educational purposes only, provided that you (1) do not modify it, (2) use it only for the duration of this course, and (3) include both this notice and any copyright notice originally included with the material. Beyond this use, no material from the course web site may be copied, reproduced, re-published, uploaded, posted, transmitted, or distributed in any way without the permission of the original copyright holder. The instructor assumes no responsibility for individuals who improperly use copyrighted material placed on the web site.\n\n\nSyllabi Changes and Retention\nSyllabi are considered to be a learning agreement between students and the faculty of record. Information contained in syllabi, other than the minimum requirements, may be subject to change as deemed appropriate by the faculty of record in concurrence with the academic program and the Office of the Provost. Refer to the *Course Syllabi Policy, 02-50-050.\n*To access the OHSU Course Syllabus Policy, you must log into the OHSU O2 website.\n\n\nCommitment to Diversity & Inclusion\nOHSU is committed to creating and fostering a learning and working environment based on open communication and mutual respect. If you encounter sexual harassment, sexual misconduct, sexual assault, or discrimination based on race, color, religion, age, national origin, veteran’s status, ancestry, sex, marital status, pregnancy or parenting status, sexual orientation, gender identity, disability or any other protected status please contact the Affirmative Action and Equal Opportunity Department at 503-494-5148 or aaeo@ohsu.edu. Inquiries about Title IX compliance or sex/gender discrimination and harassment may be directed to the OHSU Title IX Coordinator at 503-494-0258 or titleix@ohsu.edu.\n\n\nModified Operations, Policy 01-40-010\nPortland Campus:  Marquam Hill and South Waterfront\nStudents should review O2 or call OHSU’s weather alert line at 503-494-9021 for the most up-to-date information on OHSU-wide modified operations which include but are not limited to delays or closures for inclement weather.\nIf your home institution is not on the Portland campus (Marquam Hill or South Waterfront, contact your home institution for more information.\n\n\nOHSU Resources Available to Students*:\nRemote Learning Resources\nThe Remote Learning webpage on O2 contains concise, practical resources, and strategies for students that need to quickly transition to a fully remote instructional format.\nRegistrar’s Office\nMackenzie Hall, Rm. 1120\n503-494-7800; Email the Registrar\nStudent Registration Information: \nTo Register for Classes\nOHSU ITG Help Desk\nRegular staff hours are 6 a.m. to 6 p.m., Monday through Friday, but phones are answered seven days a week, 24 hours a day. Call 503 494-2222.\nTeaching and Learning Center\nAcademic Support Counseling and Sakai Course Management System, please contact the TLC Help Desk at 877-972-5249 or email TLC Help Desk\nStudent Academic Support Services\nFor resources on improving student’s study strategies, time management, motivation, test-taking skills and more, Please access the Student Academic Support Services Sakai page. For one-on-one appointments or to arrange a workshop for students, please contact Emily Hillhouse.\nConfidential Advocacy Program\nSupport for OHSU employees, students, and volunteers who have experienced any form of sexual misconduct, including sexual harassment, sexual assault, intimate-partner violence, stalking, relationship/dating violence, and other forms — regardless of when or where it took place. Contact Us.\nConcourse Syllabus Management\nFor help with accessing your Concourse Syllabus:  Please contact the Sakai help Desk for all other Concourse inquiries please visit the Concourse Support - Sakai or please contact the Mark Rivera at rivermar@ohsu.edu or call 503-494-0934\nPublic Safety\nOHSU Public Safety-Portland Campus (Marquam Hill and South Waterfront)\n\nEmergency on Campus: 503-494-4444 (Portland)\nNon-emergency: 503-494-7744; Contact Public Safety\n\nStudent Health & Wellness Center \nBaird Hall, Rm. 18 (Primary Care) and Rm. 6 (Behavioral Health)\n503-494-8665; For urgent care after hours, 503-494-8311 and ask for the Nurse on call.\nWellness Center Information  \nWellness Center Website\nIf your home institution is not on the Portland campus, contact your home institution student support services for more information.\nOmbudsman Office\nGaines Hall, Rm. 117\n707 SW Gaines Street, Portland, OR 97239\n503-494-5397; Contact Ombudsman; Ombudsman Website\nLibrary: Biomedical Information Communication Center\nBICC Library Hours of Operation\n\n\nPrivacy While Learning\nStudents may be asked to take classes remotely through videoconferencing software like WebEx. Some of these remote classes will be recorded. Any recording will capture the presenter’s audio, video, and computer screen. Student video and audio will be recorded if and when you unmute your audio and share your video during the recorded sessions. These recordings will not be shared with or accessible to the public without prior written consent. \n\n\nStudent Central\nKey information for students across OHSU’s Schools of Dentistry, Medicine, Nursing, the OHSU-PSU School of Public Health and the College of Pharmacy. Student Central helps you find out more about student services, resources, policies and technology."
  },
  {
    "objectID": "lessons/03_Independent_Events/03_IndependentEvents_muddy_points.html",
    "href": "lessons/03_Independent_Events/03_IndependentEvents_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "In class, we were wondering why/if \\(2^{|S|}\\) is the general formula for calculating the total number of possible events. We were specifically wondering if the \\(2\\) came from the fact that we had two options (heads and tails) for our outcome. Let’s work through the example of a 6-sided die to explain this further. The sample space is \\(S=\\{1, 2, 3, 4, 5, 6\\}\\). So is the total number of possible events \\(2^6\\) or \\(6^6\\) or something else? We can actually think about an event by using an indicator variable for each outcome of the sample space. An indicator variable is just a way to give us a yes/no answer to a question. So in this case, we are wondering: is this outcome a part of our event? If our event is \\(\\{1\\}\\) then for the outcome \\(1\\), the answer is “yes, the outcome is part of the event. For outcomes \\(2-6\\), the answer is”no, the outcome is not apart of the event.”\n\nFor each outcome, we have a “yes” or “no” answer. We can look at another example of an event. Let’s say our event is rolling an even number:\n\nFor \\(2\\), \\(4\\), and \\(6\\), the answer is “yes.” We can define the indicator variable for whether an outcome is in an event or not. The indicator gives a 1 or 0 for yes and no respectively.\n\nAs stated above, the \\(2\\) in \\(2^6\\) comes from the \\(2\\) options from our indicator. Each side has two options, and there are \\(6\\) sides. Thus, \\(2^6\\) possible events.\n\n\n\nI think this will become clearer when we start thinking about events in the context of probability. When we think of events outside of probability, we may think of something we actually do or something that happens, like going to a concert or coming to class or missing the streetcar. In this case, we think of the event as the single thing (out of all the options) that actually occured. For example, if I’m taking the streetcar to class, I can think of two definitive options of what might occur: I miss the streetcar or I get on the streetcar. Only one of these things can occur, which I may call an event colloquially.\nIt is important to make the distinction with events defined within probability. Events are not necessarily a single thing that occurred. Instead it can be a collection of things that may occur. In the example of the streetcar, I can define my event to include both options. Thus, my event is that I make the streetcar or I miss it. Both of these things cannot happen simultaneously, but if I want to calculate the probability that I miss or make the streetcar, then it is helpful to have the event defined.\n\n\n\nThis is in reference to the Chapter 1 notes on “BP example variation (3/3)” slide. I explained the event that at least one subject does not have high blood pressure using a venn diagram. In this venn diagram, I assumed \\(n=4\\), and I wanted to show that the union of complements is equal to the complement of unions: \\(\\bigcup\\limits_{i=1}^{n}H_i^C = \\Big(\\bigcap\\limits_{i=1}^{n}H_i\\Big)^C\\).\n\n Now we can look at \\(\\bigcup\\limits_{i=1}^{4}H_i^C\\). We first need to define \\(H_i^c\\)\n\n\n\n\n\n\nFurther explanations of the propositions can be found in the textbook from pages 24-27. For many of the explanations in class, I was working to produce a union of disjoint events, so that the probability could easily be calculated. Proposition 3 and 4 were specifically mentioned, so I will include some writing notes on them here:\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\nIn this proposition, I want to define event \\(B\\) as a union of disjoint events so that I can show \\(P(B)\\) is the sum of \\(P(A)\\) and some greater-than-or-equal-to 0 probability event. If the following is my venn diagram of A and B:\n\n\n\n\n\nThen I can define B as the union of disjoint events: \nIf we then take the probability of each side of the equation \\(B = A \\cup (A^c \\cap B)\\), we get \\[P(B) = P\\big(A \\cup (A^c \\cap B)\\big)\\]\nSince events \\(A\\) and \\(A^c \\cap B\\) are disjoint, the probability of their union is just: \\[P(A) + P(A^c \\cap B)\\]\nThus, our equation is now \\[P(B) = P(A) + P(A^c \\cap B)\\]\nFrom Axiom 1, we know for event \\(A^c \\cap B\\), \\(P(A^c \\cap B) \\geq 0\\).\nSo the probability of event B is the sum of the probability of event A and an event that is \\(\\geq\\) 0. This means \\(P(B) \\geq P(A)\\).\n\n\n\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)\n\n\nFrom the pictures above, we can see some similar disjoint events.\nIf we look back at \\(A \\cup B\\), we can start manipulating the right side of the equation:\n\n \n\n\n\n\nI will post this in the previous week’s Muddy Points as well. Please follow this link for my work through of the example. And here is the PDF with my work.\nSub-question: why don’t we just multiply the probability of A and B to get the intersection? This is a specific property of probability when A and B are independent. Only when A and B are independent can we conclude that \\(P(A \\cap B) = P(A)P(B)\\).\n\n\n\nWe’ve been working with event partitions throughout Chapter 2, but we have not formally identified them. Partitions are advantageous to define for two reasons:\n\nThe partitions may be easier to calculate. We can then use the partitions to reconstruct other probabilities that may be more difficult to calculate\nPartitions have nice properties as a consequence of being disjoint. For example, the probability of the union of partitions is the sum of the probabilities across each partition: \\[P\\bigg(\\bigcup_{i=1}^n A_i\\bigg) = P(A_1)P(A_2)P(A_3) \\cdot \\cdot \\cdot P(A_n)\\]"
  },
  {
    "objectID": "lessons/03_Independent_Events/03_IndependentEvents_muddy_points.html#from-fall-2023",
    "href": "lessons/03_Independent_Events/03_IndependentEvents_muddy_points.html#from-fall-2023",
    "title": "Muddy Points",
    "section": "",
    "text": "In class, we were wondering why/if \\(2^{|S|}\\) is the general formula for calculating the total number of possible events. We were specifically wondering if the \\(2\\) came from the fact that we had two options (heads and tails) for our outcome. Let’s work through the example of a 6-sided die to explain this further. The sample space is \\(S=\\{1, 2, 3, 4, 5, 6\\}\\). So is the total number of possible events \\(2^6\\) or \\(6^6\\) or something else? We can actually think about an event by using an indicator variable for each outcome of the sample space. An indicator variable is just a way to give us a yes/no answer to a question. So in this case, we are wondering: is this outcome a part of our event? If our event is \\(\\{1\\}\\) then for the outcome \\(1\\), the answer is “yes, the outcome is part of the event. For outcomes \\(2-6\\), the answer is”no, the outcome is not apart of the event.”\n\nFor each outcome, we have a “yes” or “no” answer. We can look at another example of an event. Let’s say our event is rolling an even number:\n\nFor \\(2\\), \\(4\\), and \\(6\\), the answer is “yes.” We can define the indicator variable for whether an outcome is in an event or not. The indicator gives a 1 or 0 for yes and no respectively.\n\nAs stated above, the \\(2\\) in \\(2^6\\) comes from the \\(2\\) options from our indicator. Each side has two options, and there are \\(6\\) sides. Thus, \\(2^6\\) possible events.\n\n\n\nI think this will become clearer when we start thinking about events in the context of probability. When we think of events outside of probability, we may think of something we actually do or something that happens, like going to a concert or coming to class or missing the streetcar. In this case, we think of the event as the single thing (out of all the options) that actually occured. For example, if I’m taking the streetcar to class, I can think of two definitive options of what might occur: I miss the streetcar or I get on the streetcar. Only one of these things can occur, which I may call an event colloquially.\nIt is important to make the distinction with events defined within probability. Events are not necessarily a single thing that occurred. Instead it can be a collection of things that may occur. In the example of the streetcar, I can define my event to include both options. Thus, my event is that I make the streetcar or I miss it. Both of these things cannot happen simultaneously, but if I want to calculate the probability that I miss or make the streetcar, then it is helpful to have the event defined.\n\n\n\nThis is in reference to the Chapter 1 notes on “BP example variation (3/3)” slide. I explained the event that at least one subject does not have high blood pressure using a venn diagram. In this venn diagram, I assumed \\(n=4\\), and I wanted to show that the union of complements is equal to the complement of unions: \\(\\bigcup\\limits_{i=1}^{n}H_i^C = \\Big(\\bigcap\\limits_{i=1}^{n}H_i\\Big)^C\\).\n\n Now we can look at \\(\\bigcup\\limits_{i=1}^{4}H_i^C\\). We first need to define \\(H_i^c\\)\n\n\n\n\n\n\nFurther explanations of the propositions can be found in the textbook from pages 24-27. For many of the explanations in class, I was working to produce a union of disjoint events, so that the probability could easily be calculated. Proposition 3 and 4 were specifically mentioned, so I will include some writing notes on them here:\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\nIn this proposition, I want to define event \\(B\\) as a union of disjoint events so that I can show \\(P(B)\\) is the sum of \\(P(A)\\) and some greater-than-or-equal-to 0 probability event. If the following is my venn diagram of A and B:\n\n\n\n\n\nThen I can define B as the union of disjoint events: \nIf we then take the probability of each side of the equation \\(B = A \\cup (A^c \\cap B)\\), we get \\[P(B) = P\\big(A \\cup (A^c \\cap B)\\big)\\]\nSince events \\(A\\) and \\(A^c \\cap B\\) are disjoint, the probability of their union is just: \\[P(A) + P(A^c \\cap B)\\]\nThus, our equation is now \\[P(B) = P(A) + P(A^c \\cap B)\\]\nFrom Axiom 1, we know for event \\(A^c \\cap B\\), \\(P(A^c \\cap B) \\geq 0\\).\nSo the probability of event B is the sum of the probability of event A and an event that is \\(\\geq\\) 0. This means \\(P(B) \\geq P(A)\\).\n\n\n\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)\n\n\nFrom the pictures above, we can see some similar disjoint events.\nIf we look back at \\(A \\cup B\\), we can start manipulating the right side of the equation:\n\n \n\n\n\n\nI will post this in the previous week’s Muddy Points as well. Please follow this link for my work through of the example. And here is the PDF with my work.\nSub-question: why don’t we just multiply the probability of A and B to get the intersection? This is a specific property of probability when A and B are independent. Only when A and B are independent can we conclude that \\(P(A \\cap B) = P(A)P(B)\\).\n\n\n\nWe’ve been working with event partitions throughout Chapter 2, but we have not formally identified them. Partitions are advantageous to define for two reasons:\n\nThe partitions may be easier to calculate. We can then use the partitions to reconstruct other probabilities that may be more difficult to calculate\nPartitions have nice properties as a consequence of being disjoint. For example, the probability of the union of partitions is the sum of the probabilities across each partition: \\[P\\bigg(\\bigcup_{i=1}^n A_i\\bigg) = P(A_1)P(A_2)P(A_3) \\cdot \\cdot \\cdot P(A_n)\\]"
  },
  {
    "objectID": "homeworks.html#homeworks",
    "href": "homeworks.html#homeworks",
    "title": "Homework",
    "section": "",
    "text": "Homework\nDue date (@11pm)\nAssignment\nAnswers\nSolutions (.qmd)\nSolutions (.html)*\n\n\n\n\n0\n10/3\n\n\n\n\n\n\n1\n10/10\n\n\n\n\n\n\n2\n10/17\n\n\n\n\n\n\n3\n10/25\n\n\n\n\n\n\n4\n10/31\n\n\n\n\n\n\n5\n11/7\n\n\n\n\n\n\n6\n11/16\n\n\n\n\n\n\n7\n11/21\n\n\n\n\n\n\n8\n11/26\n\n\n\n\n\n\n9\n12/5\n\n\n\n\n\n\n10 (optional)\n12/12\n\n\n\n\n\n\n\n*Please note that you need to download the .html file to see the LaTeX math properly."
  },
  {
    "objectID": "homeworks.html#structure",
    "href": "homeworks.html#structure",
    "title": "Homework",
    "section": "Structure",
    "text": "Structure\nThere are three distinct parts to our homework:\n\n\n\n\n\n\n\n\n\nHomework part\nDue date\nWhat is required?\nGrading\n\n\n\n\nIndividual assignment\nDate specified above\nYou will complete the homework assignment, and turn in an individual copy of your work. This will be graded for completion.\nFor completion\n\n\nGroup solutions\n\nWith groups of 4, you will make a homework key for 4 questions (that Nicky chooses). Each group member will be in charge of turning in one question’s solutions. This will be graded for correctness. The group will receive the same grade, which is summed across questions.\nFor correctness\n\n\nIndividual presentation\n\nFor homeworks __ and ___, you will also need to make a video or meet with me. You will use less than 10 minutes to explain your homework question solutions. This will be graded for correctness.\nGraded out of 4 points. 0 indicating no understanding of the solutions. 1 indicating some basic understanding, but missing major steps. 3 indicating that most of the problem is considered, but not necessarily all or all correctly. 4 indicating that all needed parts were considered and correctly solved.\n\n\n\nIf you are having any group dynamic issues, please please please come see me earlier rather than later! You do not need to wait for group evals. We will come up with options for moving forward!"
  },
  {
    "objectID": "homework/HW_06.html",
    "href": "homework/HW_06.html",
    "title": "Homework 6",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf or html format.\nYou can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. The Adobe Scan phone app is an easy way to scan photos and compile into a PDF. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nYou must show all of your work to receive credit.\nExtra problems do not need to be turned in!"
  },
  {
    "objectID": "homework/HW_06.html#directions",
    "href": "homework/HW_06.html#directions",
    "title": "Homework 6",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf or html format.\nYou can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. The Adobe Scan phone app is an easy way to scan photos and compile into a PDF. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nYou must show all of your work to receive credit.\nExtra problems do not need to be turned in!"
  },
  {
    "objectID": "homework/HW_06.html#non-textbook-problems-ntb",
    "href": "homework/HW_06.html#non-textbook-problems-ntb",
    "title": "Homework 6",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nCalculus Review\n\n\\[\\int_0^yc(x+y)dx\\]\n\\[\\frac{d}{dx}\\bigg(\\frac{4}{9}x^2y^2+\\frac{5}{9}xy^4\\bigg)\\]\n\\[\\frac{d}{dy}\\bigg(\\frac{4}{9}x^2y^2+\\frac{5}{9}xy^4\\bigg)\\]\n\\[\\int_0^y2e^{-x}e^{-y}dx\\]\n\\[\\int_0^\\infty xye^{-(x+y)}dy\\]\n\\[\\int_x^{2x} 2e^{-(x+3y)}dy\\]\nFind the area of the region bounded by the graphs of \\(f(x)=2-x^2\\) and \\(g(x)=x\\) by integrating with respect to \\(x\\).\nFind the area of the region bounded by the graphs of \\(f(x)=2-x^2\\) and \\(g(x)=x\\) by integrating with respect to \\(y\\).\nFind the area of the region bounded by the graphs of \\(x=3-y^2\\) and \\(y=x-1\\) by integrating with respect to \\(x\\).\nFind the area of the region bounded by the graphs of \\(x=3-y^2\\) and \\(y=x-1\\) by integrating with respect to \\(y\\)."
  },
  {
    "objectID": "homework/HW_06.html#some-select-answers",
    "href": "homework/HW_06.html#some-select-answers",
    "title": "Homework 6",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nCalculus Review\n\n(a)  \\(c(\\frac{y^{2}}{2}+y^{2})\\)\n(b)  \\(\\frac{8}{9}xy^{2}+\\frac{5}{9}y^{4}\\)\n(c)  \\(\\frac{8}{9}x^{2}y+\\frac{20}{9}xy^{3}\\)\n(d)  \\(-2e^{-2y}+2e^{-y}\\)\n(e)  \\(xe^{-x}\\)\n(f)  \\(-\\frac{2}{3}(e^{-7x}-e^{-4x})\\)\n(g)  \\(\\frac{9}{2}\\)\n(h)  \\(\\frac{9}{2}\\)\n(i)  \\(\\frac{9}{2}\\)\n(j)  \\(\\frac{9}{2}\\)\n\nChapter 24\n\n# 2: (a) Discrete     (b) Discrete     (c) Continuous\n# 22: \\[f_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x &lt;0 \\\\\n            \\frac{7x}{4} & \\quad 0\\leq x\\leq 1 \\\\\n            0 & \\quad 1&lt; x&lt; 7 \\\\\n            \\frac{1}{8} & \\quad 7\\leq x\\leq 8 \\\\\n            0 & \\quad  x&gt;8 \\\\\n        \\end{array}\n    \\right.\\]\n\nChapter 25\n\n# 4:   7/16\n# 8:  (a) \\(\\frac{25}{228}\\)     (b) \\(f_X(x)=\\frac{1}{12}(x+1)\\), for \\(0\\leq x\\leq 4\\)     (c) \\(f_Y(y)=\\frac{3}{76}(y^2+1)\\), for \\(0\\leq y\\leq 4\\)\n# 18:  5/6\n# 24:  (a) \\(f_X(x)=-2e^{-2x}+2e^{-x}\\), for \\(x\\geq 0\\)     (b) \\(f_Y(y)=2e^{-2y}\\), for \\(y\\geq 0\\)\n\nChapter 26\n\n# 12:  (b) \\(\\frac{233}{256}\\)     (c) \\(\\frac{65}{256}\\)     (d) \\(\\frac{1}{512}\\)\n# 20:  (a) Yes.     (b) \\(\\frac{15}{16}\\)\nNTB # 3: (b) 0.09999546   (d) \\(f_Z(z) =\\Big(\\frac{11}{5} - \\frac{2z}{5}\\Big)e^{-2z}\\), for what values of \\(z\\)?\n\nChapter 27\n\n# 6: \\(f_{X|Y}(x|y)=\\frac{e^{-x/4-y/5}}{4(e^{-y/5}-e^{-9y/20})}\\), for \\(0&lt; x&lt; y\\)\n# 8: \\(f_{X|Y}(x|y)=\\frac{1-x^2}{1-y-\\frac{(1-y)^3}{3}}\\), for \\(0\\leq x, 0\\leq y, x+y\\leq 1\\)\n# 12: (a) \\(f_{X|Y}(x|y)=\\frac{1}{2}\\)    (c) \\(\\frac{4}{7}\\)"
  },
  {
    "objectID": "homework/HW_05.html",
    "href": "homework/HW_05.html",
    "title": "Homework 5",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf or html format.\nYou can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. The Adobe Scan phone app is an easy way to scan photos and compile into a PDF. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nYou must show all of your work to receive credit.\nExtra problems do not need to be turned in!"
  },
  {
    "objectID": "homework/HW_05.html#directions",
    "href": "homework/HW_05.html#directions",
    "title": "Homework 5",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf or html format.\nYou can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. The Adobe Scan phone app is an easy way to scan photos and compile into a PDF. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nYou must show all of your work to receive credit.\nExtra problems do not need to be turned in!"
  },
  {
    "objectID": "homework/HW_05.html#non-textbook-problems-ntb",
    "href": "homework/HW_05.html#non-textbook-problems-ntb",
    "title": "Homework 5",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nLet \\(X_i\\sim\\) Binomial(\\(n_i,p\\)) be independent r.v.’s for \\(i=1,\\ldots,m\\).\n\nWhat does the r.v. \\(X=\\sum_{i=1}^mX_i\\) count, and what is the distribution of \\(X\\)? Make sure to specify the parameters of \\(X\\)’s distribution.\nFind \\(\\mathbb{E}[X]\\). Make sure to show your work for (b) and (c). However, you may use without proof what you know about the mean and variance of each \\(X_i\\).\nFind \\(Var[X]\\).\n\nApproximately 10% of U.S. Veterans are women. Suppose an investigator plans a study with 4500 participants that are Veterans. How many women can they expect to be included? Your answer must be calculated by defining a random variable and showing how to calculate the expected value.\nProve that for a r.v. \\(X\\) and constants \\(a\\) and \\(b\\), that \\[\\mathrm{Var}[aX+b]=a^2\\mathrm{Var}[X].\\]\nLet \\(\\bar{X}\\) be the random variable for the sample mean, \\(\\bar{X}=\\frac{\\sum_{i=1}^nX_i}{n}\\), where the \\(X_i\\) are i.i.d. random variables with common mean \\(\\mu\\) and variance \\(\\sigma^2\\).\n\nFind \\(\\mathbb{E}[\\bar{X}]\\).\nFind \\(Var[\\bar{X}]\\).\n\n\n\nExtra problems\n\nThere is a bowl containing 30 cashews, 20 pecans, 25 almonds, and 25 walnuts. I am going to randomly pick and eat 3 nuts (without replacement). Find the expected value of the number of cashews by defining the number of cashews as a sum of random variables. (This one takes a little while if we don’t rely on the\n\n\n\nLet \\(\\hat{p}\\) be the random variable for the sample proportion, \\(\\hat{p}=\\frac{X}{n}\\), where \\(X\\) is the number of successes in a random sample of size \\(n\\). Assume the probability of success is \\(p\\).\n\nFind \\(\\mathbb{E}[\\hat{p}]\\).\nFind \\(Var[\\hat{p}]\\)."
  },
  {
    "objectID": "homework/HW_05.html#some-select-answers",
    "href": "homework/HW_05.html#some-select-answers",
    "title": "Homework 5",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nNon-textbook problems\n\n# 1:\n\nChapter 10\n\n# 6:  750.5\n# 8:  0.9\n# 10:   201\n# 14:   (a) 1.875     (b) 3.125     \n\nChapter 11\n\n# 2:  1.6\n# 18:  a) 48.5     (b) 96     \n# 20:  \\(\\approx\\) 23.077"
  },
  {
    "objectID": "homework/HW_00.html",
    "href": "homework/HW_00.html",
    "title": "Homework 0",
    "section": "",
    "text": "Due 10/02\nThis homework does not need to be turned in on Sakai."
  },
  {
    "objectID": "homework/HW_00.html#directions",
    "href": "homework/HW_00.html#directions",
    "title": "Homework 0",
    "section": "",
    "text": "This homework does not need to be turned in on Sakai.\n\n\nThis homework is meant to introduce yourself to me and your peers. In the first class, we will all briefly introduce ourselves, but we don’t have enough time in-depth introductions. Thus, I’d like you to share some information with the class over Slack.\n\n\n\nGrading will be done as a check/no check for turning in your work. If you are stressed about time, please give yourself an extension."
  },
  {
    "objectID": "homework/HW_00.html#questions",
    "href": "homework/HW_00.html#questions",
    "title": "Homework 0",
    "section": "Questions",
    "text": "Questions\n\nQuestion 1\nPlease upload a picture of yourself to Sakai. Make sure your face is visible in this picture. It will help me and the TAs identify you.\nPlease follow the below steps to add a picture of yourself in Sakai:\n\nClick on the top right circle on your Sakai page. If you do not have a picture already, your initials will be showing.\nClick “Profile.”\nOnce in your profile, hover over the square then click “Change picture.”\nUpload a picture file of yourself.\n\n\n\nQuestion 2\nProvide a pronunciation of your name: Please follow the below steps to add an audio and written pronunciation of your name in Sakai:\n\nClick on the top right circle on your Sakai page. If you do not have a picture already, your initials will be showing.\nClick “Profile.”\nHover over the section “Name Pronunciation and Pronouns.” Click the edit button that should appear in the top right corner of the section.\nAdd a recording of your name pronunciation. Please say your name a little slow! Check out my profile for an example.\nOPTIONAL You may also edit the phonetic pronunciation of your name. I realize that doing this is may require a lot of time researching phonetics.\nOPTIONAL If you are comfortable sharing your pronouns, please change these as well.\n\n\n\nQuestion 3\nPlease complete the following when2meet poll so that we can schedule office hours. Please use a unique identifier (does not have to be your name), so that I can make sure each student can attend at least one office hour.\n\n\nQuestion 4\nUse this Microsoft form to fill out your preferences on homework due dates and attendance policy.\n\n\nQuestion 5\nCompletion of this question is only necessary if you have accommodations. If you have any learning accommodations, please email me about your needs. I should receive a direct email from the Office of Student Access, but it is important that we discuss how accommodations will translate to our class. If you plan to seek accommodations, but do not have the formal document yet, please let me know!\nI highly suggest that you make an appointment with a learning specialist through Student Academic Support Services! If you often need more time on a test, struggle to focus in class, or noticed a difference between your learning style and typical styles offered in school, talk to academic support services and see if you qualify for accommodations! Most professors should be working towards an inclusive classroom, but this is the best way to insure you get the learning environment you need!"
  },
  {
    "objectID": "homework/HW_03.html",
    "href": "homework/HW_03.html",
    "title": "Homework 3",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf or html format.\nYou can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. The Adobe Scan phone app is an easy way to scan photos and compile into a PDF. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nYou must show all of your work to receive credit.\nExtra problems do not need to be turned in!!"
  },
  {
    "objectID": "homework/HW_03.html#directions",
    "href": "homework/HW_03.html#directions",
    "title": "Homework 3",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf or html format.\nYou can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. The Adobe Scan phone app is an easy way to scan photos and compile into a PDF. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nYou must show all of your work to receive credit.\nExtra problems do not need to be turned in!!"
  },
  {
    "objectID": "homework/HW_03.html#non-textbook-problems-ntb",
    "href": "homework/HW_03.html#non-textbook-problems-ntb",
    "title": "Homework 3",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\nDo not do this problem!!\n\nLet \\(X_i\\sim\\) Binomial(\\(n_i,p\\)) be independent r.v.’s for \\(i=1,\\ldots,m\\).\n\nWhat does the r.v. \\(X=\\sum_{i=1}^mX_i\\) count, and what is the distribution of \\(X\\)? Make sure to specify the parameters of \\(X\\)’s distribution.\nFind \\(\\mathbb{E}[X]\\). Make sure to show your work for (b) and (c). However, you may use without proof what you know about the mean and variance of each \\(X_i\\).\nFind \\(Var[X]\\).\n\n\n\nExtra Problems\n\nCalculus Review\n\n\\[\\int_0^yc(x+y)dx\\]\n\\[\\frac{d}{dx}\\bigg(\\frac{4}{9}x^2y^2+\\frac{5}{9}xy^4\\bigg)\\]\n\\[\\frac{d}{dy}\\bigg(\\frac{4}{9}x^2y^2+\\frac{5}{9}xy^4\\bigg)\\]\n\\[\\int_0^y2e^{-x}e^{-y}dx\\]\n\\[\\int_0^\\infty xye^{-(x+y)}dy\\]\n\\[\\int_x^{2x} 2e^{-(x+3y)}dy\\]\nFind the area of the region bounded by the graphs of \\(f(x)=2-x^2\\) and \\(g(x)=x\\) by integrating with respect to \\(x\\).\nFind the area of the region bounded by the graphs of \\(f(x)=2-x^2\\) and \\(g(x)=x\\) by integrating with respect to \\(y\\).\nFind the area of the region bounded by the graphs of \\(x=3-y^2\\) and \\(y=x-1\\) by integrating with respect to \\(x\\).\nFind the area of the region bounded by the graphs of \\(x=3-y^2\\) and \\(y=x-1\\) by integrating with respect to \\(y\\).\n\nRead the Washington Post article The amazing woman who can smell Parkinson’s disease - before symptoms appear (http://www.washingtonpost.com/news/morning-mix/wp/2015/10/23/scottish-woman-detects-a-musky-smell-that-could-radically-improve-how-parkinsons-disease-is-diagnosed/)\nAssuming Joy Milne does not have the ability to detect Parkinson’s disease via smell, answer the following questions:\n\nWhat is the probability of her correctly detecting Parkinson’s by smelling one t-shirt?\nWhat is the probability of her correctly detecting Parkinson’s in 12 out of 12 t-shirts?\n\nLet \\(X_i\\sim\\) Negative Binomial(\\(r_i,p\\)) be independent r.v.’s for \\(i=1,\\ldots,m\\).\n\nWhat does the r.v. \\(X=\\sum_{i=1}^mX_i\\) count, and what is the distribution of \\(X\\)? Make sure to specify the parameters of \\(X\\)’s distribution.\nFind \\(\\mathbb{E}[X]\\). Make sure to show your work for (b) and (c). However, you may use without proof what you know about the mean and variance of each \\(X_i\\).\nFind \\(Var[X]\\)."
  },
  {
    "objectID": "homework/HW_03.html#some-select-answers",
    "href": "homework/HW_03.html#some-select-answers",
    "title": "Homework 3",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 5\n\nNTB # 1: 0.3916\n\nChapter 7\n\n# 2: \\(X\\in(0,\\infty)\\), continuous; \\(Y\\in\\{0,1,2,\\ldots\\}\\), discrete\n# 10: \\(X_j\\in[0,\\infty),j=1,\\ldots,100\\); \\(Y\\in[0,\\infty)\\); both continuous\n# 16: \\(Y\\) could be 0\n# 18: Yes, a r.v. can be both. Give an example!\n\nChapter 8\n\n# 2: (a) \\(p(x)=\\binom{7}{x}(.5)^7\\) for \\(x=0,1,2,\\ldots,7\\)\n# 9: (a) \\(c = \\frac{1}{8}\\)\n# 10:\n\n\n\n\n\\(x\\)\n2\n4\n6\n8\n\n\n\n\n\\(p(x)\\)\n3/10\n1/2\n3/20\n1/20"
  },
  {
    "objectID": "homework/HW_08.html",
    "href": "homework/HW_08.html",
    "title": "Homework 8",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf or html format.\nYou can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. The Adobe Scan phone app is an easy way to scan photos and compile into a PDF. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nYou must show all of your work to receive credit.\nExtra problems do not need to be turned in!"
  },
  {
    "objectID": "homework/HW_08.html#directions",
    "href": "homework/HW_08.html#directions",
    "title": "Homework 8",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf or html format.\nYou can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. The Adobe Scan phone app is an easy way to scan photos and compile into a PDF. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nYou must show all of your work to receive credit.\nExtra problems do not need to be turned in!"
  },
  {
    "objectID": "homework/HW_08.html#non-textbook-problems-ntb",
    "href": "homework/HW_08.html#non-textbook-problems-ntb",
    "title": "Homework 8",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nLet \\(X_i\\sim\\) Binomial(\\(n_i,p\\)) be independent r.v.’s for \\(i=1,\\ldots,m\\).\n\nWhat does the r.v. \\(X=\\sum_{i=1}^mX_i\\) count, and what is the distribution of \\(X\\)? Make sure to specify the parameters of \\(X\\)’s distribution.\nFind \\(\\mathbb{E}[X]\\). Make sure to show your work for (b) and (c). However, you may use without proof what you know about the mean and variance of each \\(X_i\\).\nFind \\(Var[X]\\).\n\n\n\nExtra problems\n\nSuppose that voters arrive at a polling station at the rate of 120 per hour.For each of the following parts, give the name and parameter(s) of the distribution to be used to model the event and set up the expression to find the specified probability.You do not need to compute the probability.\n\nThe probability that the next voter will arrive in less than 30 seconds.\nThe probability that 200 voters will arrive within two hours of each other.\nThe probability that the \\(50^{th}\\) voter will arrive in between 15 and 30 minutes.\n\nThe automatic opening device of a military cargo parachute has been designed to open when the parachute is 200 m above the ground. Suppose opening altitude actually has a normal distribution with mean value 200 m and standard deviation 30 m. Equipment damage will occur if the parachute opens at an altitude of less than 100 m. What is the probability that there is equipment damage to the payload of at least one of the five independently dropped parachutes?"
  },
  {
    "objectID": "homework/HW_08.html#some-select-answers",
    "href": "homework/HW_08.html#some-select-answers",
    "title": "Homework 8",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 25\n\n# 4:   7/16\n# 8:  (a) \\(\\frac{25}{228}\\)     (b) \\(f_X(x)=\\frac{1}{12}(x+1)\\), for \\(0\\leq x\\leq 4\\)     (c) \\(f_Y(y)=\\frac{3}{76}(y^2+1)\\), for \\(0\\leq y\\leq 4\\)\n# 18:  5/6\n# 24:  (a) \\(f_X(x)=-2e^{-2x}+2e^{-x}\\), for \\(x\\geq 0\\)     (b) \\(f_Y(y)=2e^{-2y}\\), for \\(y\\geq 0\\)\n\nChapter 26\n\n# 12:  (b) \\(\\frac{233}{256}\\)     (c) \\(\\frac{65}{256}\\)     (d) \\(\\frac{1}{512}\\)\n# 20:  (a) Yes.     (b) \\(\\frac{15}{16}\\)\nNTB # 3: (b) 0.09999546   (d) \\(f_Z(z) =\\Big(\\frac{11}{5} - \\frac{2z}{5}\\Big)e^{-2z}\\), for what values of \\(z\\)?\n\nChapter 27\n\n# 6: \\(f_{X|Y}(x|y)=\\frac{e^{-x/4-y/5}}{4(e^{-y/5}-e^{-9y/20})}\\), for \\(0&lt; x&lt; y\\)\n# 8: \\(f_{X|Y}(x|y)=\\frac{1-x^2}{1-y-\\frac{(1-y)^3}{3}}\\), for \\(0\\leq x, 0\\leq y, x+y\\leq 1\\)\n# 12: (a) \\(f_{X|Y}(x|y)=\\frac{1}{2}\\)    (c) \\(\\frac{4}{7}\\)\n\nChapter 28\n\n# 10: (a) 8/9     (b) 14/3     \n# 18: 4/5\n\nChapter 29\n\n# 10: (a) 26/81     (b) 74/9\n# 14: (a) 67/3     (b) 1/14     (c) 25/12     (d) \\(\\sqrt{25/12}\\)\n# 26: 250\n# 32: See notes (or book) for the proof from the discrete random variables case. The proof doesn’t depend on what type of random variable (discrete vs. continuous) is being used.\nNTB # 3: (a) 63     (b) 287/3     (c) -1, 41/3     (d) -7, 287/3\n\nChapter 30\n\n# 4: \\(f_x(x)=1/2\\) for \\(2\\leq x\\leq 4\\)\n# 8: (a) T     (b) T     (c) F\n# 10: (a) F     (b) T\n# 12: (a) T     (b) T     (c) F     (d) T\n\nChapter 31\n\n# 14: (a) 0.25     (b) 0.02887     (c) 0.063     (d) 0.0145     (e) 0.01625     (f) 0.0055     (f) 6.195    (g) 0.00433     (h) 61.95     (i) 0.0433\n# 17: 2.25\n# 18: 7/15\n\nChapter 32\n\n# 8: 0.2526\n# 5: 0.8047\n# 10: 0.4323\n\nChapter 33\n\n#10: (a) \\(f_x(x)=\\frac{x}{9}e^{-x/3}\\) for \\(x&gt; 0\\)     (b) 0.4963\n\nChapter 35\n\n# 6: (a) 0     (b) -1.13     (c) \\(\\pm 0.32\\)\n# 10: (a) 0.0475     (b) 0.0475     (c) 0.2283     (d) 68.97 to 81.03     (e) 48 to 102     (f) 68.97\n# 24: (a) 0.2119     (b) 0.0011\nNTB # 5:   0.002\n\nChapter 36\n\n# 4: 0.0044\n# 12: (a) 0.9525     (b) 0.7939     (c) 0.7939\n# 14: 0.5911\n# 16: (a) \\(R=8.225\\sigma+25\\mu\\)     (b) \\(R=16.45\\sigma+100\\mu\\)     (c) \\(R=164.5\\sigma+10,000\\mu\\)     (d) \\(R=1.645\\sqrt{n}\\sigma+n\\mu\\)\n\nChapter 37\n\n# 2: 0.8869\n# 4: 0.0023\n# 20: 0.3936\n# 24: 0.4562\n# 30: (b) 0.0022     (c) \\(478.696\\approx 479\\)"
  },
  {
    "objectID": "homework/HW_08.html#footnotes",
    "href": "homework/HW_08.html#footnotes",
    "title": "Homework 8",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI recommend doing the Chapter 29 Extra Problems in the order listed.↩︎"
  },
  {
    "objectID": "homework/HW_02.html",
    "href": "homework/HW_02.html",
    "title": "Homework 2",
    "section": "",
    "text": "Please turn in this homework on Sakai.\nPlease submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nYou must show all of your work to receive credit.\nExtra problems do not need to be turned in!!"
  },
  {
    "objectID": "homework/HW_02.html#directions",
    "href": "homework/HW_02.html#directions",
    "title": "Homework 2",
    "section": "",
    "text": "Please turn in this homework on Sakai.\nPlease submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nYou must show all of your work to receive credit.\nExtra problems do not need to be turned in!!"
  },
  {
    "objectID": "homework/HW_02.html#non-textbook-problems-ntb",
    "href": "homework/HW_02.html#non-textbook-problems-ntb",
    "title": "Homework 2",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nRecall from class, that we defined events \\(A,B,\\) and \\(C\\) to mutually independent if both (1) and (2) below hold. This point of this exercise is to show that \\((1)\\nRightarrow (2),\\) and \\((2)\\nRightarrow (1).\\) \\[\\begin{array}{cc}\n    (1) & \\mathbb{P}(A\\cap B\\cap C)=\\mathbb{P}(A)\\mathbb{P(}B)\\mathbb{P(}C) \\\\\n    (2) & \\mathbb{P}(A\\cap B)=\\mathbb{P}(A)\\mathbb{P(}B) \\\\\n    & \\mathbb{P}(A\\cap C)=\\mathbb{P}(A)\\mathbb{P(}C) \\\\\n    & \\mathbb{P}(B\\cap C)=\\mathbb{P}(B)\\mathbb{P(}C)%\n    \\end{array}%\\]\n\nSuppose two different fair dice are rolled. Let events \\(A,B,\\) and \\(C\\) be defined in the following way: \\[\\begin{array}{cl}\nA: & \\text{Roll a total of 7} \\\\\nB: & \\text{First die is a 6} \\\\\nC: & \\text{Second die is a 2}%\n\\end{array}%\\]\nShow that condition \\((2)\\) holds, but that condition \\((1)\\) does not.\nSuppose two different fair dice are rolled. Let events \\(A,B,\\) and \\(C\\) be defined in the following way: \\[\\begin{array}{cl}\nA: & \\text{Roll a 1 or 2 on the first die} \\\\\nB: & \\text{Roll a 3, 4, or 5 on the second die} \\\\\nC: & \\text{Roll a total of 4, 11, or 12}%\n\\end{array}%\\]\nShow that condition \\((1)\\) holds, but that condition \\((2)\\) does not.\n\nA new drug is packaged to contain 30 pills in a bottle. Suppose that 98% of all bottles contain no defective pills, 1.5% contain one defective pill, and 0.5% contain two defective pills. Two pills from a bottle are randomly selected and tested. What is the probability that there are 2 defective pills in the bottle given that one of the two tested pills is defective?"
  },
  {
    "objectID": "homework/HW_02.html#some-select-answers",
    "href": "homework/HW_02.html#some-select-answers",
    "title": "Homework 2",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 22\n\n# 30: (a) 2,835     (b) 405     (c) 10,780     (d) 7,980\n# 40: 0.6666667\n# 42: 0.002116402 (This is the answer when \\(n=5\\). Your answer needs to be in terms of \\(n\\).)\n# 44: 0.3\n# 46: 0.3333333\n# 48: 0.007936508 (This is the answer when \\(n=5\\). Your answer needs to be in terms of \\(n\\).)\n\nChapter 3\n\n# 4: (a) 0.111328    (b) 0.004872    0.995128\n# 10: (c) 0.384 If you have the right answer to (c), then you should be able to figure out the rest (see (e)).\n# 12: No.\nNTB #1: (a) 0.0799     (b) 0.07553     (c) 0.0655\n\nChapter 4\n\n#4: 0.25\n# 12: (a) 0.4285714     (b) 0.4285714     (c) 0.1428571"
  },
  {
    "objectID": "homework/HW_01.html",
    "href": "homework/HW_01.html",
    "title": "Homework 1",
    "section": "",
    "text": "Due 10/12 at 11pm"
  },
  {
    "objectID": "homework/HW_01.html#directions",
    "href": "homework/HW_01.html#directions",
    "title": "Homework 1",
    "section": "Directions",
    "text": "Directions\nPlease turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a single file with photos of your written work or any other method that can be turned into a pdf. The Adobe Scan phone app is an easy way to scan photos and compile into a PDF. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nYou must show all of your work to receive credit."
  },
  {
    "objectID": "homework/HW_01.html#non-textbook-problems-ntb",
    "href": "homework/HW_01.html#non-textbook-problems-ntb",
    "title": "Homework 1",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nSuppose the following are the percentage of US adults with the following conditions:\n\n\\(A\\): Hypertension 33%\n\\(B\\): Diabetes 9%\n\\(C\\): Metabolic syndrome 24%\n\\(A\\) or \\(B\\): 39%\n\\(A\\) or \\(C\\): 45%\n\\(B\\) or \\(C\\): 28%\n\\(A\\) or \\(B\\) or \\(C\\): 48%\n\n\nMake a Venn diagram of the 3 conditions labeling the percentage (or probability) for ALL of the 8 “sections”. Hint: Start from the last condition and work your way up!\nFor each of the following (1. - 7. below), (\\(i\\)) write out the event using unions, intersections, and/or complements of the events \\(A\\), \\(B\\), and \\(C\\) (this is NOT finding the probability, that’s in \\(ii\\)); (\\(ii\\)) find the probability of the event; and (\\(iii\\)) write a sentence explaining what the probability is of in terms of the context of the problem.\n\n\\(\\mathbb{P}\\)(event at least one of the 3)\n\\(\\mathbb{P}\\)(event none)\n\\(\\mathbb{P}\\)(event \\(A\\) only)\n\\(\\mathbb{P}\\)(event exactly one)\n\\(\\mathbb{P}\\)(event \\(A\\) and \\(B\\))\n\\(\\mathbb{P}\\)(event \\(A\\) and \\(B\\) but not \\(C\\))\n\\(\\mathbb{P}\\)(event all 3)\n\n\n\n\nExtra problem\n\nJudith has a penny, nickel, dime, and quarter in her pocket. So does Joe. They both reach into their pockets and choose a coin (all four coins are equally likely to be selected). Let X be the larger value (in cents) of the coins selected by Judith and Joe. For reference, the penny is 1 cent, nickel is 5 cents, dime is 10 cents, and quarter is 25 cents.\n\nHow many possible combinations is there for the pair of Judith’s and Joe’s selected coins? (Hint: we know to whom each coin belongs) \nDefine the sample space for X in this experiment. \nFind the probability for each possible value of X. \nFind the probability of the event that Judith’s coin is worth more than Joe’s."
  },
  {
    "objectID": "homework/HW_01.html#some-select-answers",
    "href": "homework/HW_01.html#some-select-answers",
    "title": "Homework 1",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 2\n\n# 4: 0.35\n# 8: 0.03125\n# 16: 0.48\n# 30: (a) 0.189     (b) 0.811     (c) 0.189"
  },
  {
    "objectID": "homework/HW_04.html",
    "href": "homework/HW_04.html",
    "title": "Homework 4",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf or html format.\nYou can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. The Adobe Scan phone app is an easy way to scan photos and compile into a PDF. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nYou must show all of your work to receive credit."
  },
  {
    "objectID": "homework/HW_04.html#directions",
    "href": "homework/HW_04.html#directions",
    "title": "Homework 4",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf or html format.\nYou can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. The Adobe Scan phone app is an easy way to scan photos and compile into a PDF. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nYou must show all of your work to receive credit."
  },
  {
    "objectID": "homework/HW_04.html#non-textbook-problems-ntb",
    "href": "homework/HW_04.html#non-textbook-problems-ntb",
    "title": "Homework 4",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nThe following table shows the results of a survey in which the subjects were a sample of 300 adults residing in a certain metropolitan area. Each subject was asked to indicate which of three policies they favored with respect to smoking in public places. (Table is from Biostatistics: A Foundation for Analysis in the Health Sciences, 10th Edition, Daniel, Wayne W.; Cross, Chad L., pg. 630)\n\n\n\n\n\nLet \\(X=\\) highest education level and \\(Y=\\) policy favored. We can let \\(X=1\\) for college graduate, \\(X=2\\) for high-school graduate, etc., and similarly for \\(Y\\), or just keep the category names for the different levels of \\(X\\) and \\(Y\\)\n\nMake a table for the joint pmf \\(p_{X,Y}(x,y)\\) and briefly describe in words what the values are the probability of.\nFind the marginal pmf \\(p_{X}(x)\\) and briefly describe in words what the values are the probability of.\nFind the marginal pmf \\(p_{Y}(y)\\) and briefly describe in words what the values are the probability of.\nMake a table for the joint cdf \\(F_{X,Y}(x,y)\\) and briefly describe in words what the values are the probability of.\nFind the marginal cdf \\(F_{X}(x)\\) and briefly describe in words what the values are the probability of.\nFind the marginal cdf \\(F_{Y}(y)\\) and briefly describe in words what the values are the probability of.\nMake a table for the conditional pmf \\(p_{X|Y}(x|y)\\) and briefly describe in words what the values are the probability of.\nMake a table for the conditional pmf \\(p_{Y|X}(y|x)\\) and briefly describe in words what the values are the probability of.\n\nEach day, Maude has a 1% chance of losing her cell phone (her behavior on different days is independent). Each day, Maude has a 3% chance of forgetting to eat breakfast (again, her behavior on different days is independent). Her breakfast and cell phone habits are independent. Let X be the number of days until she first loses her cell phone. Let Y be the number of days until she first forgets to eat breakfast. (Here, X and Y are independent.)\n\nFind the joint probability mass function of X and Y.\nFind the joint cdf of \\(X\\) and \\(Y\\) and briefly explain what \\(F_{X,Y}(x,y)\\) represents in the context of the problem.\nFind the conditional pmf \\(p_{Y|X}(y|x)\\)."
  },
  {
    "objectID": "homework/HW_04.html#some-select-answers",
    "href": "homework/HW_04.html#some-select-answers",
    "title": "Homework 4",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 9\n\nNTB # 1 Partial answers:\n\n\n\\(p_{X|Y}(X=\\text{high school}| Y=\\text{no smoking at all}) = 0.476\\)\n\n\n\\(p_{Y|X}( Y=\\text{no smoking at all}|X=\\text{high school}) = 0.200\\)\n\n\n\nChapter 10\n\n# 6:  750.5\n# 8:  0.9\n# 10:   201\n# 14:   (a) 1.875     (b) 3.125     \n\nChapter 11\n\n# 2:  1.6\n# 18:  a) 48.5     (b) 96     \n# 20:  \\(\\approx\\) 23.077"
  },
  {
    "objectID": "homework/HW_07.html",
    "href": "homework/HW_07.html",
    "title": "Homework 7",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf or html format.\nYou can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. The Adobe Scan phone app is an easy way to scan photos and compile into a PDF. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nYou must show all of your work to receive credit.\nExtra problems do not need to be turned in!"
  },
  {
    "objectID": "homework/HW_07.html#directions",
    "href": "homework/HW_07.html#directions",
    "title": "Homework 7",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf or html format.\nYou can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. The Adobe Scan phone app is an easy way to scan photos and compile into a PDF. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nYou must show all of your work to receive credit.\nExtra problems do not need to be turned in!"
  },
  {
    "objectID": "homework/HW_07.html#non-textbook-problems-ntb",
    "href": "homework/HW_07.html#non-textbook-problems-ntb",
    "title": "Homework 7",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nLet \\(X_i\\sim\\) Binomial(\\(n_i,p\\)) be independent r.v.’s for \\(i=1,\\ldots,m\\).\n\nWhat does the r.v. \\(X=\\sum_{i=1}^mX_i\\) count, and what is the distribution of \\(X\\)? Make sure to specify the parameters of \\(X\\)’s distribution.\nFind \\(\\mathbb{E}[X]\\). Make sure to show your work for (b) and (c). However, you may use without proof what you know about the mean and variance of each \\(X_i\\).\nFind \\(Var[X]\\).\n\nApproximately 10% of U.S. Veterans are women. Suppose an investigator plans a study with 4500 participants that are Veterans. How many women can they expect to be included? Your answer must be calculated by defining a random variable and showing how to calculate the expected value.\nProve that for a r.v. \\(X\\) and constants \\(a\\) and \\(b\\), that \\[\\mathrm{Var}[aX+b]=a^2\\mathrm{Var}[X].\\]\nLet \\(\\bar{X}\\) be the random variable for the sample mean, \\(\\bar{X}=\\frac{\\sum_{i=1}^nX_i}{n}\\), where the \\(X_i\\) are i.i.d. random variables with common mean \\(\\mu\\) and variance \\(\\sigma^2\\).\n\nFind \\(\\mathbb{E}[\\bar{X}]\\).\nFind \\(Var[\\bar{X}]\\).\n\nLet \\(f_X(x)=\\lambda e^{-\\lambda x}\\) for \\(x&gt;0\\), where \\(\\lambda&gt;0\\).\n\nShow \\(Var[X]=\\frac{1}{\\lambda^2}\\). You may use the result from class for \\(\\mathbb{E}[X]\\) without first proving it.\n\nA shipping company handles containers in three different sizes: (1) 27 \\(ft^3\\) (3 x 3 x 3), (2) 125 \\(ft^3\\), and (3) 512 \\(ft^3\\). Let \\(X_i\\) (\\(i = 1, 2, 3\\)) denote the number of type \\(i\\) containers shipped during a given week. Suppose that \\(\\mu_1 =200,\\sigma_1=10,\\mu_2 =250,\\sigma_2=12,\\mu_3 =100,\\sigma_3=8\\).\n\nAssuming that \\(X_1,X_2,X_3\\) are independent, calculate the expected value and variance of the total volume shipped.\nWould your calculations necessarily be correct if the \\(X_i\\)’s were not independent? Explain.\n\nThe automatic opening device of a military cargo parachute has been designed to open when the parachute is 200 m above the ground. Suppose opening altitude actually has a normal distribution with mean value 200 m and standard deviation 30 m. Equipment damage will occur if the parachute opens at an altitude of less than 100 m. What is the probability that there is equipment damage to the payload of at least one of the five independently dropped parachutes?"
  },
  {
    "objectID": "homework/HW_07.html#some-select-answers",
    "href": "homework/HW_07.html#some-select-answers",
    "title": "Homework 7",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 25\n\n# 4:   7/16\n# 8:  (a) \\(\\frac{25}{228}\\)     (b) \\(f_X(x)=\\frac{1}{12}(x+1)\\), for \\(0\\leq x\\leq 4\\)     (c) \\(f_Y(y)=\\frac{3}{76}(y^2+1)\\), for \\(0\\leq y\\leq 4\\)\n# 18:  5/6\n# 24:  (a) \\(f_X(x)=-2e^{-2x}+2e^{-x}\\), for \\(x\\geq 0\\)     (b) \\(f_Y(y)=2e^{-2y}\\), for \\(y\\geq 0\\)\n\nChapter 26\n\n# 12:  (b) \\(\\frac{233}{256}\\)     (c) \\(\\frac{65}{256}\\)     (d) \\(\\frac{1}{512}\\)\n# 20:  (a) Yes.     (b) \\(\\frac{15}{16}\\)\nNTB # 3: (b) 0.09999546   (d) \\(f_Z(z) =\\Big(\\frac{11}{5} - \\frac{2z}{5}\\Big)e^{-2z}\\), for what values of \\(z\\)?\n\nChapter 27\n\n# 6: \\(f_{X|Y}(x|y)=\\frac{e^{-x/4-y/5}}{4(e^{-y/5}-e^{-9y/20})}\\), for \\(0&lt; x&lt; y\\)\n# 8: \\(f_{X|Y}(x|y)=\\frac{1-x^2}{1-y-\\frac{(1-y)^3}{3}}\\), for \\(0\\leq x, 0\\leq y, x+y\\leq 1\\)\n# 12: (a) \\(f_{X|Y}(x|y)=\\frac{1}{2}\\)    (c) \\(\\frac{4}{7}\\)\n\nChapter 28\n\n# 10: (a) 8/9     (b) 14/3     \n# 18: 4/5\n\nChapter 29\n\n# 10: (a) 26/81     (b) 74/9\n# 14: (a) 67/3     (b) 1/14     (c) 25/12     (d) \\(\\sqrt{25/12}\\)\n# 26: 250\n# 32: See notes (or book) for the proof from the discrete random variables case. The proof doesn’t depend on what type of random variable (discrete vs. continuous) is being used.\nNTB # 6: (a) 63     (b) 287/3     (c) -1, 41/3     (d) -7, 287/3\n\nChapter 30\n\n# 4: \\(f_x(x)=1/2\\) for \\(2\\leq x\\leq 4\\)\n# 8: (a) T     (b) T     (c) F\n# 10: (a) F     (b) T\n# 12: (a) T     (b) T     (c) F     (d) T"
  },
  {
    "objectID": "homework/HW_07.html#footnotes",
    "href": "homework/HW_07.html#footnotes",
    "title": "Homework 7",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI recommend doing the Chapter 29 Extra Problems in the order listed.↩︎\nAssume \\(X\\) and \\(Y\\) are independent.↩︎"
  },
  {
    "objectID": "hw_answers/HW_01.html",
    "href": "hw_answers/HW_01.html",
    "title": "Homework 1 Answers",
    "section": "",
    "text": "# 1: (a)  (b) Answers for part (ii) for each:\n\n0.48\n0.52\n0.2\n0.32\n0.03\n0.01\n0.02\n\n# 2: (a) 16, (c) for one, \\(P(X=10) = \\dfrac{5}{16}\\), (d) 0.375"
  },
  {
    "objectID": "hw_answers/HW_01.html#some-select-answers",
    "href": "hw_answers/HW_01.html#some-select-answers",
    "title": "Homework 1 Answers",
    "section": "",
    "text": "Selected answers (or hints) not provided at the end the book:\n\nChapter 2\n\n# 4: 0.35\n# 8: 0.03125\n# 16: 0.48\n# 30: (a) 0.189     (b) 0.811     (c) 0.189"
  },
  {
    "objectID": "hw_answers/HW_07.html",
    "href": "hw_answers/HW_07.html",
    "title": "Homework 7 Answers",
    "section": "",
    "text": "#1:"
  },
  {
    "objectID": "hw_answers/HW_07.html#directions",
    "href": "hw_answers/HW_07.html#directions",
    "title": "Homework 7 Answers",
    "section": "Directions",
    "text": "Directions\nPlease turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nThe more work you include that shows your thought process, the more I can give you feedback.\n\n\n\n\n\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n25\nTB # 18, NTB # 1\n# 1, 4, 8, 17, 23, 24\nSlide examples: 2, 3.3, 4\n\n\n26*\nTB # 12**, NTB # 2, 3\n# 7, 9, 19, 20\nSlide examples: 3\n\n\n27\nTB # 12***\n# 6, 8, 13, 17\nSlide examples: 1.2\n\n\n28\nTB # 18\nTB # 1, 10\n\n\n291\nNTB # 4-6\nTB # 10, 14, 23, 26, 11, 13, 32\n\n\n30\n\nTB # 4, 7-12\n\n\n\n\n* Although within Chapter 26, these exercises are primarily practicing the material from Chapter 25.\n** For this problem, you only need to set up the integrals!!\n*** For Ch 27 # 12, in order to find the conditional densities in parts (a) and (b), you will need to calculate \\(f_Y(y)\\) for the specific regions of \\(y\\) specified. After finding the conditional densities in parts (a) and (b), also calculate the conditional probabilities below. Please submit these together with your other work in parts (a) and (b): Find \\(\\mathbb{P}[0.5 &lt; X &lt; 3 | Y = 4]\\). Find \\(\\mathbb{P}[0.5 &lt; X &lt; 3 | Y = 7]\\)."
  },
  {
    "objectID": "hw_answers/HW_07.html#non-textbook-problems-ntb",
    "href": "hw_answers/HW_07.html#non-textbook-problems-ntb",
    "title": "Homework 7 Answers",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nLet \\(X_1, X_2, \\ldots, X_n\\) be i.i.d. random variables with common pdf \\(f_X(x)\\) and cdf \\(F_X(x)\\). Find the pdf for the random variable \\(Z\\), where \\(Z = max(X_1, X_2, \\ldots, X_n)\\).\nLet \\(X\\) and \\(Y\\) be independent random variables with respective pdf’s \\(f_X(x)=\\frac{1}{5}\\), for \\(0\\leq x\\leq 5\\), and \\(f_Y(y)=2e^{-2y}\\), for \\(y&gt;0\\).\n\nFind the joint distribution \\(f_{X,Y}(x,y)\\).\nFind the probability that \\(X\\) is less than \\(Y\\).\nLet \\(Z\\) be the random variable that is the smaller of \\(X\\) and \\(Y\\). Find the cumulative distribution function for \\(Z\\).\nFind the pdf for Z.\n\nSuppose that the random variables \\(X\\) and \\(Y\\) have joint density \\(f_{X,Y}(x,y)\\), for \\(0&lt;x&lt;1\\), and \\(\\frac{1}{2}&lt;y&lt;1\\). Set up the equation for the cdf of \\(Z\\), where \\(Z=X/Y\\).\nHint: First determine what the possible values for \\(Z\\) are. Then make a sketch of the domain of the joint pdf and shade in the region representing the cdf of Z for different values of \\(z\\). Make sure to pay close attention to how the region we need to integrate over changes as \\(z\\) changes. The cdf has two different cases depending on the value of \\(z\\). Plug in specific values of \\(z\\) and shade in the region representing the cdf to see why two different cases are needed.\nLet \\(f_X(x)=\\lambda e^{-\\lambda x}\\) for \\(x&gt;0\\), where \\(\\lambda&gt;0\\).\n\nShow \\(Var[X]=\\frac{1}{\\lambda^2}\\). You may use the result from class for \\(\\mathbb{E}[X]\\) without first proving it.\n\nA shipping company handles containers in three different sizes: (1) 27 \\(ft^3\\) (3 x 3 x 3), (2) 125 \\(ft^3\\), and (3) 512 \\(ft^3\\). Let \\(X_i\\) (\\(i = 1, 2, 3\\)) denote the number of type \\(i\\) containers shipped during a given week. Suppose that \\(\\mu_1 =200,\\sigma_1=10,\\mu_2 =250,\\sigma_2=12,\\mu_3 =100,\\sigma_3=8\\).\n\nAssuming that \\(X_1,X_2,X_3\\) are independent, calculate the expected value and variance of the total volume shipped.\nWould your calculations necessarily be correct if the \\(X_i\\)’s were not independent? Explain.\n\nSuppose your waiting time for a bus in the morning is uniformly distributed on [0, 8] (minutes), whereas waiting time in the evening is uniformly distributed on [0, 10] (minutes) independent of morning waiting time. Make sure to FIRST set up an equation for calculating the total waiting time in each question before calculating the mean and variance of the total waiting time. You may use results from class for the expected value and variance of uniform r.v.’s without proving them.\n\nIf you take the bus each morning and evening for a week (7 days), what is your total expected waiting time?\nWhat is the variance of your total waiting time?\nWhat are the expected value and variance of the difference between morning and evening waiting times on a given day?\nWhat are the expected value and variance of the difference between total morning waiting time and total evening waiting time for a particular week?"
  },
  {
    "objectID": "hw_answers/HW_07.html#some-select-answers",
    "href": "hw_answers/HW_07.html#some-select-answers",
    "title": "Homework 7 Answers",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 25\n\n# 4:   7/16\n# 8:  (a) \\(\\frac{25}{228}\\)     (b) \\(f_X(x)=\\frac{1}{12}(x+1)\\), for \\(0\\leq x\\leq 4\\)     (c) \\(f_Y(y)=\\frac{3}{76}(y^2+1)\\), for \\(0\\leq y\\leq 4\\)\n# 18:  5/6\n# 24:  (a) \\(f_X(x)=-2e^{-2x}+2e^{-x}\\), for \\(x\\geq 0\\)     (b) \\(f_Y(y)=2e^{-2y}\\), for \\(y\\geq 0\\)\n\nChapter 26\n\n# 12:  (b) \\(\\frac{233}{256}\\)     (c) \\(\\frac{65}{256}\\)     (d) \\(\\frac{1}{512}\\)\n# 20:  (a) Yes.     (b) \\(\\frac{15}{16}\\)\nNTB # 3: (b) 0.09999546   (d) \\(f_Z(z) =\\Big(\\frac{11}{5} - \\frac{2z}{5}\\Big)e^{-2z}\\), for what values of \\(z\\)?\n\nChapter 27\n\n# 6: \\(f_{X|Y}(x|y)=\\frac{e^{-x/4-y/5}}{4(e^{-y/5}-e^{-9y/20})}\\), for \\(0&lt; x&lt; y\\)\n# 8: \\(f_{X|Y}(x|y)=\\frac{1-x^2}{1-y-\\frac{(1-y)^3}{3}}\\), for \\(0\\leq x, 0\\leq y, x+y\\leq 1\\)\n# 12: (a) \\(f_{X|Y}(x|y)=\\frac{1}{2}\\)    (c) \\(\\frac{4}{7}\\)\n\nChapter 28\n\n# 10: (a) 8/9     (b) 14/3     \n# 18: 4/5\n\nChapter 29\n\n# 10: (a) 26/81     (b) 74/9\n# 14: (a) 67/3     (b) 1/14     (c) 25/12     (d) \\(\\sqrt{25/12}\\)\n# 26: 250\n# 32: See notes (or book) for the proof from the discrete random variables case. The proof doesn’t depend on what type of random variable (discrete vs. continuous) is being used.\nNTB # 6: (a) 63     (b) 287/3     (c) -1, 41/3     (d) -7, 287/3\n\nChapter 30\n\n# 4: \\(f_x(x)=1/2\\) for \\(2\\leq x\\leq 4\\)\n# 8: (a) T     (b) T     (c) F\n# 10: (a) F     (b) T\n# 12: (a) T     (b) T     (c) F     (d) T"
  },
  {
    "objectID": "hw_answers/HW_07.html#footnotes",
    "href": "hw_answers/HW_07.html#footnotes",
    "title": "Homework 7 Answers",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI recommend doing the Chapter 29 Extra Problems in the order listed.↩︎"
  },
  {
    "objectID": "hw_answers/HW_04.html",
    "href": "hw_answers/HW_04.html",
    "title": "Homework 4 Answers",
    "section": "",
    "text": "#1:\n\n\nDenominator should be 300\n\n\n\\(p_X(1) = 0.25\\), \\(p_X(2) = 0.5\\), \\(p_X(3) = 0.25\\)\n\n\n\\(p_Y(1) = 0.117\\), \\(p_Y(2) = 0.613\\), \\(p_Y(3) = 0.210\\), \\(p_Y(4) = 0.060\\)\n\n(d-f) skipping these answers\n\n\\(p_{X|Y}(X=\\text{high school}| Y=\\text{no smoking at all}) = 0.476\\)\n\n\n\\(p_{Y|X}( Y=\\text{no smoking at all}|X=\\text{high school}) = 0.200\\)\n\n\n#2:\n\n\n\\(p_{X,Y}(x, y) = [0.99^{x-1}0.01][0.97^{y-1}0.03]\\) for \\(x = 1, 2, 3, ...\\) and \\(y = 1, 2, 3, ...\\)\n\n\n\n\n\n\\(p_{Y|X}(y|x) = [0.97^{y-1}0.03]\\) for \\(y=1, 2, 3, ...\\)\n\n\n#3: 450\n#4: 0.9"
  },
  {
    "objectID": "hw_answers/HW_04.html#directions",
    "href": "hw_answers/HW_04.html#directions",
    "title": "Homework 4 Answers",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nThe more work you include that shows your thought process, the more I can give you feedback.\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n9\nNTB # 1, 2\n# 1, 2, 4, \\(8^{\\#}\\), 9, 10\n\n\n10*\nTB # 6\n# 1, 8, 10, 11, 14, 17\n\n\n11**\nNTB # 3, 4\n# 1, 2, 9***, 17***, 18***, 20\n\n\n\n\n\\(^\\#\\) Break up your solution to Chapter 9 #8 into the following 5 parts:\n\nMake a table of the joint probabilities for \\(X\\) and \\(Y\\).\nUsing the table in the previous part, write down the piecewise-defined equation for \\(p_{X,Y}(x,y)\\). There should be only 3 pieces (cases) for \\(p_{X,Y}(x,y)\\).\nExpress \\(p_Y(y)\\) as a formula (i.e. a function in terms of \\(y\\)).\nFind the conditional pmf \\(p_{X|Y}(x|y)\\) and express your answer as a piecewise-defined equation. There should be only 3 pieces (cases) for \\(p_{X|Y}(x|y)\\).\nMake a table of the joint cdf \\(F_{X,Y}(x,y)\\) values.\n\n* Use Chapter 10 techniques when computing expected values for Chapter 10 problems, i.e. computing the expected value directly using the definition of \\(\\mathbb{E}[X]\\).\n** Use Chapter 11 techniques when computing expected values for Chapter 11 problems, i.e. expressing the r.v. as a sum of other r.v.’s and calculating the expected value of the sum of r.v.’s. Also, as I mentioned in class and posted on Sakai, we will be skipping the more complex examples of finding expected values using indicator r.v.’s. You can skip Examples 11.5, 11.10, and 11.11. We will not be covering these techniques.\n*** Although Chapter 11 exercises, these are to be done using Chapter 10 techniques since we aren’t covering the more complex examples of finding expected values using indicator r.v.’s."
  },
  {
    "objectID": "hw_answers/HW_04.html#non-textbook-problems-ntb",
    "href": "hw_answers/HW_04.html#non-textbook-problems-ntb",
    "title": "Homework 4 Answers",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nThe following table shows the results of a survey in which the subjects were a sample of 300 adults residing in a certain metropolitan area. Each subject was asked to indicate which of three policies they favored with respect to smoking in public places. (Table is from Biostatistics: A Foundation for Analysis in the Health Sciences, 10th Edition, Daniel, Wayne W.; Cross, Chad L., pg. 630)\n\n\n\n\n\nLet \\(X=\\) highest education level and \\(Y=\\) policy favored. We can let \\(X=1\\) for college graduate, \\(X=2\\) for high-school graduate, etc., and similarly for \\(Y\\), or just keep the category names for the different levels of \\(X\\) and \\(Y\\)\n\nMake a table for the joint pmf \\(p_{X,Y}(x,y)\\) and briefly describe in words what the values are the probability of.\nFind the marginal pmf \\(p_{X}(x)\\) and briefly describe in words what the values are the probability of.\nFind the marginal pmf \\(p_{Y}(y)\\) and briefly describe in words what the values are the probability of.\nMake a table for the joint cdf \\(F_{X,Y}(x,y)\\) and briefly describe in words what the values are the probability of.\nFind the marginal cdf \\(F_{X}(x)\\) and briefly describe in words what the values are the probability of.\nFind the marginal cdf \\(F_{Y}(y)\\) and briefly describe in words what the values are the probability of.\nMake a table for the conditional pmf \\(p_{X|Y}(x|y)\\) and briefly describe in words what the values are the probability of.\nMake a table for the conditional pmf \\(p_{Y|X}(y|x)\\) and briefly describe in words what the values are the probability of.\n\nEach day, Maude has a 1% chance of losing her cell phone (her behavior on different days is independent). Each day, Maude has a 3% chance of forgetting to eat breakfast (again, her behavior on different days is independent). Her breakfast and cell phone habits are independent. Let X be the number of days until she first loses her cell phone. Let Y be the number of days until she first forgets to eat breakfast. (Here, X and Y are independent.)\n\nFind the joint probability mass function of X and Y.\nFind the joint cdf of \\(X\\) and \\(Y\\) and briefly explain what \\(F_{X,Y}(x,y)\\) represents in the context of the problem.\nFind the conditional pmf \\(p_{Y|X}(y|x)\\).\n\nApproximately 10% of U.S. Veterans are women. Suppose an investigator plans a study with 4500 participants that are Veterans. How many women can they expect to be included? Your answer must be calculated by defining a random variable and showing how to calculate the expected value.\nThere is a bowl containing 30 cashews, 20 pecans, 25 almonds, and 25 walnuts. I am going to randomly pick and eat 3 nuts (without replacement). Find the expected value of the number of cashews by defining the number of cashews as a sum of random variables. (This one takes a little while if we don’t rely on the"
  },
  {
    "objectID": "hw_answers/HW_04.html#some-select-answers",
    "href": "hw_answers/HW_04.html#some-select-answers",
    "title": "Homework 4 Answers",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 9\n\nNTB # 1 Partial answers:\n\n\n\\(p_{X|Y}(X=\\text{high school}| Y=\\text{no smoking at all}) = 0.476\\)\n\n\n\\(p_{Y|X}( Y=\\text{no smoking at all}|X=\\text{high school}) = 0.200\\)\n\n\n\nChapter 10\n\n# 6:  750.5\n# 8:  0.9\n# 10:   201\n# 14:   (a) 1.875     (b) 3.125     \n\nChapter 11\n\n# 2:  1.6\n# 18:  a) 48.5     (b) 96     \n# 20:  \\(\\approx\\) 23.077"
  },
  {
    "objectID": "hw_answers/HW_02.html",
    "href": "hw_answers/HW_02.html",
    "title": "Homework 2 Answers",
    "section": "",
    "text": "#1: (a) 1 does not hold because \\(0 \\neq \\dfrac{1}{216}\\)      (b) 2 does not hold because \\(P(B \\cap C) \\neq P(B)P(C)\\)\nNTB # 2: 0.3916"
  },
  {
    "objectID": "hw_answers/HW_02.html#directions",
    "href": "hw_answers/HW_02.html#directions",
    "title": "Homework 2",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nThe more work you include that shows your thought process, the more I can give you feedback.\n\n\n\n\n\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n22*\nTB # 1\n# 3, 5, 7, 25, 27, 30, 31, 39-41, 43-48\n\n\n3\nTB # 10, NTB # 1\n# 4, 9, 12, 13**\n\n\n4\nTB # 5\n# 1, 4, 11, 13\n\n\n\n\nSee also the handout Conditional Probability Practice posted in Week 2 Course Materials on Sakai for more practice.\n* Please note the following for Chapter 22:\n\nSee the table on pg. 277, which summarizes some key combinatorics concepts.\nProblems 39-48 are a set that build on one another and more advanced than the other problems. It’ll be much easier to do #42 after doing 39-41.\nI highly recommend reading Chapter 23, which is a series of case studies in counting: poker hands and Yahtzee.\n\n**For #3.13, mathematically solve for the sample size instead of plugging in numbers and guessing."
  },
  {
    "objectID": "hw_answers/HW_02.html#non-textbook-problems-ntb",
    "href": "hw_answers/HW_02.html#non-textbook-problems-ntb",
    "title": "Homework 2",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nRecall from class, that we defined events \\(A,B,\\) and \\(C\\) to mutually independent if both (1) and (2) below hold. This point of this exercise is to show that \\((1)\\nRightarrow (2),\\) and \\((2)\\nRightarrow (1).\\) \\[\\begin{array}{cc}\n    (1) & \\mathbb{P}(A\\cap B\\cap C)=\\mathbb{P}(A)\\mathbb{P(}B)\\mathbb{P(}C) \\\\\n    (2) & \\mathbb{P}(A\\cap B)=\\mathbb{P}(A)\\mathbb{P(}B) \\\\\n    & \\mathbb{P}(A\\cap C)=\\mathbb{P}(A)\\mathbb{P(}C) \\\\\n    & \\mathbb{P}(B\\cap C)=\\mathbb{P}(B)\\mathbb{P(}C)%\n    \\end{array}%\\]\n\nSuppose two different fair dice are rolled. Let events \\(A,B,\\) and \\(C\\) be defined in the following way: \\[\\begin{array}{cl}\nA: & \\text{Roll a total of 7} \\\\\nB: & \\text{First die is a 6} \\\\\nC: & \\text{Second die is a 2}%\n\\end{array}%\\]\nShow that condition \\((2)\\) holds, but that condition \\((1)\\) does not.\nSuppose two different fair dice are rolled. Let events \\(A,B,\\) and \\(C\\) be defined in the following way: \\[\\begin{array}{cl}\nA: & \\text{Roll a 1 or 2 on the first die} \\\\\nB: & \\text{Roll a 3, 4, or 5 on the second die} \\\\\nC: & \\text{Roll a total of 4, 11, or 12}%\n\\end{array}%\\]\nShow that condition \\((1)\\) holds, but that condition \\((2)\\) does not."
  },
  {
    "objectID": "hw_answers/HW_02.html#some-select-answers",
    "href": "hw_answers/HW_02.html#some-select-answers",
    "title": "Homework 2",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 22\n\n# 30: (a) 2,835     (b) 405     (c) 10,780     (d) 7,980\n# 40: 0.6666667\n# 42: 0.002116402 (This is the answer when \\(n=5\\). Your answer needs to be in terms of \\(n\\).)\n# 44: 0.3\n# 46: 0.3333333\n# 48: 0.007936508 (This is the answer when \\(n=5\\). Your answer needs to be in terms of \\(n\\).)\n\nChapter 3\n\n# 4: (a) 0.111328    (b) 0.004872    0.995128\n# 10: (c) 0.384 If you have the right answer to (c), then you should be able to figure out the rest (see (e)).\n# 12: No.\nNTB #1: (a) 0.0799     (b) 0.07553     (c) 0.0655\n\nChapter 4\n\n#4: 0.25\n# 12: (a) 0.4285714     (b) 0.4285714     (c) 0.1428571"
  },
  {
    "objectID": "hw_answers/HW_08.html",
    "href": "hw_answers/HW_08.html",
    "title": "Homework 8 Answers",
    "section": "",
    "text": "#1:"
  },
  {
    "objectID": "hw_answers/HW_08.html#directions",
    "href": "hw_answers/HW_08.html#directions",
    "title": "Homework 8 Answers",
    "section": "Directions",
    "text": "Directions\nPlease turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nThe more work you include that shows your thought process, the more I can give you feedback.\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n31\nTB # 18\nTB # 13, 14, 17\n\n\n32\nTB # 8\nTB # 3, 5, 101, 15\n\n\n33\nNTB # 1\nTB # 3, 9, 10\n\n\n35\nTB # 10, NTB # 2\nTB # 6, 9, 24\n\n\n36\nTB # 122, 14\nTB # 4, 11, 13, 15, 16\n\n\n37\nTB # 24, 30\nTB # 2, 4, 13, 20, 29\n\n\n\n\n* Although within Chapter 26, these exercises are primarily practicing the material from Chapter 25.\n** For Ch 27 # 12, in order to find the conditional densities in parts (a) and (b), you will need to calculate \\(f_Y(y)\\) for the specific regions of \\(y\\) specified. After finding the conditional densities in parts (a) and (b), also calculate the conditional probabilities below. Please submit these together with your other work in parts (a) and (b): Find \\(\\mathbb{P}[0.5 &lt; X &lt; 3 | Y = 4]\\). Find \\(\\mathbb{P}[0.5 &lt; X &lt; 3 | Y = 7]\\)."
  },
  {
    "objectID": "hw_answers/HW_08.html#non-textbook-problems-ntb",
    "href": "hw_answers/HW_08.html#non-textbook-problems-ntb",
    "title": "Homework 8 Answers",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nSuppose that voters arrive at a polling station at the rate of 120 per hour.For each of the following parts, give the name and parameter(s) of the distribution to be used to model the event and set up the expression to find the specified probability.You do not need to compute the probability.\n\nThe probability that the next voter will arrive in less than 30 seconds.\nThe probability that 200 voters will arrive within two hours of each other.\nThe probability that the \\(50^{th}\\) voter will arrive in between 15 and 30 minutes.\n\nThe automatic opening device of a military cargo parachute has been designed to open when the parachute is 200 m above the ground. Suppose opening altitude actually has a normal distribution with mean value 200 m and standard deviation 30 m. Equipment damage will occur if the parachute opens at an altitude of less than 100 m. What is the probability that there is equipment damage to the payload of at least one of the five independently dropped parachutes?"
  },
  {
    "objectID": "hw_answers/HW_08.html#some-select-answers",
    "href": "hw_answers/HW_08.html#some-select-answers",
    "title": "Homework 8 Answers",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 25\n\n# 4:   7/16\n# 8:  (a) \\(\\frac{25}{228}\\)     (b) \\(f_X(x)=\\frac{1}{12}(x+1)\\), for \\(0\\leq x\\leq 4\\)     (c) \\(f_Y(y)=\\frac{3}{76}(y^2+1)\\), for \\(0\\leq y\\leq 4\\)\n# 18:  5/6\n# 24:  (a) \\(f_X(x)=-2e^{-2x}+2e^{-x}\\), for \\(x\\geq 0\\)     (b) \\(f_Y(y)=2e^{-2y}\\), for \\(y\\geq 0\\)\n\nChapter 26\n\n# 12:  (b) \\(\\frac{233}{256}\\)     (c) \\(\\frac{65}{256}\\)     (d) \\(\\frac{1}{512}\\)\n# 20:  (a) Yes.     (b) \\(\\frac{15}{16}\\)\nNTB # 3: (b) 0.09999546   (d) \\(f_Z(z) =\\Big(\\frac{11}{5} - \\frac{2z}{5}\\Big)e^{-2z}\\), for what values of \\(z\\)?\n\nChapter 27\n\n# 6: \\(f_{X|Y}(x|y)=\\frac{e^{-x/4-y/5}}{4(e^{-y/5}-e^{-9y/20})}\\), for \\(0&lt; x&lt; y\\)\n# 8: \\(f_{X|Y}(x|y)=\\frac{1-x^2}{1-y-\\frac{(1-y)^3}{3}}\\), for \\(0\\leq x, 0\\leq y, x+y\\leq 1\\)\n# 12: (a) \\(f_{X|Y}(x|y)=\\frac{1}{2}\\)    (c) \\(\\frac{4}{7}\\)\n\nChapter 28\n\n# 10: (a) 8/9     (b) 14/3     \n# 18: 4/5\n\nChapter 29\n\n# 10: (a) 26/81     (b) 74/9\n# 14: (a) 67/3     (b) 1/14     (c) 25/12     (d) \\(\\sqrt{25/12}\\)\n# 26: 250\n# 32: See notes (or book) for the proof from the discrete random variables case. The proof doesn’t depend on what type of random variable (discrete vs. continuous) is being used.\nNTB # 3: (a) 63     (b) 287/3     (c) -1, 41/3     (d) -7, 287/3\n\nChapter 30\n\n# 4: \\(f_x(x)=1/2\\) for \\(2\\leq x\\leq 4\\)\n# 8: (a) T     (b) T     (c) F\n# 10: (a) F     (b) T\n# 12: (a) T     (b) T     (c) F     (d) T\n\nChapter 31\n\n# 14: (a) 0.25     (b) 0.02887     (c) 0.063     (d) 0.0145     (e) 0.01625     (f) 0.0055     (f) 6.195    (g) 0.00433     (h) 61.95     (i) 0.0433\n# 17: 2.25\n# 18: 7/15\n\nChapter 32\n\n# 8: 0.2526\n# 5: 0.8047\n# 10: 0.4323\n\nChapter 33\n\n#10: (a) \\(f_x(x)=\\frac{x}{9}e^{-x/3}\\) for \\(x&gt; 0\\)     (b) 0.4963\n\nChapter 35\n\n# 6: (a) 0     (b) -1.13     (c) \\(\\pm 0.32\\)\n# 10: (a) 0.0475     (b) 0.0475     (c) 0.2283     (d) 68.97 to 81.03     (e) 48 to 102     (f) 68.97\n# 24: (a) 0.2119     (b) 0.0011\nNTB # 5:   0.002\n\nChapter 36\n\n# 4: 0.0044\n# 12: (a) 0.9525     (b) 0.7939     (c) 0.7939\n# 14: 0.5911\n# 16: (a) \\(R=8.225\\sigma+25\\mu\\)     (b) \\(R=16.45\\sigma+100\\mu\\)     (c) \\(R=164.5\\sigma+10,000\\mu\\)     (d) \\(R=1.645\\sqrt{n}\\sigma+n\\mu\\)\n\nChapter 37\n\n# 2: 0.8869\n# 4: 0.0023\n# 20: 0.3936\n# 24: 0.4562\n# 30: (b) 0.0022     (c) \\(478.696\\approx 479\\)"
  },
  {
    "objectID": "hw_answers/HW_08.html#footnotes",
    "href": "hw_answers/HW_08.html#footnotes",
    "title": "Homework 8 Answers",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAssume \\(X\\) and \\(Y\\) are independent.↩︎\nAssume the distances between the cars are independent.↩︎"
  },
  {
    "objectID": "hw_answers/HW_03.html",
    "href": "hw_answers/HW_03.html",
    "title": "Homework 3 Answers",
    "section": "",
    "text": "#1: 0.3916"
  },
  {
    "objectID": "hw_answers/HW_03.html#directions",
    "href": "hw_answers/HW_03.html#directions",
    "title": "Homework 3 Answers",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nThe more work you include that shows your thought process, the more I can give you feedback.\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n5\nTB # 17, NTB # 1\n# 1, 9, 11\n\n\n7\n\n# 2, 10, 16, 17, 18\n\n\n8\nTB # 8*, 18*\n# 2, 5, 7, 10\n\n\n\n\n* In addition to the graphs, include piecewise defined functions for the pmf and cdf."
  },
  {
    "objectID": "hw_answers/HW_03.html#non-textbook-problems-ntb",
    "href": "hw_answers/HW_03.html#non-textbook-problems-ntb",
    "title": "Homework 3 Answers",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nA new drug is packaged to contain 30 pills in a bottle. Suppose that 98% of all bottles contain no defective pills, 1.5% contain one defective pill, and 0.5% contain two defective pills. Two pills from a bottle are randomly selected and tested. What is the probability that there are 2 defective pills in the bottle given that one of the two tested pills is defective?"
  },
  {
    "objectID": "hw_answers/HW_03.html#some-select-answers",
    "href": "hw_answers/HW_03.html#some-select-answers",
    "title": "Homework 3 Answers",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 5\n\nNTB # 1: 0.3916\n\nChapter 7\n\n# 2: \\(X\\in(0,\\infty)\\), continuous; \\(Y\\in\\{0,1,2,\\ldots\\}\\), discrete\n# 10: \\(X_j\\in[0,\\infty),j=1,\\ldots,100\\); \\(Y\\in[0,\\infty)\\); both continuous\n# 16: \\(Y\\) could be 0\n# 18: Yes, a r.v. can be both. Give an example!\n\nChapter 8\n\n# 2: (a) \\(p(x)=\\binom{7}{x}(.5)^7\\) for \\(x=0,1,2,\\ldots,7\\)\n# 9: (a) \\(c = \\frac{1}{8}\\)\n# 10:\n\n\n\n\n\\(x\\)\n2\n4\n6\n8\n\n\n\n\n\\(p(x)\\)\n3/10\n1/2\n3/20\n1/20"
  },
  {
    "objectID": "hw_answers/HW_05.html",
    "href": "hw_answers/HW_05.html",
    "title": "Homework 5 Answers",
    "section": "",
    "text": "#1: Start with definition of variance: I used \\(Var(X) = E(X^2) - [E(X)]^2\\)\n#2: (a) \\(E(\\bar{X}) = \\mu\\)      (b) \\(Var(\\bar{X}) = \\dfrac{\\sigma^2}{n}\\)\n#3: (a) \\(X\\sim binomial \\big(\\sum_{i=1}^m n_i, p\\big)\\)      (b) \\(E(X) = p\\sum_{i=1}^m n_i\\)      (c) \\(Var(X) = p(1-p)\\sum_{i=1}^m n_i\\)"
  },
  {
    "objectID": "hw_answers/HW_05.html#directions",
    "href": "hw_answers/HW_05.html#directions",
    "title": "Homework 5 Answers",
    "section": "Directions",
    "text": "Directions\nPlease turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nThe more work you include that shows your thought process, the more I can give you feedback.\n\n\n\n\n\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n12\nNTB # 1-2\n# 1, 2, 7, 11, 12, 15, 19, 25, 27, NTB # 4\n\n\n13 (review)\n\n# 3, 4, 5, 6, 8, 9, 10, 17, 25\n\n\n14\n\n# 3, 7\n\n\n15\nNTB # 3\n# 1, 5, 11, 18, 23, NTB # 5\n\n\n16\nTB # 7\n# 3a-g, 8, 11, 21\n\n\n17\nTB # 9\n# 3a-g, 6, 11, 12a-c, NTB # 6\n\n\n18\nTB # 20\n# 1, 24, 26, 27\n\n\n19\nTB # 6\n# 1, 18, 19\n\n\n20\n\n# 2, 3, 4"
  },
  {
    "objectID": "hw_answers/HW_05.html#non-textbook-problems-ntb",
    "href": "hw_answers/HW_05.html#non-textbook-problems-ntb",
    "title": "Homework 5 Answers",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nProve that for a r.v. \\(X\\) and constants \\(a\\) and \\(b\\), that \\[\\mathrm{Var}[aX+b]=a^2\\mathrm{Var}[X].\\]\nLet \\(\\bar{X}\\) be the random variable for the sample mean, \\(\\bar{X}=\\frac{\\sum_{i=1}^nX_i}{n}\\), where the \\(X_i\\) are i.i.d. random variables with common mean \\(\\mu\\) and variance \\(\\sigma^2\\).\n\nFind \\(\\mathbb{E}[\\bar{X}]\\).\nFind \\(Var[\\bar{X}]\\).\n\nLet \\(X_i\\sim\\) Binomial(\\(n_i,p\\)) be independent r.v.’s for \\(i=1,\\ldots,m\\).\n\nWhat does the r.v. \\(X=\\sum_{i=1}^mX_i\\) count, and what is the distribution of \\(X\\)? Make sure to specify the parameters of \\(X\\)’s distribution.\nFind \\(\\mathbb{E}[X]\\). Make sure to show your work for (b) and (c). However, you may use without proof what you know about the mean and variance of each \\(X_i\\).\nFind \\(Var[X]\\).\n\nExtra Problems\n\nLet \\(\\hat{p}\\) be the random variable for the sample proportion, \\(\\hat{p}=\\frac{X}{n}\\), where \\(X\\) is the number of successes in a random sample of size \\(n\\). Assume the probability of success is \\(p\\).\n\nFind \\(\\mathbb{E}[\\hat{p}]\\).\nFind \\(Var[\\hat{p}]\\).\n\nRead the Washington Post article The amazing woman who can smell Parkinson’s disease - before symptoms appear (http://www.washingtonpost.com/news/morning-mix/wp/2015/10/23/scottish-woman-detects-a-musky-smell-that-could-radically-improve-how-parkinsons-disease-is-diagnosed/)\nAssuming Joy Milne does not have the ability to detect Parkinson’s disease via smell, answer the following questions:\n\nWhat is the probability of her correctly detecting Parkinson’s by smelling one t-shirt?\nWhat is the probability of her correctly detecting Parkinson’s in 12 out of 12 t-shirts?\n\nLet \\(X_i\\sim\\) Negative Binomial(\\(r_i,p\\)) be independent r.v.’s for \\(i=1,\\ldots,m\\).\n\nWhat does the r.v. \\(X=\\sum_{i=1}^mX_i\\) count, and what is the distribution of \\(X\\)? Make sure to specify the parameters of \\(X\\)’s distribution.\nFind \\(\\mathbb{E}[X]\\). Make sure to show your work for (b) and (c). However, you may use without proof what you know about the mean and variance of each \\(X_i\\).\nFind \\(Var[X]\\)."
  },
  {
    "objectID": "hw_answers/HW_05.html#some-select-answers",
    "href": "hw_answers/HW_05.html#some-select-answers",
    "title": "Homework 5 Answers",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nChapter 12\n\n# 2:  64.8\n# 12:  1,096,357\n\nChapter 13\n\n# 4:  (a) 260/9     (b) 2.833     (c) \\(2.679\\times 10^{-5}\\)     (d) Same idea as (c) Replace 10’s with 100.     \n# 6:  (a) \\(p_X(x)=\\binom{4}{x}.3^x .7^{4-x}\\), for \\(x=0,1,\\ldots,4\\)     (d) 0.3483     (e) 0.9163     (f) 0.0233     (g) 1\n# 8:  (a) T     (b) F     (c) F     (d) F     (e) T     (f) T    (g) T\n# 10:  (a) T     (b) T    (c) F     (d) T    (e) T     (f) F    (g) T     (h) T (nonnegative instead of positive)     (i) F\n\nChapter 15\n\n# 18  (a) Bin(21,0.65)     (b) 4.78     \n\nChapter 16\n\n# 8  (a) 14.28      (b) code below     (c) \\(1.03\\times 10^{-6}\\)    (d) 10 questions: 91.43 minutes    \n\n\n1-pgeom(q = 18, prob = 0.07)\n\n[1] 0.2518698\n\n## OR\npgeom(q = 18, prob = 0.07, lower.tail = F)\n\n[1] 0.2518698\n\n\nChapter 17\n\n# 6   (a) 400, 87.18     (b) No     \n# 12   (c) 0.8000\n\nChapter 18\n\n# 24  (c) 0.8571\n# 26  162,754.8\n\nChapter 19\n\n# 6:  (c) 15.625     (d) 0.0486     (f) 0.0488\n# 18:   100\n\nChapter 20\n\n# 2:  (a) 0.0001     (b) Discrete since \\(X\\) has a finite number of possible values. Uniform since each outcome is equally likely.     (c) \\(X\\) = randomly selected 4-digit ID#; \\(X=0000,0001,\\ldots,9999\\)     (d) 5000.5     (e) 8,333,333.25"
  },
  {
    "objectID": "hw_answers/HW_06.html",
    "href": "hw_answers/HW_06.html",
    "title": "Homework 6 Answers",
    "section": "",
    "text": "#1:"
  },
  {
    "objectID": "hw_answers/HW_06.html#directions",
    "href": "hw_answers/HW_06.html#directions",
    "title": "Homework 6 Answers",
    "section": "Directions",
    "text": "Directions\nPlease turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nThe more work you include that shows your thought process, the more I can give you feedback.\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\nCalculus Review\n\nNTB # 1\n\n\n24\nTB # 19, 20*\n# 2, 3, 7, 17, 18, 22, 23\n\n\n\n\n*Also find the cdf \\(F_X(x)\\)"
  },
  {
    "objectID": "hw_answers/HW_06.html#non-textbook-problems-ntb",
    "href": "hw_answers/HW_06.html#non-textbook-problems-ntb",
    "title": "Homework 6 Answers",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nCalculus Review\n\n\\[\\int_0^yc(x+y)dx\\]\n\\[\\frac{d}{dx}\\bigg(\\frac{4}{9}x^2y^2+\\frac{5}{9}xy^4\\bigg)\\]\n\\[\\frac{d}{dy}\\bigg(\\frac{4}{9}x^2y^2+\\frac{5}{9}xy^4\\bigg)\\]\n\\[\\int_0^y2e^{-x}e^{-y}dx\\]\n\\[\\int_0^\\infty xye^{-(x+y)}dy\\]\n\\[\\int_x^{2x} 2e^{-(x+3y)}dy\\]\nFind the area of the region bounded by the graphs of \\(f(x)=2-x^2\\) and \\(g(x)=x\\) by integrating with respect to \\(x\\).\nFind the area of the region bounded by the graphs of \\(f(x)=2-x^2\\) and \\(g(x)=x\\) by integrating with respect to \\(y\\).\nFind the area of the region bounded by the graphs of \\(x=3-y^2\\) and \\(y=x-1\\) by integrating with respect to \\(x\\).\nFind the area of the region bounded by the graphs of \\(x=3-y^2\\) and \\(y=x-1\\) by integrating with respect to \\(y\\)."
  },
  {
    "objectID": "hw_answers/HW_06.html#some-select-answers",
    "href": "hw_answers/HW_06.html#some-select-answers",
    "title": "Homework 6 Answers",
    "section": "Some select answers",
    "text": "Some select answers\nSelected answers (or hints) not provided at the end the book:\n\nCalculus Review\n\n(a)  \\(c(\\frac{y^{2}}{2}+y^{2})\\)\n(b)  \\(\\frac{8}{9}xy^{2}+\\frac{5}{9}y^{4}\\)\n(c)  \\(\\frac{8}{9}x^{2}y+\\frac{20}{9}xy^{3}\\)\n(d)  \\(-2e^{-2y}+2e^{-y}\\)\n(e)  \\(xe^{-x}\\)\n(f)  \\(-\\frac{2}{3}(e^{-7x}-e^{-4x})\\)\n(g)  \\(\\frac{9}{2}\\)\n(h)  \\(\\frac{9}{2}\\)\n(i)  \\(\\frac{9}{2}\\)\n(j)  \\(\\frac{9}{2}\\)\n\nChapter 24\n\n# 2: (a) Discrete     (b) Discrete     (c) Continuous\n# 22: \\[f_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x &lt;0 \\\\\n            \\frac{7x}{4} & \\quad 0\\leq x\\leq 1 \\\\\n            0 & \\quad 1&lt; x&lt; 7 \\\\\n            \\frac{1}{8} & \\quad 7\\leq x\\leq 8 \\\\\n            0 & \\quad  x&gt;8 \\\\\n        \\end{array}\n    \\right.\\]\n\nChapter 25\n\n# 4:   7/16\n# 8:  (a) \\(\\frac{25}{228}\\)     (b) \\(f_X(x)=\\frac{1}{12}(x+1)\\), for \\(0\\leq x\\leq 4\\)     (c) \\(f_Y(y)=\\frac{3}{76}(y^2+1)\\), for \\(0\\leq y\\leq 4\\)\n# 18:  5/6\n# 24:  (a) \\(f_X(x)=-2e^{-2x}+2e^{-x}\\), for \\(x\\geq 0\\)     (b) \\(f_Y(y)=2e^{-2y}\\), for \\(y\\geq 0\\)\n\nChapter 26\n\n# 12:  (b) \\(\\frac{233}{256}\\)     (c) \\(\\frac{65}{256}\\)     (d) \\(\\frac{1}{512}\\)\n# 20:  (a) Yes.     (b) \\(\\frac{15}{16}\\)\nNTB # 3: (b) 0.09999546   (d) \\(f_Z(z) =\\Big(\\frac{11}{5} - \\frac{2z}{5}\\Big)e^{-2z}\\), for what values of \\(z\\)?\n\nChapter 27\n\n# 6: \\(f_{X|Y}(x|y)=\\frac{e^{-x/4-y/5}}{4(e^{-y/5}-e^{-9y/20})}\\), for \\(0&lt; x&lt; y\\)\n# 8: \\(f_{X|Y}(x|y)=\\frac{1-x^2}{1-y-\\frac{(1-y)^3}{3}}\\), for \\(0\\leq x, 0\\leq y, x+y\\leq 1\\)\n# 12: (a) \\(f_{X|Y}(x|y)=\\frac{1}{2}\\)    (c) \\(\\frac{4}{7}\\)"
  },
  {
    "objectID": "hw_answers/HW_02.html#non-textbook-problems",
    "href": "hw_answers/HW_02.html#non-textbook-problems",
    "title": "Homework 2 Answers",
    "section": "",
    "text": "#1: (a) 1 does not hold because \\(0 \\neq \\dfrac{1}{216}\\)      (b) 2 does not hold because \\(P(B \\cap C) \\neq P(B)P(C)\\)\nNTB # 2: 0.3916"
  },
  {
    "objectID": "hw_answers/HW_02.html#textbook-problems",
    "href": "hw_answers/HW_02.html#textbook-problems",
    "title": "Homework 2 Answers",
    "section": "Textbook problems",
    "text": "Textbook problems\nThere are answers at the back of the book!! Selected answers (or hints) not provided at the end the book:\n\nChapter 22\n\n# 30: (a) 2,835     (b) 405     (c) 10,780     (d) 7,980\n# 40: 0.6666667\n# 42: 0.002116402 (This is the answer when \\(n=5\\). Your answer needs to be in terms of \\(n\\).)\n# 44: 0.3\n# 46: 0.3333333\n# 48: 0.007936508 (This is the answer when \\(n=5\\). Your answer needs to be in terms of \\(n\\).)\n\nChapter 3\n\n# 4: (a) 0.111328    (b) 0.004872    0.995128\n# 10: (c) 0.384 If you have the right answer to (c), then you should be able to figure out the rest (see (e)).\n# 12: No.\nNTB #1: (a) 0.0799     (b) 0.07553     (c) 0.0655\n\nChapter 4\n\n#4: 0.25\n# 12: (a) 0.4285714     (b) 0.4285714     (c) 0.1428571\n\nChapter 5\n\n#17 a. 0.71; b. 0.29; c. 48/71; d. 1; e. 25/29; f. 25/39"
  },
  {
    "objectID": "hw_answers/HW_01.html#non-textbook-problems",
    "href": "hw_answers/HW_01.html#non-textbook-problems",
    "title": "Homework 1 Answers",
    "section": "",
    "text": "# 1: (a)  (b) Answers for part (ii) for each:\n\n0.48\n0.52\n0.2\n0.32\n0.03\n0.01\n0.02\n\n# 2: (a) 16, (c) for one, \\(P(X=10) = \\dfrac{5}{16}\\), (d) 0.375"
  },
  {
    "objectID": "hw_answers/HW_01.html#textbook-problems",
    "href": "hw_answers/HW_01.html#textbook-problems",
    "title": "Homework 1 Answers",
    "section": "Textbook problems",
    "text": "Textbook problems\nThere are some answers at the back of the book!! Selected answers (or hints) not provided at the end the book:\n\nChapter 2\n\n# 4: 0.35\n# 8: 0.03125\n# 16: 0.48\n# 23: 0.47\n# 30: (a) 0.189     (b) 0.811     (c) 0.189"
  },
  {
    "objectID": "hw_answers/HW_08.html#non-textbook-problems",
    "href": "hw_answers/HW_08.html#non-textbook-problems",
    "title": "Homework 8 Answers",
    "section": "",
    "text": "#1:"
  },
  {
    "objectID": "hw_answers/HW_08.html#textbook-problems",
    "href": "hw_answers/HW_08.html#textbook-problems",
    "title": "Homework 8 Answers",
    "section": "Textbook problems",
    "text": "Textbook problems\nThere are answers at the back of the book!! Selected answers (or hints) not provided at the end the book:\n\nChapter 25\n\n# 4:   7/16\n# 8:  (a) \\(\\frac{25}{228}\\)     (b) \\(f_X(x)=\\frac{1}{12}(x+1)\\), for \\(0\\leq x\\leq 4\\)     (c) \\(f_Y(y)=\\frac{3}{76}(y^2+1)\\), for \\(0\\leq y\\leq 4\\)\n# 18:  5/6\n# 24:  (a) \\(f_X(x)=-2e^{-2x}+2e^{-x}\\), for \\(x\\geq 0\\)     (b) \\(f_Y(y)=2e^{-2y}\\), for \\(y\\geq 0\\)\n\nChapter 26\n\n# 12:  (b) \\(\\frac{233}{256}\\)     (c) \\(\\frac{65}{256}\\)     (d) \\(\\frac{1}{512}\\)\n# 20:  (a) Yes.     (b) \\(\\frac{15}{16}\\)\nNTB # 3: (b) 0.09999546   (d) \\(f_Z(z) =\\Big(\\frac{11}{5} - \\frac{2z}{5}\\Big)e^{-2z}\\), for what values of \\(z\\)?\n\nChapter 27\n\n# 6: \\(f_{X|Y}(x|y)=\\frac{e^{-x/4-y/5}}{4(e^{-y/5}-e^{-9y/20})}\\), for \\(0&lt; x&lt; y\\)\n# 8: \\(f_{X|Y}(x|y)=\\frac{1-x^2}{1-y-\\frac{(1-y)^3}{3}}\\), for \\(0\\leq x, 0\\leq y, x+y\\leq 1\\)\n# 12: (a) \\(f_{X|Y}(x|y)=\\frac{1}{2}\\)    (c) \\(\\frac{4}{7}\\)\n\nChapter 28\n\n# 10: (a) 8/9     (b) 14/3     \n# 18: 4/5\n\nChapter 29\n\n# 10: (a) 26/81     (b) 74/9\n# 14: (a) 67/3     (b) 1/14     (c) 25/12     (d) \\(\\sqrt{25/12}\\)\n# 26: 250\n# 32: See notes (or book) for the proof from the discrete random variables case. The proof doesn’t depend on what type of random variable (discrete vs. continuous) is being used.\nNTB # 3: (a) 63     (b) 287/3     (c) -1, 41/3     (d) -7, 287/3\n\nChapter 30\n\n# 4: \\(f_x(x)=1/2\\) for \\(2\\leq x\\leq 4\\)\n# 8: (a) T     (b) T     (c) F\n# 10: (a) F     (b) T\n# 12: (a) T     (b) T     (c) F     (d) T"
  },
  {
    "objectID": "hw_answers/HW_03.html#non-textbook-problems",
    "href": "hw_answers/HW_03.html#non-textbook-problems",
    "title": "Homework 3 Answers",
    "section": "",
    "text": "#1: 0.3916"
  },
  {
    "objectID": "hw_answers/HW_03.html#textbook-problems",
    "href": "hw_answers/HW_03.html#textbook-problems",
    "title": "Homework 3 Answers",
    "section": "Textbook problems",
    "text": "Textbook problems\nThere are answers at the back of the book!! Selected answers (or hints) not provided at the end the book:\n\nChapter 7\n\n# 2: \\(X\\in(0,\\infty)\\), continuous; \\(Y\\in\\{0,1,2,\\ldots\\}\\), discrete\n# 10: \\(X_j\\in[0,\\infty),j=1,\\ldots,100\\); \\(Y\\in[0,\\infty)\\); both continuous\n# 16: \\(Y\\) could be 0\n# 18: Yes, a r.v. can be both. Give an example!\n\nChapter 8\n\n# 2: (a) \\(p(x)=\\binom{7}{x}(.5)^7\\) for \\(x=0,1,2,\\ldots,7\\)\n# 8: (a) \\(c = \\dfrac{1}{8}\\)     \n\n(b)\n\n(c)      \n(d) \n\n\n# 10:\n\n\n\n\n\\(x\\)\n2\n4\n6\n8\n\n\n\n\n\\(p(x)\\)\n3/10\n1/2\n3/20\n1/20\n\n\n\n\n# 18:\n\n(a) \n(b)"
  },
  {
    "objectID": "hw_answers/HW_07.html#non-textbook-problems",
    "href": "hw_answers/HW_07.html#non-textbook-problems",
    "title": "Homework 7 Answers",
    "section": "",
    "text": "#1:"
  },
  {
    "objectID": "hw_answers/HW_07.html#textbook-problems",
    "href": "hw_answers/HW_07.html#textbook-problems",
    "title": "Homework 7 Answers",
    "section": "Textbook problems",
    "text": "Textbook problems\nThere are answers at the back of the book!! Selected answers (or hints) not provided at the end the book:\n\nChapter 25\n\n# 4:   7/16\n# 8:  (a) \\(\\frac{25}{228}\\)     (b) \\(f_X(x)=\\frac{1}{12}(x+1)\\), for \\(0\\leq x\\leq 4\\)     (c) \\(f_Y(y)=\\frac{3}{76}(y^2+1)\\), for \\(0\\leq y\\leq 4\\)\n# 18:  5/6\n# 24:  (a) \\(f_X(x)=-2e^{-2x}+2e^{-x}\\), for \\(x\\geq 0\\)     (b) \\(f_Y(y)=2e^{-2y}\\), for \\(y\\geq 0\\)\n\nChapter 26\n\n# 12:  (b) \\(\\frac{233}{256}\\)     (c) \\(\\frac{65}{256}\\)     (d) \\(\\frac{1}{512}\\)\n# 20:  (a) Yes.     (b) \\(\\frac{15}{16}\\)\nNTB # 3: (b) 0.09999546   (d) \\(f_Z(z) =\\Big(\\frac{11}{5} - \\frac{2z}{5}\\Big)e^{-2z}\\), for what values of \\(z\\)?"
  },
  {
    "objectID": "hw_answers/HW_06.html#non-textbook-problems",
    "href": "hw_answers/HW_06.html#non-textbook-problems",
    "title": "Homework 6 Answers",
    "section": "",
    "text": "#1:"
  },
  {
    "objectID": "hw_answers/HW_06.html#textbook-problems",
    "href": "hw_answers/HW_06.html#textbook-problems",
    "title": "Homework 6 Answers",
    "section": "Textbook problems",
    "text": "Textbook problems\nThere are answers at the back of the book!! Selected answers (or hints) not provided at the end the book:\n\nCalculus Review\n\n(a)  \\(c(\\frac{y^{2}}{2}+y^{2})\\)\n(b)  \\(\\frac{8}{9}xy^{2}+\\frac{5}{9}y^{4}\\)\n(c)  \\(\\frac{8}{9}x^{2}y+\\frac{20}{9}xy^{3}\\)\n(d)  \\(-2e^{-2y}+2e^{-y}\\)\n(e)  \\(xe^{-x}\\)\n(f)  \\(-\\frac{2}{3}(e^{-7x}-e^{-4x})\\)\n(g)  \\(\\frac{9}{2}\\)\n(h)  \\(\\frac{9}{2}\\)\n(i)  \\(\\frac{9}{2}\\)\n(j)  \\(\\frac{9}{2}\\)\n\nChapter 24\n\n# 2: (a) Discrete     (b) Discrete     (c) Continuous\n# 22: \\[f_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x &lt;0 \\\\\n            \\frac{7x}{4} & \\quad 0\\leq x\\leq 1 \\\\\n            0 & \\quad 1&lt; x&lt; 7 \\\\\n            \\frac{1}{8} & \\quad 7\\leq x\\leq 8 \\\\\n            0 & \\quad  x&gt;8 \\\\\n        \\end{array}\n    \\right.\\]"
  },
  {
    "objectID": "hw_answers/HW_05.html#non-textbook-problems",
    "href": "hw_answers/HW_05.html#non-textbook-problems",
    "title": "Homework 5 Answers",
    "section": "",
    "text": "#1: Start with definition of variance: I used \\(Var(X) = E(X^2) - [E(X)]^2\\)\n#2: (a) \\(E(\\bar{X}) = \\mu\\)      (b) \\(Var(\\bar{X}) = \\dfrac{\\sigma^2}{n}\\)\n#3: (a) \\(X\\sim binomial \\big(\\sum_{i=1}^m n_i, p\\big)\\)      (b) \\(E(X) = p\\sum_{i=1}^m n_i\\)      (c) \\(Var(X) = p(1-p)\\sum_{i=1}^m n_i\\)"
  },
  {
    "objectID": "hw_answers/HW_05.html#textbook-problems",
    "href": "hw_answers/HW_05.html#textbook-problems",
    "title": "Homework 5 Answers",
    "section": "Textbook problems",
    "text": "Textbook problems\nThere are answers at the back of the book!! Selected answers (or hints) not provided at the end the book:\n\nChapter 12\n\n# 2:  64.8\n# 12:  1,096,357\n\nChapter 13\n\n# 4:  (a) 260/9     (b) 2.833     (c) \\(2.679\\times 10^{-5}\\)     (d) Same idea as (c) Replace 10’s with 100.     \n# 6:  (a) \\(p_X(x)=\\binom{4}{x}.3^x .7^{4-x}\\), for \\(x=0,1,\\ldots,4\\)     (d) 0.3483     (e) 0.9163     (f) 0.0233     (g) 1\n# 8:  (a) T     (b) F     (c) F     (d) F     (e) T     (f) T    (g) T\n# 10:  (a) T     (b) T    (c) F     (d) T    (e) T     (f) F    (g) T     (h) T (nonnegative instead of positive)     (i) F\n\nChapter 15\n\n# 18  (a) Bin(21,0.65)     (b) 4.78     \n\nChapter 16\n\n# 8  (a) 14.28      (b) code below     (c) \\(1.03\\times 10^{-6}\\)    (d) 10 questions: 91.43 minutes    \n\n\n1-pgeom(q = 18, prob = 0.07)\n\n[1] 0.2518698\n\n## OR\npgeom(q = 18, prob = 0.07, lower.tail = F)\n\n[1] 0.2518698\n\n\nChapter 17\n\n# 6   (a) 400, 87.18     (b) No     \n# 12   (c) 0.8000\n\nChapter 18\n\n# 20 (a) (b) 0.6514 (c) 0.0598\n# 24  (c) 0.8571\n# 26  162,754.8\n\nChapter 19\n\n# 6:  (c) 15.625     (d) 0.0486     (f) 0.0488\n# 18:   100\n\nChapter 20\n\n# 2:  (a) 0.0001     (b) Discrete since \\(X\\) has a finite number of possible values. Uniform since each outcome is equally likely.     (c) \\(X\\) = randomly selected 4-digit ID#; \\(X=0000,0001,\\ldots,9999\\)     (d) 5000.5     (e) 8,333,333.25"
  },
  {
    "objectID": "hw_answers/HW_04.html#non-textbook-problems",
    "href": "hw_answers/HW_04.html#non-textbook-problems",
    "title": "Homework 4 Answers",
    "section": "",
    "text": "#1:\n\n\nDenominator should be 300\n\n\n\\(p_X(1) = 0.25\\), \\(p_X(2) = 0.5\\), \\(p_X(3) = 0.25\\)\n\n\n\\(p_Y(1) = 0.117\\), \\(p_Y(2) = 0.613\\), \\(p_Y(3) = 0.210\\), \\(p_Y(4) = 0.060\\)\n\n(d-f) skipping these answers\n\n\\(p_{X|Y}(X=\\text{high school}| Y=\\text{no smoking at all}) = 0.476\\)\n\n\n\\(p_{Y|X}( Y=\\text{no smoking at all}|X=\\text{high school}) = 0.200\\)\n\n\n#2:\n\n\n\\(p_{X,Y}(x, y) = [0.99^{x-1}0.01][0.97^{y-1}0.03]\\) for \\(x = 1, 2, 3, ...\\) and \\(y = 1, 2, 3, ...\\)\n\n\n\n\n\n\\(p_{Y|X}(y|x) = [0.97^{y-1}0.03]\\) for \\(y=1, 2, 3, ...\\)\n\n\n#3: 450\n#4: 0.9"
  },
  {
    "objectID": "hw_answers/HW_04.html#textbook-problems",
    "href": "hw_answers/HW_04.html#textbook-problems",
    "title": "Homework 4 Answers",
    "section": "Textbook problems",
    "text": "Textbook problems\nThere are answers at the back of the book!! Selected answers (or hints) not provided at the end the book:\n\nChapter 10\n\n# 6:  750.5\n# 8:  0.9\n# 10:   201\n# 14:   (a) 1.875     (b) 3.125     \n\nChapter 11\n\n# 2:  1.6\n# 18:  a) 48.5     (b) 96     \n# 20:  \\(\\approx\\) 23.077"
  },
  {
    "objectID": "homework/HW_09.html",
    "href": "homework/HW_09.html",
    "title": "Homework 9",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf or html format.\nYou can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. The Adobe Scan phone app is an easy way to scan photos and compile into a PDF. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nYou must show all of your work to receive credit.\nExtra problems do not need to be turned in!"
  },
  {
    "objectID": "homework/HW_09.html#directions",
    "href": "homework/HW_09.html#directions",
    "title": "Homework 9",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf or html format.\nYou can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. The Adobe Scan phone app is an easy way to scan photos and compile into a PDF. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nYou must show all of your work to receive credit.\nExtra problems do not need to be turned in!"
  },
  {
    "objectID": "homework/HW_09.html#non-textbook-problems-ntb",
    "href": "homework/HW_09.html#non-textbook-problems-ntb",
    "title": "Homework 9",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nLet \\(R_X(t)=\\ln(M_X(t))\\). Show that \\(\\text{Var}(X)=R''_X(0)\\).\nThe mgf for a Gamma distribution is \\(M_X(t)=\\frac{1}{(1-t/\\lambda)^r}\\). Use the mgf of an Exponential distribution (from #43.9), to show that the sum of \\(n\\) i.i.d. Exponential(\\(\\lambda)\\) random variables has a Gamma(\\(r,\\lambda\\)) distribution.\n\n\nExtra problems\n\nUsing mgf’s, show that the sum of \\(n\\) i.i.d. Chi Square random variables with one degree of freedom (\\(\\chi^2_{(1)}\\)) r.v.’s has a Chi Square with \\(n\\) degrees of freedom (\\(\\chi^2_{(n)}\\)) distribution.\nHint: First, look up the pdf of a \\(\\chi^2_{(n)}\\). This is a special case of the Gamma distribution with what parameters? Based on that and the information from # 2 above, you can determine what the mgf of a \\(\\chi^2_{(n)}\\) is, which will help you determine whether the mgf of the sum of \\(n\\) i.i.d. \\(\\chi^2_{(1)}\\) r.v.’s has a \\(\\chi^2_{(n)}\\) distribution.\nUse the mgf of a Poisson distribution to find the mgf of the following distributions. If the mgf is that of a common named distribution, then name the distribution and state its parameter(s).\n\nThe distribution of \\(\\sum_{i=1}^nX_i\\), if \\(X_i\\sim\\)Poisson\\((\\lambda_i)\\) and are independent.\nThe distribution of \\(\\sum_{i=1}^3X_i\\), if \\(X_i\\sim\\)Poisson\\((\\lambda)\\) and are independent (i.i.d. in this case).\nThe distribution of \\(3X\\), if \\(X\\sim\\)Poisson\\((\\lambda)\\).\nWhy are the answers to (b) and (c) different?"
  },
  {
    "objectID": "homework/HW_09.html#some-select-answers",
    "href": "homework/HW_09.html#some-select-answers",
    "title": "Homework 9",
    "section": "Some select answers",
    "text": "Some select answers\n\nChapter 36\n\n#4: 0.0044\n# 12: (a) 0.9525     (b) 0.7939     (c) 0.7939\n# 14: 0.5911\n# 16:\n\n(a) \\(R=8.225\\sigma+25\\mu\\)     \n(b) \\(R=16.45\\sigma+100\\mu\\)     \n(c) \\(R=164.5\\sigma+10,000\\mu\\)     \n(d) \\(R=1.645\\sqrt{n}\\sigma+n\\mu\\)\n\n\nChapter 37\n\n#2: 0.8869\n# 4: 0.0023\n# 20: 0.3936\n# 24: 0.4562\n# 30: (b) 0.0022     (c) \\(478.696\\approx 479\\)\n\nChapter 43\n\nNTB # 3:\n\n(a) Poisson\\((\\sum_{i=1}^n \\lambda_i)\\)     \n(b) Poisson\\((3\\lambda)\\)     \n(c) \\(M_{3X}(t)=e{\\lambda(e^{3t}-1)}\\) This is not an mgf of a common probability distribution.     \n(d) In (b) we are adding independent r.v.’s \\(X_i\\), while in (c) we are adding dependent r.v.’s (\\(3X=X+X+X\\); \\(X\\) is dependent with itself)."
  },
  {
    "objectID": "homework/HW_09.html#footnotes",
    "href": "homework/HW_09.html#footnotes",
    "title": "Homework 9",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAssume the distances between the cars are independent.↩︎\nInclude in your answer an explanation as to why we need the condition that \\(t&lt;\\lambda\\).↩︎\nDo parts (a)-(c) below for #10 and #12: (a)Answer the question using the mgf \\(M_X(t)\\) as instructed in the book. (b) Answer the question using \\(R_X(t)\\) (as defined in class). (c) Which method did you prefer? Why?↩︎\nDo parts (a)-(c) below for #10 and #12: (a)Answer the question using the mgf \\(M_X(t)\\) as instructed in the book. (b) Answer the question using \\(R_X(t)\\) (as defined in class). (c) Which method did you prefer? Why?↩︎"
  },
  {
    "objectID": "homework/HW_10.html",
    "href": "homework/HW_10.html",
    "title": "Homework 10 (Optional)",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. The Adobe Scan phone app is an easy way to scan photos and compile into a PDF. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nYou must show all of your work to receive credit.\n\n\n\n\n\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n37\nTB # 24, 30\nTB # 2, 4, 13, 20, 29\n\n\n43\nTB #9*, 10**, 11, 12**, NTB # 1, 2, 4\nTB # 1-4, NTB # 3\n\n\n\n\n* Include in your answer an explanation as to why we need the condition that \\(t&lt;\\lambda\\).\n** Do parts (a)-(c) below for #10 and #12:\n\nAnswer the question using the mgf \\(M_X(t)\\) as instructed in the book.\nAnswer the question using \\(R_X(t)\\) (as defined in class, and NTB [Ch43_R_Var] below).\nWhich method did you prefer? Why?"
  },
  {
    "objectID": "homework/HW_10.html#directions",
    "href": "homework/HW_10.html#directions",
    "title": "Homework 10 (Optional)",
    "section": "",
    "text": "Please turn in this homework on Sakai. Please submit your homework in pdf format. You can type your work on your computer or submit a photo of your written work or any other method that can be turned into a pdf. The Adobe Scan phone app is an easy way to scan photos and compile into a PDF. Please let me know if you greatly prefer to submit a physical copy. We can work out another way for you to turn in homework.\nTry to complete all of the problems listed below at some point this quarter! You may want to save some of them for studying later! Only turn in the ones listed in the “Turn In” column. Please submit problems in the order they are listed.\nYou must show all of your work to receive credit.\n\n\n\n\n\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n37\nTB # 24, 30\nTB # 2, 4, 13, 20, 29\n\n\n43\nTB #9*, 10**, 11, 12**, NTB # 1, 2, 4\nTB # 1-4, NTB # 3\n\n\n\n\n* Include in your answer an explanation as to why we need the condition that \\(t&lt;\\lambda\\).\n** Do parts (a)-(c) below for #10 and #12:\n\nAnswer the question using the mgf \\(M_X(t)\\) as instructed in the book.\nAnswer the question using \\(R_X(t)\\) (as defined in class, and NTB [Ch43_R_Var] below).\nWhich method did you prefer? Why?"
  },
  {
    "objectID": "homework/HW_10.html#non-textbook-problems-ntb",
    "href": "homework/HW_10.html#non-textbook-problems-ntb",
    "title": "Homework 10 (Optional)",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nLet \\(R_X(t)=\\ln(M_X(t))\\). Show that Var\\((X)=R''_X(0)\\).\nThe mgf for a Gamma distribution is \\(M_X(t)=\\frac{1}{(1-t/\\lambda)^r}\\). Use the mgf of an Exponential distribution (from #43.9), to show that the sum of \\(n\\) i.i.d. Exponential(\\(\\lambda)\\) random variables has a Gamma(\\(r,\\lambda\\)) distribution.\nUse the mgf of a Poisson distribution to find the mgf of the following distributions. If the mgf is that of a common named distribution, then name the distribution and state its parameter(s).\n\nThe distribution of \\(\\sum_{i=1}^nX_i\\), if \\(X_i\\sim\\)Poisson\\((\\lambda_i)\\) and are independent.\nThe distribution of \\(\\sum_{i=1}^3X_i\\), if \\(X_i\\sim\\)Poisson\\((\\lambda)\\) and are independent (i.i.d. in this case).\nThe distribution of \\(3X\\), if \\(X\\sim\\)Poisson\\((\\lambda)\\).\nWhy are the answers to (b) and (c) different?\n\nUsing mgf’s, show that the sum of \\(n\\) i.i.d. Chi Square random variables with one degree of freedom (\\(\\chi^2_{(1)}\\)) r.v.’s has a Chi Square with \\(n\\) degrees of freedom (\\(\\chi^2_{(n)}\\)) distribution.\nHint: First, look up the pdf of a \\(\\chi^2_{(n)}\\). This is a special case of the Gamma distribution with what parameters? Based on that and the information from # [Ch43_SumExpGamma] above, you can determine what the mgf of a \\(\\chi^2_{(n)}\\) is, which will help you determine whether the mgf of the sum of \\(n\\) i.i.d. \\(\\chi^2_{(1)}\\) r.v.’s has a \\(\\chi^2_{(n)}\\) distribution."
  },
  {
    "objectID": "hw_answers/HW_10.html",
    "href": "hw_answers/HW_10.html",
    "title": "Homework 10 Answers",
    "section": "",
    "text": "#1:"
  },
  {
    "objectID": "hw_answers/HW_10.html#non-textbook-problems",
    "href": "hw_answers/HW_10.html#non-textbook-problems",
    "title": "Homework 10 Answers",
    "section": "",
    "text": "#1:"
  },
  {
    "objectID": "hw_answers/HW_10.html#textbook-problems",
    "href": "hw_answers/HW_10.html#textbook-problems",
    "title": "Homework 10 Answers",
    "section": "Textbook problems",
    "text": "Textbook problems\nThere are answers at the back of the book!! Selected answers (or hints) not provided at the end the book:\n\nChapter 37\n\n# 2: 0.8869\n# 4: 0.0023\n# 20: 0.3936\n# 24: 0.4562\n# 30: (b) 0.0022     (c) \\(478.696\\approx 479\\)\n\nChapter 43\n\nNTB 3: (a) Poisson\\((\\sum_{i=1}^n \\lambda_i)\\)     (b) Poisson\\((3\\lambda)\\)      (c) \\(M_{3X}(t)=e{\\lambda(e^{3t}-1)}\\) This is not an mgf of a common probability distribution.      (d) In (b) we are adding independent r.v.’s \\(X_i\\), while in (c) we are adding dependent r.v.’s (\\(3X=X+X+X\\); \\(X\\) is dependent with itself)."
  },
  {
    "objectID": "hw_answers/HW_09.html",
    "href": "hw_answers/HW_09.html",
    "title": "Homework 9 Answers",
    "section": "",
    "text": "#1:"
  },
  {
    "objectID": "hw_answers/HW_09.html#non-textbook-problems",
    "href": "hw_answers/HW_09.html#non-textbook-problems",
    "title": "Homework 9 Answers",
    "section": "",
    "text": "#1:"
  },
  {
    "objectID": "hw_answers/HW_09.html#textbook-problems",
    "href": "hw_answers/HW_09.html#textbook-problems",
    "title": "Homework 9 Answers",
    "section": "Textbook problems",
    "text": "Textbook problems\nThere are answers at the back of the book!! Selected answers (or hints) not provided at the end the book:\n\nChapter 31\n\n# 14: (a) 0.25     (b) 0.02887     (c) 0.063     (d) 0.0145     (e) 0.01625     (f) 0.0055     (f) 6.195    (g) 0.00433     (h) 61.95     (i) 0.0433\n# 17: 2.25\n# 18: 7/15\n\nChapter 32\n\n# 8: 0.2526\n# 5: 0.8047\n# 10: 0.4323\n\nChapter 33\n\n#10: (a) \\(f_x(x)=\\frac{x}{9}e^{-x/3}\\) for \\(x&gt; 0\\)     (b) 0.4963\n\nChapter 35\n\n# 6: (a) 0     (b) -1.13     (c) \\(\\pm 0.32\\)\n# 10: (a) 0.0475     (b) 0.0475     (c) 0.2283     (d) 68.97 to 81.03     (e) 48 to 102     (f) 68.97\n# 24: (a) 0.2119     (b) 0.0011\nNTB # 5:   0.002\n\nChapter 36\n\n# 4: 0.0044\n# 12: (a) 0.9525     (b) 0.7939     (c) 0.7939\n# 14: 0.5911\n# 16: (a) \\(R=8.225\\sigma+25\\mu\\)     (b) \\(R=16.45\\sigma+100\\mu\\)     (c) \\(R=164.5\\sigma+10,000\\mu\\)     (d) \\(R=1.645\\sqrt{n}\\sigma+n\\mu\\)\n\nChapter 37\n\n# 2: 0.8869\n# 4: 0.0023\n# 20: 0.3936\n# 24: 0.4562\n# 30: (b) 0.0022     (c) \\(478.696\\approx 479\\)"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability.html#monty-hall-problem",
    "href": "lessons/02_Probability/02_Probability.html#monty-hall-problem",
    "title": "Chapter 2: Introduction to Probability",
    "section": "Monty Hall Problem",
    "text": "Monty Hall Problem\nSurvivor Season 42"
  },
  {
    "objectID": "lessons/03_Independent_Events/03_Independent_Events.html#learning-objectives",
    "href": "lessons/03_Independent_Events/03_Independent_Events.html#learning-objectives",
    "title": "Chapter 3: Independent Events",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nDefine independence of 2-3 events given probability notation\nCalculate whether two or more events are independent"
  },
  {
    "objectID": "lessons/03_Independent_Events/03_Independent_Events.html#revisiting-our-coin-toss",
    "href": "lessons/03_Independent_Events/03_Independent_Events.html#revisiting-our-coin-toss",
    "title": "Chapter 3: Independent Events",
    "section": "Revisiting our coin toss",
    "text": "Revisiting our coin toss\nQuestion: Which of the following sequences of coin tosses of heads (\\(H\\)) and tails (\\(T\\)) is more likely to happen, assuming the coin is fair?\n\\[HTTHHHTHTHHTTTH\\] or \\[HTTTTTTTTHTTTTT\\]"
  },
  {
    "objectID": "lessons/03_Independent_Events/03_Independent_Events.html#independent-events",
    "href": "lessons/03_Independent_Events/03_Independent_Events.html#independent-events",
    "title": "Chapter 3: Independent Events",
    "section": "Independent Events",
    "text": "Independent Events\n\n\nDefinition: Independence\n\n\nEvents \\(A\\) and \\(B\\) are independent if \\[\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B).\\]\n\n\nNotation: For shorthand, we sometimes write \\(A \\mathrel{\\unicode{x2AEB}} B,\\) to denote that \\(A\\) and \\(B\\) are independent events.\n \n\nAlso note: \\[\\begin{aligned} \\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B) & \\implies A \\mathrel{\\unicode{x2AEB}} B \\\\\nA \\mathrel{\\unicode{x2AEB}} B & \\implies \\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B) \\end{aligned}\\]"
  },
  {
    "objectID": "lessons/03_Independent_Events/03_Independent_Events.html#example-of-two-dice",
    "href": "lessons/03_Independent_Events/03_Independent_Events.html#example-of-two-dice",
    "title": "Chapter 3: Independent Events",
    "section": "Example of two dice",
    "text": "Example of two dice\n\n\nExample 1\n\n\nTwo dice (red and blue) are rolled. Let \\(A =\\) event a total of 7 appears, and \\(B =\\) event red die is a six. Are events \\(A\\) and \\(B\\) independent?"
  },
  {
    "objectID": "lessons/03_Independent_Events/03_Independent_Events.html#independence-of-3-events",
    "href": "lessons/03_Independent_Events/03_Independent_Events.html#independence-of-3-events",
    "title": "Chapter 3: Independent Events",
    "section": "Independence of 3 Events",
    "text": "Independence of 3 Events\n\n\nDefinition: Independence of 3 Events\n\n\nEvents \\(A\\), \\(B\\), and \\(C\\) are mutually independent if\n\n\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot \\mathbb{P}(B)\\)\n\\(\\mathbb{P}(A \\cap C) = \\mathbb{P}(A) \\cdot \\mathbb{P}(C)\\)\n\\(\\mathbb{P}(B \\cap C) = \\mathbb{P}(B) \\cdot \\mathbb{P}(C)\\)\n\n\\(\\mathbb{P}(A \\cap B \\cap C) = \\mathbb{P}(A) \\cdot \\mathbb{P}(B) \\cdot \\mathbb{P}(C)\\)\n\n\n\nRemark:\nOn your homework you will show that \\((1) \\not \\Rightarrow (2)\\) and \\((2) \\not \\Rightarrow (1)\\)."
  },
  {
    "objectID": "lessons/03_Independent_Events/03_Independent_Events.html#probability-at-least-one-smoker",
    "href": "lessons/03_Independent_Events/03_Independent_Events.html#probability-at-least-one-smoker",
    "title": "Chapter 3: Independent Events",
    "section": "Probability at least one smoker",
    "text": "Probability at least one smoker\n\n\n\n\nExample 2\n\n\nSuppose you take a random sample of \\(n\\) people, of which people are smokers and non-smokers independently of each other. Let\n\n\\(A_i =\\) event person \\(i\\) is a smoker, for \\(i=1, \\ldots ,n\\), and\n\\(p_i =\\) probability person \\(i\\) is a smoker, for \\(i=1, \\ldots ,n\\).\n\nFind the probability that at least one person in the random sample is a smoker."
  },
  {
    "objectID": "lessons/03_Independent_Events/03_Independent_Events_muddy_points.html",
    "href": "lessons/03_Independent_Events/03_Independent_Events_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "1. How do I know if two events are independent?\nMy main piece of advice for independence is to rely on the math to show it, not logic! Don’t go into a problem thinking “Logically, these two events are independent.” If the problem does not say “Assume independence,” then we need to show it mathematically.\nSame goes with the definition of independence. When we say “knowing the outcome of one provides no information about the outcome of the other,” we once again need to show this mathematically, not just using logic. We translate the previous statement to \\[P(A) = P(A|B)\\] And we need to show this mathematically!\n\n\n2. Disjoint vs. Independent Events\nHere is a pretty good video breaking down disjoint (mutually exclusive) events and independent events. It includes examples as well."
  },
  {
    "objectID": "lessons/03_Independent_Events/03_Independent_Events_muddy_points.html#from-fall-2023",
    "href": "lessons/03_Independent_Events/03_Independent_Events_muddy_points.html#from-fall-2023",
    "title": "Muddy Points",
    "section": "From Fall 2023",
    "text": "From Fall 2023\n\n3. Order matters vs. order does not matter\nI think the best way to think about when order does and does not matter is through examples. So here is another example:\n\nI randomly select 3 different people to be on my committee from a larger group of 5 people (we’ll call them people A-E) …\n\nOrder matters: If I want to assign each person to a specific role as I select them, then I want to keep track of the order\nOrder does not matter: If I just want to assemble a committee without any hierarchy, then the order that I select them does not matter\n\nSo if I pick person A first, second, or third, they are still on the committee\n\n\n\nWhen order matters, the seats are now labelled as president, vice president, and treasurer:\n\n\n\n\n\nWhen order does not matter, there are just three seats to fill:\n\n\n\n\n\nFor both situations, let’s say you pick person A, C, and E. When order matters, we can arrange these three people in a few ways:\n\n\n\n\n\nSo there are 6 ways to order the three people.\nWhen order does not matter, then we just need to know that person A, E, and C are on the committee:\n\n\n\n\n\n**Remember that there are 6 permutations to this 1 combination\nLet’s answer more questions with this example…\n\nWhen order does not matter, what are we controlling for?\nIn class example 1.3 and 1.4, we went from an example where order matters to one where order does not matter. So I showed us going from a calculation of \\(\\dfrac{10!}{4!}\\) ways to order them to \\(\\dfrac{10!}{4!6!}\\) ways of choosing 6 subjects. So why do we divide by \\(6!\\) when order does not matter? Let’s think back to our three committee seats. For the three seats, and person A, C, and E selected, there were 6 ways to order them. In fact, for any three people selected, there is always 6 ways to arrange (order) them into the positions. We can calculate the number of ways to arrange them with another permutation: if given three people and three seats, we can arrange them in \\(3\\cdot2\\cdot1=6\\) ways because we have three options for president, then once the president is selected, we only have 2 options for VP, then 1 for treasurer. So for every 6 ways to order the three people, there is only one way to select them unordered. Thus, we divide the number of ordered options by the number of ways each group of three people can be ordered.\nSo the calculation for the ordered committee (with P, VP, and T) is:\n\n\n\n\n\nwhich is 60 ways to fill the committee seats when order (arrangement) matters.\nAnd the calculation for the unordered (order does not matter) committee will divide the ordered permutations by the number of ways to order within the three seats:\n\n\n\n\n\nwhich is 10 ways to fill the seats when order does not matter.\n\n\nIs the probability equal when order matters and when order does not matter?\nYes and no…\nIn the example with the spades, for order does not matter, we saw that \\(r!\\) cancels out and leaves us with a probability equal to when order does matter! This is because each spade is not distinguishable from the other. (Yes, technically each will have a different face, but we only care about the suit.) If we select a spade first then another spade, all we know of the order is spade first, spade second. If we flip that, we still get spade first, spade second. Thus, the order of the spades does not matter.\nIn the spades problem, we distinguished between “order matters” and “order does not matter” but the way we defined the probability, and the fact that spades are indistinguishable, means that the “ordered” cards really did not matter. It’ll definitely matter in an event where we get the first card as a spade and the second as a heart. We can no longer use combinations to define the event space!\nThe main take away should be that the probabilities (using order matters and order does not matter) are equal when order is not needed to define the event! When order does not matter, it can still be easier to calculate the probability using an “order matters” framework!! So we will use that to our advantage!\nBelow is some of the work demonstrating the probabilities loosely mentioned. Please note that ChatGPT could be a really helpful tool if you are curious about this question!\n\n\n\n\n\nI’ll leave the work to calculate the exact probabilities above. For Case #1, the probabilities are equal. For Case #2, the probabilities are not equal!\n\n\n\n4. Disjoint vs. Independent Events\nHere is a pretty good video breaking down disjoint (mutually exclusive) events and independent events. It includes examples as well."
  },
  {
    "objectID": "homeworks.html#structure-details-and-grading",
    "href": "homeworks.html#structure-details-and-grading",
    "title": "Homework",
    "section": "Structure, Details, and Grading",
    "text": "Structure, Details, and Grading\nThere are three distinct parts to our homework:\n\n\n\n\n\n\n\n\n\nHomework part\nDue date\nWhat is required?\nGrading\n\n\n\n\nIndividual assignment\nDate specified above\nYou will complete the homework assignment, and turn in an individual copy of your work. This will be graded for completion.\nFor completion\n\n\nGroup solutions\n\nWith groups 3, you will make a homework key for 4 questions (that Nicky chooses). Each group member will be in charge of turning in one question’s solutions. This will be graded for correctness. The group will receive the same grade, which is summed across questions.\nFor correctness\n\n\nIndividual presentation\n\nFor homeworks 3 and 7, you will also need to make a video or meet with me. You will use less than 10 minutes to explain your homework question solutions. This will be graded for correctness. Example videos will be posted after homework 1.\nGraded out of 4 points. 0 indicating no understanding of the solutions. 1 indicating some basic understanding, but missing major steps. 3 indicating that most of the problem is considered, but not necessarily all or all correctly. 4 indicating that all needed parts were considered and correctly solved.\n\n\n\nIf you are having any group dynamic issues, please please please come see me earlier rather than later! You do not need to wait for group evals. We will come up with options for moving forward!"
  },
  {
    "objectID": "lessons/00_Intro/00_Intro.html#decision-on-homework-due-dates",
    "href": "lessons/00_Intro/00_Intro.html#decision-on-homework-due-dates",
    "title": "Welcome to BSTA 550!",
    "section": "Decision on Homework due dates",
    "text": "Decision on Homework due dates\n\nI have some set due dates in the schedule\nPlease look at your other classes, your calendar, etc\nConsider what day of the week you would like to turn in your assignments\nQuestion in HW 0 to cast your vote and share your opinion"
  },
  {
    "objectID": "syllabus.html#key-course-info",
    "href": "syllabus.html#key-course-info",
    "title": "BSTA 550 Syllabus",
    "section": "Key Course Info",
    "text": "Key Course Info\n\nIf an assignment on Sakai is closed or you are submitting late work, please email me AND the TAs your work\nFor homework, you will have TWO no-questions-asked, 3-day extensions: one for the first assignment, and one for either the solutions or presentation. You just need to send me and the TAs a quick email saying “I am using my no-questions-asked extension for Homework __ assignment.”\nAttendance policy: Attend class in-person or asynchronously through recordings\n\nAttendance is recorded through Exit tickets that will be graded 7 days after each class\nAttendance is expected for most classes\n\nThe class will end on December 10, 2025. All coursework is expected to be completed by December 12, 2025 at 11pm."
  },
  {
    "objectID": "lessons/00_Intro/00_Intro.html#what-we-will-cover",
    "href": "lessons/00_Intro/00_Intro.html#what-we-will-cover",
    "title": "Welcome to BSTA 550!",
    "section": "What we will cover",
    "text": "What we will cover"
  },
  {
    "objectID": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#where-are-we",
    "href": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#where-are-we",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability.html#where-are-we",
    "href": "lessons/02_Probability/02_Probability.html#where-are-we",
    "title": "Chapter 2: Introduction to Probability",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/03_Independent_Events/03_Independent_Events.html#where-are-we",
    "href": "lessons/03_Independent_Events/03_Independent_Events.html#where-are-we",
    "title": "Chapter 3: Independent Events",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/04_Conditional_Probability/04_Conditional_Probability.html#where-are-we",
    "href": "lessons/04_Conditional_Probability/04_Conditional_Probability.html#where-are-we",
    "title": "Chapter 4: Conditional Probability",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/04_Conditional_Probability/04_Conditional_Probability.html#monty-hall-problem",
    "href": "lessons/04_Conditional_Probability/04_Conditional_Probability.html#monty-hall-problem",
    "title": "Chapter 4: Conditional Probability",
    "section": "Monty Hall Problem",
    "text": "Monty Hall Problem\nSurvivor Season 42\nWith the Wiki page on it!"
  },
  {
    "objectID": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#where-are-we",
    "href": "lessons/05_Bayes_Theorem/05_Bayes_Theorem.html#where-are-we",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/07_Random_Variables/07_Random_Variables.html#where-are-we",
    "href": "lessons/07_Random_Variables/07_Random_Variables.html#where-are-we",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#where-are-we",
    "href": "lessons/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#where-are-we",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/09_Joint_distributions/09_Joint_distributions.html#where-are-we",
    "href": "lessons/09_Joint_distributions/09_Joint_distributions.html#where-are-we",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/10_Expected_Values/10_Expected_Values.html#where-are-we",
    "href": "lessons/10_Expected_Values/10_Expected_Values.html#where-are-we",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#where-are-we",
    "href": "lessons/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#where-are-we",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/12_Variance/12_Variance.html#where-are-we",
    "href": "lessons/12_Variance/12_Variance.html#where-are-we",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#learning-objectives",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#learning-objectives",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDistinguish between Bernoulli, Binomial, Geometric, Hypergeometric, Discrete Uniform, Negative Binomial, and Poisson distributions when reading a story.\nIdentify the variable and the parameters in a story, and state what the variable and parameters mean.\nUse the formulas for the pmf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-bernoulli-rvs",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-bernoulli-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Bernoulli RVs",
    "text": "Properties of Bernoulli RVs\n\nScenario: One trial, with outcome success or failure\nShorthand: \\(X \\sim \\text{Bernoulli}(p)\\)\n\n\\[\nX = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\quad \\\\\n            0 & \\quad \\mathrm{with\\ probability}\\ 1-p \\quad\n        \\end{array}\n    \\right.\n\\]\n\\[\np_X(x) = P(X=x) = p^x(1-p)^{1-x} \\text{ for } x=0,1\n\\]\n\\[\\text{E}(X) = p\\]\n\\[\\text{Var}(X) = pq = p(1-p)\\]"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bernoulli-example-1",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bernoulli-example-1",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bernoulli Example 1",
    "text": "Bernoulli Example 1\n\n\n\n\nExample 1\n\n\n\nWe roll a fair 6-sided die.\nWe get $1 if we roll a 5, and nothing otherwise.\nLet \\(X\\) be how much money we get.\nFind the mean and variance of \\(X\\)."
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-binomial-rvs",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-binomial-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Binomial RVs",
    "text": "Properties of Binomial RVs\n\nScenario: There are \\(n\\) independent trials, each resulting in a success or failure, with constant probability, \\(p\\), in each trial. We are counting the number of successes (or failures).\nShorthand: \\(X \\sim \\text{Binomial}(n, p)\\)\n\n\\[\nX = \\text{Number of successes of } n \\text{ independent trials}\n\\]\n\\[\np_X(x) = P(X=x) = {n \\choose x}p^x(1-p)^{n-x} \\text{ for } x=0,1,2,  ..., n\n\\]\n\\[\\text{E}(X) = np\\] \\[\\text{Var}(X) = npq = np(1-p)\\]"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bernoulli-to-binomial",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bernoulli-to-binomial",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bernoulli to Binomial",
    "text": "Bernoulli to Binomial\n\n\n\n\nExample 2\n\n\n\nSuppose we roll a fair 6-sided die 50 times.\nWe get $1 every time we roll a 5, and nothing otherwise.\nLet \\(X\\) be how much money we get on the 50 rolls.\nFind the mean and variance of \\(X\\)."
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#geometric-rvs",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#geometric-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Geometric RVs",
    "text": "Geometric RVs\n\nScenario: There are repeated independent trials, each resulting in a success or failure, with constant probability of success for each trial. We are counting the number of trials until the first success.\nShorthand: \\(X \\sim \\text{Geo}(p)\\) or \\(X \\sim \\text{Geometric}(p)\\) or \\(X \\sim \\text{G}(p)\\)\n\n\n\n\n\n\n\n\n\\(X =\\) Number of trials needed for first success (count \\(x\\) includes the success)\n\\(X =\\) Number of failures before first success (count \\(x\\) does not include the success)\n\n\n\n\n\\(p _  X( x ) = P(X=x) = (1-p)^{x-1}p\\)\nfor \\(x=1,2, 3,...\\)\n\\[F_\nX(x ) = P(X\\leq x) = 1-(1-p)^x\\]\nfor \\(x=1,2, 3,...\\)\n\\(p _X (x)= P(X=x) = (1-p)^{x}p\\)\nfor \\(x=0, 1,2,...\\)\n\\[F_X ( x\n)\n= P(X\\leq x) = 1-(1-p)^{x+1}\\]\nfor \\(x=0, 1,2,...\\)\n\n\n\\(E(X)=\\dfrac{1}{p}\\)\n\\(Var(X)= \\dfrac{1-p}{p^2}\\)\n\\(E(X)=\\dfrac{1-p}{p}\\)\n\\(Var(X) = \\dfrac{1-p}{p^2}\\)"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-16",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-16",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (1/6)",
    "text": "Bullseye (1/6)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the pmf for the number of throws needed to hit the bullseye?\nWhat are the mean and variance for the number of throws needed to hit the bullseye?\nFind the probability that our first bullseye:\n\nis on one of the first four tries\nis after the fifth try\nis on one of the first fifty tries\nis after the \\(50^{th}\\) try, given that it did not happen on the first 20 tries"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-26",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-26",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (2/6)",
    "text": "Bullseye (2/6)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the pmf for the number of throws needed to hit the bullseye?"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-36",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-36",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (3/6)",
    "text": "Bullseye (3/6)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat are the mean and variance for the number of throws needed to hit the bullseye?"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-46",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-46",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (4/6)",
    "text": "Bullseye (4/6)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nFind the probability that our first bullseye:\n\nis on one of the first four tries\nis after the fourth try"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-56",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-56",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (5/6)",
    "text": "Bullseye (5/6)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nFind the probability that our first bullseye:\n\nis on one of the first fifty tries\nis after the \\(50^{th}\\) try, given that it did not happen on the first 20 tries"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#memoryless-property-for-geometric-rvs",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#memoryless-property-for-geometric-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Memoryless property for Geometric RVs",
    "text": "Memoryless property for Geometric RVs\nIf we know \\(X\\) is greater than some number (aka given \\(X &gt;j\\)), then the probability of \\(X &gt; k+j\\) is just the probability that \\(X&gt;k\\).\n \n\\(P(X &gt; k+j |X &gt; j) = P(X &gt; k)\\) \\[ P(X &gt; k+j |X &gt; j) = \\dfrac{P(X&gt;k+j \\text{ and } X&gt;j)}{P(X&gt;j)} = \\dfrac{P(X&gt;k+j)}{P(X&gt;j)} = \\dfrac{(1-p)^{k+j}}{(1-p)^{j}} = (1-p)^{k} \\]"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#hypergeometric-rvs",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#hypergeometric-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Hypergeometric RVs",
    "text": "Hypergeometric RVs\n\nScenario: There are a fixed number of successes and failures (which are known in advance), from which we make \\(n\\) draws without replacement. We are counting the number of successes from the \\(n\\) trials.\n\nThere is a finite population of \\(N\\) items\nEach item in the population is either a success or a failure, and there are \\(M\\) successes total.\nWe randomly select (sample) \\(n\\) items from the population without replacement\n\nShorthand: \\(X \\sim \\text{Hypergeo}(M, N, n)\\)\n\n\n\n\\[\nX = \\text{Number of successes in } n \\text{ draws}\n\\]\n\\[\np_X(x) = P(X=x) = \\dfrac{{M \\choose x}{N-M \\choose n-x}}{{N \\choose n}}\n\\] \\[\\text{ for } x \\text{ integer-valued } \\\\ \\max(0, n-(N-M)) \\leq x \\leq \\min(n, M)\\]\n\n\\[\\text{E}(X) =\\dfrac{nM}{N}\\]\n\\[\\text{Var}(X) = n \\dfrac{M}{N} \\bigg(1- \\dfrac{M}{N} \\bigg)\\bigg(\\dfrac{N-n}{N-1} \\bigg)\\]"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#wolf-population",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#wolf-population",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Wolf population",
    "text": "Wolf population\n\n\n\n\nExample 4\n\n\nA wildlife biologist is using mark-recapture to research a wolf population. Suppose a specific study region is known to have 24 wolves, of which 11 have already been tagged. If 5 wolves are randomly captured, what is the probability that 3 of them have already been tagged?"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#hypergeometric-vs.-binomial-rvs",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#hypergeometric-vs.-binomial-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Hypergeometric vs. Binomial RVs",
    "text": "Hypergeometric vs. Binomial RVs\nSuppose a hypergeometric RV \\(X\\) has the following properties:\n\nthe population size \\(N\\) is really big,\nthe number of successes \\(M\\) in the population is relatively large,\n\n\\(\\frac{M}{N}\\) shouldn’t be close to 0 or 1\n\nand the number of items \\(n\\) selected is small\nRule of thumb: \\(\\dfrac{n}{N}&lt;0.05\\) or \\(N&gt;20n\\)\n\nThen, in this case, making \\(n\\) draws from the population doesn’t change the probability of success much, and the hypergeometric r.v. can be approximated by a binomial r.v."
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#wolf-population-revisited",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#wolf-population-revisited",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Wolf population revisited",
    "text": "Wolf population revisited\n\n\n\n\nExample 5\n\n\nSuppose a specific study region is known to have 2400 wolves, of which 1100 have already been tagged.\n\nIf 50 wolves are randomly captured, what is the probability that 20 of them have already been tagged?\nApproximate the probability in part (1) using the binomial distribution."
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#discrete-uniform-rvs",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#discrete-uniform-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Discrete Uniform RVs",
    "text": "Discrete Uniform RVs\n\nScenario: There are \\(N\\) possible outcomes, which are all equally likely.\nShorthand: \\(X \\sim \\text{Uniform}(N)\\)\n\n\\[\nX = \\text{Outcome of interest, with } x=1, 2, ..., N\n\\]\n\\[\np_X(x) = P(X=x) = \\dfrac{1}{N} \\text{ for } x=1, 2, 3, ..., N\n\\]\n\\[\\text{E}(X) =\\dfrac{N+1}{2}\\]\n\\[\\text{Var}(X) = \\dfrac{N^2 -1}{12}\\]"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#what-discrete-uniform-rvs-have-we-seen-already",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#what-discrete-uniform-rvs-have-we-seen-already",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "What discrete uniform RVs have we seen already?",
    "text": "What discrete uniform RVs have we seen already?\n\n\n\n\nExample 6\n\n\nExamples of discrete uniform RVs\n\n\n\n\n\n\nChapter 14-20 Slides"
  },
  {
    "objectID": "lessons/17_Negative_binomial_rv/17_Negative_Binomial_rv.html#where-are-we",
    "href": "lessons/17_Negative_binomial_rv/17_Negative_Binomial_rv.html#where-are-we",
    "title": "Chapter 17: Negative Binomial RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#where-are-we",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#where-are-we",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/18_Poisson_rv/18_Poisson_rv.html#where-are-we",
    "href": "lessons/18_Poisson_rv/18_Poisson_rv.html#where-are-we",
    "title": "Chapter 18: Poisson RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/00_Intro/00_Intro.html#lets-visit-the-website-homepage",
    "href": "lessons/00_Intro/00_Intro.html#lets-visit-the-website-homepage",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website: Homepage",
    "text": "Let’s visit the website: Homepage"
  },
  {
    "objectID": "lessons/00_Intro/00_Intro.html#lets-visit-the-website-syllabus",
    "href": "lessons/00_Intro/00_Intro.html#lets-visit-the-website-syllabus",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website: Syllabus",
    "text": "Let’s visit the website: Syllabus\n\nCourse learning objectives\nTextbook online! (different than last year)\nResources: PennState STAT 414 site!\nR: you will get a lot of help in BSTA 511 and we will use some!\nAssessments and grade breakdowns\n\nMostly homework + quizzes\n\nFeedback from you to me: in the form of exit tickets, midterm feedback, and final course eval\nHow to succeed in this course: resources and assignments explained\nLate work policy / Attendance policy\nChatGPT and other AI technology\nCourse expectations: a few ways that I will show you respect and commitment to you as students\n\nAnd a few ways I expect from you!\n\nCommunicating with me: give me 24 hours to reply M-F\n\nI try really hard to keep emails from taking over my life"
  },
  {
    "objectID": "lessons/00_Intro/00_Intro.html#lets-visit-the-website-schedule",
    "href": "lessons/00_Intro/00_Intro.html#lets-visit-the-website-schedule",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website: Schedule",
    "text": "Let’s visit the website: Schedule\n\nWeeks, class info, exams, homeworks"
  },
  {
    "objectID": "lessons/00_Intro/00_Intro.html#lets-visit-the-website-search",
    "href": "lessons/00_Intro/00_Intro.html#lets-visit-the-website-search",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website: Search",
    "text": "Let’s visit the website: Search"
  },
  {
    "objectID": "lessons/00_Intro/00_Intro.html#lets-visit-the-website-homework",
    "href": "lessons/00_Intro/00_Intro.html#lets-visit-the-website-homework",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website: Homework!",
    "text": "Let’s visit the website: Homework!"
  },
  {
    "objectID": "lessons/00_Intro/00_Intro.html#lets-visit-the-website-schedule-12",
    "href": "lessons/00_Intro/00_Intro.html#lets-visit-the-website-schedule-12",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website: Schedule (1/2)",
    "text": "Let’s visit the website: Schedule (1/2)\n\nWeeks, class info, homeworks, labs"
  },
  {
    "objectID": "lessons/00_Intro/00_Intro.html#lets-visit-the-website-schedule-22",
    "href": "lessons/00_Intro/00_Intro.html#lets-visit-the-website-schedule-22",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website: Schedule (2/2)",
    "text": "Let’s visit the website: Schedule (2/2)\n\n\n\n\nKey Info\nI will post announcements and other important class related info here. For example, if I change a due date or discuss a common mistake in homework, I will put it here.\n\n\n\nSlides HTML\nThese are the basic slides that will open in your browser.\n\n\n\nSlides PDF\nThese are the slides in pdf form for easy note taking. I’m not always the best at posting these before class, so make sure you know how to save your own copy of pdf slides!\n\n\n\nSlides Notes\nThese are the annotated slides in pdf form. In class, I add my own notes to slides. After class, I will post them here.\n\n\n\nExit tix\nThese are links to that day’s exit ticket.\n\n\n\nRecording\nI record our classes. This will be a link to the OneDrive folder containing this recording.\n\n\n\nMuddy Points\nYou will have a chance to ask questions about class in your exit tickets. If I notice a trend in confusion, I will add explanations to these “Muddy Points”"
  },
  {
    "objectID": "lessons/00_Intro/00_Intro_key_info.html",
    "href": "lessons/00_Intro/00_Intro_key_info.html",
    "title": "Key Info and Announcements",
    "section": "",
    "text": "Welcome! I will put announcements and reminders on these pages!\nThanks for being patient while I’ve been out of the country!"
  },
  {
    "objectID": "lessons/00_Intro/00_Intro_key_info.html#announcements",
    "href": "lessons/00_Intro/00_Intro_key_info.html#announcements",
    "title": "Key Info and Announcements",
    "section": "",
    "text": "Welcome! I will put announcements and reminders on these pages!\nThanks for being patient while I’ve been out of the country!"
  },
  {
    "objectID": "lessons/00_Intro/00_Intro_key_info.html#exit-tickets",
    "href": "lessons/00_Intro/00_Intro_key_info.html#exit-tickets",
    "title": "Key Info and Announcements",
    "section": "Exit tickets",
    "text": "Exit tickets"
  },
  {
    "objectID": "lessons/22_Counting_Intro/22_Counting_Intro.html#where-are-we",
    "href": "lessons/22_Counting_Intro/22_Counting_Intro.html#where-are-we",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability.html#weekly-medications-1",
    "href": "lessons/02_Probability/02_Probability.html#weekly-medications-1",
    "title": "Chapter 2: Introduction to Probability",
    "section": "Weekly medications",
    "text": "Weekly medications\n\n\n\n\nExample 3\n\n\nIf a subject has an\n\n80% chance of taking their medication this week,\n70% chance of taking their medication next week, and\n10% chance of not taking their medication either week,\n\nthen find the probability of them taking their medication exactly one of the two weeks.\n\n\n\n\n\n\nChapter 2 Slides"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability.html#weekly-medications-more-space-to-work",
    "href": "lessons/02_Probability/02_Probability.html#weekly-medications-more-space-to-work",
    "title": "Chapter 2: Introduction to Probability",
    "section": "Weekly medications (more space to work)",
    "text": "Weekly medications (more space to work)\n\n\n\n\nExample 3\n\n\nIf a subject has an\n\n80% chance of taking their medication this week,\n70% chance of taking their medication next week, and\n10% chance of not taking their medication either week,\n\nthen find the probability of them taking their medication exactly one of the two weeks.\n\n\n\n\n\n\n\n\nChapter 2 Slides"
  },
  {
    "objectID": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#definitions-sample-space-and-events",
    "href": "lessons/01_Outcomes_Events_Sample/01_Outcomes_Events_Sample.html#definitions-sample-space-and-events",
    "title": "Chapter 1: Outcomes, Events, and Sample Spaces",
    "section": "Definitions: Sample Space and Events",
    "text": "Definitions: Sample Space and Events\n\n\nDefinition: Sample Space\n\n\nThe sample space \\(S\\) is the set of all outcomes\n\n\n\n\nDefinition: Event\n\n\nAn event is a collection of some outcomes. An event can include multiple outcomes or no outcomes (a subset of the sample space).\n\n\nWhen thinking about events, think about outcomes that you might be asking the probability of. For example, what is the probability that you get a heads and a tails in one flip? (Answer: 0)"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability_muddy_points.html#proofs-of-propositions",
    "href": "lessons/02_Probability/02_Probability_muddy_points.html#proofs-of-propositions",
    "title": "Muddy Points",
    "section": "1. Proofs of propositions",
    "text": "1. Proofs of propositions\nFurther explanations of the propositions can be found in the textbook from pages 24-27. For many of the explanations in class, I was working to produce a union of disjoint events, so that the probability could easily be calculated. Proposition 3 and 4 were specifically mentioned, so I will include some writing notes on them here:\n\nProposition 3\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\nIn this proposition, I want to define event \\(B\\) as a union of disjoint events so that I can show \\(P(B)\\) is the sum of \\(P(A)\\) and some greater-than-or-equal-to 0 probability event. If the following is my venn diagram of A and B:\n\n\n\n\n\nThen I can define B as the union of disjoint events: \nIf we then take the probability of each side of the equation \\(B = A \\cup (A^c \\cap B)\\), we get \\[P(B) = P\\big(A \\cup (A^c \\cap B)\\big)\\]\nSince events \\(A\\) and \\(A^c \\cap B\\) are disjoint, the probability of their union is just: \\[P(A) + P(A^c \\cap B)\\]\nThus, our equation is now \\[P(B) = P(A) + P(A^c \\cap B)\\]\nFrom Axiom 1, we know for event \\(A^c \\cap B\\), \\(P(A^c \\cap B) \\geq 0\\).\nSo the probability of event B is the sum of the probability of event A and an event that is \\(\\geq\\) 0. This means \\(P(B) \\geq P(A)\\).\n\n\nProposition 4\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)\n\n\nFrom the pictures above, we can see some similar disjoint events.\nIf we look back at \\(A \\cup B\\), we can start manipulating the right side of the equation:"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability_muddy_points.html#example-at-end-of-chapter-2-slides-venn-diagram",
    "href": "lessons/02_Probability/02_Probability_muddy_points.html#example-at-end-of-chapter-2-slides-venn-diagram",
    "title": "Muddy Points",
    "section": "2. Example at end of Chapter 2 slides (Venn Diagram)",
    "text": "2. Example at end of Chapter 2 slides (Venn Diagram)\nI will post this in the previous week’s Muddy Points as well. Please follow this link for my work through of the example. And here is the PDF with my work.\nSub-question: why don’t we just multiply the probability of A and B to get the intersection? This is a specific property of probability when A and B are independent. Only when A and B are independent can we conclude that \\(P(A \\cap B) = P(A)P(B)\\)."
  },
  {
    "objectID": "lessons/02_Probability/02_Probability_muddy_points.html#partition-of-events",
    "href": "lessons/02_Probability/02_Probability_muddy_points.html#partition-of-events",
    "title": "Muddy Points",
    "section": "3. Partition of events",
    "text": "3. Partition of events\nWe’ve been working with event partitions throughout Chapter 2, but we have not formally identified them. Partitions are advantageous to define for two reasons:\n\nThe partitions may be easier to calculate. We can then use the partitions to reconstruct other probabilities that may be more difficult to calculate\nPartitions have nice properties as a consequence of being disjoint. For example, the probability of the union of partitions is the sum of the probabilities across each partition: \\[P\\bigg(\\bigcup_{i=1}^n A_i\\bigg) = P(A_1)P(A_2)P(A_3) \\cdot \\cdot \\cdot P(A_n)\\]"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability.html#some-final-remarks-on-these-proposition",
    "href": "lessons/02_Probability/02_Probability.html#some-final-remarks-on-these-proposition",
    "title": "Chapter 2: Introduction to Probability",
    "section": "Some final remarks on these proposition",
    "text": "Some final remarks on these proposition\n\nNotice how we spliced events into multiple disjoint events\n\nIt is often easier to work with disjoint events\n\n\n \n\nIf we want to calculate the probability for one event, we may need to get creative with how we manipulate other events and the sample space\n\nHelps us use any incomplete information we have"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability_key_info.html",
    "href": "lessons/02_Probability/02_Probability_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Slack is working for a few people??\n\nhttps://join.slack.com/t/bsta550/shared_invite/zt-2qtfo9s8j-j6ozEaYdT7yy1KuHoT9Mhw"
  },
  {
    "objectID": "lessons/02_Probability/02_Probability_key_info.html#announcements",
    "href": "lessons/02_Probability/02_Probability_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Slack is working for a few people??\n\nhttps://join.slack.com/t/bsta550/shared_invite/zt-2qtfo9s8j-j6ozEaYdT7yy1KuHoT9Mhw"
  },
  {
    "objectID": "lessons/22_Counting_Intro/22_Counting_Intro_key_info.html",
    "href": "lessons/22_Counting_Intro/22_Counting_Intro_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "For homework 1, you will need to the textbook! There is a link in the Syllabus and a pdf in our shared OneDrive folder.\n\nWhat’s out shared OneDrive folder?? OHSU uses OneDrive as cloud storage. Everyone should be able to access OneDrive with their OHSU email, in addition to many other Microsoft apps.  \nIn our shared folder, I put files that I cannot share publicly. You’ll see homework solutions, recordings, and textbooks in there. For the most part, I will place links on our website directly to the files. I don’t always do the best job of this, so please take a look at those files as well. \n\nDue days\n\nI don’t want anyone to feel anxious about when exactly HW 1 is due. Almost everyone has voted, and it looks like Thursdays will be the best day for homework assignments.\n\nA result of the voting and the notes about work schedules\n\nConsequently, I want to give you more than a week after assignments are due to turn in the solutions, so solutions will be due two Sundays after the assignment is due (10 days after).\nFor example, the assignment for HW 1 is due 10/10 at 11pm and the solutions for HW 1 will be due 10/20 at 11pm.\n\nHomework solution groups!!\n\nI added a link to a Microsoft form in Homework 1\nPlease specify who you would like to partner with\n\nOffice hours\n\nLet’s discuss\nLooks like Thursdays 1-2:30pm is best or 1-2pm on Tuesday"
  },
  {
    "objectID": "lessons/22_Counting_Intro/22_Counting_Intro_key_info.html#announcements",
    "href": "lessons/22_Counting_Intro/22_Counting_Intro_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "For homework 1, you will need to the textbook! There is a link in the Syllabus and a pdf in our shared OneDrive folder.\n\nWhat’s out shared OneDrive folder?? OHSU uses OneDrive as cloud storage. Everyone should be able to access OneDrive with their OHSU email, in addition to many other Microsoft apps.  \nIn our shared folder, I put files that I cannot share publicly. You’ll see homework solutions, recordings, and textbooks in there. For the most part, I will place links on our website directly to the files. I don’t always do the best job of this, so please take a look at those files as well. \n\nDue days\n\nI don’t want anyone to feel anxious about when exactly HW 1 is due. Almost everyone has voted, and it looks like Thursdays will be the best day for homework assignments.\n\nA result of the voting and the notes about work schedules\n\nConsequently, I want to give you more than a week after assignments are due to turn in the solutions, so solutions will be due two Sundays after the assignment is due (10 days after).\nFor example, the assignment for HW 1 is due 10/10 at 11pm and the solutions for HW 1 will be due 10/20 at 11pm.\n\nHomework solution groups!!\n\nI added a link to a Microsoft form in Homework 1\nPlease specify who you would like to partner with\n\nOffice hours\n\nLet’s discuss\nLooks like Thursdays 1-2:30pm is best or 1-2pm on Tuesday"
  },
  {
    "objectID": "homework/HW_01.html#group-assignments",
    "href": "homework/HW_01.html#group-assignments",
    "title": "Homework 1",
    "section": "Group assignments",
    "text": "Group assignments\nPlease fill out this form to help me configure groups. I will first pair you based on people on your preferred list, then I will group pairs to balance working styles, R skills, and statistics exposure."
  },
  {
    "objectID": "lessons/04_Conditional_Probability/04_Conditional_Probability_key_info.html",
    "href": "lessons/04_Conditional_Probability/04_Conditional_Probability_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "For office hours, we decided to do appointments!\n\nHere’s my Calendly: https://calendly.com/nickywakim/15min\nI teach on Mondays and Wednesdays so I am keeping most of my meetings to Tuesdays and Thursdays\nFor my EPI class, I have scheduled office hours on Mondays 4-5pm in VPT 627\n\nI will give priority to EPI students, but you can drop by for those as well\n\n\nI think all the dates in the schedule were correct except for next week"
  },
  {
    "objectID": "lessons/04_Conditional_Probability/04_Conditional_Probability_key_info.html#announcements",
    "href": "lessons/04_Conditional_Probability/04_Conditional_Probability_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "For office hours, we decided to do appointments!\n\nHere’s my Calendly: https://calendly.com/nickywakim/15min\nI teach on Mondays and Wednesdays so I am keeping most of my meetings to Tuesdays and Thursdays\nFor my EPI class, I have scheduled office hours on Mondays 4-5pm in VPT 627\n\nI will give priority to EPI students, but you can drop by for those as well\n\n\nI think all the dates in the schedule were correct except for next week"
  },
  {
    "objectID": "lessons/04_Conditional_Probability/04_Conditional_Probability_key_info.html#key-dates",
    "href": "lessons/04_Conditional_Probability/04_Conditional_Probability_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 1 Assignment due this Thursday at 11pm"
  },
  {
    "objectID": "lessons/07_Random_Variables/07_Random_Variables_key_info.html",
    "href": "lessons/07_Random_Variables/07_Random_Variables_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "For office hours, we decided to do appointments!\n\nHere’s my Calendly: https://calendly.com/nickywakim/15min\nI have it set up mostly for Tuesdays and Thursdays\nIt requires a day’s notice for appointments - mainly so I can plan my next day\n\nDid you turn in HW 01 Assignment?\n\nI’m missing one! So double check!\nThen I’ll post the solutions!"
  },
  {
    "objectID": "lessons/07_Random_Variables/07_Random_Variables_key_info.html#announcements",
    "href": "lessons/07_Random_Variables/07_Random_Variables_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "For office hours, we decided to do appointments!\n\nHere’s my Calendly: https://calendly.com/nickywakim/15min\nI have it set up mostly for Tuesdays and Thursdays\nIt requires a day’s notice for appointments - mainly so I can plan my next day\n\nDid you turn in HW 01 Assignment?\n\nI’m missing one! So double check!\nThen I’ll post the solutions!"
  },
  {
    "objectID": "lessons/07_Random_Variables/07_Random_Variables_key_info.html#key-dates",
    "href": "lessons/07_Random_Variables/07_Random_Variables_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 02 Assignment due this Thursday at 11pm\nNo HW 01 Solutions"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-negative-binomial-rvs",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-negative-binomial-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Negative Binomial RVs",
    "text": "Properties of Negative Binomial RVs\n\nScenario: There are repeated independent trials, each resulting in a success or failure, with constant probability of success for each trial. We are counting the number of trials until the \\(r^{th}\\) success.\nShorthand: \\(X \\sim \\text{NegBin}(p, r)\\) or \\(X \\sim \\text{NB}(p, r)\\)\nNegative binomial is sum of \\(r\\) geometric distributions\n\n\\[\nX = \\text{Number of independent trials until } r^{th} \\text{ success}\n\\]\n\\[ p_X(x) = P(X=x) = {x-1 \\choose r-1}(1-p)^{x-r}p^r \\text{ for } x = r, r+1, r+2, ...\\]\n\\[ E(X) = \\dfrac{r}{p}\\]\n\\[Var(X) = \\dfrac{rq}{p^2} = \\dfrac{r(1-p)}{p^2}\\]"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#hitting-more-than-1-bullseye",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#hitting-more-than-1-bullseye",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Hitting more than 1 bullseye",
    "text": "Hitting more than 1 bullseye\n\n\n\n\nExample 1\n\n\nConsider again the bullseye example, where we throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the expected value and variance of the number of throws needed to hit 5 bullseyes?"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#hitting-more-than-1-bullseye-1",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#hitting-more-than-1-bullseye-1",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Hitting more than 1 bullseye",
    "text": "Hitting more than 1 bullseye\n\n\n\n\nExample 1\n\n\nConsider again the bullseye example, where we throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the probability that the \\(5^{th}\\) bullseye is on the \\(20^{th}\\) throw?"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-poisson-rvs",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-poisson-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Poisson RVs",
    "text": "Properties of Poisson RVs\n\nScenario: We are counting the number of successes in a fixed time period, which has a constant rate of successes\nShorthand: \\(X \\sim \\text{Poisson}(\\lambda)\\) or \\(X \\sim \\text{Pois}(\\lambda)\\)\n\n\\[\nX = \\text{Number of successes in a given period}\n\\]\n\\[ p_X(x) = P(X=x) = \\dfrac{e^{-\\lambda}\\lambda^x}{x!} \\text{ for } x = 0, 1, 2,3, ...\\]\n\\[ \\text{E}(X) = \\lambda\\]\n\\[\\text{Var}(X) = \\lambda\\]"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#distingushing-between-binomial-and-poisson-rvs",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#distingushing-between-binomial-and-poisson-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Distingushing between Binomial and Poisson RVs",
    "text": "Distingushing between Binomial and Poisson RVs\n\nRecall that if \\(X\\sim Binomial(n,p)\\), then\n\n\\(X\\) models the number of successes …\nin \\(n\\) independent (Bernoulli) trials …\nthat each have the same probability of success \\(p\\).\n\nPoisson r.v.’s are similar,\n\nexcept that instead of having \\(n\\) discrete independent trials,\nthere is a fixed time period (or space) during which the successes happen"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#examples-of-poisson-rvs",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#examples-of-poisson-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Examples of Poisson RVs",
    "text": "Examples of Poisson RVs\n\nNumber of visitors to an emergency room in an hour during a weekend night\nNumber of study participants enrolled in a study per week\nNumber of pedestrians walking through a square mile\nAny more?"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#emergency-room-visitors",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#emergency-room-visitors",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Emergency Room Visitors",
    "text": "Emergency Room Visitors\n\n\n\n\nExample 1\n\n\nSuppose an emergency room has an average of 50 visitors per day. Find the following probabilities.\n\nProbability of 30 visitors in a day.\nProbability of 8 visitors in an hour.\nProbability of at least 8 visitors in an hour."
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#combining-independent-poisson-distributions",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#combining-independent-poisson-distributions",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Combining independent Poisson distributions",
    "text": "Combining independent Poisson distributions\n\n\nTheorem 1\n\n\nIf \\(X\\sim Pois(\\lambda_1)\\) and \\(Y\\sim Pois(\\lambda_2)\\) are independent of each other, then \\(Z=X+Y\\sim Pois(\\lambda_1 + \\lambda_2)\\)."
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#two-emergency-rooms",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#two-emergency-rooms",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Two emergency rooms",
    "text": "Two emergency rooms\n\n\n\n\nExample 2\n\n\nSuppose emergency room 1 has an average of 50 visitors per day, and emergency room 2 has an average of 70 visitors per day, independently of each other. What is the probability distribution to model of the total number of visitors to both?"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#poisson-approximation-of-the-binomial",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#poisson-approximation-of-the-binomial",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Poisson Approximation of the Binomial",
    "text": "Poisson Approximation of the Binomial\nBoth Poisson and Binomial r.v.’s are counting the number of successes\n\nIf for a Binomial r.v.\n\nthe number of trials \\(n\\) is very large, and\nthe probability of success \\(p\\) is close to 0 or 1,\n\nThen the Poisson distribution can be used to approximate Binomial probabilities\n\nand we use \\(\\lambda = np\\)\n\nRule of thumb: We can use the Poisson approximation when \\(\\dfrac{1}{10} \\leq np(1-p) \\leq 10\\)"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#medical-lab-errors",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#medical-lab-errors",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Medical lab errors",
    "text": "Medical lab errors\n\n\n\n\nExample 3\n\n\nSuppose that in the long run, errors in a medical testing lab are made 0.1% of the time. Find the probability that fewer than 4 mistakes are made in the next 2,000 tests.\n\nFind the probability using the Binomial distribution.\nApproximate the probability in part (1) using the Poisson distribution.\n\n\n\n\nTo do for extra practice - will also see a similar problem in BSTA 511"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#our-beloved-fair-sided-die",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#our-beloved-fair-sided-die",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Our beloved fair-sided die",
    "text": "Our beloved fair-sided die\n\n\n\n\nExample 2\n\n\n\nSuppose we roll a fair 6-sided die 50 times.\nWe get $1 every time we roll a 5, and nothing otherwise.\nLet \\(X\\) be how much money we get on the 50 rolls.\nFind the mean and variance of \\(X\\)."
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#binomial-approximation-of-the-hypergeometric-rv",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#binomial-approximation-of-the-hypergeometric-rv",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Binomial approximation of the hypergeometric RV",
    "text": "Binomial approximation of the hypergeometric RV\nSuppose a hypergeometric RV \\(X\\) has the following properties:\n\nthe population size \\(N\\) is really big,\nthe number of successes \\(M\\) in the population is relatively large,\n\n\\(\\frac{M}{N}\\) shouldn’t be close to 0 or 1\n\nand the number of items \\(n\\) selected is small\nRule of thumb: \\(\\dfrac{n}{N}&lt;0.05\\) or \\(N&gt;20n\\)\n\nThen, in this case, making \\(n\\) draws from the population doesn’t change the probability of success much, and the hypergeometric RV. can be approximated by a binomial RV"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#distinguishing-between-binomial-and-poisson-rvs",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#distinguishing-between-binomial-and-poisson-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Distinguishing between Binomial and Poisson RVs",
    "text": "Distinguishing between Binomial and Poisson RVs\n\nRecall that if \\(X\\sim \\text{Binomial}(n,p)\\), then\n\n\\(X\\) models the number of successes …\nin \\(n\\) independent (Bernoulli) trials …\nthat each have the same probability of success \\(p\\).\n\nPoisson r.v.’s are similar,\n\nexcept that instead of having \\(n\\) discrete independent trials,\nthere is a fixed time period (or space) during which the successes happen"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-14",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-14",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (1/4)",
    "text": "Bullseye (1/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the pmf for the number of throws needed to hit the bullseye?\nWhat are the mean and variance for the number of throws needed to hit the bullseye?\nFind the probability that our first bullseye:\n\nis on one of the first fifty tries\nis after the \\(50^{th}\\) try, given that it did not happen on the first 20 tries"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-24",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-24",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (2/4)",
    "text": "Bullseye (2/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the pmf for the number of throws needed to hit the bullseye?"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-34",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-34",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (3/4)",
    "text": "Bullseye (3/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat are the mean and variance for the number of throws needed to hit the bullseye?"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-44",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-44",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (4/4)",
    "text": "Bullseye (4/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nFind the probability that our first bullseye:\n\nis on one of the first fifty tries\nis after the \\(50^{th}\\) try, given that it did not happen on the first 20 tries"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs_key_info.html",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 01 assignments are graded!\n\nSolutions and videos are posted!"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs_key_info.html#announcements",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 01 assignments are graded!\n\nSolutions and videos are posted!"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs_key_info.html#key-dates",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 02 Assignment due this Thursday at 11pm\nNo HW 01 Solutions"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs_muddy_points.html",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "1. In-class example of the Poisson distribution\n\nlibrary(tidyverse)\n\nx &lt;- 0:250\n# n = c(6,14,30,60)\np = c(0.1, 0.5)\n\ngeom = expand.grid(x = x, p = p) %&gt;%\n  mutate(y = dgeom(x, prob = p))\n\nggplot(geom %&gt;% filter(y &gt; 1e-5), \n       aes(x, y, color=factor(p))) +\n  geom_point(size=1) +\n  geom_segment(aes(x=x, xend=x, y=0, yend=y, color=factor(p)), lwd=0.8, alpha=0.5) +\n  facet_grid(rows = vars(p), scales=\"free_x\", space=\"free_x\") +\n  theme(legend.position = \"none\",\n        axis.title = element_text(size = 14),    # Axis title size\n        axis.text = element_text(size = 12),     # Axis text size\n        strip.text = element_text(size = 13)) +  # Facet label size\n  labs(x = \"Number of trials\", y = \"Probability\")"
  },
  {
    "objectID": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html",
    "href": "lessons/14_20_Discrete_RVs/14_20_Discrete_RVs.html",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "",
    "text": "Distinguish between Bernoulli, Binomial, Geometric, Hypergeometric, Discrete Uniform, Negative Binomial, and Poisson distributions when reading a story.\nIdentify the variable and the parameters in a story, and state what the variable and parameters mean.\nUse the formulas for the pmf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "hw_answers/HW_07_ans.html",
    "href": "hw_answers/HW_07_ans.html",
    "title": "Homework 7 Answers",
    "section": "",
    "text": "Not given.\n\n\\(E\\left(\\overline{X}\\right) = \\mu\\)\n\\(\\text{Var}\\left(\\overline{X}\\right) = \\dfrac{\\sigma^2}{n}\\)\n\nSee notes for how I start this problem!\n\n\\(E(V) = 87850 \\text{ ft}^3\\), \\(\\text{Var}(V) = 19100116 \\ (\\text{ft}^3)^2\\)\nExpected value correct, variance incorrect"
  },
  {
    "objectID": "hw_answers/HW_07_ans.html#non-textbook-problems",
    "href": "hw_answers/HW_07_ans.html#non-textbook-problems",
    "title": "Homework 7 Answers",
    "section": "Non-textbook problems",
    "text": "Non-textbook problems\n\n#1: See class notes for starting!\n#2:\n\n\\(E(V) = 87850 \\text{ ft}^3\\), \\(\\text{Var}(V) = 19100116 \\ (\\text{ft}^3)^2\\)\nExpected value correct, variance incorrect\n\n#3:\n\n\\(1 - e^{-1}\\)\n0.0008216\n\n\n#4: 0.001998"
  },
  {
    "objectID": "hw_answers/HW_07_ans.html#textbook-problems",
    "href": "hw_answers/HW_07_ans.html#textbook-problems",
    "title": "Homework 7 Answers",
    "section": "Textbook problems",
    "text": "Textbook problems\nThere are answers at the back of the book!! Selected answers (or hints) not provided at the end the book:\n\nChapter 28\n\n# 10: (a) 8/9     (b) 14/3     \n# 18: 4/5\n\nChapter 29\n\n# 10: (a) 26/81     (b) 74/9\n# 14: (a) 67/3     (b) 1/14     (c) 25/12     (d) \\(\\sqrt{25/12}\\)\n# 26: 250\n# 32: See notes (or book) for the proof from the discrete random variables case. The proof doesn’t depend on what type of random variable (discrete vs. continuous) is being used.\nNTB # 3: (a) 63     (b) 287/3     (c) -1, 41/3     (d) -7, 287/3\n\nChapter 31\n\n14.\n\n\n0.25\n\n\n\n0.02887\n\n\n\n0.063\n\n\n\n0.0145\n\n\n\n0.01625\n\n\n\n0.0055\n\n\n\n6.195\n\n\n\n0.00433\n\n\n\n61.95\n\n\n\n0.0433\n\n\n\n17. 2.25\n\n18. \\(\\frac{7}{15}\\)\n \n\nChapter 32\n\n8. 0.2526\n\n5. 0.8047\n\n10. 0.4323\n\nChapter 33\n\n10.\n\n\n\\(f_x(x) = \\frac{x}{9} e^{-x/3}\\) for \\(x &gt; 0\\)\n\n\n\n0.4963\n\n\n\nChapter 35\n\n6.\n\n\n0\n\n\n\n-1.13\n\n\n\n\\(\\pm 0.32\\)\n\n\n\n10.\n\n\n0.0475\n\n\n\n0.0475\n\n\n\n0.2283\n\n\n\n68.97 to 81.03\n\n\n\n48 to 102\n\n\n\n68.97\n\n\n\n24.\n\n\n0.2119\n\n\n\n0.0011\n\n\n\nNTB Parachute Reference: 0.002"
  },
  {
    "objectID": "hw_answers/HW_04_ans.html#textbook-problems",
    "href": "hw_answers/HW_04_ans.html#textbook-problems",
    "title": "Homework 4 Answers",
    "section": "Textbook problems",
    "text": "Textbook problems\nThere are answers at the back of the book!! Selected answers (or hints) not provided at the end the book:\n\nChapter 9\n\nNTB # 1 Partial answers:\n\n\n\\(p_{X|Y}(X=\\text{high school}| Y=\\text{no smoking at all}) = 0.476\\)\n\n\n\\(p_{Y|X}( Y=\\text{no smoking at all}|X=\\text{high school}) = 0.200\\)"
  },
  {
    "objectID": "hw_answers/HW_10_ans.html",
    "href": "hw_answers/HW_10_ans.html",
    "title": "Homework 10 Answers",
    "section": "",
    "text": "#1:"
  },
  {
    "objectID": "hw_answers/HW_10_ans.html#non-textbook-problems",
    "href": "hw_answers/HW_10_ans.html#non-textbook-problems",
    "title": "Homework 10 Answers",
    "section": "",
    "text": "#1:"
  },
  {
    "objectID": "hw_answers/HW_10_ans.html#textbook-problems",
    "href": "hw_answers/HW_10_ans.html#textbook-problems",
    "title": "Homework 10 Answers",
    "section": "Textbook problems",
    "text": "Textbook problems\nThere are answers at the back of the book!! Selected answers (or hints) not provided at the end the book:\n\nChapter 37\n\n# 2: 0.8869\n# 4: 0.0023\n# 20: 0.3936\n# 24: 0.4562\n# 30: (b) 0.0022     (c) \\(478.696\\approx 479\\)\n\nChapter 43\n\nNTB 3: (a) Poisson\\((\\sum_{i=1}^n \\lambda_i)\\)     (b) Poisson\\((3\\lambda)\\)      (c) \\(M_{3X}(t)=e{\\lambda(e^{3t}-1)}\\) This is not an mgf of a common probability distribution.      (d) In (b) we are adding independent r.v.’s \\(X_i\\), while in (c) we are adding dependent r.v.’s (\\(3X=X+X+X\\); \\(X\\) is dependent with itself)."
  },
  {
    "objectID": "hw_answers/HW_08_ans.html",
    "href": "hw_answers/HW_08_ans.html",
    "title": "Homework 8 Answers",
    "section": "",
    "text": "parameters: \\(\\sum_{i=1}^m n_i\\) and \\(p\\)\nNot given\n\\[p(1-p)\\sum_{i=1}^m n_i\\]\n\n\nExponential distribution\n\\(\\lambda = 240\\)\nNot given\n\n0.252\nFirst row given in homework problem\n#3: Poisson approximation of Binomial when \\(n\\) is large and \\(p\\) is small"
  },
  {
    "objectID": "hw_answers/HW_08_ans.html#non-textbook-problems",
    "href": "hw_answers/HW_08_ans.html#non-textbook-problems",
    "title": "Homework 8 Answers",
    "section": "Non-textbook problems",
    "text": "Non-textbook problems\n\n#1: \\(f_Z(z) = nF_X(z)^{n-1}f_X(z)\\)\n#2: (b) \\(P(X&lt;Y) = 0.099995\\) (d) \\(f_Z(z) = \\dfrac{11-2z}{5}e^{-2z}\\) for \\(0 \\leq z \\leq 5\\)\n#3: 2 cases: when \\(0&lt; z &lt; 1\\) and \\(1 \\leq z \\leq 2\\)\n#4: (a) 63 minutes, (b) \\(Var(T) = \\dfrac{287}{3}\\), (c) \\(Var(D) = \\dfrac{41}{3}\\), (d) expected diff is 7 minutes, variance is 283/3"
  },
  {
    "objectID": "hw_answers/HW_08_ans.html#textbook-problems",
    "href": "hw_answers/HW_08_ans.html#textbook-problems",
    "title": "Homework 8 Answers",
    "section": "Textbook problems",
    "text": "Textbook problems\nThere are answers at the back of the book!! Selected answers (or hints) not provided at the end the book:\n\nChapter 25\n\n# 4:   7/16\n# 8:  (a) \\(\\frac{25}{228}\\)     (b) \\(f_X(x)=\\frac{1}{12}(x+1)\\), for \\(0\\leq x\\leq 4\\)     (c) \\(f_Y(y)=\\frac{3}{76}(y^2+1)\\), for \\(0\\leq y\\leq 4\\)\n# 18:  5/6\n# 24:  (a) \\(f_X(x)=-2e^{-2x}+2e^{-x}\\), for \\(x\\geq 0\\)     (b) \\(f_Y(y)=2e^{-2y}\\), for \\(y\\geq 0\\)\n\nChapter 26\n\n# 12:  (b) \\(\\frac{233}{256}\\)     (c) \\(\\frac{65}{256}\\)     (d) \\(\\frac{1}{512}\\)\n# 20:  (a) Yes.     (b) \\(\\frac{15}{16}\\)\nNTB # 3: (b) 0.09999546   (d) \\(f_Z(z) =\\Big(\\frac{11}{5} - \\frac{2z}{5}\\Big)e^{-2z}\\), for what values of \\(z\\)?\n\nChapter 27\n\n# 6: \\(f_{X|Y}(x|y)=\\frac{e^{-x/4-y/5}}{4(e^{-y/5}-e^{-9y/20})}\\), for \\(0&lt; x&lt; y\\)\n# 8: \\(f_{X|Y}(x|y)=\\frac{1-x^2}{1-y-\\frac{(1-y)^3}{3}}\\), for \\(0\\leq x, 0\\leq y, x+y\\leq 1\\)\n# 12: (a) \\(f_{X|Y}(x|y)=\\frac{1}{2}\\)    (c) \\(\\frac{4}{7}\\)\n\nChapter 28\n\n# 10: (a) 8/9     (b) 14/3     \n# 18: 4/5\n\nChapter 29\n\n# 10: (a) 26/81     (b) 74/9\n# 14: (a) 67/3     (b) 1/14     (c) 25/12     (d) \\(\\sqrt{25/12}\\)\n# 26: 250\n# 32: See notes (or book) for the proof from the discrete random variables case. The proof doesn’t depend on what type of random variable (discrete vs. continuous) is being used.\nNTB # 3: (a) 63     (b) 287/3     (c) -1, 41/3     (d) -7, 287/3\n\nChapter 30\n\n# 4: \\(f_x(x)=1/2\\) for \\(2\\leq x\\leq 4\\)\n# 8: (a) T     (b) T     (c) F\n# 10: (a) F     (b) T\n# 12: (a) T     (b) T     (c) F     (d) T"
  },
  {
    "objectID": "hw_answers/HW_03_ans.html",
    "href": "hw_answers/HW_03_ans.html",
    "title": "Homework 3 Answers",
    "section": "",
    "text": "0.189     (b) 0.811     (c) 0.189\n\n\n4060; b. 24,360;\n\n0.3916"
  },
  {
    "objectID": "hw_answers/HW_03_ans.html#non-textbook-problems",
    "href": "hw_answers/HW_03_ans.html#non-textbook-problems",
    "title": "Homework 3 Answers",
    "section": "Non-textbook problems",
    "text": "Non-textbook problems\n\n#1 (a) \\(X\\sim binomial \\big(\\sum_{i=1}^m n_i, p\\big)\\)      (b) \\(E(X) = p\\sum_{i=1}^m n_i\\)      (c) \\(Var(X) = p(1-p)\\sum_{i=1}^m n_i\\)"
  },
  {
    "objectID": "hw_answers/HW_03_ans.html#textbook-problems",
    "href": "hw_answers/HW_03_ans.html#textbook-problems",
    "title": "Homework 3 Answers",
    "section": "Textbook problems",
    "text": "Textbook problems\nThere are answers at the back of the book!! Selected answers (or hints) not provided at the end the book:\n\nChapter 7\n\n# 2: \\(X\\in(0,\\infty)\\), continuous; \\(Y\\in\\{0,1,2,\\ldots\\}\\), discrete\n# 10: \\(X_j\\in[0,\\infty),j=1,\\ldots,100\\); \\(Y\\in[0,\\infty)\\); both continuous\n# 16: \\(Y\\) could be 0\n# 18: Yes, a r.v. can be both. Give an example!\n\nChapter 8\n\n# 2: (a) \\(p(x)=\\binom{7}{x}(.5)^7\\) for \\(x=0,1,2,\\ldots,7\\)\n# 9: (a) \\(c = \\frac{1}{8}\\)\n# 10:\n\n\n\n\n\\(x\\)\n2\n4\n6\n8\n\n\n\n\n\\(p(x)\\)\n3/10\n1/2\n3/20\n1/20\n\n\n\n\n\nChapter 15\n\n# 18  (a) Bin(21,0.65)     (b) 4.78     \n\nChapter 16\n\n# 8  (a) 14.28      (b) code below     (c) \\(1.03\\times 10^{-6}\\)    (d) 10 questions: 91.43 minutes    \n\n\n1-pgeom(q = 18, prob = 0.07)\n\n[1] 0.2518698\n\n## OR\npgeom(q = 18, prob = 0.07, lower.tail = F)\n\n[1] 0.2518698\n\n\nChapter 17\n\n# 6   (a) 400, 87.18     (b) No     \n# 12   (c) 0.8000\n\nChapter 18\n\n# 20 (a) (b) 0.6514 (c) 0.0598\n# 24  (c) 0.8571\n# 26  162,754.8\n\nChapter 19\n\n# 6:  (c) 15.625     (d) 0.0486     (f) 0.0488\n# 18:   100\n\nChapter 20\n\n# 2:  (a) 0.0001     (b) Discrete since \\(X\\) has a finite number of possible values. Uniform since each outcome is equally likely.     (c) \\(X\\) = randomly selected 4-digit ID#; \\(X=0000,0001,\\ldots,9999\\)     (d) 5000.5     (e) 8,333,333.25"
  },
  {
    "objectID": "hw_answers/HW_02_ans.html",
    "href": "hw_answers/HW_02_ans.html",
    "title": "Homework 2 Answers",
    "section": "",
    "text": "Below are some select answers from the homework."
  },
  {
    "objectID": "hw_answers/HW_02_ans.html#non-textbook-problems",
    "href": "hw_answers/HW_02_ans.html#non-textbook-problems",
    "title": "Homework 2 Answers",
    "section": "Non-textbook problems",
    "text": "Non-textbook problems\n\n#1: (a) 1 does not hold because \\(0 \\neq \\dfrac{1}{216}\\)      (b) 2 does not hold because \\(P(B \\cap C) \\neq P(B)P(C)\\)\nNTB # 2: 0.3916"
  },
  {
    "objectID": "hw_answers/HW_02_ans.html#textbook-problems",
    "href": "hw_answers/HW_02_ans.html#textbook-problems",
    "title": "Homework 2 Answers",
    "section": "Textbook problems",
    "text": "Textbook problems\nThere are answers at the back of the book!! Selected answers (or hints) not provided at the end the book:\n\nChapter 22\n\n# 30: (a) 2,835     (b) 405     (c) 10,780     (d) 7,980\n# 40: 0.6666667\n# 42: 0.002116402 (This is the answer when \\(n=5\\). Your answer needs to be in terms of \\(n\\).)\n# 44: 0.3\n# 46: 0.3333333\n# 48: 0.007936508 (This is the answer when \\(n=5\\). Your answer needs to be in terms of \\(n\\).)\n\nChapter 3\n\n# 4: (a) 0.111328    (b) 0.004872    0.995128\n# 10: (c) 0.384 If you have the right answer to (c), then you should be able to figure out the rest (see (e)).\n# 12: No.\nNTB #1: (a) 0.0799     (b) 0.07553     (c) 0.0655\n\nChapter 4\n\n#4: 0.25\n# 12: (a) 0.4285714     (b) 0.4285714     (c) 0.1428571\n\nChapter 5\n\n#17 a. 0.71; b. 0.29; c. 48/71; d. 1; e. 25/29; f. 25/39\n\n\n\nFrom HW 1"
  },
  {
    "objectID": "hw_answers/HW_01_ans.html",
    "href": "hw_answers/HW_01_ans.html",
    "title": "Homework 1 Answers",
    "section": "",
    "text": "1. Outcomes, events, and sample space\nIn the below parts, please list (i) one specific outcome, (ii) one event that contains more than one outcome, and (iii) the sample space.\n\nChris has an 5-pack of Gatorade sports drink: 1 orange, 2 lemon-lime, and 2 fruit punch. He blindly grabs one out of the pack over and over if necessary, without replacement, until he finds an orange one. Note, each lemon-lime is indistinguishable, and each fruit punch is indistinguishable.\n\n\nLet \\(L\\) = Lemon-Lime, \\(P\\) = Fruit Punch, and \\(O\\) = Orange. Since \\(L\\) and \\(P\\) are indistinguishable, we do not need include more information on the two bottles.\n\ni. Specific Outcome\n\\((L, P, O)\\) OR \\((P, O)\\)\n\n\nii. Event with More Than One Outcome\n\n\niii. Sample Space (\\(\\Omega\\))\n19 total outcomes\n\n\n\nA claw machine contains 10 plush toys: 5 Red Squishies (R), 3 Blue Dinosaurs (B), and 2 Yellow Star Puffs (Y). You successfully grab a toy, remove it, and then grab a second toy (sampling without replacement). The result is the ordered pair of the two toys’ colors.\n\n\n\ni. Specific Outcome\n(R, Y) OR (B, R)\n\n\nii. Event with More Than One Outcome\n\n\niii. Sample Space (\\(\\Omega\\))\n9 total outcomes\n\n\n\nYou are opening a series of mofusound Cat blind boxes. There are 4 possible figurines to collect: 1 shark cat (S), 1 orange striped fish cat (O), and 1 hen cat (H), and 1 cow cat (C). You buy a single blind box.\n\n\n\ni. Specific Outcome\nS (Shark Cat) OR O (Orange Striped Fish Cat)\n\n\nii. Event with More Than One Outcome\n\n\niii. Sample Space (\\(\\Omega\\))\n4 total outcomes\n\n\n\n\n2. Running a simulation!\n\nWe’ll all have slightly different answers, but with 100,000 simulations, I got the probability of 0.489."
  },
  {
    "objectID": "hw_answers/HW_01_ans.html#non-textbook-problems",
    "href": "hw_answers/HW_01_ans.html#non-textbook-problems",
    "title": "Homework 1 Answers",
    "section": "",
    "text": "# 1: (a)  (b) Answers for part (ii) for each:\n\n0.48\n0.52\n0.2\n0.32\n0.03\n0.01\n0.02\n\n# 2: (a) 16, (c) for one, \\(P(X=10) = \\dfrac{5}{16}\\), (d) 0.375"
  },
  {
    "objectID": "hw_answers/HW_01_ans.html#textbook-problems",
    "href": "hw_answers/HW_01_ans.html#textbook-problems",
    "title": "Homework 1 Answers",
    "section": "Textbook problems",
    "text": "Textbook problems\nThere are some answers at the back of the book!! Selected answers (or hints) not provided at the end the book:\n\nChapter 2\n\n# 4: 0.35\n# 8: 0.03125\n# 16: 0.48\n# 23: 0.47\n# 30: (a) 0.189     (b) 0.811     (c) 0.189"
  },
  {
    "objectID": "hw_answers/HW_09_ans.html",
    "href": "hw_answers/HW_09_ans.html",
    "title": "Homework 9 Answers",
    "section": "",
    "text": "#1:"
  },
  {
    "objectID": "hw_answers/HW_09_ans.html#non-textbook-problems",
    "href": "hw_answers/HW_09_ans.html#non-textbook-problems",
    "title": "Homework 9 Answers",
    "section": "",
    "text": "#1:"
  },
  {
    "objectID": "hw_answers/HW_09_ans.html#textbook-problems",
    "href": "hw_answers/HW_09_ans.html#textbook-problems",
    "title": "Homework 9 Answers",
    "section": "Textbook problems",
    "text": "Textbook problems\nThere are answers at the back of the book!! Selected answers (or hints) not provided at the end the book:\n\nChapter 31\n\n# 14: (a) 0.25     (b) 0.02887     (c) 0.063     (d) 0.0145     (e) 0.01625     (f) 0.0055     (f) 6.195    (g) 0.00433     (h) 61.95     (i) 0.0433\n# 17: 2.25\n# 18: 7/15\n\nChapter 32\n\n# 8: 0.2526\n# 5: 0.8047\n# 10: 0.4323\n\nChapter 33\n\n#10: (a) \\(f_x(x)=\\frac{x}{9}e^{-x/3}\\) for \\(x&gt; 0\\)     (b) 0.4963\n\nChapter 35\n\n# 6: (a) 0     (b) -1.13     (c) \\(\\pm 0.32\\)\n# 10: (a) 0.0475     (b) 0.0475     (c) 0.2283     (d) 68.97 to 81.03     (e) 48 to 102     (f) 68.97\n# 24: (a) 0.2119     (b) 0.0011\nNTB # 5:   0.002\n\nChapter 36\n\n# 4: 0.0044\n# 12: (a) 0.9525     (b) 0.7939     (c) 0.7939\n# 14: 0.5911\n# 16: (a) \\(R=8.225\\sigma+25\\mu\\)     (b) \\(R=16.45\\sigma+100\\mu\\)     (c) \\(R=164.5\\sigma+10,000\\mu\\)     (d) \\(R=1.645\\sqrt{n}\\sigma+n\\mu\\)\n\nChapter 37\n\n# 2: 0.8869\n# 4: 0.0023\n# 20: 0.3936\n# 24: 0.4562\n# 30: (b) 0.0022     (c) \\(478.696\\approx 479\\)"
  },
  {
    "objectID": "hw_answers/HW_05_ans.html",
    "href": "hw_answers/HW_05_ans.html",
    "title": "Homework 5 Answers",
    "section": "",
    "text": "Not given\n\\(f_Z(z) = nF_X(z)^{n-1}f_X(z)\\)\n\n\n\\(P(X&lt;Y) = 0.099995\\)\n\n\n\\(f_Z(z) = \\dfrac{11-2z}{5}e^{-2z}\\) for \\(0 \\leq z \\leq 5\\)\n\n\n2 cases: when \\(0&lt; z &lt; 1\\) and \\(1 \\leq z \\leq 2\\)"
  },
  {
    "objectID": "hw_answers/HW_05_ans.html#non-textbook-problems",
    "href": "hw_answers/HW_05_ans.html#non-textbook-problems",
    "title": "Homework 5 Answers",
    "section": "",
    "text": "#1:\n\n\n\\(X \\sim \\text{Binom}\\bigg( \\sum_{i=1}^m n_i, p \\bigg)\\)\n\n\n\\(E(x) = p \\cdot \\sum_{i=1}^m n_i\\)\n\n\n\\(\\text{Var}(X) = p \\cdot (1-p) \\cdot \\sum_{i=1}^m n_i\\)\n\n\n#2: 450\n#3: Hint: use the definition of variance\n#4: (a) \\(E(\\overline{X}) = \\mu\\)    (b) \\(\\text{Var}(\\overline{X}) = \\dfrac{\\sigma^2}{n}\\)"
  },
  {
    "objectID": "hw_answers/HW_05_ans.html#textbook-problems",
    "href": "hw_answers/HW_05_ans.html#textbook-problems",
    "title": "Homework 5 Answers",
    "section": "Textbook problems",
    "text": "Textbook problems\nThere are answers at the back of the book!! Selected answers (or hints) not provided at the end the book:\n\nChapter 10\n\n# 6:  750.5\n# 8:  0.9\n# 10:   201\n# 14:   (a) 1.875     (b) 3.125     \n\nChapter 11\n\n# 2:  1.6\n# 18:  a) 48.5     (b) 96     \n# 20:  \\(\\approx\\) 23.077\n\nChapter 12\n\n# 2:  64.8\n# 12:  1,096,357\n\nChapter 13\n\n# 4:  (a) 260/9     (b) 2.833     (c) \\(2.679\\times 10^{-5}\\)     (d) Same idea as (c) Replace 10’s with 100.     \n# 6:  (a) \\(p_X(x)=\\binom{4}{x}.3^x .7^{4-x}\\), for \\(x=0,1,\\ldots,4\\)     (d) 0.3483     (e) 0.9163     (f) 0.0233     (g) 1\n# 8:  (a) T     (b) F     (c) F     (d) F     (e) T     (f) T    (g) T\n# 10:  (a) T     (b) T    (c) F     (d) T    (e) T     (f) F    (g) T     (h) T (nonnegative instead of positive)     (i) F"
  },
  {
    "objectID": "hw_answers/HW_06_ans.html",
    "href": "hw_answers/HW_06_ans.html",
    "title": "Homework 6 Answers",
    "section": "",
    "text": "Partial answers:\n\n\n\n\\(p_{X|Y}(X=\\text{high school}| Y=\\text{no smoking at all}) = 0.476\\)\n\n\n\\(p_{Y|X}( Y=\\text{no smoking at all}|X=\\text{high school}) = 0.200\\)\n\n\n\n\n\n\\(p_{X,Y}(x,y) = [0.99^{x-1}0.01][0.97^{y-1}0.03]\\) for \\(x,y = 0, 1, 2, ...\\)\n\n\n And hint: \n\n\n\n\n\n\n\n\\(f_{X|Y}(x|y)=\\frac{1}{2}\\) for (need \\(x\\) and \\(y\\) domains)\n\n\n\\(\\frac{4}{7}\\)"
  },
  {
    "objectID": "hw_answers/HW_06_ans.html#non-textbook-problems",
    "href": "hw_answers/HW_06_ans.html#non-textbook-problems",
    "title": "Homework 6 Answers",
    "section": "",
    "text": "#1:"
  },
  {
    "objectID": "hw_answers/HW_06_ans.html#textbook-problems",
    "href": "hw_answers/HW_06_ans.html#textbook-problems",
    "title": "Homework 6 Answers",
    "section": "Textbook problems",
    "text": "Textbook problems\nThere are answers at the back of the book!! Selected answers (or hints) not provided at the end the book:\n\nCalculus Review\n\n(a)  \\(c(\\frac{y^{2}}{2}+y^{2})\\)\n(b)  \\(\\frac{8}{9}xy^{2}+\\frac{5}{9}y^{4}\\)\n(c)  \\(\\frac{8}{9}x^{2}y+\\frac{20}{9}xy^{3}\\)\n(d)  \\(-2e^{-2y}+2e^{-y}\\)\n(e)  \\(xe^{-x}\\)\n(f)  \\(-\\frac{2}{3}(e^{-7x}-e^{-4x})\\)\n(g)  \\(\\frac{9}{2}\\)\n(h)  \\(\\frac{9}{2}\\)\n(i)  \\(\\frac{9}{2}\\)\n(j)  \\(\\frac{9}{2}\\)\n\nChapter 24\n\n# 2: (a) Discrete     (b) Discrete     (c) Continuous\n# 19:\n\n\n\\[F_X(x) = \\left\\{\n  \\begin{array}{ll}\n      0 & \\quad x \\leq 16 \\\\\n      \\frac{1}{64}x^2 - \\frac{1}{2}x + 4 & \\quad 16 &lt; x\\leq 24 \\\\\n      1 & \\quad x &gt; 24 \\\\\n  \\end{array}\n  \\right.\\]\n\n\n\\(a=20\\)\n\n\n# 20:\n\n\n\\(k=660\\)\n\n\n\\[F_X(x) = \\left\\{\n    \\begin{array}{ll}\n        0 & \\quad x &lt; 0 \\\\\n        55x^{12} - 120x^{11} + 55x^{10} & \\quad 0 \\leq x\\leq 1 \\\\\n        1 & \\quad x &gt; 24 \\\\\n    \\end{array}\n\\right.\\]\n\n\n# 22: \\[f_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x &lt;0 \\\\\n            \\frac{7x}{4} & \\quad 0\\leq x\\leq 1 \\\\\n            0 & \\quad 1&lt; x&lt; 7 \\\\\n            \\frac{1}{8} & \\quad 7\\leq x\\leq 8 \\\\\n            0 & \\quad  x&gt;8 \\\\\n        \\end{array}\n    \\right.\\]"
  },
  {
    "objectID": "lessons/09_Joint_distributions/09_Joint_distributions_key_info.html",
    "href": "lessons/09_Joint_distributions/09_Joint_distributions_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 02 assignments are graded!\n\nSolutions and videos are posted!\n\nFinish the discrete distributions notes\n\nThen get into joint distributions"
  },
  {
    "objectID": "lessons/09_Joint_distributions/09_Joint_distributions_key_info.html#announcements",
    "href": "lessons/09_Joint_distributions/09_Joint_distributions_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 02 assignments are graded!\n\nSolutions and videos are posted!\n\nFinish the discrete distributions notes\n\nThen get into joint distributions"
  },
  {
    "objectID": "lessons/09_Joint_distributions/09_Joint_distributions_key_info.html#key-dates",
    "href": "lessons/09_Joint_distributions/09_Joint_distributions_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 03 Assignment due this Thursday at 11pm\n\nI updated the homework assignment on the 18th!"
  },
  {
    "objectID": "lessons/10_Expected_Values/10_Expected_Values_key_info.html",
    "href": "lessons/10_Expected_Values/10_Expected_Values_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 03 assignment today\nGroup evals will be taken off the assessment breakdown\nMid-quarter feedback will be put on HW 05"
  },
  {
    "objectID": "lessons/10_Expected_Values/10_Expected_Values_key_info.html#announcements",
    "href": "lessons/10_Expected_Values/10_Expected_Values_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 03 assignment today\nGroup evals will be taken off the assessment breakdown\nMid-quarter feedback will be put on HW 05"
  },
  {
    "objectID": "lessons/10_Expected_Values/10_Expected_Values_key_info.html#key-dates",
    "href": "lessons/10_Expected_Values/10_Expected_Values_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 04 assignment due Thursday\nHW 03 solutions due Sunday\n\nAnd we will have a presentation on this one!"
  },
  {
    "objectID": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#where-are-we",
    "href": "lessons/24_00_pre_Calculus_review/24_00_pre_Calculus_review.html#where-are-we",
    "title": "Calculus Review",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "hw_answers/HW_04_ans.html",
    "href": "hw_answers/HW_04_ans.html",
    "title": "Homework 4 Answers",
    "section": "",
    "text": "Not given\nNot given\n\n\\[F_X(x) = \\left\\{\n         \\begin{array}{ll}\n             0 & \\quad x \\leq 16 \\\\\n             \\frac{1}{64}x^2 - \\frac{1}{2}x + 4 & \\quad 16 &lt; x\\leq 24 \\\\\n             1 & \\quad x &gt; 24 \\\\\n         \\end{array}\n     \\right.\\]\n\\(a=20\\)\n\n\n\\(k=660\\)\n\\[F_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x &lt; 0 \\\\\n            55x^{12} - 120x^{11} + 66x^{10} & \\quad 0 \\leq x\\leq 1 \\\\\n            1 & \\quad x &gt; 24 \\\\\n        \\end{array}\n    \\right.\\]"
  },
  {
    "objectID": "homeworks.html#rubrics",
    "href": "homeworks.html#rubrics",
    "title": "Homework",
    "section": "Rubrics",
    "text": "Rubrics\n\nAssignmentsSolutionsPresentations\n\n\nA total of 1 point will be given for a complete homework. The following rubric will be used:\n\n\n\n\n\n\n\n\n\n1 point\n0 points\n\n\n\n\nCompleteness\nAll problems and parts (like a, b, c, etc.) are thoroughly attempted. Answers can be incorrect or correct. For parts with longer processes and calculations, solution set up and calculations are required.\nEntire problems or parts are skipped. -OR- The full process of a problem is not completed through the calculation.\n\n\n\n\n\nA total of 12 points is given to the whole group, 3 points per question. For each question, the following rubric will be used:\n\n\n\n\n\n\n\n\n\n\n1 point\n0.5 points\n0 points\n\n\n\n\nAccuracy\nAll calculations and answers are correct, with clear and logical steps\nMinor errors in calculations or reasoning, but most concepts are applied correctly\nMajor mistakes or incorrect application of statistical methods\n\n\nUnderstanding of concepts\nDemonstrates strong understanding of statistical concepts and their application\nSome understanding, but with gaps or misconceptions about certain concepts\nLittle or no understanding of the key statistical ideas\n\n\nPresentation and clarity\nHomework is well-organized, legible, and easy to follow, with clear explanations of steps and reasoning\nWork is somewhat disorganized or unclear, but the main points can still be understood\nPoorly organized or difficult to understand, with little to no explanation of the work\n\n\n\n\n\nImagine that a fellow student is coming to you and does not know how to do a problem. Your presentation should serve as a guide for that student. They should be able to link key phrases or theorems that you mention to class and follow your clear and correct work from beginning to end. Finally, your final answer is contextualized given the original problem.\nPresentations will be graded out of 9 points with the following rubric:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3 point\n\n\n\n\n2 points\n\n\n\n\n1 point\n\n\n\n\n0 points\n\n\n\n\n\n\n\n\nAccuracy\n\n\n\n\nAll solutions are correct, with accurate calculations and appropriate use of statistical methods\n\n\n\n\nMost solutions are correct, but there are minor errors or slight misapplications of methods\n\n\n\n\nSeveral solutions are incorrect or contain significant errors in calculations or methodology\n\n\n\n\nMost or all solutions are incorrect or missing, with little to no evidence of correct application of methods\n\n\n\n\n\n\nUnderstanding of concepts\n\n\n\n\nDemonstrates a strong understanding of the statistical concepts, applying them accurately and clearly throughout the presentation\n\n\n\n\nShows good understanding of the concepts, though there may be occasional errors, unclear explanations of key ideas, or exclusion of an important step.\n\n\n\n\nShows limited understanding, with several misapplications, gaps in conceptual explanations, or exclusion of an important step\n\n\n\n\nLittle to no understanding of the statistical concepts is demonstrated; frequent errors or misconceptions are present\n\n\n\n\n\n\nOrganization and formatting\n\n\n\n\nThe presentation is well-organized, with a logical flow that is easy to follow. Sections and explanations are clearly structured. Easy to follow thought process and learn.\n\n\n\n\nThe presentation is mostly organized, but some sections may lack logical flow. Fairly easy to follow thought process.\n\n\n-OR-\n\n\nPresentation deserves 3 points but it exceeds 10 minutes.\n\n\n\n\nThe presentation is somewhat disorganized, with several sections lacking clear structure or transitions. Hard to follow thought process.\n\n\n-OR-\n\n\nPresentation deserves 2 points but it exceeds 10 minutes.\n\n\n\n\nThe presentation is poorly organized, with no logical structure. Cannot follow thought process.\n\n\n-OR-\n\n\nPresentation deserves 1 points but it exceeds 10 minutes."
  },
  {
    "objectID": "lessons/12_Variance/12_Variance_key_info.html",
    "href": "lessons/12_Variance/12_Variance_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 4 assignment due last night!\nHW 3 solutions also due\nTime to grade later today: HW 3 solutions or HW 4 assignment?"
  },
  {
    "objectID": "lessons/12_Variance/12_Variance_key_info.html#announcements",
    "href": "lessons/12_Variance/12_Variance_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 4 assignment due last night!\nHW 3 solutions also due\nTime to grade later today: HW 3 solutions or HW 4 assignment?"
  },
  {
    "objectID": "lessons/12_Variance/12_Variance_key_info.html#key-dates",
    "href": "lessons/12_Variance/12_Variance_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates"
  },
  {
    "objectID": "homework/HW_05.html#mid-quarter-feedback",
    "href": "homework/HW_05.html#mid-quarter-feedback",
    "title": "Homework 5",
    "section": "Mid-quarter feedback",
    "text": "Mid-quarter feedback\nPlease complete the mid-quarter feedback!: https://forms.office.com/r/rC2JR2qQTq"
  },
  {
    "objectID": "lessons/12_Variance/12_Variance.html#lets-look-at-a-ghost-problem-with-replacement",
    "href": "lessons/12_Variance/12_Variance.html#lets-look-at-a-ghost-problem-with-replacement",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Let’s look at a ghost problem with replacement",
    "text": "Let’s look at a ghost problem with replacement\n\n\n\n\nExample 3.2\n\n\nThe ghost is trick-or-treating at a different house now. In this case it is known that the bag of candy has 10 chocolates, 20 lollipops, and 30 laffy taffies. The ghost grabs a handful of five pieces of candy. What is the variance for the number of chocolates the ghost takes? Let’s solve this for the cases with replacement.\n\n\n\n\nRecall probability with replacement:\n\\[\np_X(x) = {n \\choose k}p^k(1-p)^{n-k}\n\\]"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#learning-objectives",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#learning-objectives",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nFind derivatives of continuous functions with one variable\nFind antiderivatives and integrals of functions with one variable"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#where-are-we",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#where-are-we",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.1\n\n\n\\(f(x) = 2\\)\n\n\n\n\nDerivative of a constant\n\n\n\\[\\dfrac{d}{dx} c = 0\\]"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-1",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-1",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.2\n\n\n\\(f(x) = 2x\\)"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-2",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-2",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.3\n\n\n\\(f(x) = 2x+2\\)"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-3",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-3",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.4\n\n\n\\(f(x) = x^2\\)\n\n\n\n\nDerivative of \\(x\\) to a constant\n\n\n\\[\\dfrac{d}{dx} x^n = nx^{n-1}\\]"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-4",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-4",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.5\n\n\n\\(f(x) = 3\\sqrt{x}+\\frac2x+5\\)"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-5",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-5",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.6\n\n\n\\(f(x) = e^x\\)\n\n\n\n\nDerivative of exponential function\n\n\n\\(\\dfrac{d}{dx} e^x = e^x\\)"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-6",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-6",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.7\n\n\n\\(f(x) = \\ln(x)\\)\n\n\n\n\nDerivative of logarithm\n\n\n\\(\\dfrac{d}{dx} ln(x) = \\dfrac{1}{x}\\)"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-7",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-7",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.8\n\n\n\\(f(x) = x^2 e^x\\)\n\n\n\n\nProduct Rule\n\n\n\\(\\dfrac{d}{dx} f(x)g(x) = f'(x)g(x) + f(x)g'(x)\\)"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-8",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-8",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.9\n\n\n\\(f(x) = \\dfrac{x^5}{2x+7}\\)\n\n\n\n\nQuotient Rule\n\n\n\\(\\dfrac{d}{dx} \\dfrac{f(x)}{g(x)} = \\dfrac{g(x)f'(x) - f(x)g'(x)}{\\big(g(x)\\big)^2}\\)"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-9",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-9",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.10\n\n\n\\(f(x) = e^{-2x+7}\\)\n\n\n\n\nChain Rule\n\n\n\\(\\dfrac{d}{dx} f\\big(g(x)\\big)= f'\\big(g(x)\\big)g'(x)\\)"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-10",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-10",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.11\n\n\n\\(f(x) = \\ln(x^2)\\)"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.1\n\n\n\\(f(x) = 2\\)"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-1",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-1",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.2\n\n\n\\(f(x) = x\\)\n\n\n\n\nIntegration of x to a constant\n\n\n\\(\\displaystyle\\int x^n dx = \\dfrac{x^{n+1}}{n+1} + c\\)"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-2",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-2",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.3\n\n\n\\(f(x) = \\frac1x\\)"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-3",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-3",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.4\n\n\n\\(f(x) = x^{3/2}\\)"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-4",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-4",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.5\n\n\n\\(f(x) = e^x\\)"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-5",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-5",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.6\n\n\n\\(f(x) = e^{-x}\\)"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-6",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-6",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.7\n\n\n\\(f(x) = e^{-2x}\\)"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.1\n\n\n\\(\\displaystyle\\int_0^1 (2x+x^5)dx\\)"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-1",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-1",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.2\n\n\n\\(\\displaystyle\\int_2^3 e^{-x}dx\\)\n\n\n\n\nU-substitution\n\n\n\\(\\displaystyle\\int f\\big(g(x)\\big) g'(x) dx = \\displaystyle\\int f(u) dx\\)"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-2",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-2",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.3\n\n\n\\(\\displaystyle\\int_2^3 x e^{x^2}dx\\)"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-3",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-3",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.4\n\n\n\\(\\displaystyle\\int_0^{\\infty} x e^{-x}dx\\)\n\n\n\n\nIntegrating by Parts\n\n\n\\(\\displaystyle\\int f(x) g'(x) dx = f(x)g(x) -\\)\n\\(\\displaystyle\\int f'(x) g(x) dx\\)\nOR\n\\(\\displaystyle\\int_a^b u dv = uv\\bigg|^b_a - \\displaystyle\\int_a^b vdu\\)"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-4",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-4",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.5\n\n\n\\(\\displaystyle\\int_1^2 x^2 \\ln(x)dx\\)"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-5",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-5",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.6\n\n\n\\(\\displaystyle\\int_1^2 \\ln(x)dx\\)"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-6",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-6",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.7\n\n\n\\(\\displaystyle\\int_1^2 x^2 e^{x}dx\\)\n\n\n\n\n\n\nPre Chapter 24 Slides"
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html",
    "title": "Chapter 43: Moment Generating Functions Part 1",
    "section": "",
    "text": "Chapter 43: Moment Generating Functions Part 1\n\nWhat are moments?\n\n\nDefinition 1.   The \\(j^{th}\\) moment of a r.v. \\(X\\) is \\(\\mathbb{E}[X^j]\\).\n\n\nExample 2.   \\(1^{st}-4^{th}\\) moments.\n\n\n\nWhat is a moment generating function (mgf)?\n\n\nDefinition 3.   If \\(X\\) is a r.v., then \\[M_X(t)= \\mathbb{E}[e^{tX}]\\] is the moment generating function (mgf) associated with \\(X\\).\n\nRemarks\n\nFor a discrete r.v., the mgf of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\sum_{all \\ x}e^{tx}p_X(x)\\]\nFor a continuous r.v., the mgf of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\int_{-\\infty}^{\\infty}e^{tx}f_X(x)dx\\]\nThe mgf \\(M_X(t)\\) is a function of \\(t\\), not of \\(X\\), and it might not be defined (i.e. finite) for all values of \\(t\\). We just need it to be defined for \\(t=0\\).\n\n\nExample 4.   What is \\(M_X(t)\\) for \\(t=0\\)?\n\n\n\nTheorem 5.   The moment generating function uniquely specifies a probability distribution.\n\n\nTheorem 6.   \\[\\mathbb{E}[X^r] = M_X^{(r)}(0)\\]\n\n\nProof. Proof. ◻\n\n\nExample 7.   Let \\(X \\sim Poisson(\\lambda)\\).\n\nFind the mgf of \\(X\\).\nFind \\(\\mathbb{E}[X]\\).\nFind \\(Var(X)\\).\n\n\nRemark\nFinding the mean and variance is sometimes easier with the following trick.\n\nTheorem 8. Let \\[R_X(t) = \\ln[M_X(t)]\\]\nThen,\n\\[\\mu = \\mathbb{E}[X] = R_X'(0)\\] and \\[\\sigma^2 = Var(X) = R_X''(0)\\]\n\n\nProof. Proof. ◻\n\n\n\nExample 9.   Let \\(X \\sim Poisson(\\lambda)\\).\n\nFind \\(\\mathbb{E}[X]\\) using \\(R_X(t)\\).\nFind \\(Var(X)\\) using \\(R_X(t)\\).\n\n\n\nExample 10.   Let \\(Z\\) be a standard normal random variable, i.e. \\(Z \\sim N(0,1)\\).\n\nFind the mgf of \\(Z\\).\nFind \\(\\mathbb{E}[Z]\\).\nFind \\(Var(Z)\\)."
  },
  {
    "objectID": "homeworks.html#files-and-timing-information",
    "href": "homeworks.html#files-and-timing-information",
    "title": "Homework",
    "section": "",
    "text": "Homework\nAssignment\nAssignment due (@11pm)\nAnswers\nSolutions\nSol’n Videos\n\n\n\n\n0\n\n10/06\n\n\n\n\n\n1\n\n10/09\n\n\n\n\n\n2\n\n10/16\n\n\n\n\n\n3\n\n10/23\n\n\n\n\n\n4\n\n10/30\n\n\n\n\n\n5\n\n11/06\n\n\n\n\n\n6\n\n11/13\n\n\n\n\n\n7\n\n11/20\n\n\n\n\n\n8\n\n12/03\n\n\n\n\n\n9 (optional)\n\n12/10"
  },
  {
    "objectID": "homeworks.html#how-to-create-a-video",
    "href": "homeworks.html#how-to-create-a-video",
    "title": "Homework",
    "section": "How to create a video",
    "text": "How to create a video\nI think the best way to make your video will be to record a meeting in Zoom or Webex. In either app, you can enter your personal room, then share your screen with your work (or an iPad screen).\n\n\n\n\n\n\nPractice short recordings\n\n\n\nI highly recommend that you try out your recording process to make sure everything works! You can make a short video to playback.\n\n\nYou can follow Zoom or Webex’s guide for recording:\n\nWebex: https://help.webex.com/en-us/article/xl9d60/Webex-%7C-Record-a-meeting-in-the-cloud\n\nLogin with OHSU credentials\n\nZoom: https://support.zoom.com/hc/en/article?id=zm_kb&sysparm_article=KB0062627\n\nLogin with PSU credentials"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review_key_info.html",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 4 assignment due last night!\nHW 3 solutions also due\nTime to grade later today: HW 3 solutions or HW 4 assignment?\nTomorrow I will be sending out a Calendly invite for next week\n\nTo make an appointment with me to present your HW 3 solutions\nIt will be posted around 11:45am/12pm\nThere are limited spots just based on my availability"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review_key_info.html#announcements",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 4 assignment due last night!\nHW 3 solutions also due\nTime to grade later today: HW 3 solutions or HW 4 assignment?\nTomorrow I will be sending out a Calendly invite for next week\n\nTo make an appointment with me to present your HW 3 solutions\nIt will be posted around 11:45am/12pm\nThere are limited spots just based on my availability"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review_key_info.html#key-dates",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 5 due\nSunday: HW 4 solutions due\nWeek of 11/11\n\nMake a meeting with me\n11/12: recordings due if you are making that"
  },
  {
    "objectID": "lessons/24_00_Calculus_review/24_00_Calculus_review_muddy_points.html",
    "href": "lessons/24_00_Calculus_review/24_00_Calculus_review_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n1. Why we are allowed to “split” the operator d/dx into two pieces as if it were a fraction when it’s an operator\nHere is a pretty helpful StackExchange post talking about this!\n\n\n2. How to know what to use as \\(u\\) and \\(dv\\) for integration by parts\nI have two approaches to identifying \\(u\\) and \\(dv\\):\n\nTry to find a \\(u\\) that will eventually differentiate into a constant. This usually works unless you’re left with a \\(dv\\) that is hard to integrate.\n\nFor example, \\(u=x^6\\). the first derivative, \\(u'=6x^5\\), which may lead us to do another integration by parts, but eventually, at the 6th derivative, we get 720. This means, in our integration by parts, we eventually get an integral that only has \\(x\\) in the function once.\n\nIn this example, \\(x^6\\) would result in many integration by parts. I feel like we don’t typically see that many in our work.\n\nIn Example 3.5 in Calculus Review, setting \\(u=x^2\\) is a bad idea because we don’t really know how to integrate \\(dv=ln(x)\\) into \\(v\\).\n\nTry to find a \\(u\\) where \\(du\\) is the reciprocal of \\(v\\) or \\(du\\) cancels with \\(v\\).\n\nLook again at Example 3.5 in the notes! Hint: What is the derivative of \\(ln(x)\\)? And what does \\(\\dfrac{1}{x}x^3\\) equal?\n\n\n\n\n3. Looking for more practice in calculus?\nI just stumbled upon this website! Just a bunch of calculus practice problems! Might be some help."
  },
  {
    "objectID": "lessons/12_Variance/12_Variance_muddy_points.html",
    "href": "lessons/12_Variance/12_Variance_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy Points from Fall 2023:\n\n1. Proof of variance formula\nHere is the variance formula that we worked through on slide 9 of Chapter 12’s notes.\n\n\n\n\n\n\nLemma 6: “Computation formula” for variance\n\n\n\nThe variance of a r.v. \\(X\\), can be computed as \\[\\begin{align}\\sigma_X^2 & =Var(X) \\\\ & = \\mathbb{E}[X^2]-\\mu_X^2 \\\\ & = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2\\end{align}\\]\n\n\nI stepped through this quite quickly and made some implicit steps. So let’s revisit it with explicit steps!\n       \n\n\n2. What progression are we following in the course??\nSomeone asked if this is our progression: RV is function \\(\\to\\) Expected value is function to describe mean of RV \\(\\to\\) Use functions within expected value to set up variance\nBasically, yes! The random variable is a function of a random process. The RV inherits that randomness.\nFrom there, we’ve been working towards calculating the probability of a realized value ($x$) of the RV. The probability can be different for different realized values (as it links back to the random process).\nWe also want to construct ways to describe our random variables. We may want to figure out what to expect from our random variable (which translates to the mean value of the RV). Since our RV is rooted in a random process, we may want to get an idea of how spread out our realized values are. We use our expected value (mean) as an anchor in our spread. Variance is one way to measure this spread."
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv_key_info.html",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Graded: HW 4 assignment and HW 3 solutions\nCalendly is up!!"
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv_key_info.html#announcements",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Graded: HW 4 assignment and HW 3 solutions\nCalendly is up!!"
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv_key_info.html#key-dates",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 5 due\nSunday: HW 4 solutions due\nWeek of 11/11\n\nMake a meeting with me\n11/12: recordings due if you are making that\nNow on Sakai"
  },
  {
    "objectID": "lessons/24_01_Continuous_rv/24_01_Continuous_rv_muddy_points.html",
    "href": "lessons/24_01_Continuous_rv/24_01_Continuous_rv_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n1. Why we are allowed to “split” the operator d/dx into two pieces as if it were a fraction when it’s an operator\nHere is a pretty helpful StackExchange post talking about this!\n\n\n2. How to know what to use as \\(u\\) and \\(dv\\) for integration by parts\nI have two approaches to identifying \\(u\\) and \\(dv\\):\n\nTry to find a \\(u\\) that will eventually differentiate into a constant. This usually works unless you’re left with a \\(dv\\) that is hard to integrate.\n\nFor example, \\(u=x^6\\). the first derivative, \\(u'=6x^5\\), which may lead us to do another integration by parts, but eventually, at the 6th derivative, we get 720. This means, in our integration by parts, we eventually get an integral that only has \\(x\\) in the function once.\n\nIn this example, \\(x^6\\) would result in many integration by parts. I feel like we don’t typically see that many in our work.\n\nIn Example 3.5 in Calculus Review, setting \\(u=x^2\\) is a bad idea because we don’t really know how to integrate \\(dv=ln(x)\\) into \\(v\\).\n\nTry to find a \\(u\\) where \\(du\\) is the reciprocal of \\(v\\) or \\(du\\) cancels with \\(v\\).\n\nLook again at Example 3.5 in the notes! Hint: What is the derivative of \\(ln(x)\\)? And what does \\(\\dfrac{1}{x}x^3\\) equal?\n\n\n\n\n3. Looking for more practice in calculus?\nI just stumbled upon this website! Just a bunch of calculus practice problems! Might be some help."
  },
  {
    "objectID": "lessons/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#learning-objectives",
    "href": "lessons/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#learning-objectives",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate the mean (expected value) of a joint distribution of continuous RV"
  },
  {
    "objectID": "lessons/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#expected-value-from-a-joint-distribution",
    "href": "lessons/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#expected-value-from-a-joint-distribution",
    "title": "Chapter 28 and 19: Revisiting Expected Values and Variance for Joint Distributions",
    "section": "Expected value from a joint distribution",
    "text": "Expected value from a joint distribution\n\n\n\n\nExample 3\n\n\nLet \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#expected-value-from-a-joint-pdf",
    "href": "lessons/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#expected-value-from-a-joint-pdf",
    "title": "Chapter 28 and 19: Revisiting Expected Values and Variance for Joint Distributions",
    "section": "Expected value from a joint pdf",
    "text": "Expected value from a joint pdf\n\n\n\n\nExample 1\n\n\nLet \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#remark-on-expected-value-of-one-rv-from-joint-pdf",
    "href": "lessons/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#remark-on-expected-value-of-one-rv-from-joint-pdf",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "Remark on expected value of one RV from joint pdf",
    "text": "Remark on expected value of one RV from joint pdf\nIf you are given \\(f_{X,Y}(x,y)\\) and want to calculate \\(\\mathbb{E}[X]\\), you have two options:\n\nFind \\(f_X(x)\\) and use it to calculate \\(\\mathbb{E}[X]\\).\nOr, calculate \\(\\mathbb{E}[X]\\) using the joint density: \\[\\mathbb{E}[X] = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}x f_{X,Y}(x,y)dydx.\\]"
  },
  {
    "objectID": "lessons/28_Expected_Values/28_Expected_Values_key_info.html",
    "href": "lessons/28_Expected_Values/28_Expected_Values_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Wow! Week 7…\nHW 3 video/presentation\n\nTomorrow! 11/12 at 11pm: recordings due if you are making that\nCalendly is up!! Please see me original announcement\n\nNeed to grade HW 4 solutions and HW 5 assignment\nAnything else?"
  },
  {
    "objectID": "lessons/28_Expected_Values/28_Expected_Values_key_info.html#announcements",
    "href": "lessons/28_Expected_Values/28_Expected_Values_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Wow! Week 7…\nHW 3 video/presentation\n\nTomorrow! 11/12 at 11pm: recordings due if you are making that\nCalendly is up!! Please see me original announcement\n\nNeed to grade HW 4 solutions and HW 5 assignment\nAnything else?"
  },
  {
    "objectID": "lessons/28_Expected_Values/28_Expected_Values_key_info.html#key-dates",
    "href": "lessons/28_Expected_Values/28_Expected_Values_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 6 due\nSunday: HW 5 solutions due"
  },
  {
    "objectID": "lessons/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-1-expected-value-from-a-joint-distribution",
    "href": "lessons/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-1-expected-value-from-a-joint-distribution",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "Option 1: Expected value from a joint distribution",
    "text": "Option 1: Expected value from a joint distribution\n\n\n\n\nExample 3\n\n\nLet \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-2-expected-value-from-a-joint-distribution",
    "href": "lessons/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-2-expected-value-from-a-joint-distribution",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "Option 2: Expected value from a joint distribution",
    "text": "Option 2: Expected value from a joint distribution\n\n\n\n\nExample 1\n\n\nLet \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\).\n\n\n\n\n\n\nChapter 28-29 Revisited Slides"
  },
  {
    "objectID": "lessons/27_Conditional_distributions/27_Conditional_distributions.html",
    "href": "lessons/27_Conditional_distributions/27_Conditional_distributions.html",
    "title": "Chapter 27: Conditional Distributions",
    "section": "",
    "text": "Calculate the conditional probability density from a joint pdf"
  },
  {
    "objectID": "lessons/27_Conditional_distributions/27_Conditional_distributions.html#learning-objectives",
    "href": "lessons/27_Conditional_distributions/27_Conditional_distributions.html#learning-objectives",
    "title": "Chapter 27: Conditional Distributions",
    "section": "",
    "text": "Calculate the conditional probability density from a joint pdf"
  },
  {
    "objectID": "lessons/27_Conditional_distributions/27_Conditional_distributions.html#conditional-probabilities-weve-seen-before",
    "href": "lessons/27_Conditional_distributions/27_Conditional_distributions.html#conditional-probabilities-weve-seen-before",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Conditional probabilities we’ve seen before",
    "text": "Conditional probabilities we’ve seen before\n\n\nWhat do we know about conditional probabilities for events and discrete RVs?    \nFor events:\n\\[P(A | B) = \\dfrac{P(A \\cap B)}{P(B)}\\]    \nFor discrete RVs: \\[p_{X|Y}(x|y) = P(X=x|Y=y) = \\dfrac{p_{X,Y}(x,y)}{p_Y(y)}\\]\n\n\n\nWhat does it mean for conditional densities of continuous RVs?\nFor continuous RVs:"
  },
  {
    "objectID": "lessons/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-first-try",
    "href": "lessons/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-first-try",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf: first try!",
    "text": "Example starting from a joint pdf: first try!\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(2&lt;X&lt;10|Y=4)\\)"
  },
  {
    "objectID": "lessons/27_Conditional_distributions/27_Conditional_distributions.html#what-is-a-conditional-density",
    "href": "lessons/27_Conditional_distributions/27_Conditional_distributions.html#what-is-a-conditional-density",
    "title": "Chapter 27: Conditional Distributions",
    "section": "What is a conditional density?",
    "text": "What is a conditional density?\n\n\n\n\nDefinition: Conditional density\n\n\nThe conditional density of a r.v. \\(X\\) given \\(Y=y\\), is \\[f_{X|Y}(x|y)= \\frac{f_{X,Y}(x,y)}{f_Y(y)},\\] for \\(f_Y(y)&gt; 0\\)\n\n\n\n\n\nRemarks\n\nIt follows from the definition for the conditional density \\(f_{X|Y}(x|y)\\), that \\[f_{X,Y}(x,y)= f_{X|Y}(x|y)f_Y(y).\\]\n\n     \n\nFor a fixed value of \\(Y=y\\), the conditional density \\(f_{X|Y}(x|y)\\) is an actual pdf, meaning\n\n\\(f_{X|Y}(x|y)\\geq 0\\) for all \\(x\\) and \\(y\\), and\n\\(\\displaystyle\\int_{-\\infty}^{\\infty} f_{X|Y}(x|y)dx =1\\)."
  },
  {
    "objectID": "lessons/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try",
    "href": "lessons/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf: second try!",
    "text": "Example starting from a joint pdf: second try!\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(2&lt;X&lt;10|Y=4)\\)"
  },
  {
    "objectID": "lessons/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf",
    "href": "lessons/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf",
    "text": "Example starting from a joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(X&gt;20 |Y=5)\\)"
  },
  {
    "objectID": "lessons/27_Conditional_distributions/27_Conditional_distributions.html#finding-probability-with-conditional-domain-and-pdf",
    "href": "lessons/27_Conditional_distributions/27_Conditional_distributions.html#finding-probability-with-conditional-domain-and-pdf",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Finding probability with conditional domain and pdf",
    "text": "Finding probability with conditional domain and pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 2\n\n\nRandomly choose a point \\(X\\) from the interval \\([0,1]\\), and given \\(X=x\\), randomly choose a point \\(Y\\) from \\([0,x]\\). Find \\(\\mathbb{P}(0 &lt; Y &lt; \\frac14)\\)."
  },
  {
    "objectID": "lessons/27_Conditional_distributions/27_Conditional_distributions.html#independence-and-conditional-distributions",
    "href": "lessons/27_Conditional_distributions/27_Conditional_distributions.html#independence-and-conditional-distributions",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Independence and conditional distributions",
    "text": "Independence and conditional distributions\n    Question What is \\(f_{X|Y}(x|y)\\) if \\(X\\) and \\(Y\\) are independent?\n\\[f_{X|Y}(x|y) = \\dfrac{f_{X,Y}(x,y)}{f_y(y)} = \\dfrac{f_{X}(x)f_y(y)}{f_y(y)} = f_{X}(x)\\]\n       \n\nIf \\(f_{X|Y}(x|y)\\) does not depend on \\(y\\) (including the bounds/domain), then \\(X\\) and \\(Y\\) are independent."
  },
  {
    "objectID": "hw_answers/HW_07_ans.html#footnotes",
    "href": "hw_answers/HW_07_ans.html#footnotes",
    "title": "Homework 7 Answers",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI recommend doing the Chapter 29 Extra Problems in the order listed.↩︎\nAssume \\(X\\) and \\(Y\\) are independent.↩︎"
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#learning-objectives",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#learning-objectives",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDistinguish between Uniform, Exponential, Gamma, and Normal distributions when reading a story.\nIdentify the variable and the parameters in a story, and state what the variable and parameters mean.\nUse the formulas for the pdf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#where-are-we",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#where-are-we",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#properties-of-continuous-uniform-rvs",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#properties-of-continuous-uniform-rvs",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Properties of continuous uniform RVs",
    "text": "Properties of continuous uniform RVs\n\nScenario: Events are equally likely to happen anywhere or anytime in an interval of values\nShorthand: \\(X \\sim \\text{U}[a,b]\\)\n\n\\[\nf_X(x) = \\dfrac{1}{b-a}, \\text{ for }a \\leq x \\leq b\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;a \\quad \\\\\n            \\dfrac{x-a}{b-a} & \\quad a \\leq x \\leq b\\quad \\\\\n            1 & \\quad x&gt;b \\quad\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{a+b}{2} \\text{, } \\text{ Var}(X) = \\dfrac{(b-a)^2}{12}\\]"
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#identifying-continuous-uniform-rv-from-word-problems",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#identifying-continuous-uniform-rv-from-word-problems",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Identifying continuous uniform RV from word problems",
    "text": "Identifying continuous uniform RV from word problems\n\nLook for some indication that all events are equally likely\n\nCould also say “uniformly distributed”\n\nLook for an interval\n\nTime example: Costumer in your store will approach the cash register in next 30 minutes. Approaching the register throughout the 30 minutes is equally likely.\nLength example: You have a 12 inch string that you need to cut. You are equally likely to cut anywhere on the string.\n\nDifferent than the discrete uniform\n\nDiscrete usually includes a countable number of events that are equally likely\nContinuous is not countable\n\nExact time and length can be measured with infinite decimal places"
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re looking at equally likely arrival times between 10 am and 11 am.\n\nIf we want to know the probability that someone arrives at 10:30am or earlier:\n\npunif(q = 30, min = 0, max = 60)\n\n[1] 0.5\n\n\nIf we want to know the time, say \\(t\\), where the probability of arriving at \\(t\\) or earlier is 0.35:\n\nqunif(p = 0.35, min = 0, max = 60)\n\n[1] 21\n\n\nIf we want to know the probability that someone arrives between 10:14 and 10:16 am:\n\npunif(q = 16, min = 0, max = 60) - punif(q = 14, min = 0, max = 60)\n\n[1] 0.03333333\n\n\nIf we want to sample 20 arrival times from the distribution:\n\nrunif(n = 20, min = 0, max = 60)\n\n [1] 14.678120 51.978743 20.053322 30.961489 18.560075 23.306970  6.055852\n [8] 58.759085 28.970863 42.766885 37.308040 47.688816  4.226385 46.083334\n[15]  6.912673 31.533889 26.919587 35.281129  2.206351 46.045267"
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#bird-on-a-wire-tb-31.5",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#bird-on-a-wire-tb-31.5",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Bird on a wire (TB 31.5)",
    "text": "Bird on a wire (TB 31.5)\n\n\n\n\nExample 1\n\n\nA bird lands at a location that is Uniformly distributed along an electrical wire of length 150 feet. The wire is stretched tightly between two poles. What is the probability that the bird is 20 feet or less from one or the other of the poles?"
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#properties-of-exponential-rvs",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#properties-of-exponential-rvs",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Properties of exponential RVs",
    "text": "Properties of exponential RVs\n\nScenario: Modeling the time until the next (first) event\nContinuous analog to the geometric distribution!\nShorthand: \\(X \\sim \\text{Exp}(\\lambda)\\)\n\n\\[\nf_X(x) = \\lambda e^{-\\lambda x}\\text{ for } x&gt;0, \\lambda&gt;0\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;0 \\quad \\\\\n            1 - e^{-\\lambda x} & \\quad x\\geq0 \\\\\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{1}{\\lambda}\\] \\[\\text{Var}(X) = \\dfrac{1}{\\lambda^2}\\]"
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#memoryless-property",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#memoryless-property",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Memoryless Property",
    "text": "Memoryless Property\n   \nIf \\(b&gt;0\\),\n\\[P(X &gt; a +b | X&gt; a) = P(X &gt; b)\\]\n     \n\nThis can be interpreted as:\n\nIf you have waited \\(a\\) seconds (or any other measure of time) without a success\nThen the probability that you have to wait \\(b\\) more seconds is the same as as the probability of waiting \\(b\\) seconds initially."
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#identifying-exponential-rv-from-word-problems",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#identifying-exponential-rv-from-word-problems",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Identifying exponential RV from word problems",
    "text": "Identifying exponential RV from word problems\n\nLook for time between events/successes\nLook for a rate of the events over time period\nHow does it differ from the geometric distribution?\n\nGeometric is number of trials until first success\nExponential is time until first success\n\nRelation to the Poisson distribution?\n\nWhen the time between arrivals is exponential, the number of arrivals in a fixed time interval is Poisson with the mean \\(\\lambda\\)"
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-1",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-1",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re sitting at the bus stop, measuring the time until our bus arrives. We know the bus comes every 10 minutes on average.\n\nIf we want to know the probability that the bus arrives in the next 5 minutes:\n\npexp(q = 5, rate = 1/10)\n\n[1] 0.3934693\n\n\nIf we want to know the time, say \\(t\\), where the probability of the bus arriving at \\(t\\) or earlier is 0.35:\n\nqexp(p = 0.35, rate = 1/10)\n\n[1] 4.307829\n\n\nIf we want to know the probability that the bus arrives between 3 and 5 minutes:\n\npexp(q = 5, rate = 1/10) - pexp(q = 3, rate = 1/10)\n\n[1] 0.1342876\n\n\nIf we want to sample 20 bus arrival times from the distribution:\n\nrexp(n = 20, rate = 1/10)\n\n [1]  2.6536492  9.9241230  9.8590037 16.7313808  1.7358231  9.5964185\n [7]  1.3491135  2.2182230  9.6290820  0.6212311 53.4122497  4.6816007\n[13] 14.0487481  7.0381356  7.5556238  6.3182355  3.5183107 27.6916935\n[19]  0.4412962 28.0393721"
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#transformation-of-independent-exponential-rvs",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#transformation-of-independent-exponential-rvs",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Transformation of independent exponential RVs",
    "text": "Transformation of independent exponential RVs\n\n\nRevisit after joint notes:\n\n\nExample 1\n\n\nLet \\(X_i \\sim \\textrm{Exp}(\\lambda_i)\\) be independent RVs, for \\(i=1 \\ldots n\\). Find the pdf for the first of the arrival times."
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#properties-of-gamma-rvs",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#properties-of-gamma-rvs",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Properties of gamma RVs",
    "text": "Properties of gamma RVs\n\nScenario: Modeling the time until the \\(r^{th}\\) event.\nContinuous analog to the Negative Binomial distribution\nShorthand: \\(X \\sim \\text{Gamma}(r, \\lambda)\\)\n\n\\[\nf_X(x) = \\dfrac{\\lambda^r}{\\Gamma(r)}x^{r-1} e^{-\\lambda x}\\text{ for } x&gt;0, \\lambda&gt;0, \\Gamma(r) = (r-1)!\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;0 \\quad \\\\\n            1 - e^{-\\lambda x}\\displaystyle\\sum_{j=0}^{r-1}\\dfrac{(\\lambda x)^j}{j!}  & \\quad x\\geq0 \\\\\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{r}{\\lambda}\\text{, }\\text{ Var}(X) = \\dfrac{r}{\\lambda^2}\\]\nCommon to see \\(\\alpha = r\\) and \\(\\beta = \\lambda\\)"
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#identifying-gamma-rv-from-word-problems",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#identifying-gamma-rv-from-word-problems",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Identifying gamma RV from word problems",
    "text": "Identifying gamma RV from word problems\n\nGamma distribution with \\(r=1\\) is same as exponential\n\nJust like Negative Binomial with \\(r=1\\) is same as the geometric distribution\n\nSimilar to exponential\n\nLook for time between or until events/successes\n\nBUT now we are measuring time until more than 1 success\n\nLook for a rate of the events over time period"
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-2",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-2",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re sitting at the bus stop, measuring the time until 4 buses arrive. We know the bus comes every 10 minutes on average.\n\nIf we want to know the probability that the 4 buses arrive in the next 50 minutes:\n\n\n\n\npgamma(q = 50, rate = 1/10, shape = 4)\n\n[1] 0.7349741\n\n\n\n\npgamma(q = 50, scale = 10, shape = 4)\n\n[1] 0.7349741\n\n\n\n\n\nIf we want to know the time, say \\(t\\), where the probability of the 4 buses arriving at \\(t\\) or earlier is 0.35:\n\nqgamma(p = 0.35, rate = 1/10, shape = 4)\n\n[1] 29.87645\n\n\nIf we want to know the probability that the 4 buses arrives between 30 and 50 minutes:\n\npgamma(q = 50, scale = 10, shape = 4) - pgamma(q = 30, scale = 10, shape = 4)\n\n[1] 0.382206\n\n\nIf we want to sample 20 arrival times for the 4 buses:\n\nrgamma(n = 20, scale = 10, shape = 4)\n\n [1]  43.334506  11.669883 107.085600  68.256312   6.594443  40.773304\n [7]  20.604468  39.343215  22.625283  44.203254  30.295759  42.049533\n[13]  28.457668  47.731174  46.818598  60.548348  45.123801  36.140067\n[19]  37.573537  31.463989"
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#remarks",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#remarks",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Remarks",
    "text": "Remarks\n\nThe parameter \\(r\\) in a Gamma(\\(r\\),\\(\\lambda\\)) distribution does NOT need to be a positive integer\n\n\\(r\\) is usually a positive integer\n\nWhen \\(r\\) is a positive integer, the distribution is sometimes called an Erlang(\\(r\\),\\(\\lambda\\)) distribution\n \n \nWhen \\(r\\) is any positive real number, we have a general gamma distribution that is usually instead parameterized by \\(\\alpha&gt;0\\) and \\(\\beta&gt;0\\), where:\n\n\\(\\alpha = \\text{shape parameter}\\) : same as \\(k\\), the total number of events we must witness\n\nIn R code example: 4 buses to wait for\n\n\\(\\beta = \\text{scale parameter}\\) : same as \\(\\lambda\\), the rate parameter\n\nIn R code example: 1 bus per 10 minutes (1/10)"
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#sending-money-orders",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#sending-money-orders",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Sending money orders",
    "text": "Sending money orders\n\n\n\n\nExample 1\n\n\nOn average, someone sends a money order once per 15 minutes. What is the probability someone sends 10 money orders in less than 3 hours?"
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#additional-resource",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#additional-resource",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Additional Resource",
    "text": "Additional Resource\n\nAnother helpful site with R code: https://rpubs.com/mpfoley73/459051"
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#properties-of-normal-rvs",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#properties-of-normal-rvs",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Properties of Normal RVs",
    "text": "Properties of Normal RVs\n\nNo scenario description here because the Normal distribution is so universal\n\nCentral Limit Theorem (next class) makes it applicable to many types of events\n\nShorthand: \\(X \\sim \\text{Normal}(\\mu, \\sigma^2)\\)\n\n\\[\nf_X(x) = \\dfrac{1}{\\sqrt{2\\pi \\sigma^2}}e^{-(x-\\mu)^2/(2\\sigma^2)} \\text{, for} -inf &lt; x &lt; inf\n\\]\n\\[\\text{E}(X) = \\mu \\] \\[\\text{Var}(X) = \\sigma^2\\]"
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-3",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-3",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re measuring the high temperature today. The average high temperature on this day across many, many years is 50 degrees with a standard deviation of 4 degrees.\n\nIf we want to know the probability that the high temperature is below 45 degrees:\n\npnorm(q = 45, mean = 50, sd = 4)\n\n[1] 0.1056498\n\n\nIf we want to know the temoerature, say \\(t\\), where the probability of that the temperature is at \\(t\\) or lower is 0.35:\n\nqnorm(p = 0.35, mean = 50, sd = 4)\n\n[1] 48.45872\n\n\nIf we want to know the probability that the temperature is between 45 and 50 degrees:\n\npnorm(q = 50, mean = 50, sd = 4) - pnorm(q = 45, mean = 50, sd = 4)\n\n[1] 0.3943502\n\n\nIf we want to sample 20 days’ temperature (over the years) from the distribution:\n\nrnorm(n = 20, mean = 50, sd = 4)\n\n [1] 58.19334 48.69453 48.01503 46.60855 42.96407 50.10835 49.07470 50.74432\n [9] 43.80155 47.44748 50.30352 53.64828 47.59478 50.79763 52.01850 52.46709\n[17] 51.06833 46.64400 60.99100 55.08259"
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#movie-night-while-studying",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#movie-night-while-studying",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Movie night while studying",
    "text": "Movie night while studying\n\n\n\n\nExample 1\n\n\nChildren’s movies run an average of 98 minutes with a standard deviation of 10 minutes. You check out a random movie from the library to entertain your kids so you can study for your test. Assume that your kids will be occupied for the entire length of the movie.\n\nWhat is the probability that your kids will be occupied for at least the 2 hours you would like to study?\nWhat is range for the bottom quartile (lowest 25%) of time they will be occupied?"
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#standard-normal-distribution",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs.html#standard-normal-distribution",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Standard Normal Distribution",
    "text": "Standard Normal Distribution\n\\[ Z \\sim \\text{Normal}(\\mu = 0, \\sigma^2 = 1)\\]\n\nUsed to be more helpful when computing was not as advanced\n\nUse tables of the standard normal\nYou can convert any normal distribution to a standard normal through transformation\n\n\\(Z = \\dfrac{X - \\mu_X}{\\sigma_X}\\)\n\nComes from \\(X = \\sigma_X Z + \\mu_X\\)\nSince \\(\\sigma_X\\) and \\(\\mu_X\\) are constants, then \\(E(X) = \\mu_X\\) and \\(SD(X) = \\sigma_X SD(Z) = \\sigma_X\\)\n\n\n\n\nChapter 31-35 Slides"
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs_key_info.html",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 videos should be in!\n\nSome presentations today\n\nNeed to grade HW 4 solutions and HW 5 assignment STILL\n\nHappy to be flexible on the HW 5 solutions deadline\n\nAnything else?"
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs_key_info.html#announcements",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 videos should be in!\n\nSome presentations today\n\nNeed to grade HW 4 solutions and HW 5 assignment STILL\n\nHappy to be flexible on the HW 5 solutions deadline\n\nAnything else?"
  },
  {
    "objectID": "lessons/31_35_Cont_RVs/31_35_Cont_RVs_key_info.html#key-dates",
    "href": "lessons/31_35_Cont_RVs/31_35_Cont_RVs_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 6 due\nSunday: HW 5 solutions due\n\nFLEXIBLE"
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities_key_info.html",
    "href": "lessons/25_Joint_densities/25_Joint_densities_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 6 assignment today!\n\nFeel free to turn in solutions later than 11/24 since I took so long to grade\n\nI made quite a few changes to the homeworks\n\nHW 10 is gone\nHW 9 is optional\nInstead of a HW assignment due over late November break\n\nHW 8 will include material from Week 8 and 9 and be due 12/5\n\n\nI have quite a bit of grading to catch up on!\nRealizing I never gave you mid-quarter feedback forms…\n\nLet’s chat about this and our assessment breakdown in the coming weeks\n\nAnything else?"
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities_key_info.html#announcements",
    "href": "lessons/25_Joint_densities/25_Joint_densities_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 6 assignment today!\n\nFeel free to turn in solutions later than 11/24 since I took so long to grade\n\nI made quite a few changes to the homeworks\n\nHW 10 is gone\nHW 9 is optional\nInstead of a HW assignment due over late November break\n\nHW 8 will include material from Week 8 and 9 and be due 12/5\n\n\nI have quite a bit of grading to catch up on!\nRealizing I never gave you mid-quarter feedback forms…\n\nLet’s chat about this and our assessment breakdown in the coming weeks\n\nAnything else?"
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities_key_info.html#key-dates",
    "href": "lessons/25_Joint_densities/25_Joint_densities_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 7 due\nSunday: HW 6 solutions due"
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "href": "lessons/25_Joint_densities/25_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "title": "Chapter 25: Joint densities",
    "section": "Finding the pdf of a transformation",
    "text": "Finding the pdf of a transformation\n\nLet \\(M\\) be a transformation of \\(X\\) and \\(Y\\)\nWhen we have a transformation of \\(X\\) and \\(Y\\), \\(M\\), we need to follow a specific process to find the pdf of \\(M\\)\n\nWe follow this process:\n\nStart with the joint pdf for \\(X\\) and \\(Y\\)\n\naka \\(f_{X,Y}(x, y)\\)\n\nTranslate the domain of \\(X\\) and \\(Y\\) to \\(M\\)\nFind the CDF of \\(M\\)\n\naka \\(F_M(m)\\) or \\(P(M \\leq m)\\)\n\nTake the derivative of the CDF of \\(M\\) to find the pdf of \\(M\\)\n\naka \\(f_M(m) = \\dfrac{d}{dm}F_M(m)\\)"
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities.html#common-steps-for-solving-problems",
    "href": "lessons/25_Joint_densities/25_Joint_densities.html#common-steps-for-solving-problems",
    "title": "Chapter 25: Joint densities",
    "section": "Common steps for solving problems",
    "text": "Common steps for solving problems\n\nSet up the domain of the pdf with a picture\nTranslate to needed integrands\n\nFor probability: shade in the area of interest, then translate\nFor expected value: translate domain\n\nSet up integral: \\(dxdy\\) or \\(dydx\\)?\nSolve integral!"
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities_muddy points.html",
    "href": "lessons/25_Joint_densities/25_Joint_densities_muddy points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n1. How do pdf, CDF, and probability interact with each other?\nLet’s say we have a pdf, \\(f_X(x) = \\dfrac{1}{9}x^2\\) for \\(0 \\leq x \\leq 3\\). This is just a function. The pdf is not used on its own to report any probability. We must integrate over the pdf to find a probability.\n\nlibrary(\"ggplot2\")\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3)\n\n\n\n\nThe total area under the pdf is 1. This makes our pdf valid.\n\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 3),\n                geom = \"area\", \n                aes(fill = \"red\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 1\", color = \"black\")\n\n\n\n\nIf we only look at a proportion of the area under the pdf, then we start constructing our probabilities. For example, we can look at probability that we have a value between 0 and 1.5.\n\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 1.5),\n                geom = \"area\", \n                aes(fill = \"blue\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 0.125\", color = \"black\")\n\n\n\n\nInstead of calculating the EXACT probability for each value between 0 and 3, we can find the CDF of the pdf.\nThe CDF is: \\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;3 \\quad \\\\\n            \\dfrac{1}{27}x^3 & \\quad 0 \\leq x \\leq 3\\quad \\\\\n            1 & \\quad x&gt;3 \\quad\n        \\end{array}\n    \\right.\n\\]\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\")\n\n\n\n\nWhen \\(x=1.5\\), we can calculate the probability using the CDF. Remember that \\(F_X(x) = P(X \\leq x)\\). So we can say \\(P(X \\leq 1.5) = F_X(1.5) = \\dfrac{1}{27}(1.5)^3\\), which equals 0.125.\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\") +\n  geom_point(aes(x=1.5, y=.125), colour=\"blue\", size=3) +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"CDF = 0.125\", color = \"black\")\n\nWarning in geom_point(aes(x = 1.5, y = 0.125), colour = \"blue\", size = 3): All aesthetics have length 1, but the data has 2 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\nWe can also calculate the probability with an integral: \\(P(X \\leq 1.5) = \\displaystyle\\int_0^{1.5} \\dfrac{1}{9}x^2 dx\\).\nWe can also find the probability that X is between two numbers. \\(P(1\\leq X \\leq 1.5) = F_X(1.5) - F_X(1)\\) or \\(P(1\\leq X \\leq 1.5) = \\displaystyle\\int_1^{1.5} \\dfrac{1}{9}x^2 dx\\).\n\n\n2. Joint vs marginal vs conditional: How are we calculating the probability?\nIf we start at a joint probability \\(f_{X,Y}(x,y)\\)…. we can look at a few probabilities:\n\nJoint probability: \\(P(a \\leq X \\leq b, c \\leq Y \\leq d)\\)\n\\[P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=c}^{y=d} f_{X,Y}(x,y) dydx\\]\nMarginal probability: \\(P(a \\leq X \\leq b)\\)\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b} f_{X}(x) dx\\]\nOR\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=-\\inf}^{y=\\inf} f_{X,Y}(x,y) dydx\\]\nConditional probability: \\(P(a \\leq X \\leq b | Y = c)\\)\n\\[P(a \\leq X \\leq b | Y=c) = \\displaystyle\\int_{x=a}^{x=b} f_{X|Y}(x|y=c) dx\\]\nYou cannot calculate \\(P(a \\leq X \\leq b | Y = c)\\) by \\(\\dfrac{P(a \\leq X \\leq b, Y=c)}{P(Y = c)}\\) because \\(P(Y = c)\\) is 0. Instead, we need to find \\(f_{X|Y}(x|y=c)\\) by \\(\\dfrac{f_{X,Y}(x,y=c)}{f_{Y}(y=c)}\\) and THEN integrate over X.\n\n\n\n3. What are we actually finding by solving the double integral. In the first example, we found the probability was 1/16 after integrating but what does 1/16 mean in relation to the random variables X and Y?\nIt means that the volume contained by \\(0\\leq X \\leq 1\\), \\(0\\leq Y \\leq 1/2\\), and their joint pdf is 1/16 of the total volume contained by \\(0\\leq X \\leq 2\\), \\(0\\leq Y \\leq 1\\), and their joint pdf. The probability for a joint pdf is now a measure of the proportion of the volume.\nThis is not be confused with a probability from marginal pdf or pdf from one RV. The probability for marginal/single RV pdfs is the proportion of the area under the pdf for a specific range of values.\n\n\n4. Here’s a 3D plot of one of our joint pdf’s\n\\[\nf_{X,Y}(x,y) = 5e^{-x-3y} \\text{ for } 0 \\leq y \\leq x/2\n\\]\n\nlibrary(plotly)\n\nx = seq(0, 5, 0.1)\ny = seq(0, max(x)/2, 0.1/2)\nfn = expand.grid(x=x,y=y)\nfn$z = ifelse(fn$y&lt;fn$x/2, 5*exp( (-1)*fn$x - 3*fn$y), NA)\n\nz = matrix(fn$z, ncol = 51, nrow = 51, byrow = T)\n\nfig &lt;- plot_ly(x = x, y=y, z=z) %&gt;% add_surface()\n\nfig"
  },
  {
    "objectID": "lessons/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try-12",
    "href": "lessons/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try-12",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf: second try! (1/2)",
    "text": "Example starting from a joint pdf: second try! (1/2)\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(2&lt;X&lt;10|Y=4)\\)"
  },
  {
    "objectID": "lessons/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try-22",
    "href": "lessons/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try-22",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf: second try! (2/2)",
    "text": "Example starting from a joint pdf: second try! (2/2)"
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rv.html#finding-cdf-from-two-independent-rvs",
    "href": "lessons/26_Independent_rvs/26_Independent_rv.html#finding-cdf-from-two-independent-rvs",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Finding CDF from two independent RVs",
    "text": "Finding CDF from two independent RVs\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for \\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(F_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rv_key_info.html",
    "href": "lessons/26_Independent_rvs/26_Independent_rv_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 presentations are graded! You did great!\nHW 7 assignment: I’ll grade tonight!\nAnything else?"
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rv_key_info.html#announcements",
    "href": "lessons/26_Independent_rvs/26_Independent_rv_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 presentations are graded! You did great!\nHW 7 assignment: I’ll grade tonight!\nAnything else?"
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rv_key_info.html#key-dates",
    "href": "lessons/26_Independent_rvs/26_Independent_rv_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 7 due\nSunday: HW 7 solutions due (feel free to take an additional 3 days)"
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rvs_key_info.html",
    "href": "lessons/26_Independent_rvs/26_Independent_rvs_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 presentations are graded! You did great!\nHW 7 assignment: I’ll grade tonight!\nAnything else?"
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rvs_key_info.html#announcements",
    "href": "lessons/26_Independent_rvs/26_Independent_rvs_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 presentations are graded! You did great!\nHW 7 assignment: I’ll grade tonight!\nAnything else?"
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rvs_key_info.html#key-dates",
    "href": "lessons/26_Independent_rvs/26_Independent_rvs_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: NONE due\nSunday: HW 7 solutions due (feel free to take an additional 3 days)"
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rvs.html#learning-objectives",
    "href": "lessons/26_Independent_rvs/26_Independent_rvs.html#learning-objectives",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nShow that a joint pdf consists of two independent, continuous RVs.\nCombine two independent RVs into one joint pdf or CDF."
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rvs.html#how-do-we-represent-independent-continuous-rvs-in-a-joint-pdf",
    "href": "lessons/26_Independent_rvs/26_Independent_rvs.html#how-do-we-represent-independent-continuous-rvs-in-a-joint-pdf",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "How do we represent independent continuous RVs in a joint pdf?",
    "text": "How do we represent independent continuous RVs in a joint pdf?\n\n\nWhat do we know about independence for events and discrete RVs?\nFor events: If \\(A \\perp B\\)\n\\[P(A \\cap B) = P(A)P(B)\\] \\[P(A|B) = P(A)\\]\nFor discrete RVs: If \\(X \\perp Y\\) \\[p_{X,Y}(x,y) = p_{X}(x)p_{Y}(y)\\] \\[F_{X,Y}(x,y) = F_{X}(x)F_{Y}(y)\\] \\[p_{X|Y}(x|y) = p_{X}(x)\\] \\[p_{Y|X}(y|x) = p_{Y}(y)\\]\n\n\n\nWhat does it mean for continuous r.v.’s to be independent?\nFor continuous RVs: If \\(X \\perp Y\\)"
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rvs.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs",
    "href": "lessons/26_Independent_rvs/26_Independent_rvs.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Constructing a joint pdf from two independent, continuous RVs",
    "text": "Constructing a joint pdf from two independent, continuous RVs\n\n\n\n\nExample 1.1\n\n\nLet \\(X\\) and \\(Y\\) be independent r.v.’s with \\(f_X(x)= \\frac12\\), for \\(0 \\leq x \\leq 2\\) and \\(f_Y(y)= 3y^2\\), for \\(0 \\leq y \\leq 1\\).\n\nFind \\(f_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rvs.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs-1",
    "href": "lessons/26_Independent_rvs/26_Independent_rvs.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs-1",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Constructing a joint pdf from two independent, continuous RVs",
    "text": "Constructing a joint pdf from two independent, continuous RVs\n\n\n\n\nExample 1.2\n\n\nLet \\(X\\) and \\(Y\\) be independent r.v.’s with \\(f_X(x)= \\frac12\\), for \\(0 \\leq x \\leq 2\\) and \\(f_Y(y)= 3y^2\\), for \\(0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)."
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rvs.html#showing-independence-from-joint-pdf",
    "href": "lessons/26_Independent_rvs/26_Independent_rvs.html#showing-independence-from-joint-pdf",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Showing independence from joint pdf",
    "text": "Showing independence from joint pdf\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for \\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\).\n\nAre \\(X\\) and \\(Y\\) independent?"
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rvs.html#finding-cdf-from-two-independent-rvs",
    "href": "lessons/26_Independent_rvs/26_Independent_rvs.html#finding-cdf-from-two-independent-rvs",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Finding CDF from two independent RVs",
    "text": "Finding CDF from two independent RVs\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for \\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(F_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rvs.html#showing-independence-from-joint-pdf-1",
    "href": "lessons/26_Independent_rvs/26_Independent_rvs.html#showing-independence-from-joint-pdf-1",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Showing independence from joint pdf",
    "text": "Showing independence from joint pdf\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 3\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Are \\(X\\) and \\(Y\\) independent?"
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rvs.html#final-statement-on-independence",
    "href": "lessons/26_Independent_rvs/26_Independent_rvs.html#final-statement-on-independence",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Final statement on independence",
    "text": "Final statement on independence\n\nIf \\(f_{X,Y}(x,y)= g(x)h(y)\\), where \\(g(x)\\) and \\(h(y)\\) are pdf’s, then \\(X\\) and \\(Y\\) are independent.\n\nThe domain of the joint pdf needs to be independent as well!!\n\n\n       \n\nIf \\(F_{X,Y}(x,y)= G(x)H(y)\\), where \\(G(x)\\) and \\(H(y)\\) are cdf’s, then \\(X\\) and \\(Y\\) are independent.\n\nThe domain of the joint CDF needs to be independent as well!!\n\n\n\n\nChapter 26 Slides"
  },
  {
    "objectID": "lessons/25_Joint_densities/25_Joint_densities_muddy_points.html",
    "href": "lessons/25_Joint_densities/25_Joint_densities_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n1. How do pdf, CDF, and probability interact with each other?\nLet’s say we have a pdf, \\(f_X(x) = \\dfrac{1}{9}x^2\\) for \\(0 \\leq x \\leq 3\\). This is just a function. The pdf is not used on its own to report any probability. We must integrate over the pdf to find a probability.\n\nlibrary(\"ggplot2\")\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3)\n\n\n\n\nThe total area under the pdf is 1. This makes our pdf valid.\n\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 3),\n                geom = \"area\", \n                aes(fill = \"red\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 1\", color = \"black\")\n\n\n\n\nIf we only look at a proportion of the area under the pdf, then we start constructing our probabilities. For example, we can look at probability that we have a value between 0 and 1.5.\n\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 1.5),\n                geom = \"area\", \n                aes(fill = \"blue\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 0.125\", color = \"black\")\n\n\n\n\nInstead of calculating the EXACT probability for each value between 0 and 3, we can find the CDF of the pdf.\nThe CDF is: \\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;3 \\quad \\\\\n            \\dfrac{1}{27}x^3 & \\quad 0 \\leq x \\leq 3\\quad \\\\\n            1 & \\quad x&gt;3 \\quad\n        \\end{array}\n    \\right.\n\\]\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\")\n\n\n\n\nWhen \\(x=1.5\\), we can calculate the probability using the CDF. Remember that \\(F_X(x) = P(X \\leq x)\\). So we can say \\(P(X \\leq 1.5) = F_X(1.5) = \\dfrac{1}{27}(1.5)^3\\), which equals 0.125.\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\") +\n  geom_point(aes(x=1.5, y=.125), colour=\"blue\", size=3) +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"CDF = 0.125\", color = \"black\")\n\nWarning in geom_point(aes(x = 1.5, y = 0.125), colour = \"blue\", size = 3): All aesthetics have length 1, but the data has 2 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\nWe can also calculate the probability with an integral: \\(P(X \\leq 1.5) = \\displaystyle\\int_0^{1.5} \\dfrac{1}{9}x^2 dx\\).\nWe can also find the probability that X is between two numbers. \\(P(1\\leq X \\leq 1.5) = F_X(1.5) - F_X(1)\\) or \\(P(1\\leq X \\leq 1.5) = \\displaystyle\\int_1^{1.5} \\dfrac{1}{9}x^2 dx\\).\n\n\n2. Joint vs marginal vs conditional: How are we calculating the probability?\nIf we start at a joint probability \\(f_{X,Y}(x,y)\\)…. we can look at a few probabilities:\n\nJoint probability: \\(P(a \\leq X \\leq b, c \\leq Y \\leq d)\\)\n\\[P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=c}^{y=d} f_{X,Y}(x,y) dydx\\]\nMarginal probability: \\(P(a \\leq X \\leq b)\\)\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b} f_{X}(x) dx\\]\nOR\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=-\\inf}^{y=\\inf} f_{X,Y}(x,y) dydx\\]\nConditional probability: \\(P(a \\leq X \\leq b | Y = c)\\)\n\\[P(a \\leq X \\leq b | Y=c) = \\displaystyle\\int_{x=a}^{x=b} f_{X|Y}(x|y=c) dx\\]\nYou cannot calculate \\(P(a \\leq X \\leq b | Y = c)\\) by \\(\\dfrac{P(a \\leq X \\leq b, Y=c)}{P(Y = c)}\\) because \\(P(Y = c)\\) is 0. Instead, we need to find \\(f_{X|Y}(x|y=c)\\) by \\(\\dfrac{f_{X,Y}(x,y=c)}{f_{Y}(y=c)}\\) and THEN integrate over X.\n\n\n\n3. What are we actually finding by solving the double integral. In the first example, we found the probability was 1/16 after integrating but what does 1/16 mean in relation to the random variables X and Y?\nIt means that the volume contained by \\(0\\leq X \\leq 1\\), \\(0\\leq Y \\leq 1/2\\), and their joint pdf is 1/16 of the total volume contained by \\(0\\leq X \\leq 2\\), \\(0\\leq Y \\leq 1\\), and their joint pdf. The probability for a joint pdf is now a measure of the proportion of the volume.\nThis is not be confused with a probability from marginal pdf or pdf from one RV. The probability for marginal/single RV pdfs is the proportion of the area under the pdf for a specific range of values.\n\n\n4. Here’s a 3D plot of one of our joint pdf’s\n\\[\nf_{X,Y}(x,y) = 5e^{-x-3y} \\text{ for } 0 \\leq y \\leq x/2\n\\]\n\nlibrary(plotly)\n\nx = seq(0, 5, 0.1)\ny = seq(0, max(x)/2, 0.1/2)\nfn = expand.grid(x=x,y=y)\nfn$z = ifelse(fn$y&lt;fn$x/2, 5*exp( (-1)*fn$x - 3*fn$y), NA)\n\nz = matrix(fn$z, ncol = 51, nrow = 51, byrow = T)\n\nfig &lt;- plot_ly(x = x, y=y, z=z) %&gt;% add_surface()\n\nfig"
  },
  {
    "objectID": "lessons/26_Independent_rvs/26_Independent_rvs_muddy_points.html",
    "href": "lessons/26_Independent_rvs/26_Independent_rvs_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n2. Joint vs marginal vs conditional: How are we calculating the probability?\nIf we start at a joint probability \\(f_{X,Y}(x,y)\\)…. we can look at a few probabilities:\n\nJoint probability: \\(P(a \\leq X \\leq b, c \\leq Y \\leq d)\\)\n\\[P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=c}^{y=d} f_{X,Y}(x,y) dydx\\]\nMarginal probability: \\(P(a \\leq X \\leq b)\\)\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b} f_{X}(x) dx\\]\nOR\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=-\\inf}^{y=\\inf} f_{X,Y}(x,y) dydx\\]\nConditional probability: \\(P(a \\leq X \\leq b | Y = c)\\)\n\\[P(a \\leq X \\leq b | Y=c) = \\displaystyle\\int_{x=a}^{x=b} f_{X|Y}(x|y=c) dx\\]\nYou cannot calculate \\(P(a \\leq X \\leq b | Y = c)\\) by \\(\\dfrac{P(a \\leq X \\leq b, Y=c)}{P(Y = c)}\\) because \\(P(Y = c)\\) is 0. Instead, we need to find \\(f_{X|Y}(x|y=c)\\) by \\(\\dfrac{f_{X,Y}(x,y=c)}{f_{Y}(y=c)}\\) and THEN integrate over X.\n\n\n\n4. Here’s a 3D plot of one of our joint pdf’s\n\\[\nf_{X,Y}(x,y) = 5e^{-x-3y} \\text{ for } 0 \\leq y \\leq x/2\n\\]\n\nlibrary(plotly)\n\nx = seq(0, 5, 0.1)\ny = seq(0, max(x)/2, 0.1/2)\nfn = expand.grid(x=x,y=y)\nfn$z = ifelse(fn$y&lt;fn$x/2, 5*exp( (-1)*fn$x - 3*fn$y), NA)\n\nz = matrix(fn$z, ncol = 51, nrow = 51, byrow = T)\n\nfig &lt;- plot_ly(x = x, y=y, z=z) %&gt;% add_surface()\n\nfig"
  },
  {
    "objectID": "lessons/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance_muddy_points.html",
    "href": "lessons/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n2. How do we set the bounds on a double integral?\nWhen the domain of the RVs are not dependent on each other, then we use the bounds as is. In example 2 of Chapter 26 notes, we have the joint pdf \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for\\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\). If we wanted to calculate something like \\(E(X)\\), then we could use the bounds as they are. Below is the domain for \\(x\\) and \\(y\\):\n\n\n\n\n\nHere is the integral for the expected value where we integrate over the whole domain of \\(x\\) and \\(y\\):\n\\[ E(X) = \\displaystyle\\int_0^1 \\displaystyle\\int_0^1 x (18 x^2 y^5 )dy dx \\]If we want to find the probability \\(P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75)\\), then we can look at the specific values of the probability:\n\n\n\n\n\nNote the blue lines above indicate how we integrate over \\(y\\) first from 0.5 to 0.75 and the green lines indicate how integrate over \\(x\\) first from 0.25 to 0.5. It seems like we’ve integrated over an area that isn’t within our specified probability. However, the integrated area is ONLY the overlap of the \\(x\\) and \\(y\\) bounds for the probability.\n\\[P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.25}^{0.5} \\displaystyle\\int_{0.5}^{0.75} 18 x^2 y^5 dy dx\\]\nLet’s use the same pdf, but now the domain of the two RVs is dependent on one another. We have the joint pdf \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for\\(0 \\leq x \\leq y\\leq1\\)\nIf we wanted to calculate something like \\(E(X)\\), then we need to account for fact that \\(x\\) must be less than of equal to \\(y\\). We can look back at the domain for this:\n\n\n\n\n\nNote the blue lines above still indicate how we integrate over \\(y\\) first from \\(x\\) to 1, and the green lines indicate how integrate over \\(x\\) first from 0 to 1. Once again, it seems like we’ve integrated over an area that isn’t within the domain. However, the integrated area is ONLY the overlap of the \\(x\\) and \\(y\\) bounds. Thus, once we’ve restricted \\(y\\) to the area between \\(x\\) and 1, we no longer need to restrict \\(x\\) to the are of 0 to \\(y\\).\n\\[ E(X) = \\displaystyle\\int_0^1 \\displaystyle\\int_x^1 x (18 x^2 y^5 )dy dx \\] If we want to find the probability \\(P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75)\\), then we should look back at our domain. For now, we are focusing on the orange area:\n\n\n\n\n\nBecause the orange area is totally within our domain, we can leave our integral our bounds as the exact values we specified:\n\\[P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.25}^{0.5} \\displaystyle\\int_{0.5}^{0.75} 18 x^2 y^5 dy dx\\]\nHowever, if we want the probability \\(P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75)\\), we would focus on the pink area above. We would limit one of our integrals to the \\(y=x\\) equation:\n\\[P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.5}^{0.75} \\displaystyle\\int_{x}^{0.75} 18 x^2 y^5 dy dx\\]\nOR\n\\[P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.5}^{0.75} \\displaystyle\\int_{0.5}^{y} 18 x^2 y^5 dx dy\\]\nThe key to these probabilities is that the bounds with the other variable is on the inside integral! Otherwise we end up with a answer that includes a RV."
  },
  {
    "objectID": "schedule.html#footnotes",
    "href": "schedule.html#footnotes",
    "title": "Schedule",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHere’s a link to Meike’s recordings for certain problems that I said to do at home.↩︎\nHere’s a link to Meike’s recordings for certain problems that I said to do at home.↩︎\nHere’s a link to Meike’s recordings for certain problems that I said to do at home.↩︎\nHere’s a link to Meike’s recordings for certain problems that I said to do at home.↩︎"
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#learning-objectives",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#learning-objectives",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nLearn the definition of a moment-generating function.\nFind the moment-generating function of a binomial random variable.\nUse a moment-generating function to find the mean and variance of a random variable."
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#what-are-moments",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#what-are-moments",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "What are moments?",
    "text": "What are moments?\n\n\nDefinition 1\n\n\nThe \\(j^{th}\\) moment of a r.v. \\(X\\) is \\(\\mathbb{E}[X^j]\\)\n\n\n\n\nExample 1\n\n\n\\(1^{st}-4^{th}\\) moments"
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#example-1",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#example-1",
    "title": "Chapter 43: Moment Generating Functions Part 1",
    "section": "Example",
    "text": "Example\n\n\n\n\nExample 10\n\n\nLet \\(Z\\) be a standard normal random variable, i.e. \\(Z \\sim N(0,1)\\).\n\nFind the mgf of \\(Z\\)\nFind \\(\\mathbb{E}[Z]\\)\nFind \\(Var(Z)\\)\n\n\n\n\n\n\n\nChapter 43 Slides"
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#what-is-an-mgf",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#what-is-an-mgf",
    "title": "Chapter 43: Moment Generating Functions Part 1",
    "section": "What is an MGF?",
    "text": "What is an MGF?\n\nWhat is a moment generating function (mgf)?\n\n\nDefinition 3.   If \\(X\\) is a r.v., then \\[M_X(t)= \\mathbb{E}[e^{tX}]\\] is the moment generating function (mgf) associated with \\(X\\).\n\nRemarks\n\nFor a discrete r.v., the mgf of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\sum_{all \\ x}e^{tx}p_X(x)\\]\nFor a continuous r.v., the mgf of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\int_{-\\infty}^{\\infty}e^{tx}f_X(x)dx\\]\nThe mgf \\(M_X(t)\\) is a function of \\(t\\), not of \\(X\\), and it might not be defined (i.e. finite) for all values of \\(t\\). We just need it to be defined for \\(t=0\\)."
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#example",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#example",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Example",
    "text": "Example\n\n\n\n\nExample 4\n\n\nWhat is \\(M_X(t)\\) for \\(t=0\\)?"
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#theorem",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#theorem",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Theorem",
    "text": "Theorem\n\n\nTheorem 5\n\n\nThe moment generating function uniquely specifies a probability distribution.\n\n\n\n\nTheorem 6\n\n\n\\[\\mathbb{E}[X^r] = M_X^{(r)}(0)\\]\n\\((r)\\) in this equation is the \\(r\\)th derivative with respect to \\(t\\)\n\n\n\nWhen \\(r=1\\), we are taking the first derivative\nWhen \\(r=4\\), we are taking the fourth derivative"
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#example-2",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#example-2",
    "title": "Chapter 43: Moment Generating Functions Part 1",
    "section": "Example",
    "text": "Example\n\n\n\n\nExample 10\n\n\nLet \\(Z\\) be a standard normal random variable, i.e. \\(Z \\sim N(0,1)\\).\n\nFind the mgf of \\(Z\\)\nFind \\(\\mathbb{E}[Z]\\)\nFind \\(Var(Z)\\)\n\n\n\n\n\n\n\nChapter 43 Slides"
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#theorem-1",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#theorem-1",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Theorem",
    "text": "Theorem\nRemark: Finding the mean and variance is sometimes easier with the following trick\n\n\nTheorem 8\n\n\nLet \\(R_X(t) = \\ln[M_X(t)]\\). Then,\n\\[\\mu = \\mathbb{E}[X] = R_X'(0) \\text{, and}\\] \\[\\sigma^2 = Var(X) = R_X''(0)\\]\n\n\n\nProof."
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#example-3",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#example-3",
    "title": "Chapter 43: Moment Generating Functions Part 1",
    "section": "Example",
    "text": "Example\n\n\n\n\nExample 10\n\n\nLet \\(Z\\) be a standard normal random variable, i.e. \\(Z \\sim N(0,1)\\).\n\nFind the mgf of \\(Z\\)\nFind \\(\\mathbb{E}[Z]\\)\nFind \\(Var(Z)\\)\n\n\n\n\n\n\n\nChapter 43 Slides"
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#example-4",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#example-4",
    "title": "Chapter 43: Moment Generating Functions Part 1",
    "section": "Example",
    "text": "Example\n\n\n\n\nExample 10\n\n\nLet \\(Z\\) be a standard normal random variable, i.e. \\(Z \\sim N(0,1)\\).\n\nFind the mgf of \\(Z\\)\nFind \\(\\mathbb{E}[Z]\\)\nFind \\(Var(Z)\\)\n\n\n\n\n\n\n\nChapter 43 Slides"
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#what-is-an-moment-generating-function-mgf",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#what-is-an-moment-generating-function-mgf",
    "title": "Chapter 43: Moment Generating Functions Part 1",
    "section": "What is an moment generating function (mgf)??",
    "text": "What is an moment generating function (mgf)??\n\n\nDefinition 3\n\n\nIf \\(X\\) is a r.v., then the moment generating function (mgf) associated with \\(X\\) is: \\[M_X(t)= \\mathbb{E}[e^{tX}]\\]\n\n\nRemarks\n\n\n\nFor a discrete r.v., the mgf of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\sum_{all \\ x}e^{tx}p_X(x)\\]\nFor a continuous r.v., the mgf of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\int_{-\\infty}^{\\infty}e^{tx}f_X(x)dx\\]\n\n\n\nThe mgf \\(M_X(t)\\) is a function of \\(t\\), not of \\(X\\), and it might not be defined (i.e. finite) for all values of \\(t\\). We just need it to be defined for \\(t=0\\)."
  },
  {
    "objectID": "lessons/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html",
    "href": "lessons/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Homework 7 presentations due soon!\n\nI will check your HW 7 solutions ASAP!\n\nDepending on how far we get today and Wednesday, I might cancel the 12/9 class\nAnything else?"
  },
  {
    "objectID": "lessons/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#announcements",
    "href": "lessons/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Homework 7 presentations due soon!\n\nI will check your HW 7 solutions ASAP!\n\nDepending on how far we get today and Wednesday, I might cancel the 12/9 class\nAnything else?"
  },
  {
    "objectID": "lessons/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#key-dates",
    "href": "lessons/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 8 assignment due\nSunday: HW 7 presentations due at 11pm"
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#what-is-a-moment-generating-function-mgf",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#what-is-a-moment-generating-function-mgf",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "What is a moment generating function (mgf)??",
    "text": "What is a moment generating function (mgf)??\n\n\nDefinition 3\n\n\nIf \\(X\\) is a r.v., then the moment generating function (mgf) associated with \\(X\\) is: \\[M_X(t)= \\mathbb{E}[e^{tX}]\\]\n\n\nRemarks\n\n\n\nFor a discrete r.v., the mgf of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\sum_{all \\ x}e^{tx}p_X(x)\\]\nFor a continuous r.v., the mgf of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\int_{-\\infty}^{\\infty}e^{tx}f_X(x)dx\\]\n\n\n\nThe mgf \\(M_X(t)\\) is a function of \\(t\\), not of \\(X\\), and it might not be defined (i.e. finite) for all values of \\(t\\). We just need it to be defined for \\(t=0\\)."
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-a-probability-distribution",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-a-probability-distribution",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Using the mgf to uniquely describe a probability distribution",
    "text": "Using the mgf to uniquely describe a probability distribution\n\n\n\n\nExample 7\n\n\nLet \\(X \\sim Poisson(\\lambda)\\)\n\nFind the mgf of \\(X\\)\nFind \\(\\mathbb{E}[X]\\)\nFind \\(Var(X)\\)"
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-r_xt-to-uniquely-describe-a-probability-distribution",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-r_xt-to-uniquely-describe-a-probability-distribution",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Using \\(R_X(t)\\) to uniquely describe a probability distribution",
    "text": "Using \\(R_X(t)\\) to uniquely describe a probability distribution\n\n\n\n\nExample 9\n\n\nLet \\(X \\sim Poisson(\\lambda)\\).\n\nFind \\(\\mathbb{E}[X]\\) using \\(R_X(t)\\)\nFind \\(Var(X)\\) using \\(R_X(t)\\)"
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-the-standard-normal-distribution",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-the-standard-normal-distribution",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Using the mgf to uniquely describe the standard normal distribution",
    "text": "Using the mgf to uniquely describe the standard normal distribution\n\n\n\n\nExample 10\n\n\nLet \\(Z\\) be a standard normal random variable, i.e. \\(Z \\sim N(0,1)\\).\n\nFind the mgf of \\(Z\\)\nFind \\(\\mathbb{E}[Z]\\)\nFind \\(Var(Z)\\)"
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#main-takeaways",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#main-takeaways",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Main takeaways",
    "text": "Main takeaways\n\nMgf’s are a purely mathematically definition\n\nWe can’t really relate it to our real world analysis\n\nThey are helpful mathematically because they are unique to a probability distribution\n\nWe can find the unique mgf from for a probability distribution\nAnd we can find a distribution from an mgf\n\nMgf’s can sometimes make it easier to find the mean and variance of an RV\nMgf’s are most helpful when we are finding a joint distribution that is a sum or transformation of two RV’s\n\nMake the calculation easier!\n\nMgf’s are often used to prove certain distribution are sums of other ones!"
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#more-resources",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#more-resources",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "More resources",
    "text": "More resources\n\nhttps://online.stat.psu.edu/stat414/book/export/html/676\nhttps://www.youtube.com/watch/ez_vq23xWrQ\nhttps://www.youtube.com/watch/2p9J9ChTeFI\nhttps://www.youtube.com/watch/A5bWU8xcQkE\nhttps://www.youtube.com/watch/QeUrTGFTFm4\nhttps://www.youtube.com/watch/HhrkwyyRtgI\n\n\n\nChapter 43 Slides"
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#mgfs-of-sums-of-independent-rvs",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#mgfs-of-sums-of-independent-rvs",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Mgf’s of sums of independent RV’s",
    "text": "Mgf’s of sums of independent RV’s\n\n\nTheorem 9\n\n\nIf \\(X\\) and \\(Y\\) are independent RV’s with respective mgf’s \\(M_X(t)\\) and \\(M_Y(t)\\), then\n\\[M_{X+Y}(t) = E[e^{t(X+Y)}] = E[e^{tX} e^{tY}] = E[e^{tX}]E[e^{tY}]=M_{X}(t)M_{Y}(t)\\]"
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "LAST CLASS!!!!\nHomework 7and 6 solutions are graded\nHW 7 meetings are up on Calendly\n\nSee my announcement from Sakai\n\nI will be finalizing and posting HW 9 tomorrow\n\nOptional!\n\nPlease do your course evals!!\n\nEspecially in a small class\n\nFriday 12/13 is the absolute deadline for turning in materials if you are completing the course! _ Check Sakai that I have all your HW grades in!\nAnything else?"
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html#announcements",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "LAST CLASS!!!!\nHomework 7and 6 solutions are graded\nHW 7 meetings are up on Calendly\n\nSee my announcement from Sakai\n\nI will be finalizing and posting HW 9 tomorrow\n\nOptional!\n\nPlease do your course evals!!\n\nEspecially in a small class\n\nFriday 12/13 is the absolute deadline for turning in materials if you are completing the course! _ Check Sakai that I have all your HW grades in!\nAnything else?"
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html#key-dates",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday (12/5): HW 8 assignment due\nSunday (12/8): HW 7 presentations due at 11pm\n\nI can be pretty flexible until 12/13\n\nThursday (12/12): Optional HW 9 assignment due\nFriday (12/13): HW 8 solutions due"
  },
  {
    "objectID": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#where-are-we",
    "href": "lessons/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#where-are-we",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability_key_info.html",
    "href": "lessons/01_Probability/01_Probability_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Slack is working for a few people??\n\nhttps://join.slack.com/t/bsta550/shared_invite/zt-2qtfo9s8j-j6ozEaYdT7yy1KuHoT9Mhw"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability_key_info.html#announcements",
    "href": "lessons/01_Probability/01_Probability_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Slack is working for a few people??\n\nhttps://join.slack.com/t/bsta550/shared_invite/zt-2qtfo9s8j-j6ozEaYdT7yy1KuHoT9Mhw"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability_muddy_points.html",
    "href": "lessons/01_Probability/01_Probability_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "In class, we were wondering why/if \\(2^{|S|}\\) is the general formula for calculating the total number of possible events. We were specifically wondering if the \\(2\\) came from the fact that we had two options (heads and tails) for our outcome. Let’s work through the example of a 6-sided die to explain this further. The sample space is \\(S=\\{1, 2, 3, 4, 5, 6\\}\\). So is the total number of possible events \\(2^6\\) or \\(6^6\\) or something else? We can actually think about an event by using an indicator variable for each outcome of the sample space. An indicator variable is just a way to give us a yes/no answer to a question. So in this case, we are wondering: is this outcome a part of our event? If our event is \\(\\{1\\}\\) then for the outcome \\(1\\), the answer is “yes, the outcome is part of the event. For outcomes \\(2-6\\), the answer is”no, the outcome is not apart of the event.”\n\nFor each outcome, we have a “yes” or “no” answer. We can look at another example of an event. Let’s say our event is rolling an even number:\n\nFor \\(2\\), \\(4\\), and \\(6\\), the answer is “yes.” We can define the indicator variable for whether an outcome is in an event or not. The indicator gives a 1 or 0 for yes and no respectively.\n\nAs stated above, the \\(2\\) in \\(2^6\\) comes from the \\(2\\) options from our indicator. Each side has two options, and there are \\(6\\) sides. Thus, \\(2^6\\) possible events.\n\n\n\nI think this will become clearer when we start thinking about events in the context of probability. When we think of events outside of probability, we may think of something we actually do or something that happens, like going to a concert or coming to class or missing the streetcar. In this case, we think of the event as the single thing (out of all the options) that actually occured. For example, if I’m taking the streetcar to class, I can think of two definitive options of what might occur: I miss the streetcar or I get on the streetcar. Only one of these things can occur, which I may call an event colloquially.\nIt is important to make the distinction with events defined within probability. Events are not necessarily a single thing that occurred. Instead it can be a collection of things that may occur. In the example of the streetcar, I can define my event to include both options. Thus, my event is that I make the streetcar or I miss it. Both of these things cannot happen simultaneously, but if I want to calculate the probability that I miss or make the streetcar, then it is helpful to have the event defined.\n\n\nAn outcome is a single result. The two options in the above example, missing the streetcar or getting on the streetcar, are two potential outcomes. Events are the collection of 0, 1, or more outcomes. So the possible events are: the empty set, missing the streetcar, getting on the streetcar, or the set of missing the streetcar and getting on the streetcar."
  },
  {
    "objectID": "lessons/01_Probability/01_Probability_muddy_points.html#proofs-of-propositions",
    "href": "lessons/01_Probability/01_Probability_muddy_points.html#proofs-of-propositions",
    "title": "Muddy Points",
    "section": "1. Proofs of propositions",
    "text": "1. Proofs of propositions\nFurther explanations of the propositions can be found in the textbook from pages 24-27. For many of the explanations in class, I was working to produce a union of disjoint events, so that the probability could easily be calculated. Proposition 3 and 4 were specifically mentioned, so I will include some writing notes on them here:\n\nProposition 3\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\nIn this proposition, I want to define event \\(B\\) as a union of disjoint events so that I can show \\(P(B)\\) is the sum of \\(P(A)\\) and some greater-than-or-equal-to 0 probability event. If the following is my venn diagram of A and B:\n\n\n\n\n\nThen I can define B as the union of disjoint events: \nIf we then take the probability of each side of the equation \\(B = A \\cup (A^c \\cap B)\\), we get \\[P(B) = P\\big(A \\cup (A^c \\cap B)\\big)\\]\nSince events \\(A\\) and \\(A^c \\cap B\\) are disjoint, the probability of their union is just: \\[P(A) + P(A^c \\cap B)\\]\nThus, our equation is now \\[P(B) = P(A) + P(A^c \\cap B)\\]\nFrom Axiom 1, we know for event \\(A^c \\cap B\\), \\(P(A^c \\cap B) \\geq 0\\).\nSo the probability of event B is the sum of the probability of event A and an event that is \\(\\geq\\) 0. This means \\(P(B) \\geq P(A)\\).\n\n\nProposition 4\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)\n\n\nFrom the pictures above, we can see some similar disjoint events.\nIf we look back at \\(A \\cup B\\), we can start manipulating the right side of the equation:"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability_muddy_points.html#example-at-end-of-chapter-2-slides-venn-diagram",
    "href": "lessons/01_Probability/01_Probability_muddy_points.html#example-at-end-of-chapter-2-slides-venn-diagram",
    "title": "Muddy Points",
    "section": "2. Example at end of Chapter 2 slides (Venn Diagram)",
    "text": "2. Example at end of Chapter 2 slides (Venn Diagram)\nI will post this in the previous week’s Muddy Points as well. Please follow this link for my work through of the example. And here is the PDF with my work.\nSub-question: why don’t we just multiply the probability of A and B to get the intersection? This is a specific property of probability when A and B are independent. Only when A and B are independent can we conclude that \\(P(A \\cap B) = P(A)P(B)\\)."
  },
  {
    "objectID": "lessons/01_Probability/01_Probability_muddy_points.html#partition-of-events",
    "href": "lessons/01_Probability/01_Probability_muddy_points.html#partition-of-events",
    "title": "Muddy Points",
    "section": "3. Partition of events",
    "text": "3. Partition of events\nWe’ve been working with event partitions throughout Chapter 2, but we have not formally identified them. Partitions are advantageous to define for two reasons:\n\nThe partitions may be easier to calculate. We can then use the partitions to reconstruct other probabilities that may be more difficult to calculate\nPartitions have nice properties as a consequence of being disjoint. For example, the probability of the union of partitions is the sum of the probabilities across each partition: \\[P\\bigg(\\bigcup_{i=1}^n A_i\\bigg) = P(A_1)P(A_2)P(A_3) \\cdot \\cdot \\cdot P(A_n)\\]"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html",
    "href": "lessons/01_Probability/01_Probability.html",
    "title": "Chapter 2: Introduction to Probability",
    "section": "",
    "text": "Define basic axioms and propositions in probability\nAssign probabilities to events\nPerform manipulations on probabilities to make calculations easier"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#probabilities-of-equally-likely-events-1",
    "href": "lessons/01_Probability/01_Probability.html#probabilities-of-equally-likely-events-1",
    "title": "Lesson 1: Introduction to Probability",
    "section": "Probabilities of equally likely events",
    "text": "Probabilities of equally likely events\n\n“Equally likely” means the probability of any possible outcome is the same\n\nThink: each side of die is equally likely or picking a card in a deck is equally likely"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#pick-an-equally-likely-card-any-equally-likely-card",
    "href": "lessons/01_Probability/01_Probability.html#pick-an-equally-likely-card-any-equally-likely-card",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Pick an equally likely card, any equally likely card",
    "text": "Pick an equally likely card, any equally likely card\n\n\nExample 1\n\n\nSuppose you have a regular well-shuffled deck of cards. What’s the probability of drawing:\n\nany heart\nthe queen of hearts\nany queen"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#lets-break-down-this-probability",
    "href": "lessons/01_Probability/01_Probability.html#lets-break-down-this-probability",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Let’s break down this probability",
    "text": "Let’s break down this probability\nIf \\(S\\) is a finite sample space, with equally likely outcomes, then\n\\[\\mathbb{P}(A) = \\frac{|A|}{|S|}\\]\nIn human speak:\n\nFor equally likely outcomes, the probability that a certain event occurs is: the number of outcomes within the event of interest (\\(|A|\\)) divided by the total number of possible outcomes (\\(|S|\\))\n\n\\[\\mathbb{P}(A) = \\frac{\\text{total number of outcomes in event A}}{\\text{total number of outcomes in sample space}}\\]\n\nThus, it is important to be able to count the outcomes within an event"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#a-probability-is-a-function",
    "href": "lessons/01_Probability/01_Probability.html#a-probability-is-a-function",
    "title": "Lesson 1: Introduction to Probability",
    "section": "A probability is a function…",
    "text": "A probability is a function…\n\n\\(\\mathbb{P}(A)\\) is a function with\n\nInput: event \\(A\\) from the sample space \\(S\\), (\\(A \\subseteq S\\))\n\n\\(A \\subseteq S\\) means “A contained within S” or “A is a subset of S”\n\nOutput: a number between 0 and 1 (inclusive)\n\n\n \n\nThe probability function maps an event (input) to value between 0 and 1 (output)\n\nWhen we speak of the probability function, we often call the values between 0 and 1 “probabilities”\n\nExample: “The probability of drawing a heart is 0.25” for \\(P(\\text{heart}) = 0.25\\)\n\n\n\n \n\nThe probability function needs to follow some specific rules (called axioms)!"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#probability-axioms-1",
    "href": "lessons/01_Probability/01_Probability.html#probability-axioms-1",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Probability Axioms",
    "text": "Probability Axioms\n\n\n\n\nAxiom 1\n\n\nFor every event \\(A\\), \\(0\\leq\\mathbb{P}(A)\\leq 1\\). Probability is between 0 and 1.\n\n\n\n\nAxiom 2\n\n\nFor the sample space \\(S\\), \\(\\mathbb{P}(S)=1\\).\n\n\n\n\nAxiom 3\n\n\nIf \\(A_1, A_2, A_3, \\ldots\\), is a collection of disjoint events, then \\[\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i).\\] The probability of at least one \\(A_i\\) is the sum of the individual probabilities of each."
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#some-probability-properties-1",
    "href": "lessons/01_Probability/01_Probability.html#some-probability-properties-1",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Some probability properties",
    "text": "Some probability properties\nUsing the Axioms, we can prove all other probability properties! Events A, B, and C are not necessarily disjoint!\n\n\n\n\nProposition 1\n\n\nFor any event \\(A\\), \\(\\mathbb{P}(A)= 1 - \\mathbb{P}(A^C)\\)\n\n\n\n\nProposition 2\n\n\n\\(\\mathbb{P}(\\emptyset)=0\\)\n\n\n\n\nProposition 3\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\n\n\n\n\n\nProposition 4\n\n\n\\[\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\] where \\(A\\) and \\(B\\) are not necessarily disjoint\n\n\n\n\nProposition 5\n\n\n\\(\\begin{aligned} \\mathbb{P}(A \\cup B & \\cup C) = \\mathbb{P}(A) + \\mathbb{P}(B) + \\\\ & \\mathbb{P}(C) - \\mathbb{P}(A \\cap B) - \\mathbb{P}(A \\cap C) - \\\\ & \\mathbb{P}(B \\cap C) + \\mathbb{P}(A \\cap B \\cap C) \\end{aligned}\\)"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#proposition-1-proof",
    "href": "lessons/01_Probability/01_Probability.html#proposition-1-proof",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Proposition 1 Proof",
    "text": "Proposition 1 Proof\n\n\n\n\nProposition 1\n\n\nFor any event \\(A\\), \\(\\mathbb{P}(A)= 1 - \\mathbb{P}(A^C)\\)\n\n\n\n\n\nUse Axioms!\n\n\nA1: \\(0\\leq\\mathbb{P}(A)\\leq 1\\)\nA2: \\(\\mathbb{P}(S)=1\\)\nA3: For disjoint \\(A_i\\),\n\\(\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i)\\)"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#proposition-2-proof",
    "href": "lessons/01_Probability/01_Probability.html#proposition-2-proof",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Proposition 2 Proof",
    "text": "Proposition 2 Proof\n\n\n\n\nProposition 2\n\n\n\\(\\mathbb{P}(\\emptyset)=0\\)\n\n\n\n\n\nUse Axioms!\n\n\nA1: \\(0\\leq\\mathbb{P}(A)\\leq 1\\)\nA2: \\(\\mathbb{P}(S)=1\\)\nA3: For disjoint \\(A_i\\),\n\\(\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i)\\)"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#proposition-3-proof",
    "href": "lessons/01_Probability/01_Probability.html#proposition-3-proof",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Proposition 3 Proof",
    "text": "Proposition 3 Proof\n\n\n\n\nProposition 3\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\n\n\n\n\n\nUse Axioms!\n\n\nA1: \\(0\\leq\\mathbb{P}(A)\\leq 1\\)\nA2: \\(\\mathbb{P}(S)=1\\)\nA3: For disjoint \\(A_i\\),\n\\(\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i)\\)"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#proposition-4-visual-proof",
    "href": "lessons/01_Probability/01_Probability.html#proposition-4-visual-proof",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Proposition 4 Visual Proof",
    "text": "Proposition 4 Visual Proof\n\n\nProposition 4\n\n\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#proposition-5-visual-proof",
    "href": "lessons/01_Probability/01_Probability.html#proposition-5-visual-proof",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Proposition 5 Visual Proof",
    "text": "Proposition 5 Visual Proof\n\n\nProposition 5\n\n\n\\(\\mathbb{P}(A \\cup B \\cup C) = \\mathbb{P}(A) + \\mathbb{P}(B) + \\mathbb{P}(C) - \\mathbb{P}(A \\cap B) - \\mathbb{P}(A \\cap C) - \\mathbb{P}(B \\cap C) + \\mathbb{P}(A \\cap B \\cap C)\\)"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#some-final-remarks-on-these-proposition",
    "href": "lessons/01_Probability/01_Probability.html#some-final-remarks-on-these-proposition",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Some final remarks on these proposition",
    "text": "Some final remarks on these proposition\n\nNotice how we spliced events into multiple disjoint events\n\nIt is often easier to work with disjoint events\n\n\n \n\nIf we want to calculate the probability for one event, we may need to get creative with how we manipulate other events and the sample space\n\nHelps us use any incomplete information we have"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#partitions-1",
    "href": "lessons/01_Probability/01_Probability.html#partitions-1",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Partitions",
    "text": "Partitions\n\n\n\n\nDefinition: Partition\n\n\nA set of events \\(\\{A_i\\}_{i=1}^{n}\\) create a partition of \\(A\\), if\n\nthe \\(A_i\\)’s are disjoint (mutually exclusive) and\n\\(\\bigcup \\limits_{i=1}^n A_i = A\\)\n\n\n\n\n\nExample 2\n\n\n\nIf \\(A \\subset B\\), then \\(\\{A, B \\cap A^C\\}\\) is a partition of \\(B\\).\nIf \\(S = \\bigcup \\limits_{i=1}^n A_i\\), and the \\(A_i\\)’s are disjoint, then the \\(A_i\\)’s are a partition of the sample space.\n\n\n\n\n\n\nCreating partitions is sometimes used to help calculate probabilities, since by Axiom 3 we can add the probabilities of disjoint events."
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#weekly-medications",
    "href": "lessons/01_Probability/01_Probability.html#weekly-medications",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Weekly medications",
    "text": "Weekly medications\n\n\n\n\nExample 3\n\n\nIf a subject has an\n\n80% chance of taking their medication this week,\n70% chance of taking their medication next week, and\n10% chance of not taking their medication either week,\n\nthen find the probability of them taking their medication exactly one of the two weeks.\n\n\n\nHint: Draw a Venn diagram labelling each of the parts to find the probability."
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#where-are-we",
    "href": "lessons/01_Probability/01_Probability.html#where-are-we",
    "title": "Lesson 1: Introduction to Probability",
    "section": "Where are we?",
    "text": "Where are we?\n\nBig part of this lesson is motivating why we care about probability and simulations, then we’ll dive into some basics"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#what-is-probability",
    "href": "lessons/01_Probability/01_Probability.html#what-is-probability",
    "title": "Lesson 1: Introduction to Probability",
    "section": "What is probability?",
    "text": "What is probability?\n\nWe hear the word “probability” pretty often\n\nCommon in news reports, advertisements, sports, medicine, etc.\n\n\n\nResearchers say the probability of living past 110 is on the rise\nCNBC, 2021\n\n\nWe may hear “probability” or similar words like “chance,” “likelihood,” or “odds”\n\n\nScientists fine-tune odds of asteroid Bennu hitting Earth through 2300 with NASA probe’s help\nSpace.com, 2021"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#probabilities-of-equally-likely-events",
    "href": "lessons/01_Probability/01_Probability.html#probabilities-of-equally-likely-events",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Probabilities of equally likely events",
    "text": "Probabilities of equally likely events\n\n“Equally likely” means the probability of any possible outcome is the same\n\nThink: each side of die is equally likely or picking a card in a deck is equally likely"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#what-is-probability-12",
    "href": "lessons/01_Probability/01_Probability.html#what-is-probability-12",
    "title": "Lesson 1: Introduction to Probability",
    "section": "What is probability? (1/2)",
    "text": "What is probability? (1/2)\n\nWe hear the word “probability” pretty often\n\nCommon in news reports, advertisements, sports, medicine, etc.\n\n\n\nResearchers say the probability of living past 110 is on the rise\nCNBC, 2021\n\n\nWe may hear “probability” or similar words like “chance,” “likelihood,” or “odds”\n\n\nScientists fine-tune odds of asteroid Bennu hitting Earth through 2300 with NASA probe’s help\nSpace.com, 2021"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#what-is-probability-22",
    "href": "lessons/01_Probability/01_Probability.html#what-is-probability-22",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "What is probability? (2/2)",
    "text": "What is probability? (2/2)\n\nProbability requires randomness\nSomething is random if there are many potential outcome, but there is uncertainty which outcome will occur\nWe often use physical randomness to demonstrate this\n\nThink: flipping coins, rolling a dice, drawing cards\n\nThe occurrence of outcomes can be uncertain, but there is an underlying distribution of the probability of outcomes\n\nThere is a distribution of outcomes over large number of (hypothetical repetitions)"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#coin-flip",
    "href": "lessons/01_Probability/01_Probability.html#coin-flip",
    "title": "Lesson 1: Introduction to Probability",
    "section": "Coin flip",
    "text": "Coin flip\nSeeing Theory, Chapter 1: Basic Probability, Chance Events"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#a-single-coin-flip-then-100-coin-flips",
    "href": "lessons/01_Probability/01_Probability.html#a-single-coin-flip-then-100-coin-flips",
    "title": "Lesson 1: Introduction to Probability",
    "section": "A single coin flip then 100 coin flips",
    "text": "A single coin flip then 100 coin flips\nSeeing Theory, Chapter 1: Basic Probability, Chance Events"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#how-do-we-simulate-this-in-r",
    "href": "lessons/01_Probability/01_Probability.html#how-do-we-simulate-this-in-r",
    "title": "Lesson 1: Introduction to Probability",
    "section": "How do we simulate this in R?",
    "text": "How do we simulate this in R?\n\nWe know that heads and tails are equally likely for a single flip\n\n\nset.seed(13)\ncoin = c(\"heads\", \"tails\")\nsample(coin, 1)\n\n[1] \"tails\"\n\n\n\nWhen we only flip the coin once, we only only get one outcome (heads or tails)\n\nWe cannot see any distribution of the probability of outcomes"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#why-is-simulation-important",
    "href": "lessons/01_Probability/01_Probability.html#why-is-simulation-important",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Why is simulation important?",
    "text": "Why is simulation important?\n\nIn the previous example, coding a simulation seemed more educational than necessary\nWe can often calculate probabilities mathematically, but we will eventually get to complex calculations\n\nSimulations can help us (or be necessary) to solve a problem when calculations are complex\n\nSimulations are a great way to check your work!\nSimulation based reasoning is helpful in statistics\n\nYou’ll see this in confidence intervals in Biostatistics courses\n\nSimulations allow you to change assumptions easily and see how they affect your results"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#section",
    "href": "lessons/01_Probability/01_Probability.html#section",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "",
    "text": "(ref:coin-flips-plot-cap) Running proportion of H versus number of flips for the 10 coin flips in Table @ref(tab:coin-flips-table).\n\n(ref:coin-flips-plot-cap)"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#probability-and-randomness",
    "href": "lessons/01_Probability/01_Probability.html#probability-and-randomness",
    "title": "Lesson 1: Introduction to Probability",
    "section": "Probability and randomness",
    "text": "Probability and randomness\n\nProbability requires randomness\nSomething is random if there are many potential outcomes, but there is uncertainty which outcome will occur\n\n \n\nOutcomes can be “equally likely,” meaning each outcome has the same probability of happening\n\nBut random does NOT necessarily mean equally likely\n\nWe often use physical randomness to demonstrate equally likely outcomes\n\nThink: flipping coins, rolling a dice, drawing cards\n\n\n \n\nThe occurrence of outcomes can be uncertain, but there is an underlying distribution of the probability of outcomes\n\nThere is a distribution of outcomes over large number of (hypothetical repetitions)"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#why-are-simulations-important",
    "href": "lessons/01_Probability/01_Probability.html#why-are-simulations-important",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Why are simulations important?",
    "text": "Why are simulations important?\n\nIn the previous example, coding a simulation seemed more educational than necessary\nWe can often calculate probabilities mathematically, but we will eventually get to complex calculations\n\nSimulations can help us (or be necessary) to solve a problem when calculations are complex\n\nSimulations are a great way to check your work!\nSimulation based reasoning is helpful in statistics\n\nYou’ll see this in confidence intervals in Biostatistics courses\n\nSimulations allow you to change assumptions easily and see how they affect your results\nIt is often how statisticians “run” experiments on their methods of hypotheses"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#before-we-even-get-into-it",
    "href": "lessons/01_Probability/01_Probability.html#before-we-even-get-into-it",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Before we even get into it",
    "text": "Before we even get into it\n\nThe following few slides use some undefined words to define new words that in turn define other words\nIt’s confusing!\nWe’re going off assumption that we all have some understanding of probability, so stop me if you are confused!"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#before-we-take-one-more-step",
    "href": "lessons/01_Probability/01_Probability.html#before-we-take-one-more-step",
    "title": "Lesson 1: Introduction to Probability",
    "section": "Before we take one more step",
    "text": "Before we take one more step\n\nThe following few slides use some undefined words to define new words that in turn define the previously undefined words\nIt’s confusing!\nWe’re going off assumption that we all have some daily understanding of probability, so stop me if you are confused!"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#can-we-simulate-more",
    "href": "lessons/01_Probability/01_Probability.html#can-we-simulate-more",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Can we simulate more??",
    "text": "Can we simulate more??\n\nI can start to count the number of tails in the flips\n\n\nsum( sample(coin, 100, replace = T) == \"tails\" )\n\n[1] 58\n\n\n\nAnd I can see the proportion of tails in the flips\n\n\nsum( sample(coin, 100, replace = T) == \"tails\" ) / 100\n\n[1] 0.58\n\n\n\nI can do this with more flips\n\n\nsum( sample(coin, 1000, replace = T) == \"tails\" ) / 1000\n\n[1] 0.469\n\nsum( sample(coin, 10000, replace = T) == \"tails\" ) / 10000\n\n[1] 0.5044\n\nsum( sample(coin, 100000, replace = T) == \"tails\" ) / 100000\n\n[1] 0.49967"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#as-the-number-of-flips-increases-we-converge-to-the-expected-probability",
    "href": "lessons/01_Probability/01_Probability.html#as-the-number-of-flips-increases-we-converge-to-the-expected-probability",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "As the number of flips increases, we converge to the expected probability",
    "text": "As the number of flips increases, we converge to the expected probability\n\n\n\nResults and running proportion of H for 10 flips of a fair coin.\n\n\nFlip\nResult\nRunning count of H\nRunning proportion of H\n\n\n\n\n1\nH\n1\n1.000\n\n\n2\nH\n2\n1.000\n\n\n3\nT\n2\n0.667\n\n\n4\nT\n2\n0.500\n\n\n5\nH\n3\n0.600\n\n\n6\nH\n4\n0.667\n\n\n7\nH\n5\n0.714\n\n\n8\nH\n6\n0.750\n\n\n9\nH\n7\n0.778\n\n\n10\nT\n7\n0.700"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#what-if-i-sample-10-coin-flips",
    "href": "lessons/01_Probability/01_Probability.html#what-if-i-sample-10-coin-flips",
    "title": "Lesson 1: Introduction to Probability",
    "section": "What if I sample 10 coin flips?",
    "text": "What if I sample 10 coin flips?\n\nHow many tails do we get? Are we getting closer to a distribution of heads and tails that we expect?\n\n\n\n\nResults and running proportion of H for 10 flips of a fair coin.\n\n\nFlip\nResult\nRunning count of H\nRunning proportion of H\n\n\n\n\n1\nH\n1\n1.000\n\n\n2\nT\n1\n0.500\n\n\n3\nH\n2\n0.667\n\n\n4\nT\n2\n0.500\n\n\n5\nH\n3\n0.600\n\n\n6\nT\n3\n0.500\n\n\n7\nT\n3\n0.429\n\n\n8\nT\n3\n0.375\n\n\n9\nT\n3\n0.333\n\n\n10\nT\n3\n0.300"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#what-if-i-sample-100-coin-flips",
    "href": "lessons/01_Probability/01_Probability.html#what-if-i-sample-100-coin-flips",
    "title": "Lesson 1: Introduction to Probability",
    "section": "What if I sample 100 coin flips?",
    "text": "What if I sample 100 coin flips?"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#whats-the-point",
    "href": "lessons/01_Probability/01_Probability.html#whats-the-point",
    "title": "Lesson 1: Introduction to Probability",
    "section": "What’s the point?",
    "text": "What’s the point?\n\nWe know the probability of a heads is 0.5!\n\n \n\nWhy do we need to simulate 100s or 1000s of coin flips?\n\nWith enough repetitions, we can use simulations to approximate the probability of an event\n\n\n \n\nOkay, but why is that helpful? (next slide!)"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#why-are-simulations-important-bigger-picture",
    "href": "lessons/01_Probability/01_Probability.html#why-are-simulations-important-bigger-picture",
    "title": "Lesson 1: Introduction to Probability",
    "section": "Why are simulations important? (bigger picture)",
    "text": "Why are simulations important? (bigger picture)\nIn the previous example, coding a simulation seemed more educational than necessary\n \n\nSimulations can help us (or be necessary) to solve a problem when calculations are complex\n\nWe can often calculate probabilities mathematically, but we will eventually get to complex calculations\n\nSimulations are a great way to check your work!\nSimulation based reasoning is helpful in statistics\n\nYou’ll see this in confidence intervals in Biostatistics courses\n\nSimulations allow you to change assumptions easily and see how they affect your results\nIt is often how statisticians “run” experiments on their methods of hypotheses"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#do-we-know-how-to-use-r",
    "href": "lessons/01_Probability/01_Probability.html#do-we-know-how-to-use-r",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Do we know how to use R?",
    "text": "Do we know how to use R?"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#learning-objectives",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#learning-objectives",
    "title": "Lesson 2: Language of Probability",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nbuilding important definitions so that we have a mutual understanding of the language of probability\n\nDefine basic terms related to events such as events, outcomes, and sample space.\nUse proper set notation for events\nCharacterize possible outcomes, when something random occurs\nDescribe events into which outcomes can be grouped\nDefine important terms and rules within set theory such as unions, intersections, complements, mutually exclusive, and De Morgan’s Laws"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#where-are-we",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#where-are-we",
    "title": "Lesson 3: Language of Probability",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#coin-toss-example-1-coin-13",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#coin-toss-example-1-coin-13",
    "title": "Lesson 2: Language of Probability and Simulation",
    "section": "Coin Toss Example: 1 coin (1/3)",
    "text": "Coin Toss Example: 1 coin (1/3)\n\n\n\n\nSingle coin toss\n\n\nSuppose you toss one coin.\n\nWhat are the possible outcomes?\n \nWhat is the sample space?\n \nWhat are the possible events?"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#coin-toss-example-1-coin-23",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#coin-toss-example-1-coin-23",
    "title": "Lesson 2: Language of Probability and Simulation",
    "section": "Coin Toss Example: 1 coin (2/3)",
    "text": "Coin Toss Example: 1 coin (2/3)\nSuppose you toss one coin.\n\nWhat are the possible outcomes?\n\nHeads (\\(H\\))\nTails (\\(T\\))\n\n\n \n\n\nNote\n\n\nWhen something happens at random, such as a coin toss, there are several possible outcomes, and exactly one of the outcomes will occur."
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#definitions-sample-space-and-events",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#definitions-sample-space-and-events",
    "title": "Lesson 2: Language of Probability and Simulation",
    "section": "Definitions: Sample Space and Events",
    "text": "Definitions: Sample Space and Events\n\n\nDefinition: Sample Space\n\n\nThe sample space \\(S\\) is the set of all outcomes\n\n\n\n\nDefinition: Event\n\n\nAn event is a collection of some outcomes. An event can include multiple outcomes or no outcomes (a subset of the sample space).\n\n\nWhen thinking about events, think about outcomes that you might be asking the probability of. For example, what is the probability that you get a heads and a tails in one flip? (Answer: 0)"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#coin-toss-example-1-coin-33",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#coin-toss-example-1-coin-33",
    "title": "Lesson 2: Language of Probability and Simulation",
    "section": "Coin Toss Example: 1 coin (3/3)",
    "text": "Coin Toss Example: 1 coin (3/3)\n\n\n\nWhat is the sample space?\n\n\\(S =\\)\n\n\n \n \n\nWhat are the possible events?\n\n\n\n\n\n\n \n\n\n\n\nNote #1\n\n\nWe use curly brackets (\\(\\{\\}\\)) to denote a set (collecting a list of outcomes or values)\n\n\n\n\nNote #2\n\n\nThe total number of possible events is \\[2^{|S|}\\] where \\(|S|\\) is the total number of outcomes in the sample space. Also, possible events are not necessarily something that can actually occur (i.e. getting a heads and a tails on a single coin flip)"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#coin-toss-example-2-coins",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#coin-toss-example-2-coins",
    "title": "Lesson 2: Language of Probability and Simulation",
    "section": "Coin Toss Example: 2 coins",
    "text": "Coin Toss Example: 2 coins\nSuppose you toss two coins.\n\nWhat is the sample space? Assume the coins are distinguishable\n\n\\(S =\\)\n\n\n \n\nWhat are some possible events?\n\n\\(A =\\) exactly one \\(H =\\)\n\\(B =\\) at least one \\(H =\\)"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#more-info-on-events-and-sample-spaces",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#more-info-on-events-and-sample-spaces",
    "title": "Lesson 2: Language of Probability and Simulation",
    "section": "More info on events and sample spaces",
    "text": "More info on events and sample spaces\n\nWe usually use capital letters from the beginning of the alphabet to denote events. However, other letters might be chosen to be more descriptive.\n\nExamples: \\(A, B, C, A_1, A_2\\)\n\nWe can also define a new event as a combination of other events\n\nExamples: \\(A \\cup B\\) (union), \\(A \\cap B\\) (intersection), \\(A^C\\) (complement)\n\n\n \n\nWe use the notation \\(|S|\\) to denote the size of the sample space.\n\n \n\nThe total number of possible events is \\(2^{|S|}\\), which is the total number of possible subsets of \\(S\\).\n\n \n\nThe empty set, denoted by \\(\\emptyset\\), is the set containing no outcomes."
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#example-keep-sampling-until",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#example-keep-sampling-until",
    "title": "Lesson 2: Language of Probability and Simulation",
    "section": "Example: Keep sampling until…",
    "text": "Example: Keep sampling until…\nSuppose you keep sampling people until you have someone with high blood pressure (BP)\n \nWhat is the sample space?\n\nLet \\(H =\\) denote someone with high BP.\nLet \\(H^C =\\) denote someone with not high blood pressure, such as low or regular BP.\n\n \n\nThen, \\(S =\\)"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#set-theory-12",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#set-theory-12",
    "title": "Lesson 3: Language of Probability",
    "section": "Set Theory (1/2)",
    "text": "Set Theory (1/2)\n\n\n \n\n\nDefinition: Union\n\n\nThe union of events \\(A\\) and \\(B\\), denoted by \\(A \\cup B\\), contains all outcomes that are in \\(A\\) or \\(B\\) or both\n\n\n\n\nDefinition: Intersection\n\n\nThe intersection of events \\(A\\) and \\(B\\), denoted by \\(A \\cap B\\), contains all outcomes that are both in \\(A\\) and \\(B\\).\n\n\n\nVenn diagrams"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#set-theory-22",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#set-theory-22",
    "title": "Lesson 3: Language of Probability",
    "section": "Set Theory (2/2)",
    "text": "Set Theory (2/2)\n\n\n \n\n\nDefinition: Complement\n\n\nThe complement of event \\(A\\), denoted by \\(A^C\\) or \\(A'\\), contains all outcomes in the sample space \\(S\\) that are not in \\(A\\) .\n\n\n\n\nDefinition: Mutually Exclusive\n\n\nEvents \\(A\\) and \\(B\\) are mutually exclusive, or disjoint, if they have no outcomes in common. In this case \\(A \\cap B = \\emptyset\\), where \\(\\emptyset\\) is the empty set.\n\n\n\nVenn diagrams"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#bp-example-variation-13",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#bp-example-variation-13",
    "title": "Lesson 3: Language of Probability",
    "section": "BP example variation (1/3)",
    "text": "BP example variation (1/3)\n\nSuppose you have \\(n\\) subjects in a study.\nLet \\(H_i\\) be the event that person \\(i\\) has high BP, for \\(i=1\\ldots n\\).\n\n \nUse set theory notation to denote the following events:\n\nEvent subject \\(i\\) does not have high BP\nEvent all \\(n\\) subjects have high BP\nEvent at least one subject has high BP\nEvent all of them do not have high BP\nEvent at least one subject does not have high BP"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#bp-example-variation-23",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#bp-example-variation-23",
    "title": "Lesson 3: Language of Probability",
    "section": "BP example variation (2/3)",
    "text": "BP example variation (2/3)\n\nSuppose you have \\(n\\) subjects in a study.\nLet \\(H_i\\) be the event that person \\(i\\) has high BP, for \\(i=1\\ldots n\\).\n\nUse set theory notation to denote the following events:\n\nEvent subject \\(i\\) does not have high BP\n \nEvent all \\(n\\) subjects have high BP\n \n \nEvent at least one subject has high BP"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#bp-example-variation-33",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#bp-example-variation-33",
    "title": "Lesson 3: Language of Probability",
    "section": "BP example variation (3/3)",
    "text": "BP example variation (3/3)\n\nEvent all of them do not have high BP\n \n \n \nEvent at least one subject does not have high BP"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#de-morgans-laws",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#de-morgans-laws",
    "title": "Lesson 3: Language of Probability",
    "section": "De Morgan’s Laws",
    "text": "De Morgan’s Laws\n\n\nTheorem: De Morgan’s 1st Law\n\n\nFor a collection of events (sets) \\(A_1, A_2, A_3, \\ldots\\)\n\\[\\bigcap\\limits_{i=1}^{n}A_i^C = \\Big(\\bigcup\\limits_{i=1}^{n}A_i\\Big)^C\\]\n\n\n“all not A = \\((\\)at least one event A\\()^C\\)” or “intersection of the complements is the complement of the union”\n\n\nTheorem: De Morgan’s 2nd Law\n\n\nFor a collection of events (sets) \\(A_1, A_2, A_3, \\ldots\\)\n\\[\\bigcup\\limits_{i=1}^{n}A_i^C = \\Big(\\bigcap\\limits_{i=1}^{n}A_i\\Big)^C\\]\n\n\n“at least one event not A = \\((\\)all A\\()^C\\)” or “union of complements is complement of the intersection”"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#remarks-on-de-morgans-laws",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#remarks-on-de-morgans-laws",
    "title": "Lesson 3: Language of Probability",
    "section": "Remarks on De Morgan’s Laws",
    "text": "Remarks on De Morgan’s Laws\n\nThese laws also hold for infinite collections of events.\n \nDraw Venn diagrams to convince yourself that these are true!\n \nThese laws are very useful when calculating probabilities.\n\nThis is because calculating the probability of the intersection of events is often much easier than the union of events.\nThis is not obvious right now, but we will see in the coming chapters why."
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#pick-an-equally-likely-card-any-equally-likely-card",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#pick-an-equally-likely-card-any-equally-likely-card",
    "title": "Lesson 2: Language of Probability and Simulation",
    "section": "Pick an equally likely card, any equally likely card",
    "text": "Pick an equally likely card, any equally likely card\n\n\nExample 1\n\n\nSuppose you have a regular well-shuffled deck of cards. What’s the probability of drawing:\n\nany heart\nthe queen of hearts\nany queen"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#lets-break-down-this-probability",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#lets-break-down-this-probability",
    "title": "Lesson 2: Language of Probability and Simulation",
    "section": "Let’s break down this probability",
    "text": "Let’s break down this probability\nIf \\(S\\) is a finite sample space, with equally likely outcomes, then\n\\[\\mathbb{P}(A) = \\frac{|A|}{|S|}\\]\nIn human speak:\n\nFor equally likely outcomes, the probability that a certain event occurs is: the number of outcomes within the event of interest (\\(|A|\\)) divided by the total number of possible outcomes (\\(|S|\\))\n\n\\[\\mathbb{P}(A) = \\frac{\\text{total number of outcomes in event A}}{\\text{total number of outcomes in sample space}}\\]\n\nThus, it is important to be able to count the outcomes within an event"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#a-probability-is-a-function",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#a-probability-is-a-function",
    "title": "Lesson 2: Language of Probability and Simulation",
    "section": "A probability is a function…",
    "text": "A probability is a function…\n\n\\(\\mathbb{P}(A)\\) is a function with\n\nInput: event \\(A\\) from the sample space \\(S\\), (\\(A \\subseteq S\\))\n\n\\(A \\subseteq S\\) means “A contained within S” or “A is a subset of S”\n\nOutput: a number between 0 and 1 (inclusive)\n\n\n \n\nThe probability function maps an event (input) to value between 0 and 1 (output)\n\nWhen we speak of the probability function, we often call the values between 0 and 1 “probabilities”\n\nExample: “The probability of drawing a heart is 0.25” for \\(P(\\text{heart}) = 0.25\\)\n\n\n\n \n\nThe probability function needs to follow some specific rules (called axioms)!"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#probability-axioms-1",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#probability-axioms-1",
    "title": "Lesson 2: Language of Probability",
    "section": "Probability Axioms",
    "text": "Probability Axioms\n\n\n\n\nAxiom 1\n\n\nFor every event \\(A\\), \\(0\\leq\\mathbb{P}(A)\\leq 1\\). Probability is between 0 and 1.\n\n\n\n\nAxiom 2\n\n\nFor the sample space \\(S\\), \\(\\mathbb{P}(S)=1\\).\n\n\n\n\nAxiom 3\n\n\nIf \\(A_1, A_2, A_3, \\ldots\\), is a collection of disjoint events, then \\[\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i).\\] The probability of at least one \\(A_i\\) is the sum of the individual probabilities of each."
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#some-probability-properties-1",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#some-probability-properties-1",
    "title": "Lesson 2: Language of Probability",
    "section": "Some probability properties",
    "text": "Some probability properties\nUsing the Axioms, we can prove all other probability properties! Events A, B, and C are not necessarily disjoint!\n\n\n\n\nProposition 1\n\n\nFor any event \\(A\\), \\(\\mathbb{P}(A)= 1 - \\mathbb{P}(A^C)\\)\n\n\n\n\nProposition 2\n\n\n\\(\\mathbb{P}(\\emptyset)=0\\)\n\n\n\n\nProposition 3\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\n\n\n\n\n\nProposition 4\n\n\n\\[\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\] where \\(A\\) and \\(B\\) are not necessarily disjoint\n\n\n\n\nProposition 5\n\n\n\\(\\begin{aligned} \\mathbb{P}(A \\cup B & \\cup C) = \\mathbb{P}(A) + \\mathbb{P}(B) + \\\\ & \\mathbb{P}(C) - \\mathbb{P}(A \\cap B) - \\mathbb{P}(A \\cap C) - \\\\ & \\mathbb{P}(B \\cap C) + \\mathbb{P}(A \\cap B \\cap C) \\end{aligned}\\)"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#proposition-1-proof",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#proposition-1-proof",
    "title": "Lesson 3: Language of Probability",
    "section": "Proposition 1 Proof",
    "text": "Proposition 1 Proof\n\n\n\n\nProposition 1\n\n\nFor any event \\(A\\), \\(\\mathbb{P}(A)= 1 - \\mathbb{P}(A^C)\\)\n\n\n\n\n\nUse Axioms!\n\n\nA1: \\(0\\leq\\mathbb{P}(A)\\leq 1\\)\nA2: \\(\\mathbb{P}(S)=1\\)\nA3: For disjoint \\(A_i\\),\n\\(\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i)\\)"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#proposition-2-proof",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#proposition-2-proof",
    "title": "Lesson 3: Language of Probability",
    "section": "Proposition 2 Proof",
    "text": "Proposition 2 Proof\n\n\n\n\nProposition 2\n\n\n\\(\\mathbb{P}(\\emptyset)=0\\)\n\n\n\n\n\nUse Axioms!\n\n\nA1: \\(0\\leq\\mathbb{P}(A)\\leq 1\\)\nA2: \\(\\mathbb{P}(S)=1\\)\nA3: For disjoint \\(A_i\\),\n\\(\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i)\\)"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#proposition-3-proof",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#proposition-3-proof",
    "title": "Lesson 3: Language of Probability",
    "section": "Proposition 3 Proof",
    "text": "Proposition 3 Proof\n\n\n\n\nProposition 3\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\n\n\n\n\n\nUse Axioms!\n\n\nA1: \\(0\\leq\\mathbb{P}(A)\\leq 1\\)\nA2: \\(\\mathbb{P}(S)=1\\)\nA3: For disjoint \\(A_i\\),\n\\(\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i)\\)"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#proposition-4-visual-proof",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#proposition-4-visual-proof",
    "title": "Lesson 3: Language of Probability",
    "section": "Proposition 4 Visual Proof",
    "text": "Proposition 4 Visual Proof\n\n\nProposition 4\n\n\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#proposition-5-visual-proof",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#proposition-5-visual-proof",
    "title": "Lesson 3: Language of Probability",
    "section": "Proposition 5 Visual Proof",
    "text": "Proposition 5 Visual Proof\n\n\nProposition 5\n\n\n\\(\\mathbb{P}(A \\cup B \\cup C) = \\mathbb{P}(A) + \\mathbb{P}(B) + \\mathbb{P}(C) - \\mathbb{P}(A \\cap B) - \\mathbb{P}(A \\cap C) - \\mathbb{P}(B \\cap C) + \\mathbb{P}(A \\cap B \\cap C)\\)"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#some-final-remarks-on-these-proposition",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#some-final-remarks-on-these-proposition",
    "title": "Lesson 3: Language of Probability",
    "section": "Some final remarks on these proposition",
    "text": "Some final remarks on these proposition\n\nNotice how we spliced events into multiple disjoint events\n\nIt is often easier to work with disjoint events\n\n\n \n\nIf we want to calculate the probability for one event, we may need to get creative with how we manipulate other events and the sample space\n\nHelps us use any incomplete information we have"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#partitions-1",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#partitions-1",
    "title": "Lesson 2: Language of Probability",
    "section": "Partitions",
    "text": "Partitions\n\n\n\n\nDefinition: Partition\n\n\nA set of events \\(\\{A_i\\}_{i=1}^{n}\\) create a partition of \\(A\\), if\n\nthe \\(A_i\\)’s are disjoint (mutually exclusive) and\n\\(\\bigcup \\limits_{i=1}^n A_i = A\\)\n\n\n\n\n\nExample 2\n\n\n\nIf \\(A \\subset B\\), then \\(\\{A, B \\cap A^C\\}\\) is a partition of \\(B\\).\nIf \\(S = \\bigcup \\limits_{i=1}^n A_i\\), and the \\(A_i\\)’s are disjoint, then the \\(A_i\\)’s are a partition of the sample space.\n\n\n\n\n\n\nCreating partitions is sometimes used to help calculate probabilities, since by Axiom 3 we can add the probabilities of disjoint events."
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#weekly-medications",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#weekly-medications",
    "title": "Lesson 3: Language of Probability",
    "section": "Weekly medications",
    "text": "Weekly medications\n\n\n\n\nExample 3\n\n\nIf a subject has an\n\n80% chance of taking their medication this week,\n70% chance of taking their medication next week, and\n10% chance of not taking their medication either week,\n\nthen find the probability of them taking their medication exactly one of the two weeks.\n\n\n\nHint: Draw a Venn diagram labelling each of the parts to find the probability."
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#outcomes-events-sample-spaces",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#outcomes-events-sample-spaces",
    "title": "Lesson 2: Language of Probability and Simulation",
    "section": "Outcomes, events, sample spaces",
    "text": "Outcomes, events, sample spaces\n\n\nDefinition: Outcome\n\n\nThe possible results in a random phenomenon.\n\n\n\n\nDefinition: Sample Space\n\n\nThe sample space \\(S\\) is the set of all outcomes\n\n\n\n\nDefinition: Event\n\n\nAn event is a collection of some outcomes. An event can include multiple outcomes or no outcomes (a subset of the sample space).\n\n\nWhen thinking about events, think about outcomes that you might be asking the probability of. For example, what is the probability that you get a heads or a tails in one flip? (Answer: 1)"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#lets-define-probability-with-events-and-spaces",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#lets-define-probability-with-events-and-spaces",
    "title": "Lesson 2: Language of Probability and Simulation",
    "section": "Let’s define probability with events and spaces",
    "text": "Let’s define probability with events and spaces\nIf \\(S\\) is a finite sample space, with equally likely outcomes, then\n\\[\\mathbb{P}(A) = \\frac{|A|}{|S|}\\]\nIn human speak:\n\nFor equally likely outcomes, the probability that a certain event occurs is: the number of outcomes within the event of interest (\\(|A|\\)) divided by the total number of possible outcomes (\\(|S|\\))\n\n\\[\\mathbb{P}(A) = \\frac{\\text{total number of outcomes in event A}}{\\text{total number of outcomes in sample space}}\\]\n\nThus, it is important to be able to count the outcomes within an event"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#outcomes-events-sample-spaces",
    "href": "lessons/01_Probability/01_Probability.html#outcomes-events-sample-spaces",
    "title": "Lesson 1: Introduction to Probability",
    "section": "Outcomes, events, sample spaces",
    "text": "Outcomes, events, sample spaces\n\n\nDefinition: Outcome\n\n\nThe possible results in a random phenomenon.\n\n\n\n\nDefinition: Sample Space\n\n\nThe sample space \\(S\\) is the set of all outcomes\n\n\n\n\nDefinition: Event\n\n\nAn event is a collection of some outcomes. An event can include multiple outcomes or no outcomes (a subset of the sample space).\n\n\nWhen thinking about events, think about outcomes that you might be asking the probability of. For example, what is the probability that you get a heads or a tails in one flip? (Answer: 1)"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#coin-toss-example-1-coin-13",
    "href": "lessons/01_Probability/01_Probability.html#coin-toss-example-1-coin-13",
    "title": "Lesson 1: Introduction to Probability",
    "section": "Coin Toss Example: 1 coin (1/3)",
    "text": "Coin Toss Example: 1 coin (1/3)\n\n\n\n\nSingle coin toss\n\n\nSuppose you toss one coin.\n\nWhat are the possible outcomes?\n \nWhat is the sample space?\n \nWhat are the possible events?"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#coin-toss-example-1-coin-23",
    "href": "lessons/01_Probability/01_Probability.html#coin-toss-example-1-coin-23",
    "title": "Lesson 1: Introduction to Probability",
    "section": "Coin Toss Example: 1 coin (2/3)",
    "text": "Coin Toss Example: 1 coin (2/3)\nSuppose you toss one coin.\n\nWhat are the possible outcomes?\n\nHeads (\\(H\\))\nTails (\\(T\\))\n\n\n \n\n\nNote\n\n\nWhen something happens at random, such as a coin toss, there are several possible outcomes, and exactly one of the outcomes will occur."
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#coin-toss-example-1-coin-33",
    "href": "lessons/01_Probability/01_Probability.html#coin-toss-example-1-coin-33",
    "title": "Lesson 1: Introduction to Probability",
    "section": "Coin Toss Example: 1 coin (3/3)",
    "text": "Coin Toss Example: 1 coin (3/3)\n\n\n\nWhat is the sample space?\n\n\\(S =\\)\n\n\n \n \n\nWhat are the possible events?\n\n\n\n\n\n\n \n\n\n\n\nNote #1\n\n\nWe use curly brackets (\\(\\{\\}\\)) to denote a set (collecting a list of outcomes or values)\n\n\n\n\nNote #2\n\n\nThe total number of possible events is \\[2^{|S|}\\] where \\(|S|\\) is the total number of outcomes in the sample space. Also, possible events are not necessarily something that can actually occur (i.e. getting a heads and a tails on a single coin flip)"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#coin-toss-example-2-coins",
    "href": "lessons/01_Probability/01_Probability.html#coin-toss-example-2-coins",
    "title": "Lesson 1: Introduction to Probability",
    "section": "Coin Toss Example: 2 coins",
    "text": "Coin Toss Example: 2 coins\nSuppose you toss two coins.\n\nWhat is the sample space? Assume the coins are distinguishable\n\n\\(S =\\)\n\n\n \n\nWhat are some possible events?\n\n\\(A =\\) exactly one \\(H =\\)\n\\(B =\\) at least one \\(H =\\)"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#more-info-on-events-and-sample-spaces",
    "href": "lessons/01_Probability/01_Probability.html#more-info-on-events-and-sample-spaces",
    "title": "Lesson 1: Introduction to Probability",
    "section": "More info on events and sample spaces",
    "text": "More info on events and sample spaces\n\nWe usually use capital letters from the beginning of the alphabet to denote events. However, other letters might be chosen to be more descriptive.\n\nExamples: \\(A, B, C, A_1, A_2\\)\n\nWe can also define a new event as a combination of other events (next lesson)\n\nExamples: \\(A \\cup B\\) (union), \\(A \\cap B\\) (intersection), \\(A^C\\) (complement)\n\n\n \n\nWe use the notation \\(|S|\\) to denote the size of the sample space.\n\n \n\nThe total number of possible events is \\(2^{|S|}\\), which is the total number of possible subsets of \\(S\\).\n\n \n\nThe empty set, denoted by \\(\\emptyset\\), is the set containing no outcomes."
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#example-keep-sampling-until",
    "href": "lessons/01_Probability/01_Probability.html#example-keep-sampling-until",
    "title": "Lesson 1: Introduction to Probability",
    "section": "Example: Keep sampling until…",
    "text": "Example: Keep sampling until…\nSuppose you keep sampling people until you have someone with high blood pressure (BP)\n \nWhat is the sample space?\n\nLet \\(H =\\) denote someone with high BP.\nLet \\(H^C =\\) denote someone with not high blood pressure, such as low or regular BP.\n\n \n\nThen, \\(S =\\)"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#lets-define-probability-with-events-and-spaces",
    "href": "lessons/01_Probability/01_Probability.html#lets-define-probability-with-events-and-spaces",
    "title": "Lesson 1: Introduction to Probability",
    "section": "Let’s define probability with events and spaces",
    "text": "Let’s define probability with events and spaces\nIf \\(S\\) is a finite sample space, with equally likely outcomes, then\n\\[\\mathbb{P}(A) = \\frac{|A|}{|S|}\\]\nIn human speak:\n\nFor equally likely outcomes, the probability that a certain event occurs is: the number of outcomes within the event of interest (\\(|A|\\)) divided by the total number of possible outcomes (\\(|S|\\))\n\n\\[\\mathbb{P}(A) = \\frac{\\text{total number of outcomes in event A}}{\\text{total number of outcomes in sample space}}\\]\n\nThus, it is important to be able to count the outcomes within an event"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob_muddy_points.html",
    "href": "lessons/02_Lang_prob/02_Lang_prob_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "1. Why is the number of possible events \\(2^{|S|}\\)?\nIn class, we were wondering why/if \\(2^{|S|}\\) is the general formula for calculating the total number of possible events. We were specifically wondering if the \\(2\\) came from the fact that we had two options (heads and tails) for our outcome. Let’s work through the example of a 6-sided die to explain this further. The sample space is \\(S=\\{1, 2, 3, 4, 5, 6\\}\\). So is the total number of possible events \\(2^6\\) or \\(6^6\\) or something else? We can actually think about an event by using an indicator variable for each outcome of the sample space. An indicator variable is just a way to give us a yes/no answer to a question. So in this case, we are wondering: is this outcome a part of our event? If our event is \\(\\{1\\}\\) then for the outcome \\(1\\), the answer is “yes, the outcome is part of the event. For outcomes \\(2-6\\), the answer is”no, the outcome is not apart of the event.”\n\nFor each outcome, we have a “yes” or “no” answer. We can look at another example of an event. Let’s say our event is rolling an even number:\n\nFor \\(2\\), \\(4\\), and \\(6\\), the answer is “yes.” We can define the indicator variable for whether an outcome is in an event or not. The indicator gives a 1 or 0 for yes and no respectively.\n\nAs stated above, the \\(2\\) in \\(2^6\\) comes from the \\(2\\) options from our indicator. Each side has two options, and there are \\(6\\) sides. Thus, \\(2^6\\) possible events.\n\n\n2. What is an event??\nI think this will become clearer when we start thinking about events in the context of probability. When we think of events outside of probability, we may think of something we actually do or something that happens, like going to a concert or coming to class or missing the streetcar. In this case, we think of the event as the single thing (out of all the options) that actually occured. For example, if I’m taking the streetcar to class, I can think of two definitive options of what might occur: I miss the streetcar or I get on the streetcar. Only one of these things can occur, which I may call an event colloquially.\nIt is important to make the distinction with events defined within probability. Events are not necessarily a single thing that occurred. Instead it can be a collection of things that may occur. In the example of the streetcar, I can define my event to include both options. Thus, my event is that I make the streetcar or I miss it. Both of these things cannot happen simultaneously, but if I want to calculate the probability that I miss or make the streetcar, then it is helpful to have the event defined.\n\nAnd what is the difference between event and outcome?\nAn outcome is a single result. The two options in the above example, missing the streetcar or getting on the streetcar, are two potential outcomes. Events are the collection of 0, 1, or more outcomes. So the possible events are: the empty set, missing the streetcar, getting on the streetcar, or the set of missing the streetcar and getting on the streetcar.\n\n\n\n3. Confusion on the Venn Diagram for the high blood pressure example\nThis is in reference to the Chapter 1 notes on “BP example variation (3/3)” slide. I explained the event that at least one subject does not have high blood pressure using a venn diagram. In this venn diagram, I assumed \\(n=4\\), and I wanted to show that the union of complements is equal to the complement of unions: \\(\\bigcup\\limits_{i=1}^{n}H_i^C = \\Big(\\bigcap\\limits_{i=1}^{n}H_i\\Big)^C\\).\n\n Now we can look at \\(\\bigcup\\limits_{i=1}^{4}H_i^C\\). We first need to define \\(H_i^c\\)\n\n\n\n\n\n4. Proofs of propositions\nFurther explanations of the propositions can be found in the textbook from pages 24-27. For many of the explanations in class, I was working to produce a union of disjoint events, so that the probability could easily be calculated. Proposition 3 and 4 were specifically mentioned, so I will include some writing notes on them here:\n\nProposition 3\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\nIn this proposition, I want to define event \\(B\\) as a union of disjoint events so that I can show \\(P(B)\\) is the sum of \\(P(A)\\) and some greater-than-or-equal-to 0 probability event. If the following is my venn diagram of A and B:\n\n\n\n\n\nThen I can define B as the union of disjoint events: \nIf we then take the probability of each side of the equation \\(B = A \\cup (A^c \\cap B)\\), we get \\[P(B) = P\\big(A \\cup (A^c \\cap B)\\big)\\]\nSince events \\(A\\) and \\(A^c \\cap B\\) are disjoint, the probability of their union is just: \\[P(A) + P(A^c \\cap B)\\]\nThus, our equation is now \\[P(B) = P(A) + P(A^c \\cap B)\\]\nFrom Axiom 1, we know for event \\(A^c \\cap B\\), \\(P(A^c \\cap B) \\geq 0\\).\nSo the probability of event B is the sum of the probability of event A and an event that is \\(\\geq\\) 0. This means \\(P(B) \\geq P(A)\\).\n\n\nProposition 4\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)\n\n\nFrom the pictures above, we can see some similar disjoint events.\nIf we look back at \\(A \\cup B\\), we can start manipulating the right side of the equation:\n\n \n\n\n\n5. Example at end of Chapter 2 slides (Venn Diagram)\nI will post this in the previous week’s Muddy Points as well. Please follow this link for my work through of the example. And here is the PDF with my work.\nSub-question: why don’t we just multiply the probability of A and B to get the intersection? This is a specific property of probability when A and B are independent. Only when A and B are independent can we conclude that \\(P(A \\cap B) = P(A)P(B)\\).\n\n\n6. Partition of events\nWe’ve been working with event partitions throughout Chapter 2, but we have not formally identified them. Partitions are advantageous to define for two reasons:\n\nThe partitions may be easier to calculate. We can then use the partitions to reconstruct other probabilities that may be more difficult to calculate\nPartitions have nice properties as a consequence of being disjoint. For example, the probability of the union of partitions is the sum of the probabilities across each partition: \\[P\\bigg(\\bigcup_{i=1}^n A_i\\bigg) = P(A_1)P(A_2)P(A_3) \\cdot \\cdot \\cdot P(A_n)\\]"
  },
  {
    "objectID": "draft_schedule.html",
    "href": "draft_schedule.html",
    "title": "DRAFT Schedule",
    "section": "",
    "text": "Last year, did material in 17 classes. Can I make that more efficient??\n\n\n\n\n\n\n\n\n\n\nclass\nLesson\nTopic\nTB\nThings covered\n\n\n\n\n1\n\nWelcome\n\nHello and stuff\n\n\n\n1\nIntroduction to Probability\n1.1, 2.1, 2.2, 2.4\nrandomness, probability, single coin toss + simulation, def of prob, outcomes, events, sample space\n\n\n2\n2\nLanguage of Probability and Simulations\n2.2, 2.4,\nunion, intersections, complements, mutually exclusive, prob axioms, prob properties, de morgans laws, partitions\n\n\n3\n\nIntroduction to Simulations\n2.5\n\n\n\n4\n3\nRules of probability\n3.5, 2.7, 3.4, 3.3\nmultiplication rule, law of total probability, bayes rule, conditional prob, independence, fun link: https://pudding.cool/2018/04/birthday-paradox/\n\n\n5\n\nEqually Likely Outcomes (some counting)\n3.6\n\n\n\n6\npre-24\nOptional class: Calculus Review\n\n\n\n\n7\n7\nRandom Variables\n2.3, 4.1\n\n\n\n\n8\npmfs\n4.2\n\n\n\n8\n\npdfs\n4.3\n\n\n\n\n\nCDFs\n4.4\n\n\n\n9\n9\nTranformations of distributions, joint distributions\n4.6, 4.7\n\n\n\n10\n\nIndependence and Conditioning (Joint Distributions)\n4.8, 4.9\n\n\n\n11\n10\nExpected Values\n5.1\n\n\n\n\n11\nExpected Values of sums\n5.5\n\n\n\n\n\nconditional expect value\n5.6\n\n\n\n12\n12\nVariance\n5.2, 5.3\n\n\n\n13\n14-20\nSome Important Discrete RVs\n6\n\n\n\n14\n31-35\nSome Important Continuous RVs\n7\n\n\n\n15\n37\nCentral limit theorem\n8.1\n\n\n\n\n43\nMoment generating functions\n\n\n\n\n16\n\nMGF part 2??\n\n\n\n\n17"
  },
  {
    "objectID": "draft_schedule.html#footnotes",
    "href": "draft_schedule.html#footnotes",
    "title": "DRAFT Schedule",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHere’s a link to Meike’s recordings for certain problems that I said to do at home.↩︎\nHere’s a link to Meike’s recordings for certain problems that I said to do at home.↩︎\nHere’s a link to Meike’s recordings for certain problems that I said to do at home.↩︎\nHere’s a link to Meike’s recordings for certain problems that I said to do at home.↩︎"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html",
    "title": "Lesson 2: Language of Probability",
    "section": "",
    "text": "building important definitions so that we have a mutual understanding of the language of probability\n\nDefine basic terms related to events such as events, outcomes, and sample space.\nUse proper set notation for events\nCharacterize possible outcomes, when something random occurs\nDescribe events into which outcomes can be grouped\nDefine important terms and rules within set theory such as unions, intersections, complements, mutually exclusive, and De Morgan’s Laws"
  },
  {
    "objectID": "lessons copy/10_CDFs/10_CDFs.html#what-is-a-cumulative-distribution-function",
    "href": "lessons copy/10_CDFs/10_CDFs.html#what-is-a-cumulative-distribution-function",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "What is a cumulative distribution function?",
    "text": "What is a cumulative distribution function?\n\n\nCumulative distribution function\n\n\nThe cumulative distribution function (cdf) of a continuous random variable \\(X\\), is the function \\(F_X(x)\\), such that for all real values of \\(x\\), \\[F_X(x)= \\mathbb{P}(X \\leq x) = \\int_{-\\infty}^x f_X(s)ds\\]\n\n\nRemarks: In general, \\(F_X(x)\\) is increasing and\n\n\\(\\lim_{x\\rightarrow -\\infty} F_X(x)= 0\\)\n\\(\\lim_{x\\rightarrow \\infty} F_X(x)= 1\\)\n\\(P(X &gt; a) = 1 - P(X \\leq a) = 1 - F_X(a)\\)\n\\(P(a \\leq X \\leq b) = F_X(b) - F_X(a)\\)"
  },
  {
    "objectID": "lessons copy/10_CDFs/10_CDFs.html#lets-demonstrate-the-cdf-with-an-example",
    "href": "lessons copy/10_CDFs/10_CDFs.html#lets-demonstrate-the-cdf-with-an-example",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the CDF with an example",
    "text": "Let’s demonstrate the CDF with an example\n\n\n\n\nExample 2\n\n\nLet \\(f_X(x)= 2\\), for \\(2.5 \\leq x \\leq 3\\). Find \\(F_X(x)\\)."
  },
  {
    "objectID": "lessons copy/10_CDFs/10_CDFs.html#derivatives-of-the-cdf",
    "href": "lessons copy/10_CDFs/10_CDFs.html#derivatives-of-the-cdf",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Derivatives of the CDF",
    "text": "Derivatives of the CDF\n\n\nTheorem 1\n\n\nIf \\(X\\) is a continuous random variable with pdf \\(f_X(x)\\) and cdf \\(F_X(x)\\), then for all real values of \\(x\\) at which \\(F'_X(x)\\) exists, \\[\\frac{d}{dx} F_X(x)= F'_X(x) = f_X(x)\\]"
  },
  {
    "objectID": "lessons copy/10_CDFs/10_CDFs.html#finding-the-pdf-from-a-cdf",
    "href": "lessons copy/10_CDFs/10_CDFs.html#finding-the-pdf-from-a-cdf",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Finding the PDF from a CDF",
    "text": "Finding the PDF from a CDF\n\n\n\n\nExample 3\n\n\nLet \\(X\\) be a RV with cdf \\[F_X(x)= \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x &lt; 2.5 \\\\\n            2x-5 & \\quad 2.5 \\leq x \\leq 3 \\\\\n            1 & \\quad x &gt; 3\n        \\end{array}\n    \\right.\\] Find the pdf \\(f_X(x)\\)."
  },
  {
    "objectID": "lessons copy/10_CDFs/10_CDFs.html#lets-go-through-another-example-17",
    "href": "lessons copy/10_CDFs/10_CDFs.html#lets-go-through-another-example-17",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (1/7)",
    "text": "Let’s go through another example (1/7)\n\n\n\n\nExample 4\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nShow \\(f_X(x)\\) is a pdf.\nFind \\(\\mathbb{P}(1 \\leq X \\leq 3)\\).\nFind \\(F_X(x)\\).\nGiven \\(F_X(x)\\), find \\(f_X(x)\\).\nFind \\(\\mathbb{P}(X \\geq 1 | X \\leq 3)\\).\nFind the median of the distribution of \\(X\\)."
  },
  {
    "objectID": "lessons copy/10_CDFs/10_CDFs.html#lets-go-through-another-example-27",
    "href": "lessons copy/10_CDFs/10_CDFs.html#lets-go-through-another-example-27",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (2/7)",
    "text": "Let’s go through another example (2/7)\n\n\n\n\nExample 4.1\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nShow \\(f_X(x)\\) is a pdf."
  },
  {
    "objectID": "lessons copy/10_CDFs/10_CDFs.html#lets-go-through-another-example-37",
    "href": "lessons copy/10_CDFs/10_CDFs.html#lets-go-through-another-example-37",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (3/7)",
    "text": "Let’s go through another example (3/7)\n\n\n\nDo this problem at home for extra practice.\n\n\n\n\n\n\n\nExample 4.2\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nFind \\(\\mathbb{P}(1 \\leq X \\leq 3)\\)."
  },
  {
    "objectID": "lessons copy/10_CDFs/10_CDFs.html#lets-go-through-another-example-47",
    "href": "lessons copy/10_CDFs/10_CDFs.html#lets-go-through-another-example-47",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (4/7)",
    "text": "Let’s go through another example (4/7)\n\n\n\n\nExample 4.3\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nFind \\(F_X(x)\\)."
  },
  {
    "objectID": "lessons copy/10_CDFs/10_CDFs.html#lets-go-through-another-example-57",
    "href": "lessons copy/10_CDFs/10_CDFs.html#lets-go-through-another-example-57",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (5/7)",
    "text": "Let’s go through another example (5/7)\n\n\n\nDo this problem at home for extra practice.\n\n\n\n\n\n\n\nExample 4.4\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nGiven \\(F_X(x)\\), find \\(f_X(x)\\)."
  },
  {
    "objectID": "lessons copy/10_CDFs/10_CDFs.html#lets-go-through-another-example-67",
    "href": "lessons copy/10_CDFs/10_CDFs.html#lets-go-through-another-example-67",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (6/7)",
    "text": "Let’s go through another example (6/7)\n\n\n\n\nExample 4.5\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nFind \\(\\mathbb{P}(X \\geq 1 | X \\leq 3)\\)."
  },
  {
    "objectID": "lessons copy/10_CDFs/10_CDFs.html#lets-go-through-another-example-77",
    "href": "lessons copy/10_CDFs/10_CDFs.html#lets-go-through-another-example-77",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (7/7)",
    "text": "Let’s go through another example (7/7)\n\n\n\n\nExample 4.6\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nFind the median of the distribution of \\(X\\)."
  },
  {
    "objectID": "lessons copy/09_pdfs/24_01_Continuous_rv.html#learning-objectives",
    "href": "lessons copy/09_pdfs/24_01_Continuous_rv.html#learning-objectives",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDistinguish between discrete and continuous random variables.\nCalculate probabilities for continuous random variables.\nCalculate and graph a density (i.e., probability density function, PDF).\nCalculate and graph a CDF (i.e., a cumulative distribution function)"
  },
  {
    "objectID": "lessons copy/09_pdfs/24_01_Continuous_rv.html#discrete-vs.-continuous-rvs",
    "href": "lessons copy/09_pdfs/24_01_Continuous_rv.html#discrete-vs.-continuous-rvs",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Discrete vs. Continuous RVs",
    "text": "Discrete vs. Continuous RVs\n\n\n\nFor a discrete RV, the set of possible values is either finite or can be put into a countably infinite list.\n \nContinuous RVs take on values from continuous intervals, or unions of continuous intervals\n\n\n\n\n\nFigure from Introduction to Probability TB (pg. 301)"
  },
  {
    "objectID": "lessons copy/09_pdfs/24_01_Continuous_rv.html#how-to-define-probabilities-for-continuous-rvs",
    "href": "lessons copy/09_pdfs/24_01_Continuous_rv.html#how-to-define-probabilities-for-continuous-rvs",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "How to define probabilities for continuous RVs?",
    "text": "How to define probabilities for continuous RVs?\n\n\nDiscrete RV \\(X\\):\n\n\n\n\n\n\n\n\n\n\npmf: \\(p_X(x) = P(X=x)\\)\n\n\nContinuous RV \\(X\\):\n\n\n\n\n\n\n\n\n\n\ndensity: \\(f_X(x)\\)\nprobability: \\(P(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\)"
  },
  {
    "objectID": "lessons copy/09_pdfs/24_01_Continuous_rv.html#what-is-a-probability-density-function",
    "href": "lessons copy/09_pdfs/24_01_Continuous_rv.html#what-is-a-probability-density-function",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "What is a probability density function?",
    "text": "What is a probability density function?\n\n\nProbability density function\n\n\nThe probability distribution, or probability density function (pdf), of a continuous random variable \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\),\n\\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\]\n\n\nRemarks:\n\nNote that \\(f_X(x) \\neq \\mathbb{P}(X=x)\\)!!!\nIn order for \\(f_X(x)\\) to be a pdf, it needs to satisfy the properties\n\n\\(f_X(x) \\geq 0\\) for all \\(x\\)\n\\(\\int_{-\\infty}^{\\infty} f_X(x)dx=1\\)"
  },
  {
    "objectID": "lessons copy/09_pdfs/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-15",
    "href": "lessons copy/09_pdfs/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-15",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (1/5)",
    "text": "Let’s demonstrate the PDF with an example (1/5)\n\n\n\n\nExample 1.1\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind the value of \\(a\\) so that \\(f_X(x)\\) is a pdf."
  },
  {
    "objectID": "lessons copy/09_pdfs/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-25",
    "href": "lessons copy/09_pdfs/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-25",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (2/5)",
    "text": "Let’s demonstrate the PDF with an example (2/5)\n\n\n\n\nExample 1.2\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(2.7 \\leq X \\leq 2.9)\\)."
  },
  {
    "objectID": "lessons copy/09_pdfs/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-35",
    "href": "lessons copy/09_pdfs/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-35",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (3/5)",
    "text": "Let’s demonstrate the PDF with an example (3/5)\n\n\n\n\nExample 1.3\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(2.7 &lt; X \\leq 2.9)\\)."
  },
  {
    "objectID": "lessons copy/09_pdfs/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-45",
    "href": "lessons copy/09_pdfs/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-45",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (4/5)",
    "text": "Let’s demonstrate the PDF with an example (4/5)\n\n\n\n\nExample 1.4\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(X = 2.9)\\)."
  },
  {
    "objectID": "lessons copy/09_pdfs/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-55",
    "href": "lessons copy/09_pdfs/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-55",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (5/5)",
    "text": "Let’s demonstrate the PDF with an example (5/5)\n\n\n\n\nExample 1.5\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(X \\leq 2.8)\\)."
  },
  {
    "objectID": "lessons copy/Continuous_distributions.html",
    "href": "lessons copy/Continuous_distributions.html",
    "title": "Continuous Random Variables",
    "section": "",
    "text": "Scenario: Events are equally likely to happen anywhere or anytime in an interval of values\nShorthand: \\(X \\sim \\text{U}[a,b]\\)\n\n\\[\nf_X(x) = \\dfrac{1}{b-a}, \\text{ for }a \\leq x \\leq b\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;a \\quad \\\\\n            \\dfrac{x-a}{b-a} & \\quad a \\leq x \\leq b\\quad \\\\\n            1 & \\quad x&gt;b \\quad\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{a+b}{2} \\text{, } \\text{ Var}(X) = \\dfrac{(b-a)^2}{12}\\]"
  },
  {
    "objectID": "lessons copy/Continuous_distributions.html#properties-of-continuous-uniform-rvs",
    "href": "lessons copy/Continuous_distributions.html#properties-of-continuous-uniform-rvs",
    "title": "Continuous Random Variables",
    "section": "",
    "text": "Scenario: Events are equally likely to happen anywhere or anytime in an interval of values\nShorthand: \\(X \\sim \\text{U}[a,b]\\)\n\n\\[\nf_X(x) = \\dfrac{1}{b-a}, \\text{ for }a \\leq x \\leq b\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;a \\quad \\\\\n            \\dfrac{x-a}{b-a} & \\quad a \\leq x \\leq b\\quad \\\\\n            1 & \\quad x&gt;b \\quad\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{a+b}{2} \\text{, } \\text{ Var}(X) = \\dfrac{(b-a)^2}{12}\\]"
  },
  {
    "objectID": "lessons copy/Continuous_distributions.html#properties-of-exponential-rvs",
    "href": "lessons copy/Continuous_distributions.html#properties-of-exponential-rvs",
    "title": "Continuous Random Variables",
    "section": "Properties of exponential RVs",
    "text": "Properties of exponential RVs\n\nScenario: Modeling the time until the next (first) event\nContinuous analog to the geometric distribution!\nShorthand: \\(X \\sim \\text{Exp}(\\lambda)\\)\n\n\\[\nf_X(x) = \\lambda e^{-\\lambda x}\\text{ for } x&gt;0, \\lambda&gt;0\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;0 \\quad \\\\\n            1 - e^{-\\lambda x} & \\quad x\\geq0 \\\\\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{1}{\\lambda}\\] \\[\\text{Var}(X) = \\dfrac{1}{\\lambda^2}\\]"
  },
  {
    "objectID": "lessons copy/Continuous_distributions.html#properties-of-gamma-rvs",
    "href": "lessons copy/Continuous_distributions.html#properties-of-gamma-rvs",
    "title": "Continuous Random Variables",
    "section": "Properties of gamma RVs",
    "text": "Properties of gamma RVs\n\nScenario: Modeling the time until the \\(r^{th}\\) event.\nContinuous analog to the Negative Binomial distribution\nShorthand: \\(X \\sim \\text{Gamma}(r, \\lambda)\\)\n\n\\[\nf_X(x) = \\dfrac{\\lambda^r}{\\Gamma(r)}x^{r-1} e^{-\\lambda x}\\text{ for } x&gt;0, \\lambda&gt;0, \\Gamma(r) = (r-1)!\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;0 \\quad \\\\\n            1 - e^{-\\lambda x}\\displaystyle\\sum_{j=0}^{r-1}\\dfrac{(\\lambda x)^j}{j!}  & \\quad x\\geq0 \\\\\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{r}{\\lambda}\\text{, }\\text{ Var}(X) = \\dfrac{r}{\\lambda^2}\\]\nCommon to see \\(\\alpha = r\\) and \\(\\beta = \\lambda\\)"
  },
  {
    "objectID": "lessons copy/Continuous_distributions.html#properties-of-normal-rvs",
    "href": "lessons copy/Continuous_distributions.html#properties-of-normal-rvs",
    "title": "Continuous Random Variables",
    "section": "Properties of Normal RVs",
    "text": "Properties of Normal RVs\n\nNo scenario description here because the Normal distribution is so universal\n\nCentral Limit Theorem (next class) makes it applicable to many types of events\n\nShorthand: \\(X \\sim \\text{Normal}(\\mu, \\sigma^2)\\)\n\n\\[\nf_X(x) = \\dfrac{1}{\\sqrt{2\\pi \\sigma^2}}e^{-(x-\\mu)^2/(2\\sigma^2)} \\text{, for} -inf &lt; x &lt; inf\n\\]\n\\[\\text{E}(X) = \\mu \\] \\[\\text{Var}(X) = \\sigma^2\\]"
  },
  {
    "objectID": "lessons copy/09_pdfs/24_01_Continuous_rv_key_info.html",
    "href": "lessons copy/09_pdfs/24_01_Continuous_rv_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Graded: HW 4 assignment and HW 3 solutions\nCalendly is up!!"
  },
  {
    "objectID": "lessons copy/09_pdfs/24_01_Continuous_rv_key_info.html#announcements",
    "href": "lessons copy/09_pdfs/24_01_Continuous_rv_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Graded: HW 4 assignment and HW 3 solutions\nCalendly is up!!"
  },
  {
    "objectID": "lessons copy/09_pdfs/24_01_Continuous_rv_key_info.html#key-dates",
    "href": "lessons copy/09_pdfs/24_01_Continuous_rv_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 5 due\nSunday: HW 4 solutions due\nWeek of 11/11\n\nMake a meeting with me\n11/12: recordings due if you are making that\nNow on Sakai"
  },
  {
    "objectID": "lessons copy/02_Lang_prob/02_Lang_prob.html",
    "href": "lessons copy/02_Lang_prob/02_Lang_prob.html",
    "title": "Lesson 2: Language of Probability",
    "section": "",
    "text": "building important definitions so that we have a mutual understanding of the language of probability\n\nDefine basic terms related to events such as events, outcomes, and sample space.\nUse proper set notation for events\nCharacterize possible outcomes, when something random occurs\nDescribe events into which outcomes can be grouped\nDefine important terms and rules within set theory such as unions, intersections, complements, mutually exclusive, and De Morgan’s Laws"
  },
  {
    "objectID": "lessons copy/02_Lang_prob/02_Lang_prob.html#learning-objectives",
    "href": "lessons copy/02_Lang_prob/02_Lang_prob.html#learning-objectives",
    "title": "Lesson 2: Language of Probability",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nbuilding important definitions so that we have a mutual understanding of the language of probability\n\nDefine basic terms related to events such as events, outcomes, and sample space.\nUse proper set notation for events\nCharacterize possible outcomes, when something random occurs\nDescribe events into which outcomes can be grouped\nDefine important terms and rules within set theory such as unions, intersections, complements, mutually exclusive, and De Morgan’s Laws"
  },
  {
    "objectID": "lessons copy/02_Lang_prob/02_Lang_prob.html#where-are-we",
    "href": "lessons copy/02_Lang_prob/02_Lang_prob.html#where-are-we",
    "title": "Lesson 2: Language of Probability",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/02_Lang_prob/02_Lang_prob.html#set-theory-12",
    "href": "lessons copy/02_Lang_prob/02_Lang_prob.html#set-theory-12",
    "title": "Lesson 2: Language of Probability",
    "section": "Set Theory (1/2)",
    "text": "Set Theory (1/2)\n\n\n \n\n\nDefinition: Union\n\n\nThe union of events \\(A\\) and \\(B\\), denoted by \\(A \\cup B\\), contains all outcomes that are in \\(A\\) or \\(B\\) or both\n\n\n\n\nDefinition: Intersection\n\n\nThe intersection of events \\(A\\) and \\(B\\), denoted by \\(A \\cap B\\), contains all outcomes that are both in \\(A\\) and \\(B\\).\n\n\n\nVenn diagrams"
  },
  {
    "objectID": "lessons copy/02_Lang_prob/02_Lang_prob.html#set-theory-22",
    "href": "lessons copy/02_Lang_prob/02_Lang_prob.html#set-theory-22",
    "title": "Lesson 2: Language of Probability",
    "section": "Set Theory (2/2)",
    "text": "Set Theory (2/2)\n\n\n \n\n\nDefinition: Complement\n\n\nThe complement of event \\(A\\), denoted by \\(A^C\\) or \\(A'\\), contains all outcomes in the sample space \\(S\\) that are not in \\(A\\) .\n\n\n\n\nDefinition: Mutually Exclusive\n\n\nEvents \\(A\\) and \\(B\\) are mutually exclusive, or disjoint, if they have no outcomes in common. In this case \\(A \\cap B = \\emptyset\\), where \\(\\emptyset\\) is the empty set.\n\n\n\nVenn diagrams"
  },
  {
    "objectID": "lessons copy/02_Lang_prob/02_Lang_prob.html#probability-axioms-1",
    "href": "lessons copy/02_Lang_prob/02_Lang_prob.html#probability-axioms-1",
    "title": "Lesson 2: Language of Probability",
    "section": "Probability Axioms",
    "text": "Probability Axioms\n\n\n\n\nAxiom 1\n\n\nFor every event \\(A\\), \\(0\\leq\\mathbb{P}(A)\\leq 1\\). Probability is between 0 and 1.\n\n\n\n\nAxiom 2\n\n\nFor the sample space \\(S\\), \\(\\mathbb{P}(S)=1\\).\n\n\n\n\nAxiom 3\n\n\nIf \\(A_1, A_2, A_3, \\ldots\\), is a collection of disjoint events, then \\[\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i).\\] The probability of at least one \\(A_i\\) is the sum of the individual probabilities of each."
  },
  {
    "objectID": "lessons copy/02_Lang_prob/02_Lang_prob.html#some-probability-properties-1",
    "href": "lessons copy/02_Lang_prob/02_Lang_prob.html#some-probability-properties-1",
    "title": "Lesson 2: Language of Probability",
    "section": "Some probability properties",
    "text": "Some probability properties\nUsing the Axioms, we can prove all other probability properties! Events A, B, and C are not necessarily disjoint!\n\n\n\n\nProposition 1\n\n\nFor any event \\(A\\), \\(\\mathbb{P}(A)= 1 - \\mathbb{P}(A^C)\\)\n\n\n\n\nProposition 2\n\n\n\\(\\mathbb{P}(\\emptyset)=0\\)\n\n\n\n\nProposition 3\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\n\n\n\n\n\nProposition 4\n\n\n\\[\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\] where \\(A\\) and \\(B\\) are not necessarily disjoint\n\n\n\n\nProposition 5\n\n\n\\(\\begin{aligned} \\mathbb{P}(A \\cup B & \\cup C) = \\mathbb{P}(A) + \\mathbb{P}(B) + \\\\ & \\mathbb{P}(C) - \\mathbb{P}(A \\cap B) - \\mathbb{P}(A \\cap C) - \\\\ & \\mathbb{P}(B \\cap C) + \\mathbb{P}(A \\cap B \\cap C) \\end{aligned}\\)"
  },
  {
    "objectID": "lessons copy/02_Lang_prob/02_Lang_prob.html#proposition-1-proof",
    "href": "lessons copy/02_Lang_prob/02_Lang_prob.html#proposition-1-proof",
    "title": "Lesson 2: Language of Probability",
    "section": "Proposition 1 Proof",
    "text": "Proposition 1 Proof\n\n\n\n\nProposition 1\n\n\nFor any event \\(A\\), \\(\\mathbb{P}(A)= 1 - \\mathbb{P}(A^C)\\)\n\n\n\n\n\nUse Axioms!\n\n\nA1: \\(0\\leq\\mathbb{P}(A)\\leq 1\\)\nA2: \\(\\mathbb{P}(S)=1\\)\nA3: For disjoint \\(A_i\\),\n\\(\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i)\\)"
  },
  {
    "objectID": "lessons copy/02_Lang_prob/02_Lang_prob.html#proposition-2-proof",
    "href": "lessons copy/02_Lang_prob/02_Lang_prob.html#proposition-2-proof",
    "title": "Lesson 2: Language of Probability",
    "section": "Proposition 2 Proof",
    "text": "Proposition 2 Proof\n\n\n\n\nProposition 2\n\n\n\\(\\mathbb{P}(\\emptyset)=0\\)\n\n\n\n\n\nUse Axioms!\n\n\nA1: \\(0\\leq\\mathbb{P}(A)\\leq 1\\)\nA2: \\(\\mathbb{P}(S)=1\\)\nA3: For disjoint \\(A_i\\),\n\\(\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i)\\)"
  },
  {
    "objectID": "lessons copy/02_Lang_prob/02_Lang_prob.html#proposition-3-proof",
    "href": "lessons copy/02_Lang_prob/02_Lang_prob.html#proposition-3-proof",
    "title": "Lesson 2: Language of Probability",
    "section": "Proposition 3 Proof",
    "text": "Proposition 3 Proof\n\n\n\n\nProposition 3\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\n\n\n\n\n\nUse Axioms!\n\n\nA1: \\(0\\leq\\mathbb{P}(A)\\leq 1\\)\nA2: \\(\\mathbb{P}(S)=1\\)\nA3: For disjoint \\(A_i\\),\n\\(\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i)\\)"
  },
  {
    "objectID": "lessons copy/02_Lang_prob/02_Lang_prob.html#proposition-4-visual-proof",
    "href": "lessons copy/02_Lang_prob/02_Lang_prob.html#proposition-4-visual-proof",
    "title": "Lesson 2: Language of Probability",
    "section": "Proposition 4 Visual Proof",
    "text": "Proposition 4 Visual Proof\n\n\nProposition 4\n\n\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)"
  },
  {
    "objectID": "lessons copy/02_Lang_prob/02_Lang_prob.html#proposition-5-visual-proof",
    "href": "lessons copy/02_Lang_prob/02_Lang_prob.html#proposition-5-visual-proof",
    "title": "Lesson 2: Language of Probability",
    "section": "Proposition 5 Visual Proof",
    "text": "Proposition 5 Visual Proof\n\n\nProposition 5\n\n\n\\(\\mathbb{P}(A \\cup B \\cup C) = \\mathbb{P}(A) + \\mathbb{P}(B) + \\mathbb{P}(C) - \\mathbb{P}(A \\cap B) - \\mathbb{P}(A \\cap C) - \\mathbb{P}(B \\cap C) + \\mathbb{P}(A \\cap B \\cap C)\\)"
  },
  {
    "objectID": "lessons copy/02_Lang_prob/02_Lang_prob.html#some-final-remarks-on-these-proposition",
    "href": "lessons copy/02_Lang_prob/02_Lang_prob.html#some-final-remarks-on-these-proposition",
    "title": "Lesson 2: Language of Probability",
    "section": "Some final remarks on these proposition",
    "text": "Some final remarks on these proposition\n\nNotice how we spliced events into multiple disjoint events\n\nIt is often easier to work with disjoint events\n\n\n \n\nIf we want to calculate the probability for one event, we may need to get creative with how we manipulate other events and the sample space\n\nHelps us use any incomplete information we have"
  },
  {
    "objectID": "lessons copy/02_Lang_prob/02_Lang_prob.html#de-morgans-laws",
    "href": "lessons copy/02_Lang_prob/02_Lang_prob.html#de-morgans-laws",
    "title": "Lesson 2: Language of Probability",
    "section": "De Morgan’s Laws",
    "text": "De Morgan’s Laws\n\n\nTheorem: De Morgan’s 1st Law\n\n\nFor a collection of events (sets) \\(A_1, A_2, A_3, \\ldots\\)\n\\[\\bigcap\\limits_{i=1}^{n}A_i^C = \\Big(\\bigcup\\limits_{i=1}^{n}A_i\\Big)^C\\]\n\n\n“all not A = \\((\\)at least one event A\\()^C\\)” or “intersection of the complements is the complement of the union”\n\n\nTheorem: De Morgan’s 2nd Law\n\n\nFor a collection of events (sets) \\(A_1, A_2, A_3, \\ldots\\)\n\\[\\bigcup\\limits_{i=1}^{n}A_i^C = \\Big(\\bigcap\\limits_{i=1}^{n}A_i\\Big)^C\\]\n\n\n“at least one event not A = \\((\\)all A\\()^C\\)” or “union of complements is complement of the intersection”"
  },
  {
    "objectID": "lessons copy/02_Lang_prob/02_Lang_prob.html#bp-example-variation-13",
    "href": "lessons copy/02_Lang_prob/02_Lang_prob.html#bp-example-variation-13",
    "title": "Lesson 2: Language of Probability",
    "section": "BP example variation (1/3)",
    "text": "BP example variation (1/3)\n\nSuppose you have \\(n\\) subjects in a study.\nLet \\(H_i\\) be the event that person \\(i\\) has high BP, for \\(i=1\\ldots n\\).\n\n \nUse set theory notation to denote the following events:\n\nEvent subject \\(i\\) does not have high BP\nEvent all \\(n\\) subjects have high BP\nEvent at least one subject has high BP\nEvent all of them do not have high BP\nEvent at least one subject does not have high BP"
  },
  {
    "objectID": "lessons copy/02_Lang_prob/02_Lang_prob.html#bp-example-variation-23",
    "href": "lessons copy/02_Lang_prob/02_Lang_prob.html#bp-example-variation-23",
    "title": "Lesson 2: Language of Probability",
    "section": "BP example variation (2/3)",
    "text": "BP example variation (2/3)\n\nSuppose you have \\(n\\) subjects in a study.\nLet \\(H_i\\) be the event that person \\(i\\) has high BP, for \\(i=1\\ldots n\\).\n\nUse set theory notation to denote the following events:\n\nEvent subject \\(i\\) does not have high BP\n \nEvent all \\(n\\) subjects have high BP\n \n \nEvent at least one subject has high BP"
  },
  {
    "objectID": "lessons copy/02_Lang_prob/02_Lang_prob.html#bp-example-variation-33",
    "href": "lessons copy/02_Lang_prob/02_Lang_prob.html#bp-example-variation-33",
    "title": "Lesson 2: Language of Probability",
    "section": "BP example variation (3/3)",
    "text": "BP example variation (3/3)\n\nEvent all of them do not have high BP\n \n \n \nEvent at least one subject does not have high BP"
  },
  {
    "objectID": "lessons copy/02_Lang_prob/02_Lang_prob.html#remarks-on-de-morgans-laws",
    "href": "lessons copy/02_Lang_prob/02_Lang_prob.html#remarks-on-de-morgans-laws",
    "title": "Lesson 2: Language of Probability",
    "section": "Remarks on De Morgan’s Laws",
    "text": "Remarks on De Morgan’s Laws\n\nThese laws also hold for infinite collections of events.\n \nDraw Venn diagrams to convince yourself that these are true!\n \nThese laws are very useful when calculating probabilities.\n\nThis is because calculating the probability of the intersection of events is often much easier than the union of events.\nThis is not obvious right now, but we will see in the coming chapters why."
  },
  {
    "objectID": "lessons copy/02_Lang_prob/02_Lang_prob.html#partitions-1",
    "href": "lessons copy/02_Lang_prob/02_Lang_prob.html#partitions-1",
    "title": "Lesson 2: Language of Probability",
    "section": "Partitions",
    "text": "Partitions\n\n\n\n\nDefinition: Partition\n\n\nA set of events \\(\\{A_i\\}_{i=1}^{n}\\) create a partition of \\(A\\), if\n\nthe \\(A_i\\)’s are disjoint (mutually exclusive) and\n\\(\\bigcup \\limits_{i=1}^n A_i = A\\)\n\n\n\n\n\nExample 2\n\n\n\nIf \\(A \\subset B\\), then \\(\\{A, B \\cap A^C\\}\\) is a partition of \\(B\\).\nIf \\(S = \\bigcup \\limits_{i=1}^n A_i\\), and the \\(A_i\\)’s are disjoint, then the \\(A_i\\)’s are a partition of the sample space.\n\n\n\n\n\n\nCreating partitions is sometimes used to help calculate probabilities, since by Axiom 3 we can add the probabilities of disjoint events."
  },
  {
    "objectID": "lessons copy/02_Lang_prob/02_Lang_prob.html#weekly-medications",
    "href": "lessons copy/02_Lang_prob/02_Lang_prob.html#weekly-medications",
    "title": "Lesson 2: Language of Probability",
    "section": "Weekly medications",
    "text": "Weekly medications\n\n\n\n\nExample 3\n\n\nIf a subject has an\n\n80% chance of taking their medication this week,\n70% chance of taking their medication next week, and\n10% chance of not taking their medication either week,\n\nthen find the probability of them taking their medication exactly one of the two weeks.\n\n\n\nHint: Draw a Venn diagram labelling each of the parts to find the probability."
  },
  {
    "objectID": "lessons copy/07_Random_Variables/07_Random_Variables.html",
    "href": "lessons copy/07_Random_Variables/07_Random_Variables.html",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "",
    "text": "Map the sample space to the set of real numbers using a discrete and continuous random variable\nDistinguish between discrete and continuous random variables from a written description"
  },
  {
    "objectID": "lessons copy/07_Random_Variables/07_Random_Variables.html#learning-objectives",
    "href": "lessons copy/07_Random_Variables/07_Random_Variables.html#learning-objectives",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "",
    "text": "Map the sample space to the set of real numbers using a discrete and continuous random variable\nDistinguish between discrete and continuous random variables from a written description"
  },
  {
    "objectID": "lessons copy/07_Random_Variables/07_Random_Variables.html#where-are-we",
    "href": "lessons copy/07_Random_Variables/07_Random_Variables.html#where-are-we",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/07_Random_Variables/07_Random_Variables.html#what-is-a-random-variable",
    "href": "lessons copy/07_Random_Variables/07_Random_Variables.html#what-is-a-random-variable",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "What is a random variable?",
    "text": "What is a random variable?\n\n\nDefinition: Random Variable\n\n\nFor a given sample space \\(S\\), a random variable (r.v.) is a function whose domain is \\(S\\) and whose range is the set of real numbers \\(\\mathbb{R}\\). A random variable assigns a real number to each outcome in the sample space."
  },
  {
    "objectID": "lessons copy/07_Random_Variables/07_Random_Variables.html#lets-demonstrate-this-definition-with-our-coin-toss",
    "href": "lessons copy/07_Random_Variables/07_Random_Variables.html#lets-demonstrate-this-definition-with-our-coin-toss",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Let’s demonstrate this definition with our coin toss",
    "text": "Let’s demonstrate this definition with our coin toss\n\n\n\n\nExample 1\n\n\nSuppose we toss 3 fair coins.\n\nWhat is the sample space?\nWhat are the probabilities for each of the elements in the sample space?\nWhat are the probabilities that you get 0, 1, 2, or 3 tails?"
  },
  {
    "objectID": "lessons copy/07_Random_Variables/07_Random_Variables.html#lets-stretch-our-definition-of-random-variables",
    "href": "lessons copy/07_Random_Variables/07_Random_Variables.html#lets-stretch-our-definition-of-random-variables",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Let’s stretch our definition of random variables",
    "text": "Let’s stretch our definition of random variables\n\n\n\n\nExample 2\n\n\nWhat are some other random variables we could consider in Example 1?"
  },
  {
    "objectID": "lessons copy/07_Random_Variables/07_Random_Variables.html#some-remarks-on-random-variables",
    "href": "lessons copy/07_Random_Variables/07_Random_Variables.html#some-remarks-on-random-variables",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Some remarks on random variables",
    "text": "Some remarks on random variables\n\nA random variable’s value is completely determined by the outcome \\(\\omega\\), where \\(\\omega \\in S\\)\n\nWhat is random is the outcome \\(\\omega\\)\n\nA random variable is a function from the sample space (with outcomes \\(\\omega\\)) to the set of real numbers\n\nWe typically write \\(X\\) instead of \\(X(\\omega)\\), where \\(X\\) is our random variable\n\nFor example, if we roll three dice, there are \\(6^3 = 216\\) possible outcomes (which is \\(\\omega\\))\n\nWe can define a random variable as the sum of the of the three dice\nIf our outcome is the set of numbers the dice landed on ( \\(\\omega=(a,b,c)\\) ), then \\[ X(\\omega) = X = a + b + c \\]"
  },
  {
    "objectID": "lessons copy/07_Random_Variables/07_Random_Variables.html#lets-look-at-a-continuous-r.v.",
    "href": "lessons copy/07_Random_Variables/07_Random_Variables.html#lets-look-at-a-continuous-r.v.",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Let’s look at a continuous R.V.",
    "text": "Let’s look at a continuous R.V.\n\n\n\n\nExample 3\n\n\nLet \\(X =\\) how many hours you slept last night.\n\nWhat is the sample space \\(S\\)?\nWhat is the range of possible values for \\(X\\)?\nWhat is \\(X(\\omega)\\)?"
  },
  {
    "objectID": "lessons copy/07_Random_Variables/07_Random_Variables.html#discrete-vs.-continuous-r.v.s",
    "href": "lessons copy/07_Random_Variables/07_Random_Variables.html#discrete-vs.-continuous-r.v.s",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Discrete vs. Continuous r.v.’s",
    "text": "Discrete vs. Continuous r.v.’s\n\nFor a discrete r.v., the set of possible values is either finite or can be put into a countably infinite list\n\nYou could theoretically list the specific possible outcomes that the variable can take\nIf you sum the rolls of three dice, you must get a whole number. For example, you can’t get any number between 3 and 4.\n\n\n   \n\nContinuous r.v.’s take on values from continuous intervals, or unions of continuous intervals\n\nVariable takes on a range of values, but there are infinitely possible values within the range\nIf you keep track of the time you sleep, you can sleep for 8 hours or 7.9 hours or 7.99 hours or 7.999 hours …"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro.html",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro.html",
    "title": "Chapter 22: Introduction to Counting",
    "section": "",
    "text": "Define permutations and combinations\nCharacterize difference between sampling with and without replacement\nCharacterize difference between sampling when order matters and when order does not matter\nCalculate the probability of sampling any combination of the following: with or without replacement and order does or does not matter"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro.html#learning-objectives",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro.html#learning-objectives",
    "title": "Chapter 22: Introduction to Counting",
    "section": "",
    "text": "Define permutations and combinations\nCharacterize difference between sampling with and without replacement\nCharacterize difference between sampling when order matters and when order does not matter\nCalculate the probability of sampling any combination of the following: with or without replacement and order does or does not matter"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro.html#where-are-we",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro.html#where-are-we",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro.html#basic-counting-examples-13",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro.html#basic-counting-examples-13",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Basic Counting Examples (1/3)",
    "text": "Basic Counting Examples (1/3)\n\n\nExample 1\n\n\nSuppose we have 10 (distinguishable) subjects for study.\n\nHow many possible ways are there to order them?\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?\n\nHow many ways to order them without replacement and only need 6?\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro.html#basic-counting-examples-23",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro.html#basic-counting-examples-23",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Basic Counting Examples (2/3)",
    "text": "Basic Counting Examples (2/3)\nSuppose we have 10 (distinguishable) subjects for study.\n\n\n\n\nExample 1.1\n\n\nHow many possible ways are there to order them?\n\n\n \n\n\nExample 1.2\n\n\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro.html#basic-counting-examples-33",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro.html#basic-counting-examples-33",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Basic Counting Examples (3/3)",
    "text": "Basic Counting Examples (3/3)\nSuppose we have 10 (distinguishable) subjects for study.\n\n\n\n\nExample 1.3\n\n\nHow many ways to order them without replacement and only need 6?\n\n\n \n\n\nExample 1.4\n\n\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro.html#permutations-and-combinations-1",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro.html#permutations-and-combinations-1",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Permutations and Combinations",
    "text": "Permutations and Combinations\n\n\nDefinition: Permutations\n\n\nPermutations are the number of ways to arrange in order \\(r\\) distinct objects when there are \\(n\\) total.\n\\[nPr = \\frac{n!}{(n-r)!}\\]\n\n\n\n\nDefinition: Combinations\n\n\nCombinations are the number of ways to choose (order doesn’t matter) \\(r\\) objects from \\(n\\) without replacement.\n\\[nCr = \\textrm{\"n choose r\"} = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro.html#some-combinations-properties",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro.html#some-combinations-properties",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Some combinations properties",
    "text": "Some combinations properties\n\n\n\n\n\n\n\nProperty\nProof\n\n\n\n\n\\[\\binom{n}{r} = \\binom{n}{n-r}\\]\n\\(\\binom{n}{r} = \\dfrac{n!}{r!(n-r)!}\\) and \\(\\binom{n}{n-r} = \\dfrac{n!}{(n-r)!(n-(n-r))!} = \\dfrac{n!}{(n-r)!r!}\\)\n\n\n\\[\\binom{n}{1} = n\\]\n\\[\\binom{n}{1} = \\dfrac{n!}{1!(n-1)!}=\\dfrac{n\\cdot(n-1)\\cdot(n-2)\\cdots1}{1! \\cdot (n-1)\\cdot(n-2)\\cdots1} = \\dfrac{n\\cdot(n-1)!}{1\\cdot (n-1)!} = \\dfrac{n}{1}=n\\]\n\n\n\\[\\binom{n}{0} = 1\\]\n\\[\\binom{n}{0} = \\dfrac{n!}{0!(n-0)!}=\\dfrac{n!}{1\\cdot n!} = 1\\]"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro.html#table-of-different-cases",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro.html#table-of-different-cases",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Table of different cases",
    "text": "Table of different cases\nSee table on pg. 277 of textbook\n\n\\(n\\) = total number of objects\n\\(r\\) = number objects needed\n\n\n\n\n\n\n\n\n\nwith replacement\nwithout replacement\n\n\n\n\norder matters\n\\[n^r\\]\n\\[n\\text{P}r = \\frac{n!}{(n-r)!}\\]\n\n\norder doesn’t matter\n\\[ \\binom{n+r-1}{r}\\]\n\\[n\\text{C}r = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro.html#enumerating-events-and-sample-space",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro.html#enumerating-events-and-sample-space",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Enumerating Events and Sample Space",
    "text": "Enumerating Events and Sample Space\n\nRecall, \\(P(A) = \\dfrac{|A|}{|S|}\\)\n\nWithin combinatorics, we can use the previous equations to help enumerate the event and sample space\nBut \\(A\\) might be a combination of enumerations\n\n\n \n\nFor example in the following example drawing 2 spades when order does not matter, we actually need to enumerate the other cards that are NOT spades. So the event is choosing 2 spades out of 13 AND choosing 0 other cards of 39 cards (13 hearts + 13 clubs + 13 diamonds).\nThus the probability is actually:\n\n\\[ P(\\text{two spades}) = \\dfrac{{13 \\choose 2}{39 \\choose 0}}{{52 \\choose 2}} \\]\n\nNote that \\(13 + 39 = 52\\) and \\(2+ 0 = 2\\). So the numerator’s \\(n\\)’s add up to the denominator’s \\(n\\) and the numerator’s \\(r\\)’s add up to the denominator’s \\(r\\)’s"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro.html#more-examples-order-matters-vs.-not-12",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro.html#more-examples-order-matters-vs.-not-12",
    "title": "Chapter 22: Introduction to Counting",
    "section": "More examples: order matters vs. not (1/2)",
    "text": "More examples: order matters vs. not (1/2)\n\n\n\n\nExample 2\n\n\nSuppose we draw 2 cards from a standard deck without replacement. What is the probability that both are spades when\n\norder matters?\norder doesn’t matter?"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review_muddy_points.html",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n1. Why we are allowed to “split” the operator d/dx into two pieces as if it were a fraction when it’s an operator\nHere is a pretty helpful StackExchange post talking about this!\n\n\n2. How to know what to use as \\(u\\) and \\(dv\\) for integration by parts\nI have two approaches to identifying \\(u\\) and \\(dv\\):\n\nTry to find a \\(u\\) that will eventually differentiate into a constant. This usually works unless you’re left with a \\(dv\\) that is hard to integrate.\n\nFor example, \\(u=x^6\\). the first derivative, \\(u'=6x^5\\), which may lead us to do another integration by parts, but eventually, at the 6th derivative, we get 720. This means, in our integration by parts, we eventually get an integral that only has \\(x\\) in the function once.\n\nIn this example, \\(x^6\\) would result in many integration by parts. I feel like we don’t typically see that many in our work.\n\nIn Example 3.5 in Calculus Review, setting \\(u=x^2\\) is a bad idea because we don’t really know how to integrate \\(dv=ln(x)\\) into \\(v\\).\n\nTry to find a \\(u\\) where \\(du\\) is the reciprocal of \\(v\\) or \\(du\\) cancels with \\(v\\).\n\nLook again at Example 3.5 in the notes! Hint: What is the derivative of \\(ln(x)\\)? And what does \\(\\dfrac{1}{x}x^3\\) equal?\n\n\n\n\n3. Looking for more practice in calculus?\nI just stumbled upon this website! Just a bunch of calculus practice problems! Might be some help."
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review_key_info.html",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 4 assignment due last night!\nHW 3 solutions also due\nTime to grade later today: HW 3 solutions or HW 4 assignment?\nTomorrow I will be sending out a Calendly invite for next week\n\nTo make an appointment with me to present your HW 3 solutions\nIt will be posted around 11:45am/12pm\nThere are limited spots just based on my availability"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review_key_info.html#announcements",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 4 assignment due last night!\nHW 3 solutions also due\nTime to grade later today: HW 3 solutions or HW 4 assignment?\nTomorrow I will be sending out a Calendly invite for next week\n\nTo make an appointment with me to present your HW 3 solutions\nIt will be posted around 11:45am/12pm\nThere are limited spots just based on my availability"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review_key_info.html#key-dates",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 5 due\nSunday: HW 4 solutions due\nWeek of 11/11\n\nMake a meeting with me\n11/12: recordings due if you are making that"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs_muddy_points.html",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "1. In-class example of the Poisson distribution\n\nlibrary(tidyverse)\n\nx &lt;- 0:250\n# n = c(6,14,30,60)\np = c(0.1, 0.5)\n\ngeom = expand.grid(x = x, p = p) %&gt;%\n  mutate(y = dgeom(x, prob = p))\n\nggplot(geom %&gt;% filter(y &gt; 1e-5), \n       aes(x, y, color=factor(p))) +\n  geom_point(size=1) +\n  geom_segment(aes(x=x, xend=x, y=0, yend=y, color=factor(p)), lwd=0.8, alpha=0.5) +\n  facet_grid(rows = vars(p), scales=\"free_x\", space=\"free_x\") +\n  theme(legend.position = \"none\",\n        axis.title = element_text(size = 14),    # Axis title size\n        axis.text = element_text(size = 12),     # Axis text size\n        strip.text = element_text(size = 13)) +  # Facet label size\n  labs(x = \"Number of trials\", y = \"Probability\")"
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "",
    "text": "Distinguish between Uniform, Exponential, Gamma, and Normal distributions when reading a story.\nIdentify the variable and the parameters in a story, and state what the variable and parameters mean.\nUse the formulas for the pdf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#properties-of-continuous-uniform-rvs",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#properties-of-continuous-uniform-rvs",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Properties of continuous uniform RVs",
    "text": "Properties of continuous uniform RVs\n\nScenario: Events are equally likely to happen anywhere or anytime in an interval of values\nShorthand: \\(X \\sim \\text{U}[a,b]\\)\n\n\\[\nf_X(x) = \\dfrac{1}{b-a}, \\text{ for }a \\leq x \\leq b\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;a \\quad \\\\\n            \\dfrac{x-a}{b-a} & \\quad a \\leq x \\leq b\\quad \\\\\n            1 & \\quad x&gt;b \\quad\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{a+b}{2} \\text{, } \\text{ Var}(X) = \\dfrac{(b-a)^2}{12}\\]"
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#identifying-continuous-uniform-rv-from-word-problems",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#identifying-continuous-uniform-rv-from-word-problems",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Identifying continuous uniform RV from word problems",
    "text": "Identifying continuous uniform RV from word problems\n\nLook for some indication that all events are equally likely\n\nCould also say “uniformly distributed”\n\nLook for an interval\n\nTime example: Costumer in your store will approach the cash register in next 30 minutes. Approaching the register throughout the 30 minutes is equally likely.\nLength example: You have a 12 inch string that you need to cut. You are equally likely to cut anywhere on the string.\n\nDifferent than the discrete uniform\n\nDiscrete usually includes a countable number of events that are equally likely\nContinuous is not countable\n\nExact time and length can be measured with infinite decimal places"
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re looking at equally likely arrival times between 10 am and 11 am.\n\nIf we want to know the probability that someone arrives at 10:30am or earlier:\n\npunif(q = 30, min = 0, max = 60)\n\n[1] 0.5\n\n\nIf we want to know the time, say \\(t\\), where the probability of arriving at \\(t\\) or earlier is 0.35:\n\nqunif(p = 0.35, min = 0, max = 60)\n\n[1] 21\n\n\nIf we want to know the probability that someone arrives between 10:14 and 10:16 am:\n\npunif(q = 16, min = 0, max = 60) - punif(q = 14, min = 0, max = 60)\n\n[1] 0.03333333\n\n\nIf we want to sample 20 arrival times from the distribution:\n\nrunif(n = 20, min = 0, max = 60)\n\n [1] 28.472954 41.428976 46.978279 45.645563 15.763938 59.517065 24.674587\n [8] 17.477877 41.751479 22.868319  9.294208 50.329785 48.675595 59.226207\n[15]  8.386209 22.723738  3.344226 28.056609 47.654213 20.145319"
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#bird-on-a-wire-tb-31.5",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#bird-on-a-wire-tb-31.5",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Bird on a wire (TB 31.5)",
    "text": "Bird on a wire (TB 31.5)\n\n\n\n\nExample 1\n\n\nA bird lands at a location that is Uniformly distributed along an electrical wire of length 150 feet. The wire is stretched tightly between two poles. What is the probability that the bird is 20 feet or less from one or the other of the poles?"
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#properties-of-exponential-rvs",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#properties-of-exponential-rvs",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Properties of exponential RVs",
    "text": "Properties of exponential RVs\n\nScenario: Modeling the time until the next (first) event\nContinuous analog to the geometric distribution!\nShorthand: \\(X \\sim \\text{Exp}(\\lambda)\\)\n\n\\[\nf_X(x) = \\lambda e^{-\\lambda x}\\text{ for } x&gt;0, \\lambda&gt;0\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;0 \\quad \\\\\n            1 - e^{-\\lambda x} & \\quad x\\geq0 \\\\\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{1}{\\lambda}\\] \\[\\text{Var}(X) = \\dfrac{1}{\\lambda^2}\\]"
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#memoryless-property",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#memoryless-property",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Memoryless Property",
    "text": "Memoryless Property\n   \nIf \\(b&gt;0\\),\n\\[P(X &gt; a +b | X&gt; a) = P(X &gt; b)\\]\n     \n\nThis can be interpreted as:\n\nIf you have waited \\(a\\) seconds (or any other measure of time) without a success\nThen the probability that you have to wait \\(b\\) more seconds is the same as as the probability of waiting \\(b\\) seconds initially."
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#identifying-exponential-rv-from-word-problems",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#identifying-exponential-rv-from-word-problems",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Identifying exponential RV from word problems",
    "text": "Identifying exponential RV from word problems\n\nLook for time between events/successes\nLook for a rate of the events over time period\nHow does it differ from the geometric distribution?\n\nGeometric is number of trials until first success\nExponential is time until first success\n\nRelation to the Poisson distribution?\n\nWhen the time between arrivals is exponential, the number of arrivals in a fixed time interval is Poisson with the mean \\(\\lambda\\)"
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-1",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-1",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re sitting at the bus stop, measuring the time until our bus arrives. We know the bus comes every 10 minutes on average.\n\nIf we want to know the probability that the bus arrives in the next 5 minutes:\n\npexp(q = 5, rate = 1/10)\n\n[1] 0.3934693\n\n\nIf we want to know the time, say \\(t\\), where the probability of the bus arriving at \\(t\\) or earlier is 0.35:\n\nqexp(p = 0.35, rate = 1/10)\n\n[1] 4.307829\n\n\nIf we want to know the probability that the bus arrives between 3 and 5 minutes:\n\npexp(q = 5, rate = 1/10) - pexp(q = 3, rate = 1/10)\n\n[1] 0.1342876\n\n\nIf we want to sample 20 bus arrival times from the distribution:\n\nrexp(n = 20, rate = 1/10)\n\n [1]  5.385679  6.561348 23.473112 13.433119 12.851668 18.478479  1.222714\n [8]  4.967056 11.826832 15.812497 10.275761 22.068548  3.061180  9.940844\n[15] 12.062761  2.320492 19.292359 15.578615 10.967372  1.717174"
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#transformation-of-independent-exponential-rvs",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#transformation-of-independent-exponential-rvs",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Transformation of independent exponential RVs",
    "text": "Transformation of independent exponential RVs\n\n\nRevisit after joint notes:\n\n\nExample 1\n\n\nLet \\(X_i \\sim \\textrm{Exp}(\\lambda_i)\\) be independent RVs, for \\(i=1 \\ldots n\\). Find the pdf for the first of the arrival times."
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#properties-of-gamma-rvs",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#properties-of-gamma-rvs",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Properties of gamma RVs",
    "text": "Properties of gamma RVs\n\nScenario: Modeling the time until the \\(r^{th}\\) event.\nContinuous analog to the Negative Binomial distribution\nShorthand: \\(X \\sim \\text{Gamma}(r, \\lambda)\\)\n\n\\[\nf_X(x) = \\dfrac{\\lambda^r}{\\Gamma(r)}x^{r-1} e^{-\\lambda x}\\text{ for } x&gt;0, \\lambda&gt;0, \\Gamma(r) = (r-1)!\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;0 \\quad \\\\\n            1 - e^{-\\lambda x}\\displaystyle\\sum_{j=0}^{r-1}\\dfrac{(\\lambda x)^j}{j!}  & \\quad x\\geq0 \\\\\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{r}{\\lambda}\\text{, }\\text{ Var}(X) = \\dfrac{r}{\\lambda^2}\\]\nCommon to see \\(\\alpha = r\\) and \\(\\beta = \\lambda\\)"
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#identifying-gamma-rv-from-word-problems",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#identifying-gamma-rv-from-word-problems",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Identifying gamma RV from word problems",
    "text": "Identifying gamma RV from word problems\n\nGamma distribution with \\(r=1\\) is same as exponential\n\nJust like Negative Binomial with \\(r=1\\) is same as the geometric distribution\n\nSimilar to exponential\n\nLook for time between or until events/successes\n\nBUT now we are measuring time until more than 1 success\n\nLook for a rate of the events over time period"
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-2",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-2",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re sitting at the bus stop, measuring the time until 4 buses arrive. We know the bus comes every 10 minutes on average.\n\nIf we want to know the probability that the 4 buses arrive in the next 50 minutes:\n\n\n\n\npgamma(q = 50, rate = 1/10, shape = 4)\n\n[1] 0.7349741\n\n\n\n\npgamma(q = 50, scale = 10, shape = 4)\n\n[1] 0.7349741\n\n\n\n\n\nIf we want to know the time, say \\(t\\), where the probability of the 4 buses arriving at \\(t\\) or earlier is 0.35:\n\nqgamma(p = 0.35, rate = 1/10, shape = 4)\n\n[1] 29.87645\n\n\nIf we want to know the probability that the 4 buses arrives between 30 and 50 minutes:\n\npgamma(q = 50, scale = 10, shape = 4) - pgamma(q = 30, scale = 10, shape = 4)\n\n[1] 0.382206\n\n\nIf we want to sample 20 arrival times for the 4 buses:\n\nrgamma(n = 20, scale = 10, shape = 4)\n\n [1] 99.987901 23.394271 51.505789 81.449040 27.018828 75.869081 19.010813\n [8] 14.107932 19.915131 36.148873 98.595582 58.614097 33.542028 67.591344\n[15] 50.575848 37.578969  7.665158 53.301350 53.322710 59.260831"
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#remarks",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#remarks",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Remarks",
    "text": "Remarks\n\nThe parameter \\(r\\) in a Gamma(\\(r\\),\\(\\lambda\\)) distribution does NOT need to be a positive integer\n\n\\(r\\) is usually a positive integer\n\nWhen \\(r\\) is a positive integer, the distribution is sometimes called an Erlang(\\(r\\),\\(\\lambda\\)) distribution\n \n \nWhen \\(r\\) is any positive real number, we have a general gamma distribution that is usually instead parameterized by \\(\\alpha&gt;0\\) and \\(\\beta&gt;0\\), where:\n\n\\(\\alpha = \\text{shape parameter}\\) : same as \\(k\\), the total number of events we must witness\n\nIn R code example: 4 buses to wait for\n\n\\(\\beta = \\text{scale parameter}\\) : same as \\(\\lambda\\), the rate parameter\n\nIn R code example: 1 bus per 10 minutes (1/10)"
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#sending-money-orders",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#sending-money-orders",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Sending money orders",
    "text": "Sending money orders\n\n\n\n\nExample 1\n\n\nOn average, someone sends a money order once per 15 minutes. What is the probability someone sends 10 money orders in less than 3 hours?"
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#additional-resource",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#additional-resource",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Additional Resource",
    "text": "Additional Resource\n\nAnother helpful site with R code: https://rpubs.com/mpfoley73/459051"
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#properties-of-normal-rvs",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#properties-of-normal-rvs",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Properties of Normal RVs",
    "text": "Properties of Normal RVs\n\nNo scenario description here because the Normal distribution is so universal\n\nCentral Limit Theorem (next class) makes it applicable to many types of events\n\nShorthand: \\(X \\sim \\text{Normal}(\\mu, \\sigma^2)\\)\n\n\\[\nf_X(x) = \\dfrac{1}{\\sqrt{2\\pi \\sigma^2}}e^{-(x-\\mu)^2/(2\\sigma^2)} \\text{, for} -inf &lt; x &lt; inf\n\\]\n\\[\\text{E}(X) = \\mu \\] \\[\\text{Var}(X) = \\sigma^2\\]"
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-3",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-3",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re measuring the high temperature today. The average high temperature on this day across many, many years is 50 degrees with a standard deviation of 4 degrees.\n\nIf we want to know the probability that the high temperature is below 45 degrees:\n\npnorm(q = 45, mean = 50, sd = 4)\n\n[1] 0.1056498\n\n\nIf we want to know the temoerature, say \\(t\\), where the probability of that the temperature is at \\(t\\) or lower is 0.35:\n\nqnorm(p = 0.35, mean = 50, sd = 4)\n\n[1] 48.45872\n\n\nIf we want to know the probability that the temperature is between 45 and 50 degrees:\n\npnorm(q = 50, mean = 50, sd = 4) - pnorm(q = 45, mean = 50, sd = 4)\n\n[1] 0.3943502\n\n\nIf we want to sample 20 days’ temperature (over the years) from the distribution:\n\nrnorm(n = 20, mean = 50, sd = 4)\n\n [1] 54.49995 51.43093 44.60434 55.28638 48.86996 56.53307 46.48497 48.20090\n [9] 46.37584 52.38489 55.19571 48.79630 54.04826 40.43634 51.76632 44.64265\n[17] 47.03582 45.21445 40.12497 43.92587"
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#movie-night-while-studying",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#movie-night-while-studying",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Movie night while studying",
    "text": "Movie night while studying\n\n\n\n\nExample 1\n\n\nChildren’s movies run an average of 98 minutes with a standard deviation of 10 minutes. You check out a random movie from the library to entertain your kids so you can study for your test. Assume that your kids will be occupied for the entire length of the movie.\n\nWhat is the probability that your kids will be occupied for at least the 2 hours you would like to study?\nWhat is range for the bottom quartile (lowest 25%) of time they will be occupied?"
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#standard-normal-distribution",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs.html#standard-normal-distribution",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Standard Normal Distribution",
    "text": "Standard Normal Distribution\n\\[ Z \\sim \\text{Normal}(\\mu = 0, \\sigma^2 = 1)\\]\n\nUsed to be more helpful when computing was not as advanced\n\nUse tables of the standard normal\nYou can convert any normal distribution to a standard normal through transformation\n\n\\(Z = \\dfrac{X - \\mu_X}{\\sigma_X}\\)\n\nComes from \\(X = \\sigma_X Z + \\mu_X\\)\nSince \\(\\sigma_X\\) and \\(\\mu_X\\) are constants, then \\(E(X) = \\mu_X\\) and \\(SD(X) = \\sigma_X SD(Z) = \\sigma_X\\)"
  },
  {
    "objectID": "lessons copy/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance_muddy_points.html",
    "href": "lessons copy/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n2. How do we set the bounds on a double integral?\nWhen the domain of the RVs are not dependent on each other, then we use the bounds as is. In example 2 of Chapter 26 notes, we have the joint pdf \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for\\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\). If we wanted to calculate something like \\(E(X)\\), then we could use the bounds as they are. Below is the domain for \\(x\\) and \\(y\\):\n\n\n\n\n\nHere is the integral for the expected value where we integrate over the whole domain of \\(x\\) and \\(y\\):\n\\[ E(X) = \\displaystyle\\int_0^1 \\displaystyle\\int_0^1 x (18 x^2 y^5 )dy dx \\]If we want to find the probability \\(P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75)\\), then we can look at the specific values of the probability:\n\n\n\n\n\nNote the blue lines above indicate how we integrate over \\(y\\) first from 0.5 to 0.75 and the green lines indicate how integrate over \\(x\\) first from 0.25 to 0.5. It seems like we’ve integrated over an area that isn’t within our specified probability. However, the integrated area is ONLY the overlap of the \\(x\\) and \\(y\\) bounds for the probability.\n\\[P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.25}^{0.5} \\displaystyle\\int_{0.5}^{0.75} 18 x^2 y^5 dy dx\\]\nLet’s use the same pdf, but now the domain of the two RVs is dependent on one another. We have the joint pdf \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for\\(0 \\leq x \\leq y\\leq1\\)\nIf we wanted to calculate something like \\(E(X)\\), then we need to account for fact that \\(x\\) must be less than of equal to \\(y\\). We can look back at the domain for this:\n\n\n\n\n\nNote the blue lines above still indicate how we integrate over \\(y\\) first from \\(x\\) to 1, and the green lines indicate how integrate over \\(x\\) first from 0 to 1. Once again, it seems like we’ve integrated over an area that isn’t within the domain. However, the integrated area is ONLY the overlap of the \\(x\\) and \\(y\\) bounds. Thus, once we’ve restricted \\(y\\) to the area between \\(x\\) and 1, we no longer need to restrict \\(x\\) to the are of 0 to \\(y\\).\n\\[ E(X) = \\displaystyle\\int_0^1 \\displaystyle\\int_x^1 x (18 x^2 y^5 )dy dx \\] If we want to find the probability \\(P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75)\\), then we should look back at our domain. For now, we are focusing on the orange area:\n\n\n\n\n\nBecause the orange area is totally within our domain, we can leave our integral our bounds as the exact values we specified:\n\\[P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.25}^{0.5} \\displaystyle\\int_{0.5}^{0.75} 18 x^2 y^5 dy dx\\]\nHowever, if we want the probability \\(P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75)\\), we would focus on the pink area above. We would limit one of our integrals to the \\(y=x\\) equation:\n\\[P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.5}^{0.75} \\displaystyle\\int_{x}^{0.75} 18 x^2 y^5 dy dx\\]\nOR\n\\[P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.5}^{0.75} \\displaystyle\\int_{0.5}^{y} 18 x^2 y^5 dx dy\\]\nThe key to these probabilities is that the bounds with the other variable is on the inside integral! Otherwise we end up with a answer that includes a RV."
  },
  {
    "objectID": "lessons copy/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html",
    "href": "lessons copy/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "",
    "text": "Calculate the mean (expected value) of sums of discrete random variables"
  },
  {
    "objectID": "lessons copy/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#learning-objectives",
    "href": "lessons copy/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#learning-objectives",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "",
    "text": "Calculate the mean (expected value) of sums of discrete random variables"
  },
  {
    "objectID": "lessons copy/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#where-are-we",
    "href": "lessons copy/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#where-are-we",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#revisiting-our-two-card-draw",
    "href": "lessons copy/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#revisiting-our-two-card-draw",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Revisiting our two card draw",
    "text": "Revisiting our two card draw\n\n\n\n\nExample 1\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw. Find \\(\\mathbb{E}[X]\\).\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "lessons copy/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#what-if-we-draw-a-lot-of-cards",
    "href": "lessons copy/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#what-if-we-draw-a-lot-of-cards",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "What if we draw A LOT of cards?",
    "text": "What if we draw A LOT of cards?\n\n\n\n\nExample 2\n\n\nWhat is the expected number of hearts in Example 1 if you draw 200 cards?\n\n\n\n\nRecall Binomial RV with \\(n=200\\):\n\\[p_X(x) = {200 \\choose x}p^x(1-p)^{200-x}\\] \\[\\text{  for } x = 0, 1, 2, ..., 200\\]"
  },
  {
    "objectID": "lessons copy/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#sum-of-discrete-rvs",
    "href": "lessons copy/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#sum-of-discrete-rvs",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Sum of discrete RVs",
    "text": "Sum of discrete RVs\n\n\nTheorem 11.1: Sum of discrete RVs\n\n\nFor discrete r.v.’s \\(X_i\\) and constants \\(a_i\\), \\(i=1,2,\\dots, n\\), \\[\\mathbb{E}\\Bigg[\\sum_{i=1}^n a_iX_i\\Bigg] = \\sum_{i=1}^n a_i\\mathbb{E}[X_i] .\\] Remark: The theorem holds for infinitely r.v.’s \\(X_i\\) as well.\n\n\n\nFor two RVs, \\(X\\) and \\(Y\\):\n\nWe can say \\(E[X+Y] = E[X] + E[Y]\\)\n… and constant numbers \\(a\\) and \\(b\\), we can also say \\(E[aX+bY] = aE[X] + bE[Y]\\)\nWe can also also say \\(E[X-Y] = E[X] - E[Y]\\), since \\(b=-1\\)"
  },
  {
    "objectID": "lessons copy/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#corollaries-from-thm-11.1",
    "href": "lessons copy/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#corollaries-from-thm-11.1",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Corollaries from Thm 11.1",
    "text": "Corollaries from Thm 11.1\n\n\n\n\nCorollary 11.1.1\n\n\nFor a discrete r.v. \\(X\\), and constants \\(a\\) and \\(b\\), \\[\\mathbb{E}[aX+b] = a\\mathbb{E}[X] + b.\\]\n\n\n\n\n\nCorollary 11.1.2\n\n\nIf \\(X_i\\), \\(i=1,2,\\dots, n\\), are identically distributed r.v.’s, then \\[\\mathbb{E}\\bigg[\\sum_{i=1}^n X_i\\bigg] = n\\mathbb{E}[X_1] .\\]"
  },
  {
    "objectID": "lessons copy/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#cost-of-hotel-rooms",
    "href": "lessons copy/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#cost-of-hotel-rooms",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Cost of hotel rooms",
    "text": "Cost of hotel rooms\n\n\n\n\nExample 4\n\n\nA tour group is planning a visit to the city of Minneapolis and needs to book 30 hotel rooms. The average price of a room is $200. In addition, there is a 10% tourism tax for each room. What is the expected cost for the 30 hotel rooms?"
  },
  {
    "objectID": "lessons copy/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html",
    "href": "lessons copy/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "",
    "text": "Calculate probability of a sample mean using a Normally distributed population"
  },
  {
    "objectID": "lessons copy/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#learning-objectives",
    "href": "lessons copy/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#learning-objectives",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "",
    "text": "Calculate probability of a sample mean using a Normally distributed population"
  },
  {
    "objectID": "lessons copy/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#sum-of-normal-rvs",
    "href": "lessons copy/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#sum-of-normal-rvs",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "Sum of Normal RVs",
    "text": "Sum of Normal RVs\n\n\nTheorem 1\n\n\nLet \\(X\\sim N(\\mu, \\sigma^2)\\), and let \\(Y=aX+b\\), where \\(a\\) and \\(b\\) are constants. Then \\[Y \\sim N(a\\mu+b, a^2\\sigma^2)\\]\n\n\n\n\nTheorem 2\n\n\nLet \\(X_i \\sim N(\\mu_i, \\sigma_i^2)\\) be independent normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\sim N\\Bigg(\\sum_{i=1}^n \\mu_i , \\sum_{i=1}^n \\sigma^2_i\\Bigg)\\]"
  },
  {
    "objectID": "lessons copy/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#special-cases",
    "href": "lessons copy/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#special-cases",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "Special Cases",
    "text": "Special Cases\n\nLet \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\sim N\\big(n\\mu, n \\sigma^2\\big)\\]\nLet \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\bar{X}=\\frac{\\sum_{i=1}^n X_i}{n} \\sim N\\big(\\mu, \\sigma^2 / n\\big)\\]\nLet \\(X\\sim N(\\mu_X,\\sigma_X^2)\\), and \\(Y\\sim N(\\mu_Y,\\sigma_Y^2)\\). Then \\[X-Y \\sim N\\big(\\mu_X - \\mu_Y, \\sigma^2_X + \\sigma^2_Y \\big)\\]"
  },
  {
    "objectID": "lessons copy/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#detecting-and-solving-sums-of-normal-rvs-from-a-word-problem",
    "href": "lessons copy/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#detecting-and-solving-sums-of-normal-rvs-from-a-word-problem",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "Detecting and solving sums of Normal RVs from a word problem",
    "text": "Detecting and solving sums of Normal RVs from a word problem\n\n\n\n\nExample 1\n\n\nGlaucoma is an eye disease that is manifested by high intraocular pressure (IOP). The distribution of IOP in the general population is approximately normal with mean 16 mmHg and standard deviation 3 mmHg.\n\nSuppose a patient has 40 IOP readings. What is the probability that their average reading is greater than 20.32 mmHg, assuming their eyes are healthy?\nRepeat the previous question for a patient with 10 IOP readings."
  },
  {
    "objectID": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html",
    "href": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "LAST CLASS!!!!\nHomework 7and 6 solutions are graded\nHW 7 meetings are up on Calendly\n\nSee my announcement from Sakai\n\nI will be finalizing and posting HW 9 tomorrow\n\nOptional!\n\nPlease do your course evals!!\n\nEspecially in a small class\n\nFriday 12/13 is the absolute deadline for turning in materials if you are completing the course! _ Check Sakai that I have all your HW grades in!\nAnything else?"
  },
  {
    "objectID": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html#announcements",
    "href": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "LAST CLASS!!!!\nHomework 7and 6 solutions are graded\nHW 7 meetings are up on Calendly\n\nSee my announcement from Sakai\n\nI will be finalizing and posting HW 9 tomorrow\n\nOptional!\n\nPlease do your course evals!!\n\nEspecially in a small class\n\nFriday 12/13 is the absolute deadline for turning in materials if you are completing the course! _ Check Sakai that I have all your HW grades in!\nAnything else?"
  },
  {
    "objectID": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html#key-dates",
    "href": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday (12/5): HW 8 assignment due\nSunday (12/8): HW 7 presentations due at 11pm\n\nI can be pretty flexible until 12/13\n\nThursday (12/12): Optional HW 9 assignment due\nFriday (12/13): HW 8 solutions due"
  },
  {
    "objectID": "lessons copy/20_Moment_Generating_Functions/43_Moment_Generating_Functions_Part2.html",
    "href": "lessons copy/20_Moment_Generating_Functions/43_Moment_Generating_Functions_Part2.html",
    "title": "Chapter 43: Moment Generating Functions Part 2",
    "section": "",
    "text": "Chapter 43: Moment Generating Functions Part 2\nRecap: What is an mgf?\n\nExample 1.   Let \\(X\\) be a random variable with mgf \\[M_X(t)= \\frac{1}{5}e^t + \\frac{3}{10}e^{2t} + \\frac{1}{2}e^{3t}.\\] Find the pmf or pdf of \\(X\\).\n\n\nExample 2.   Let \\(X\\) be a normal random variable with mean \\(\\mu\\) and variance \\(\\sigma^2\\), i.e. \\(X \\sim N(\\mu,\\sigma^2)\\).\n\nFind the mgf of \\(X\\).\nFind \\(\\mathbb{E}[X]\\).\nFind \\(Var(X)\\).\n\n\n\n\nTheorem 3.   Let \\(X\\) have mgf \\(M_X(t)\\), and let \\(Y=aX+b\\), where \\(a\\) and \\(b\\) are constants. Then \\[M_Y(t)=\\]\n\n\nProof. Proof. ◻\n\nQuestion: Do linear transformations always preserve the distribution type?\nI.e., if \\(X\\) has a certain probability distribution, does \\(aX+b\\) always have the same distribution type?\n\n\nExample 4.   Let \\(X \\sim U[0,1]\\), and \\(Y = 2X+3\\). Is \\(Y\\) also a uniform rv? If so, what are its parameters?\n\n\nExample 5.   Let \\(X \\sim Exp(\\lambda=5)\\), and \\(Y = 2X+3\\). Is \\(Y\\) also an exponential rv? If so, what is its parameter?\n\nMgf’s of Sums of Independent rv’s\n\n\nTheorem 6.   Let \\(X_1, X_2, \\ldots, X_n\\) be independent rv’s with respective mgf’s \\(M_{X_i}(t)\\), for \\(i=1,2,\\ldots,n\\). Let \\(Y=\\sum_{i=1}^n a_iX_i\\), where \\(a_i\\) are constants. Then \\[M_Y(t)= %\\Pi_{i=1}^n M_{X_i}(a_it).\\]\n\n\nProof. Proof. ◻\n\n\n\nExample 7.   Let \\(X_i \\sim N(\\mu_i, \\sigma_i^2)\\) be independent normal rv’s. What is the distribution of  \\(Y=\\sum_{i=1}^n X_i\\)?\n\n\n\nExample 8.   Let \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). What is the distribution of  \\(\\bar{X}=\\frac{\\sum_{i=1}^n X_i}{n}\\)?\n\n\nExample 9.   Let \\(Z\\) be a standard normal random variable, i.e. \\(Z \\sim N(0,1)\\). Show that \\(Z^2 \\sim \\chi_1^2\\), i.e. is a chi-squared rv with 1 degree of freedom."
  },
  {
    "objectID": "lessons copy/00_Intro/00_Intro.html",
    "href": "lessons copy/00_Intro/00_Intro.html",
    "title": "Welcome to BSTA 550!",
    "section": "",
    "text": "Call me “Nicky,” “Dr. W,” “Professor Wakim,” or any combo!\nAssistant Professor of Biostatistics\n \nGrew up in DC area (Virginia side!)\nMoved here from Michigan around 2 years ago\nTwo sweet kitties\nVolleyball, pickleball, ceramics, strolling around my neighborhood\nBut also sleeping, TV, and reading\nProud plant mamma\nA few other things about myself that I will share non-publicly\n\n\n\n\n Video"
  },
  {
    "objectID": "lessons copy/00_Intro/00_Intro.html#nicky-wakim-sheher",
    "href": "lessons copy/00_Intro/00_Intro.html#nicky-wakim-sheher",
    "title": "Welcome to BSTA 550!",
    "section": "",
    "text": "Call me “Nicky,” “Dr. W,” “Professor Wakim,” or any combo!\nAssistant Professor of Biostatistics\n \nGrew up in DC area (Virginia side!)\nMoved here from Michigan around 2 years ago\nTwo sweet kitties\nVolleyball, pickleball, ceramics, strolling around my neighborhood\nBut also sleeping, TV, and reading\nProud plant mamma\nA few other things about myself that I will share non-publicly\n\n\n\n\n Video"
  },
  {
    "objectID": "lessons copy/00_Intro/00_Intro.html#some-important-tasks",
    "href": "lessons copy/00_Intro/00_Intro.html#some-important-tasks",
    "title": "Welcome to BSTA 550!",
    "section": "Some important tasks",
    "text": "Some important tasks\n\nJoin the Slack page!\nStar the class website: https://nwakim.github.io/BSTA_550_F24/\nComplete the WhenIsGood for office hours\nComplete Homework 0 by this Thursday at 11pm!\n\nIncludes some items above\nThink about what day of the week you would like your homeworks due\n\nHighly suggest that you make an appointment with a learning specialist through Student Academic Success Center!"
  },
  {
    "objectID": "lessons copy/00_Intro/00_Intro.html#lets-visit-the-website-homepage",
    "href": "lessons copy/00_Intro/00_Intro.html#lets-visit-the-website-homepage",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website: Homepage",
    "text": "Let’s visit the website: Homepage\n\n\n\nHomepage"
  },
  {
    "objectID": "lessons copy/00_Intro/00_Intro.html#lets-visit-the-website-syllabus",
    "href": "lessons copy/00_Intro/00_Intro.html#lets-visit-the-website-syllabus",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website: Syllabus",
    "text": "Let’s visit the website: Syllabus\n\nCourse learning objectives\nTextbook in shared folder!\nResources: PennState STAT 414 site!\nR: not a big worry in our class, you will get a lot of help in BSTA 511\nAssessments and grade breakdowns\nHomework: 3 parts + grading\nFeedback: in the form of exit tickets, group evals, midterm feedback, and final course\nHow to succeed in this course: resources and assignments explained\nLate work policy / Attendance policy\nChatGPT and other AI technology\nCourse expectations: a few ways that I will show you respect and commitment to you as students\n\nAnd a few ways I expect from you!\n\nCommunicating with me: give me 24 hours to reply M-F\n\nOnline communication is not my strength!"
  },
  {
    "objectID": "lessons copy/00_Intro/00_Intro.html#lets-visit-the-website-schedule-12",
    "href": "lessons copy/00_Intro/00_Intro.html#lets-visit-the-website-schedule-12",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website: Schedule (1/2)",
    "text": "Let’s visit the website: Schedule (1/2)\n\nWeeks, class info, exams, homeworks"
  },
  {
    "objectID": "lessons copy/00_Intro/00_Intro.html#lets-visit-the-website-schedule-22",
    "href": "lessons copy/00_Intro/00_Intro.html#lets-visit-the-website-schedule-22",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website: Schedule (2/2)",
    "text": "Let’s visit the website: Schedule (2/2)\n\n\n\n\nKey Info\nI will post announcements and other important class related info here. For example, if I change a due date or discuss a common mistake in homework, I will put it here.\n\n\n\nSlides QMD\nThese are the basic slides that will open in your browser.\n\n\n\nSlides PDF\nThese are the slides in pdf form for easy note taking. I’m not always the best at posting these before class, so make sure you know how to save your own copy of pdf slides!\n\n\n\nSlides Notes\nThese are the annotated slides in pdf form. In class, I add my own notes to slides. After class, I will post them here.\n\n\n\nExit tix\nThese are links to that day’s exit ticket.\n\n\n\nRecording\nI record our classes. This will be a link to the OneDrive folder containing this recording.\n\n\n\nMuddy Points\nYou will have a chance to ask questions about class in your exit tickets. If I notice a trend in confusion, I will add explanations to these “Muddy Points”"
  },
  {
    "objectID": "lessons copy/00_Intro/00_Intro.html#lets-visit-the-website-search",
    "href": "lessons copy/00_Intro/00_Intro.html#lets-visit-the-website-search",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website: Search",
    "text": "Let’s visit the website: Search"
  },
  {
    "objectID": "lessons copy/00_Intro/00_Intro.html#lets-visit-the-website-homework",
    "href": "lessons copy/00_Intro/00_Intro.html#lets-visit-the-website-homework",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website: Homework!",
    "text": "Let’s visit the website: Homework!"
  },
  {
    "objectID": "lessons copy/00_Intro/00_Intro.html#decision-on-homework-due-dates",
    "href": "lessons copy/00_Intro/00_Intro.html#decision-on-homework-due-dates",
    "title": "Welcome to BSTA 550!",
    "section": "Decision on Homework due dates",
    "text": "Decision on Homework due dates\n\nI have some set due dates in the schedule\nPlease look at your other classes, your calendar, etc\nConsider what day of the week you would like to turn in your assignment, solutions, and video/meeting\nQuestion in HW 0 to cast your vote and share your opinion"
  },
  {
    "objectID": "lessons copy/00_Intro/00_Intro.html#structure-for-this-course",
    "href": "lessons copy/00_Intro/00_Intro.html#structure-for-this-course",
    "title": "Welcome to BSTA 550!",
    "section": "Structure for this course",
    "text": "Structure for this course\n\nLearning the basic tools to understand statistics\nIt is going to feel useless at times, but I swear it is not!\nThis class will help you build a toolbox that allows to analyze data while understanding the inner theory at play"
  },
  {
    "objectID": "lessons copy/00_Intro/00_Intro.html#what-we-will-cover",
    "href": "lessons copy/00_Intro/00_Intro.html#what-we-will-cover",
    "title": "Welcome to BSTA 550!",
    "section": "What we will cover",
    "text": "What we will cover"
  },
  {
    "objectID": "lessons copy/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html",
    "href": "lessons copy/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "",
    "text": "Calculate expected value of functions of RVs\nCalculate variance of RVs"
  },
  {
    "objectID": "lessons copy/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#learning-objectives",
    "href": "lessons copy/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#learning-objectives",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "",
    "text": "Calculate expected value of functions of RVs\nCalculate variance of RVs"
  },
  {
    "objectID": "lessons copy/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#expected-value-of-a-function-of-a-continuous-rv",
    "href": "lessons copy/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#expected-value-of-a-function-of-a-continuous-rv",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Expected value of a function of a continuous RV",
    "text": "Expected value of a function of a continuous RV\n\n\nHow do we calculate the expected value of a function of a discrete RV or joint RVs?\n   \nFor discrete RVs:\n\\[\\mathbb{E}[g(X)] = \\sum_{\\{all\\ x\\}}\\ g(x) p_X(x).\\] \\[\\mathbb{E}[g(X, Y)] = \\sum_{\\{all\\ x\\}}\\sum_{\\{all\\ y\\}}\\ g(x,y) p_{X,Y}(x,y).\\]\n\n\n\nHow do we calculate the expected value of a function of a continuous RV or joint RVs?\n   \nFor continuous RVs:"
  },
  {
    "objectID": "lessons copy/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#important-properties-of-expected-values-of-functions-of-continuous-rvs",
    "href": "lessons copy/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#important-properties-of-expected-values-of-functions-of-continuous-rvs",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Important properties of expected values of functions of continuous RVs",
    "text": "Important properties of expected values of functions of continuous RVs\n\n\n\n\nFunction of RV with two constants\n\n\n\\(\\mathbb{E}[aX+b] =a\\mathbb{E}[X]+b\\)\n\n\n\n\nFunction of two RVs added\n\n\n\\(\\mathbb{E}[X+Y] =\\mathbb{E}[X]+\\mathbb{E}[Y]\\)\n\n\n\n\nExpected value of sum of independent RVs pt 1\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are continuous RVs and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\[\\mathbb{E}\\Bigg[\\sum_{i=1}^{n} a_i X_i\\Bigg] = \\sum_{i=1}^{n}a_i\\mathbb{E}[X_i]\\]\n\n\n\n\n\nExpected value of multiplication of function of independent RVs\n\n\nIf \\(X\\) and \\(Y\\) are independent continuous RVs, and \\(g\\) and \\(h\\) are functions, then \\[\\mathbb{E}[g(X)h(Y)] =\\mathbb{E}[g(X)]\\mathbb{E}[h(Y)]\\]\n\n\n\n\nExpected value of multiplication of independent RVs\n\n\nIf \\(X\\) and \\(Y\\) are independent continuous RVs, then \\[\\mathbb{E}[XY] = \\mathbb{E}[X] \\mathbb{E}[Y] \\]"
  },
  {
    "objectID": "lessons copy/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-continuous-rvs",
    "href": "lessons copy/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-continuous-rvs",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Variance of continuous RVs",
    "text": "Variance of continuous RVs\n\n\nHow do we calculate the variance of a discrete RV?\n   \nFor discrete RVs:\n\\[\n\\begin{align}\nVar(X) & =\n\\mathbb{E}[(X-\\mu_X)^2] \\\\ & = \\mathbb{E}[(X-\\mathbb{E}[X])^2] \\\\ &= \\mathbb{E}[X^2]-(\\mathbb{E}[X])^2 \\\\ & = \\sum_{\\{all\\ x\\}}(x-\\mu_x)^2 p_{X}(x)\n\\end{align}\n\\]\n\n\n\nHow do we calculate the variance of a continuous RV?\n    \nFor continuous RVs:"
  },
  {
    "objectID": "lessons copy/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-an-uniform-distribution",
    "href": "lessons copy/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-an-uniform-distribution",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Variance of an Uniform distribution",
    "text": "Variance of an Uniform distribution\n\n\n\n\nExample 2\n\n\nLet \\(f_X(x)= \\frac{1}{b-a}\\), for \\(a \\leq x \\leq b\\). Find \\(Var[X]\\)."
  },
  {
    "objectID": "lessons copy/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-exponential-distribution",
    "href": "lessons copy/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-exponential-distribution",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Variance of exponential distribution",
    "text": "Variance of exponential distribution\n\n\nIn the homework:\n\n\nExample 3\n\n\nLet \\(f_X(x)= \\lambda e^{-\\lambda x}\\), for \\(x &gt; 0\\) and \\(\\lambda&gt; 0\\). Find \\(Var[X]\\)."
  },
  {
    "objectID": "lessons copy/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#important-properties-of-variances-of-continuous-rvs",
    "href": "lessons copy/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#important-properties-of-variances-of-continuous-rvs",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Important properties of variances of continuous RVs",
    "text": "Important properties of variances of continuous RVs\n\n\n\n\nFunction of RV with two constants\n\n\n\\[Var[aX+b] = a^2Var[X]\\]\n\n\n\n\n\nVariance of sum of independent RVs pt 1\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous RVs and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\[Var\\Bigg(\\sum_{i=1}^{n} a_i X_i\\Bigg) =\\sum_{i=1}^{n} a^2_i Var(X_i)\\]\n\n\n\n\nVariance of sum of independent RVs pt 2\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous RVs, then \\[Var\\Bigg(\\sum_{i=1}^{n} X_i\\Bigg) = \\sum_{i=1}^{n} Var(X_i)\\]"
  },
  {
    "objectID": "lessons copy/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#find-the-mean-and-sd-from-word-problem",
    "href": "lessons copy/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#find-the-mean-and-sd-from-word-problem",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Find the mean and sd from word problem",
    "text": "Find the mean and sd from word problem\n\n\n\n\nExample 4\n\n\nA machine manufactures cubes with a side length that varies uniformly from 1 to 2 inches. Assume the sides of the base and height are equal. The cost to make a cube is 10 ¢ per cubic inch, and 5 ¢ cents for the general cost per cube. Find the mean and standard deviation of the cost to make 10 cubes."
  },
  {
    "objectID": "lessons copy/15_Variance/12_Variance_key_info.html",
    "href": "lessons copy/15_Variance/12_Variance_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 4 assignment due last night!\nHW 3 solutions also due\nTime to grade later today: HW 3 solutions or HW 4 assignment?"
  },
  {
    "objectID": "lessons copy/15_Variance/12_Variance_key_info.html#announcements",
    "href": "lessons copy/15_Variance/12_Variance_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 4 assignment due last night!\nHW 3 solutions also due\nTime to grade later today: HW 3 solutions or HW 4 assignment?"
  },
  {
    "objectID": "lessons copy/15_Variance/12_Variance_key_info.html#key-dates",
    "href": "lessons copy/15_Variance/12_Variance_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities_muddy_points.html",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n1. How do pdf, CDF, and probability interact with each other?\nLet’s say we have a pdf, \\(f_X(x) = \\dfrac{1}{9}x^2\\) for \\(0 \\leq x \\leq 3\\). This is just a function. The pdf is not used on its own to report any probability. We must integrate over the pdf to find a probability.\n\nlibrary(\"ggplot2\")\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3)\n\n\n\n\n\n\n\n\nThe total area under the pdf is 1. This makes our pdf valid.\n\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 3),\n                geom = \"area\", \n                aes(fill = \"red\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 1\", color = \"black\")\n\n\n\n\n\n\n\n\nIf we only look at a proportion of the area under the pdf, then we start constructing our probabilities. For example, we can look at probability that we have a value between 0 and 1.5.\n\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 1.5),\n                geom = \"area\", \n                aes(fill = \"blue\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 0.125\", color = \"black\")\n\n\n\n\n\n\n\n\nInstead of calculating the EXACT probability for each value between 0 and 3, we can find the CDF of the pdf.\nThe CDF is: \\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;3 \\quad \\\\\n            \\dfrac{1}{27}x^3 & \\quad 0 \\leq x \\leq 3\\quad \\\\\n            1 & \\quad x&gt;3 \\quad\n        \\end{array}\n    \\right.\n\\]\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nWhen \\(x=1.5\\), we can calculate the probability using the CDF. Remember that \\(F_X(x) = P(X \\leq x)\\). So we can say \\(P(X \\leq 1.5) = F_X(1.5) = \\dfrac{1}{27}(1.5)^3\\), which equals 0.125.\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\") +\n  geom_point(aes(x=1.5, y=.125), colour=\"blue\", size=3) +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"CDF = 0.125\", color = \"black\")\n\nWarning in geom_point(aes(x = 1.5, y = 0.125), colour = \"blue\", size = 3): All aesthetics have length 1, but the data has 2 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\nWe can also calculate the probability with an integral: \\(P(X \\leq 1.5) = \\displaystyle\\int_0^{1.5} \\dfrac{1}{9}x^2 dx\\).\nWe can also find the probability that X is between two numbers. \\(P(1\\leq X \\leq 1.5) = F_X(1.5) - F_X(1)\\) or \\(P(1\\leq X \\leq 1.5) = \\displaystyle\\int_1^{1.5} \\dfrac{1}{9}x^2 dx\\).\n\n\n2. Joint vs marginal vs conditional: How are we calculating the probability?\nIf we start at a joint probability \\(f_{X,Y}(x,y)\\)…. we can look at a few probabilities:\n\nJoint probability: \\(P(a \\leq X \\leq b, c \\leq Y \\leq d)\\)\n\\[P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=c}^{y=d} f_{X,Y}(x,y) dydx\\]\nMarginal probability: \\(P(a \\leq X \\leq b)\\)\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b} f_{X}(x) dx\\]\nOR\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=-\\inf}^{y=\\inf} f_{X,Y}(x,y) dydx\\]\nConditional probability: \\(P(a \\leq X \\leq b | Y = c)\\)\n\\[P(a \\leq X \\leq b | Y=c) = \\displaystyle\\int_{x=a}^{x=b} f_{X|Y}(x|y=c) dx\\]\nYou cannot calculate \\(P(a \\leq X \\leq b | Y = c)\\) by \\(\\dfrac{P(a \\leq X \\leq b, Y=c)}{P(Y = c)}\\) because \\(P(Y = c)\\) is 0. Instead, we need to find \\(f_{X|Y}(x|y=c)\\) by \\(\\dfrac{f_{X,Y}(x,y=c)}{f_{Y}(y=c)}\\) and THEN integrate over X.\n\n\n\n3. What are we actually finding by solving the double integral. In the first example, we found the probability was 1/16 after integrating but what does 1/16 mean in relation to the random variables X and Y?\nIt means that the volume contained by \\(0\\leq X \\leq 1\\), \\(0\\leq Y \\leq 1/2\\), and their joint pdf is 1/16 of the total volume contained by \\(0\\leq X \\leq 2\\), \\(0\\leq Y \\leq 1\\), and their joint pdf. The probability for a joint pdf is now a measure of the proportion of the volume.\nThis is not be confused with a probability from marginal pdf or pdf from one RV. The probability for marginal/single RV pdfs is the proportion of the area under the pdf for a specific range of values.\n\n\n4. Here’s a 3D plot of one of our joint pdf’s\n\\[\nf_{X,Y}(x,y) = 5e^{-x-3y} \\text{ for } 0 \\leq y \\leq x/2\n\\]\n\nlibrary(plotly)\n\nx = seq(0, 5, 0.1)\ny = seq(0, max(x)/2, 0.1/2)\nfn = expand.grid(x=x,y=y)\nfn$z = ifelse(fn$y&lt;fn$x/2, 5*exp( (-1)*fn$x - 3*fn$y), NA)\n\nz = matrix(fn$z, ncol = 51, nrow = 51, byrow = T)\n\nfig &lt;- plot_ly(x = x, y=y, z=z) %&gt;% add_surface()\n\nfig"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html",
    "title": "Chapter 25: Joint densities",
    "section": "",
    "text": "Solve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#learning-objectives",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#learning-objectives",
    "title": "Chapter 25: Joint densities",
    "section": "",
    "text": "Solve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#double-integrals-mini-lesson-13",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#double-integrals-mini-lesson-13",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (1/3)",
    "text": "Double Integrals Mini Lesson (1/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 1\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} xy dydx\\)"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#double-integrals-mini-lesson-23",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#double-integrals-mini-lesson-23",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (2/3)",
    "text": "Double Integrals Mini Lesson (2/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 2\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} (x+y) dydx\\)"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#double-integrals-mini-lesson-33",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#double-integrals-mini-lesson-33",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (3/3)",
    "text": "Double Integrals Mini Lesson (3/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 3\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} e^{x+y} dydx\\)"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "title": "Chapter 25: Joint densities",
    "section": "How to define the joint pdf for continuous RVs?",
    "text": "How to define the joint pdf for continuous RVs?\n\n\nFor a single continuous RV \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\), \\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\]\n\nFor two continuous RVs (\\(X\\) and \\(Y\\)), we can define the joint pdf, \\(f_{X,Y}(x,y)\\), such that for all real values \\(a,b, c, d\\) with \\(a \\leq b\\) and \\(c \\leq d\\), \\[\\mathbb{P}(a \\leq X \\leq b, c \\leq Y \\leq d) = \\int_a^b \\int_c^d f_{X,Y}(x,y)dydx\\]"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#important-properties-of-the-joint-pdf",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#important-properties-of-the-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Important properties of the joint pdf",
    "text": "Important properties of the joint pdf\n\nNote that \\(f_{X,Y}(x,y)\\neq \\mathbb{P}(X=x, Y=y)\\)!!!\nIn order for \\(f_{X,Y}(x,y)\\) to be a pdf, it needs to satisfy the properties\n\n\\(f_{X,Y}(x,y)\\geq 0\\) for all \\(x,y\\)\n\\(\\displaystyle\\int_{-\\infty}^{\\infty}\\displaystyle\\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dxdy=1\\)"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "title": "Chapter 25: Joint densities",
    "section": "What is the joint cumulative distribution function?",
    "text": "What is the joint cumulative distribution function?\n\n\nDefinition: Joint cumulative distribution function (Joint CDF)\n\n\nThe joint cumulative distribution function (cdf) of continuous random variables \\(X\\) and \\(Y\\), is the function \\(F_{X,Y}(x,y)\\), such that for all real values of \\(x\\) and \\(y\\), \\[F_{X,Y}(x,y)= \\mathbb{P}(X \\leq x, Y \\leq y) = \\int_{-\\infty}^x\\int_{-\\infty}^y f_{X,Y}(s,t)dtds\\]\n\n\nRemarks:\n\nThe definition above for \\(F_{X,Y}(x,y)\\) is a function of \\(x\\) and \\(y\\).\nThe joint cdf at the point \\((a,b)\\), is \\[F_{X,Y}(a,b) = \\mathbb{P}(X \\leq a, Y \\leq b) = \\int_{-\\infty}^a\\int_{-\\infty}^b f_{X,Y}(s,t)dtds\\]"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#what-are-the-marginal-pdfs",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#what-are-the-marginal-pdfs",
    "title": "Chapter 25: Joint densities",
    "section": "What are the marginal pdf’s?",
    "text": "What are the marginal pdf’s?\n\n\nDefinition: Marginal pdf’s\n\n\nSuppose \\(X\\) and \\(Y\\) are continuous r.v.’s, with joint pdf \\(f_{X,Y}(x,y)\\). Then the marginal probability density functions are \\[\\begin{aligned}\nf_X(x)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dy\\\\\nf_Y(y)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dx\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#common-steps-for-solving-problems",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#common-steps-for-solving-problems",
    "title": "Chapter 25: Joint densities",
    "section": "Common steps for solving problems",
    "text": "Common steps for solving problems\n\nSet up the domain of the pdf with a picture\nTranslate to needed integrands\n\nFor probability: shade in the area of interest, then translate\nFor expected value: translate domain\n\nSet up integral: \\(dxdy\\) or \\(dydx\\)?\nSolve integral!"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#example-of-joint-pdf",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#example-of-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)."
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#example-of-joint-pdf-1",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#example-of-joint-pdf-1",
    "title": "Chapter 25: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "title": "Chapter 25: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(\\mathbb{P}(Y &lt; 3)\\)."
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-more",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-more",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.1\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nFind \\(\\mathbb{P}(|X-Y| &lt; 2)\\)"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "title": "Chapter 25: Joint densities",
    "section": "Finding the pdf of a transformation",
    "text": "Finding the pdf of a transformation\n\nLet \\(M\\) be a transformation of \\(X\\) and \\(Y\\)\nWhen we have a transformation of \\(X\\) and \\(Y\\), \\(M\\), we need to follow a specific process to find the pdf of \\(M\\)\n\nWe follow this process:\n\nStart with the joint pdf for \\(X\\) and \\(Y\\)\n\naka \\(f_{X,Y}(x, y)\\)\n\nTranslate the domain of \\(X\\) and \\(Y\\) to \\(M\\)\nFind the CDF of \\(M\\)\n\naka \\(F_M(m)\\) or \\(P(M \\leq m)\\)\n\nTake the derivative of the CDF of \\(M\\) to find the pdf of \\(M\\)\n\naka \\(f_M(m) = \\dfrac{d}{dm}F_M(m)\\)"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-more-1",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-more-1",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.2\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(M = \\max(X,Y)\\). Find the pdf for \\(M\\), that is \\(f_M(m)\\)."
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-more-2",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-more-2",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 3.3\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(Z = \\min(X,Y)\\). Find the pdf for \\(Z\\), that is \\(f_Z(z)\\)."
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-further",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-further",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even further!",
    "text": "Let’s complicate this even further!\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 4\n\n\nLet \\(X\\) and \\(Y\\) have joint density \\(f_{X,Y}(x,y)= \\frac85(x+y)\\) in the region \\(0 &lt; x &lt; 1,\\ \\frac12 &lt; y &lt;1\\). Find the pdf of the r.v. \\(Z\\), where \\(Z=XY\\)."
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability_key_info.html",
    "href": "lessons copy/01_Probability/01_Probability_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Slack is working for a few people??\n\nhttps://join.slack.com/t/bsta550/shared_invite/zt-2qtfo9s8j-j6ozEaYdT7yy1KuHoT9Mhw"
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability_key_info.html#announcements",
    "href": "lessons copy/01_Probability/01_Probability_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Slack is working for a few people??\n\nhttps://join.slack.com/t/bsta550/shared_invite/zt-2qtfo9s8j-j6ozEaYdT7yy1KuHoT9Mhw"
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability_muddy_points.html",
    "href": "lessons copy/01_Probability/01_Probability_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "The muddy points from this year were a subset of the ones from last year, so I just decided to copy those below!"
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability_muddy_points.html#proofs-of-propositions",
    "href": "lessons copy/01_Probability/01_Probability_muddy_points.html#proofs-of-propositions",
    "title": "Muddy Points",
    "section": "1. Proofs of propositions",
    "text": "1. Proofs of propositions\nFurther explanations of the propositions can be found in the textbook from pages 24-27. For many of the explanations in class, I was working to produce a union of disjoint events, so that the probability could easily be calculated. Proposition 3 and 4 were specifically mentioned, so I will include some writing notes on them here:\n\nProposition 3\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\nIn this proposition, I want to define event \\(B\\) as a union of disjoint events so that I can show \\(P(B)\\) is the sum of \\(P(A)\\) and some greater-than-or-equal-to 0 probability event. If the following is my venn diagram of A and B:\n\n\n\n\n\nThen I can define B as the union of disjoint events: \nIf we then take the probability of each side of the equation \\(B = A \\cup (A^c \\cap B)\\), we get \\[P(B) = P\\big(A \\cup (A^c \\cap B)\\big)\\]\nSince events \\(A\\) and \\(A^c \\cap B\\) are disjoint, the probability of their union is just: \\[P(A) + P(A^c \\cap B)\\]\nThus, our equation is now \\[P(B) = P(A) + P(A^c \\cap B)\\]\nFrom Axiom 1, we know for event \\(A^c \\cap B\\), \\(P(A^c \\cap B) \\geq 0\\).\nSo the probability of event B is the sum of the probability of event A and an event that is \\(\\geq\\) 0. This means \\(P(B) \\geq P(A)\\).\n\n\nProposition 4\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)\n\n\nFrom the pictures above, we can see some similar disjoint events.\nIf we look back at \\(A \\cup B\\), we can start manipulating the right side of the equation:"
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability_muddy_points.html#example-at-end-of-chapter-2-slides-venn-diagram",
    "href": "lessons copy/01_Probability/01_Probability_muddy_points.html#example-at-end-of-chapter-2-slides-venn-diagram",
    "title": "Muddy Points",
    "section": "2. Example at end of Chapter 2 slides (Venn Diagram)",
    "text": "2. Example at end of Chapter 2 slides (Venn Diagram)\nI will post this in the previous week’s Muddy Points as well. Please follow this link for my work through of the example. And here is the PDF with my work.\nSub-question: why don’t we just multiply the probability of A and B to get the intersection? This is a specific property of probability when A and B are independent. Only when A and B are independent can we conclude that \\(P(A \\cap B) = P(A)P(B)\\)."
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability_muddy_points.html#partition-of-events",
    "href": "lessons copy/01_Probability/01_Probability_muddy_points.html#partition-of-events",
    "title": "Muddy Points",
    "section": "3. Partition of events",
    "text": "3. Partition of events\nWe’ve been working with event partitions throughout Chapter 2, but we have not formally identified them. Partitions are advantageous to define for two reasons:\n\nThe partitions may be easier to calculate. We can then use the partitions to reconstruct other probabilities that may be more difficult to calculate\nPartitions have nice properties as a consequence of being disjoint. For example, the probability of the union of partitions is the sum of the probabilities across each partition: \\[P\\bigg(\\bigcup_{i=1}^n A_i\\bigg) = P(A_1)P(A_2)P(A_3) \\cdot \\cdot \\cdot P(A_n)\\]"
  },
  {
    "objectID": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs_key_info.html",
    "href": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 presentations are graded! You did great!\nHW 7 assignment: I’ll grade tonight!\nAnything else?"
  },
  {
    "objectID": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs_key_info.html#announcements",
    "href": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 presentations are graded! You did great!\nHW 7 assignment: I’ll grade tonight!\nAnything else?"
  },
  {
    "objectID": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs_key_info.html#key-dates",
    "href": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: NONE due\nSunday: HW 7 solutions due (feel free to take an additional 3 days)"
  },
  {
    "objectID": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs_muddy_points.html",
    "href": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n2. Joint vs marginal vs conditional: How are we calculating the probability?\nIf we start at a joint probability \\(f_{X,Y}(x,y)\\)…. we can look at a few probabilities:\n\nJoint probability: \\(P(a \\leq X \\leq b, c \\leq Y \\leq d)\\)\n\\[P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=c}^{y=d} f_{X,Y}(x,y) dydx\\]\nMarginal probability: \\(P(a \\leq X \\leq b)\\)\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b} f_{X}(x) dx\\]\nOR\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=-\\inf}^{y=\\inf} f_{X,Y}(x,y) dydx\\]\nConditional probability: \\(P(a \\leq X \\leq b | Y = c)\\)\n\\[P(a \\leq X \\leq b | Y=c) = \\displaystyle\\int_{x=a}^{x=b} f_{X|Y}(x|y=c) dx\\]\nYou cannot calculate \\(P(a \\leq X \\leq b | Y = c)\\) by \\(\\dfrac{P(a \\leq X \\leq b, Y=c)}{P(Y = c)}\\) because \\(P(Y = c)\\) is 0. Instead, we need to find \\(f_{X|Y}(x|y=c)\\) by \\(\\dfrac{f_{X,Y}(x,y=c)}{f_{Y}(y=c)}\\) and THEN integrate over X.\n\n\n\n4. Here’s a 3D plot of one of our joint pdf’s\n\\[\nf_{X,Y}(x,y) = 5e^{-x-3y} \\text{ for } 0 \\leq y \\leq x/2\n\\]\n\nlibrary(plotly)\n\nx = seq(0, 5, 0.1)\ny = seq(0, max(x)/2, 0.1/2)\nfn = expand.grid(x=x,y=y)\nfn$z = ifelse(fn$y&lt;fn$x/2, 5*exp( (-1)*fn$x - 3*fn$y), NA)\n\nz = matrix(fn$z, ncol = 51, nrow = 51, byrow = T)\n\nfig &lt;- plot_ly(x = x, y=y, z=z) %&gt;% add_surface()\n\nfig"
  },
  {
    "objectID": "lessons copy/13_Expected_Values/28_Expected_Values/28_Expected_Values_key_info.html",
    "href": "lessons copy/13_Expected_Values/28_Expected_Values/28_Expected_Values_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Wow! Week 7…\nHW 3 video/presentation\n\nTomorrow! 11/12 at 11pm: recordings due if you are making that\nCalendly is up!! Please see me original announcement\n\nNeed to grade HW 4 solutions and HW 5 assignment\nAnything else?"
  },
  {
    "objectID": "lessons copy/13_Expected_Values/28_Expected_Values/28_Expected_Values_key_info.html#announcements",
    "href": "lessons copy/13_Expected_Values/28_Expected_Values/28_Expected_Values_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Wow! Week 7…\nHW 3 video/presentation\n\nTomorrow! 11/12 at 11pm: recordings due if you are making that\nCalendly is up!! Please see me original announcement\n\nNeed to grade HW 4 solutions and HW 5 assignment\nAnything else?"
  },
  {
    "objectID": "lessons copy/13_Expected_Values/28_Expected_Values/28_Expected_Values_key_info.html#key-dates",
    "href": "lessons copy/13_Expected_Values/28_Expected_Values/28_Expected_Values_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 6 due\nSunday: HW 5 solutions due"
  },
  {
    "objectID": "lessons copy/13_Expected_Values/10_Expected_Values_key_info.html",
    "href": "lessons copy/13_Expected_Values/10_Expected_Values_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 03 assignment today\nGroup evals will be taken off the assessment breakdown\nMid-quarter feedback will be put on HW 05"
  },
  {
    "objectID": "lessons copy/13_Expected_Values/10_Expected_Values_key_info.html#announcements",
    "href": "lessons copy/13_Expected_Values/10_Expected_Values_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 03 assignment today\nGroup evals will be taken off the assessment breakdown\nMid-quarter feedback will be put on HW 05"
  },
  {
    "objectID": "lessons copy/13_Expected_Values/10_Expected_Values_key_info.html#key-dates",
    "href": "lessons copy/13_Expected_Values/10_Expected_Values_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 04 assignment due Thursday\nHW 03 solutions due Sunday\n\nAnd we will have a presentation on this one!"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/03_Independent_Events/03_Independent_Events.html",
    "href": "lessons copy/04_Rules_of_prob/03_Independent_Events/03_Independent_Events.html",
    "title": "Chapter 3: Independent Events",
    "section": "",
    "text": "Define independence of 2-3 events given probability notation\nCalculate whether two or more events are independent"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/03_Independent_Events/03_Independent_Events.html#learning-objectives",
    "href": "lessons copy/04_Rules_of_prob/03_Independent_Events/03_Independent_Events.html#learning-objectives",
    "title": "Chapter 3: Independent Events",
    "section": "",
    "text": "Define independence of 2-3 events given probability notation\nCalculate whether two or more events are independent"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/03_Independent_Events/03_Independent_Events.html#where-are-we",
    "href": "lessons copy/04_Rules_of_prob/03_Independent_Events/03_Independent_Events.html#where-are-we",
    "title": "Chapter 3: Independent Events",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/03_Independent_Events/03_Independent_Events.html#independent-events",
    "href": "lessons copy/04_Rules_of_prob/03_Independent_Events/03_Independent_Events.html#independent-events",
    "title": "Chapter 3: Independent Events",
    "section": "Independent Events",
    "text": "Independent Events\n\n\nDefinition: Independence\n\n\nEvents \\(A\\) and \\(B\\) are independent if \\[\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B).\\]\n\n\nNotation: For shorthand, we sometimes write \\(A \\mathrel{\\unicode{x2AEB}} B,\\) to denote that \\(A\\) and \\(B\\) are independent events.\n \n\nAlso note: \\[\\begin{aligned} \\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B) & \\implies A \\mathrel{\\unicode{x2AEB}} B \\\\\nA \\mathrel{\\unicode{x2AEB}} B & \\implies \\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B) \\end{aligned}\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/03_Independent_Events/03_Independent_Events.html#example-of-two-dice",
    "href": "lessons copy/04_Rules_of_prob/03_Independent_Events/03_Independent_Events.html#example-of-two-dice",
    "title": "Chapter 3: Independent Events",
    "section": "Example of two dice",
    "text": "Example of two dice\n\n\nExample 1\n\n\nTwo dice (red and blue) are rolled. Let \\(A =\\) event a total of 7 appears, and \\(B =\\) event red die is a six. Are events \\(A\\) and \\(B\\) independent?"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/03_Independent_Events/03_Independent_Events.html#independence-of-3-events",
    "href": "lessons copy/04_Rules_of_prob/03_Independent_Events/03_Independent_Events.html#independence-of-3-events",
    "title": "Chapter 3: Independent Events",
    "section": "Independence of 3 Events",
    "text": "Independence of 3 Events\n\n\nDefinition: Independence of 3 Events\n\n\nEvents \\(A\\), \\(B\\), and \\(C\\) are mutually independent if\n\n\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot \\mathbb{P}(B)\\)\n\\(\\mathbb{P}(A \\cap C) = \\mathbb{P}(A) \\cdot \\mathbb{P}(C)\\)\n\\(\\mathbb{P}(B \\cap C) = \\mathbb{P}(B) \\cdot \\mathbb{P}(C)\\)\n\n\\(\\mathbb{P}(A \\cap B \\cap C) = \\mathbb{P}(A) \\cdot \\mathbb{P}(B) \\cdot \\mathbb{P}(C)\\)\n\n\n\nRemark:\nOn your homework you will show that \\((1) \\not \\Rightarrow (2)\\) and \\((2) \\not \\Rightarrow (1)\\)."
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/03_Independent_Events/03_Independent_Events.html#probability-at-least-one-smoker",
    "href": "lessons copy/04_Rules_of_prob/03_Independent_Events/03_Independent_Events.html#probability-at-least-one-smoker",
    "title": "Chapter 3: Independent Events",
    "section": "Probability at least one smoker",
    "text": "Probability at least one smoker\n\n\n\n\nExample 2\n\n\nSuppose you take a random sample of \\(n\\) people, of which people are smokers and non-smokers independently of each other. Let\n\n\\(A_i =\\) event person \\(i\\) is a smoker, for \\(i=1, \\ldots ,n\\), and\n\\(p_i =\\) probability person \\(i\\) is a smoker, for \\(i=1, \\ldots ,n\\).\n\nFind the probability that at least one person in the random sample is a smoker."
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/03_Independent_Events/03_Independent_Events.html#building-geometric-series",
    "href": "lessons copy/04_Rules_of_prob/03_Independent_Events/03_Independent_Events.html#building-geometric-series",
    "title": "Chapter 3: Independent Events",
    "section": "Building geometric series",
    "text": "Building geometric series\n\n\nExample 3\n\n\n\\(A, B,\\) and \\(C\\) toss a fair coin in order. The first to throw heads wins. What are their respective chances of winning?\n\n\nLet\n\n\\(A_H\\) and \\(A_T\\) be the events player A tosses heads and tails, respectively.\nSimilarly define \\(B_H\\), \\(B_T\\), \\(C_H\\), and \\(C_T\\)."
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability_key_info.html",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "For office hours, we decided to do appointments!\n\nHere’s my Calendly: https://calendly.com/nickywakim/15min\nI teach on Mondays and Wednesdays so I am keeping most of my meetings to Tuesdays and Thursdays\nFor my EPI class, I have scheduled office hours on Mondays 4-5pm in VPT 627\n\nI will give priority to EPI students, but you can drop by for those as well\n\n\nI think all the dates in the schedule were correct except for next week"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability_key_info.html#announcements",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "For office hours, we decided to do appointments!\n\nHere’s my Calendly: https://calendly.com/nickywakim/15min\nI teach on Mondays and Wednesdays so I am keeping most of my meetings to Tuesdays and Thursdays\nFor my EPI class, I have scheduled office hours on Mondays 4-5pm in VPT 627\n\nI will give priority to EPI students, but you can drop by for those as well\n\n\nI think all the dates in the schedule were correct except for next week"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability_key_info.html#key-dates",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 1 Assignment due this Thursday at 11pm"
  },
  {
    "objectID": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html",
    "href": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "",
    "text": "Calculate probabilities for discrete random variables\nCalculate and graph a probability mass function (pmf)\nCalculate and graph a cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#learning-objectives",
    "href": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#learning-objectives",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "",
    "text": "Calculate probabilities for discrete random variables\nCalculate and graph a probability mass function (pmf)\nCalculate and graph a cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#where-are-we",
    "href": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#where-are-we",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#what-is-a-probability-mass-function",
    "href": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#what-is-a-probability-mass-function",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "What is a probability mass function?",
    "text": "What is a probability mass function?\n\n\nDefinition: probability distribution or probability mass function (pmf)\n\n\nThe probability distribution or probability mass function (pmf) of a discrete r.v. \\(X\\) is defined for every number \\(x\\) by \\[p_X(x) = \\mathbb{P}(X=x) = \\mathbb{P}(\\mathrm{all }\\ \\omega\\in S:X(\\omega) = x)\\]"
  },
  {
    "objectID": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#lets-demonstrate-this-definition-with-our-coin-toss",
    "href": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#lets-demonstrate-this-definition-with-our-coin-toss",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Let’s demonstrate this definition with our coin toss",
    "text": "Let’s demonstrate this definition with our coin toss\n\n\n\n\nExample 1\n\n\nSuppose we toss 3 coins with probability of tails \\(p\\). If \\(X\\) is the random variable counting the number of tails, what are the probabilities of each value of \\(X\\)?"
  },
  {
    "objectID": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#remarks-on-the-pmf",
    "href": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#remarks-on-the-pmf",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Remarks on the pmf",
    "text": "Remarks on the pmf\n\n\nProperties of pmf\n\n\nA pmf \\(p_X(x)\\) must satisfy the following properties:\n\n\\(0 \\leq p_X(x) \\leq 1\\) for all \\(x\\).\n\\(\\sum \\limits_{\\{all\\ x\\}}p_X(x)=1\\).\n\n\n\n\nSome distributions depend on parameters\n\nEach value of a parameter gives a different pmf\nIn previous example, the number of coins tossed was a parameter\n\nWe tossed 3 coins\nIf we tossed 4 coins, we’d get a different pmf!\n\nThe collection of all pmf’s for different values of the parameters is called a family of pmf’s"
  },
  {
    "objectID": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#binomial-family-of-rvs",
    "href": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#binomial-family-of-rvs",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Binomial family of RVs",
    "text": "Binomial family of RVs\n\n\n\n\nExample 2\n\n\nSuppose you toss \\(n\\) coins, each with probability of tails \\(p\\). If \\(X\\) is the number of tails, what is the pmf of \\(X\\)?"
  },
  {
    "objectID": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#bernoulli-family-of-rvs",
    "href": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#bernoulli-family-of-rvs",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Bernoulli family of RVs",
    "text": "Bernoulli family of RVs\n\n\n\n\nExample 3\n\n\nSuppose you toss 1 coin, with probability of tails \\(p\\). If \\(X\\) is the number of tails, what is the pmf of \\(X\\)?"
  },
  {
    "objectID": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#household-size-15",
    "href": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#household-size-15",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (1/5)",
    "text": "Household size (1/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nWhat is the sample space for household sizes?\nDefine the random variable for household sizes.\nDo the values in the table create a pmf? Why or why not?\nMake a plot of the pmf.\nWrite the cdf as a function.\nGraph the cdf of household sizes in 2019."
  },
  {
    "objectID": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#household-size-25",
    "href": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#household-size-25",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (2/5)",
    "text": "Household size (2/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nWhat is the sample space for household sizes?\nDefine the random variable for household sizes."
  },
  {
    "objectID": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#household-size-35",
    "href": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#household-size-35",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (3/5)",
    "text": "Household size (3/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nDo the values in the table create a pmf? Why or why not?\nMake a plot of the pmf"
  },
  {
    "objectID": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#what-is-a-cumulative-distribution-function",
    "href": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#what-is-a-cumulative-distribution-function",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "What is a cumulative distribution function?",
    "text": "What is a cumulative distribution function?\n\n\nDefinition: cumulative distribution function (CDF)\n\n\nThe cumulative distribution function (cdf) of a discrete r.v. \\(X\\) with pmf \\(p_X(x)\\), is defined for every value \\(x\\) by \\[F_X(x) = \\mathbb{P}(X \\leq x) = \\sum \\limits_{\\{all\\ y:\\ y\\leq x\\}}p_X(y)\\]"
  },
  {
    "objectID": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#household-size-45",
    "href": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#household-size-45",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (4/5)",
    "text": "Household size (4/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nWrite the cdf as a function."
  },
  {
    "objectID": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#household-size-55",
    "href": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#household-size-55",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (5/5)",
    "text": "Household size (5/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nGraph the cdf of household sizes in 2019."
  },
  {
    "objectID": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#properties-of-discrete-cdfs",
    "href": "lessons copy/08_pmfs_and_cdfs/08_pmfs.html#properties-of-discrete-cdfs",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Properties of discrete CDFs",
    "text": "Properties of discrete CDFs\n\n\\(F(x)\\) is increasing or flat (never decreasing)\n\\(\\min\\limits_x F(x) = 0\\)\n\\(\\max\\limits_xF(x)=1\\)\nCDF is a step function"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability.html",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability.html",
    "title": "Chapter 4: Conditional Probability",
    "section": "",
    "text": "Use set process to calculate probability of event of interest\nCalculate the probability of an event occurring, given that another event occurred.\nDefine keys facts for conditional probabilities using notation."
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability.html#learning-objectives",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability.html#learning-objectives",
    "title": "Chapter 4: Conditional Probability",
    "section": "",
    "text": "Use set process to calculate probability of event of interest\nCalculate the probability of an event occurring, given that another event occurred.\nDefine keys facts for conditional probabilities using notation."
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability.html#where-are-we",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability.html#where-are-we",
    "title": "Chapter 4: Conditional Probability",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability.html#general-process-for-probability-word-problems",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability.html#general-process-for-probability-word-problems",
    "title": "Chapter 4: Conditional Probability",
    "section": "General Process for Probability Word Problems",
    "text": "General Process for Probability Word Problems\n\nClearly define your events of interest\nTranslate question to probability using defined events OR Venn Diagram\nAsk yourself:\n\nAre we sampling with or without replacement?\nDoes order matter?\n\nUse axioms, properties, partitions, facts, etc. to define the end probability calculation into smaller parts\n\nIf probabilities are given to you, Venn Diagrams may help you parse out the events and probability calculations\nIf you need to find probabilities with counting, pictures or diagrams might help here\n\nWrite out a concluding statement that gives the probability context\n(For own check) Make sure the calculated probability follows the axioms. Is is between 0 and 1?"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability.html#lets-revisit-our-deck-of-cards",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability.html#lets-revisit-our-deck-of-cards",
    "title": "Chapter 4: Conditional Probability",
    "section": "Let’s revisit our deck of cards",
    "text": "Let’s revisit our deck of cards\n\n\n\n\nExample 1\n\n\nSuppose we randomly draw 2 cards from a standard deck of cards. What is the probability that we draw a spade then a heart?\n\n\nLet\n\nLet \\(A =\\) event \\(1^{st}\\) card is spades\nLet \\(B =\\) event \\(2^{nd}\\) card is heart"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability.html#conditional-probability-facts-12",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability.html#conditional-probability-facts-12",
    "title": "Chapter 4: Conditional Probability",
    "section": "Conditional Probability facts (1/2)",
    "text": "Conditional Probability facts (1/2)\n\n\n\n\nFact 1: General Multiplication Rule\n\n\n\\[\\mathbb{P}(A\\cap B)=\\mathbb{P}(A)\\cdot\\mathbb{P}(B|A)\\]\n\n\n\n\n\nFact 2: Conditional Probability Definition\n\n\n\\[\\mathbb{P}(A|B)=\\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)}\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability.html#conditional-probability-facts-22",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability.html#conditional-probability-facts-22",
    "title": "Chapter 4: Conditional Probability",
    "section": "Conditional Probability facts (2/2)",
    "text": "Conditional Probability facts (2/2)\n\n\n\n\nFact 3\n\n\nIf \\(A\\) and \\(B\\) are independent events (\\(A \\unicode{x2AEB}B\\)), then \\[\\mathbb{P}(A|B) = \\mathbb{P}(A)\\]\n\n\n\n\n\nFact 4\n\n\n\\(\\mathbb{P}(A|B)\\) is a probability, meaning that it satisfies the probability axioms. In particular, \\[\\mathbb{P}(A|B) + \\mathbb{P}(A^C|B) = 1\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability.html#monty-hall-problem",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability.html#monty-hall-problem",
    "title": "Chapter 4: Conditional Probability",
    "section": "Monty Hall Problem",
    "text": "Monty Hall Problem\nSurvivor Season 42\nWith the Wiki page on it!"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability.html#conditional-probability-with-two-dice",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability/04_Conditional_Probability.html#conditional-probability-with-two-dice",
    "title": "Chapter 4: Conditional Probability",
    "section": "Conditional probability with two dice",
    "text": "Conditional probability with two dice\n\n\n\n\nExample 2\n\n\nTwo dice (red and blue) are rolled. If the dice do not show the same face, what is the probability that one of the dice is a 1?"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "",
    "text": "Calculate conditional probability of an event using Bayes’ Theorem\nUtilize additional probability rules in probability calculations, specifically the Higher Order Multiplication Rule and the Law of Total Probabilities"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#learning-objectives",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#learning-objectives",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "",
    "text": "Calculate conditional probability of an event using Bayes’ Theorem\nUtilize additional probability rules in probability calculations, specifically the Higher Order Multiplication Rule and the Law of Total Probabilities"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#where-are-we",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#where-are-we",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#introduction",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#introduction",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Introduction",
    "text": "Introduction\n\nSo we learned about conditional probabilities\n\nWe learned how the occurrence of event A affects event B (B conditional on A)\n\nCan we figure out information on how the occurrence of event B affects event A?\nWe can use the conditional probability (\\(\\mathbb{P}(A|B)\\)) to get information on the flipped conditional probability (\\(\\mathbb{P}(B|A)\\))"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#bayes-rule-for-two-events",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#bayes-rule-for-two-events",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Bayes’ Rule for two events",
    "text": "Bayes’ Rule for two events\n\n\n\n\nTheorem: Bayes’ Rule (for two events)\n\n\nFor any two events \\(A\\) and \\(B\\) with nonzero probabilties,\n\\[\\mathbb{P}(A| B) =\n\\frac{\\mathbb{P}(A) \\cdot \\mathbb{P}(B|A)}\n{\\mathbb{P}(B)}\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-higher-order-multiplication-rule",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-higher-order-multiplication-rule",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with Higher Order Multiplication Rule",
    "text": "Calculating probability with Higher Order Multiplication Rule\n\n\n\n\nExample 1\n\n\nSuppose we draw 5 cards from a standard shuffled deck of 52 cards. What is the probability of a flush, that is all the cards are of the same suit (including straight flushes)?\n\n\n\n\n\nHigher Order Multiplication Rule\n\n\n\\[\\mathbb{P}(A_1\\cap A_2 \\cap  \\ldots \\cap A_n)=\\mathbb{P}(A_1)\\cdot\\mathbb{P}(A_2|A_1) \\cdot \\\\\n\\mathbb{P}(A_3|A_1A_2)\\ldots \\cdot\\mathbb{P}(A_n|A_1A_2\\ldots A_{n-1})\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-law-of-total-probability",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-law-of-total-probability",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with Law of Total Probability",
    "text": "Calculating probability with Law of Total Probability\n\n\n\n\nExample 2\n\n\nSuppose 1% of people assigned female at birth (AFAB) and 5% of people assigned male at birth (AMAB) are color-blind. Assume person born is equally likely AFAB or AMAB (not including intersex). What is the probability that a person chosen at random is color-blind?\n\n\n\n\n\nLaw of Total Probability for 2 Events\n\n\nFor events \\(A\\) and \\(B\\),\n\\[%\\left(\n\\begin{array}{ccl}\n\\mathbb{P}(B)&=&\\mathbb{P}(B \\cap A) + \\mathbb{P}(B \\cap A^C)\\\\\n           &=& \\mathbb{P}(B|A) \\cdot \\mathbb{P}(A)+ \\mathbb{P}(B | A^C)\\cdot \\mathbb{P}(A^C)\n\\end{array}\n%\\right)\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#general-law-of-total-proability",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#general-law-of-total-proability",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "General Law of Total Proability",
    "text": "General Law of Total Proability\n\n\nLaw of Total Probability (general)\n\n\nIf \\(\\{A_i\\}_{i=1}^{n} = \\{A_1, A_2, \\ldots, A_n\\}\\) form a partition of the sample space, then for event \\(B\\),\n\\[%\\left(\n\\begin{array}{ccl}\n\\mathbb{P}(B)&=& \\sum_{i=1}^{n} \\mathbb{P}(B \\cap A_i)\\\\\n           &=& \\sum_{i=1}^{n} \\mathbb{P}(B|A_i) \\cdot \\mathbb{P}(A_i)\n\\end{array}\n%\\right)\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with generalized Law of Total Probability",
    "text": "Calculating probability with generalized Law of Total Probability"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability-1",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability-1",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with generalized Law of Total Probability",
    "text": "Calculating probability with generalized Law of Total Probability\n\n\n\n\nExample 3\n\n\nIndividuals are diagnosed with a particular type of cancer that can take on three different disease forms,* \\(D_1\\), \\(D_2\\), and \\(D_3\\). It is known that amongst people diagnosed with this particular type of cancer,\n\n20% of people will eventually be diagnosed with form \\(D_1\\),\n30% with form \\(D_2\\), and\n50% with form \\(D_3\\).\n\nThe probability of requiring chemotherapy (\\(C\\)) differs among the three forms of disease:\n\n80% with \\(D_1\\),\n30% with \\(D_2\\), and\n10% with \\(D_3\\).\n\nBased solely on the preliminary test of being diagnosed with the cancer, what is the probability of requiring chemotherapy (the event C)?\n\n\n\nSkipping in class! Let me know if you would like me to post solutions to this if you work through it!"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#lets-revisit-the-color-blind-example",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#lets-revisit-the-color-blind-example",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Let’s revisit the color-blind example",
    "text": "Let’s revisit the color-blind example\n\n\n\n\nExample 4\n\n\nRecall the color-blind example (Example 2), where\n\na person is AMAB with probability 0.5,\nAMAB people are color-blind with probability 0.05, and\nall people are color-blind with probability 0.03.\n\nAssuming people are AMAB or AFAB, find the probability that a color-blind person is AMAB."
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#calculate-probability-with-both-rules",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#calculate-probability-with-both-rules",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculate probability with both rules",
    "text": "Calculate probability with both rules\n\n\n\n\nExample 5\n\n\nSuppose\n\n1% of people who are AFAB aged 40-50 years have breast cancer,\nan AFAB person with breast cancer has a 90% chance of a positive test from a mammogram, and\nan AFAB person has a 10% chance of a false-positive result from a mammogram.\n\nWhat is the probability that an AFAB person has breast cancer given that they just had a positive test?"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#bayes-rule",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem/05_Bayes_Theorem.html#bayes-rule",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Bayes’ Rule",
    "text": "Bayes’ Rule\n\n\nTheorem: Bayes’ Rule\n\n\nIf \\(\\{A_i\\}_{i=1}^{n}\\) form a partition of the sample space \\(S\\), with \\(\\mathbb{P}(A_i)&gt;0\\) for \\(i=1\\ldots n\\) and \\(\\mathbb{P}(B)&gt;0\\), then\n\\[\\mathbb{P}(A_j | B) =\n\\frac{\\mathbb{P}(B|A_j) \\cdot \\mathbb{P}(A_j)}\n{\\sum_{i=1}^{n} \\mathbb{P}(B|A_i) \\cdot \\mathbb{P}(A_i)}\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/03_Independent_Events/03_Independent_Events_muddy_points.html",
    "href": "lessons copy/04_Rules_of_prob/03_Independent_Events/03_Independent_Events_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "1. How do I know if two events are independent?\nMy main piece of advice for independence is to rely on the math to show it, not logic! Don’t go into a problem thinking “Logically, these two events are independent.” If the problem does not say “Assume independence,” then we need to show it mathematically.\nSame goes with the definition of independence. When we say “knowing the outcome of one provides no information about the outcome of the other,” we once again need to show this mathematically, not just using logic. We translate the previous statement to \\[P(A) = P(A|B)\\] And we need to show this mathematically!\n\n\n2. Disjoint vs. Independent Events\nHere is a pretty good video breaking down disjoint (mutually exclusive) events and independent events. It includes examples as well."
  },
  {
    "objectID": "lessons copy/13_Expected_Values/28_Expected_Values/28_Expected_Values.html",
    "href": "lessons copy/13_Expected_Values/28_Expected_Values/28_Expected_Values.html",
    "title": "Chapter 28: Expected Values of Continuous Random Variables",
    "section": "",
    "text": "Calculate the mean (expected value) of a continuous RV"
  },
  {
    "objectID": "lessons copy/13_Expected_Values/28_Expected_Values/28_Expected_Values.html#learning-objectives",
    "href": "lessons copy/13_Expected_Values/28_Expected_Values/28_Expected_Values.html#learning-objectives",
    "title": "Chapter 28: Expected Values of Continuous Random Variables",
    "section": "",
    "text": "Calculate the mean (expected value) of a continuous RV"
  },
  {
    "objectID": "lessons copy/13_Expected_Values/28_Expected_Values/28_Expected_Values.html#expected-value-of-a-function-of-a-continuous-rv",
    "href": "lessons copy/13_Expected_Values/28_Expected_Values/28_Expected_Values.html#expected-value-of-a-function-of-a-continuous-rv",
    "title": "Chapter 28: Expected Values of Continuous Random Variables",
    "section": "Expected value of a function of a continuous RV",
    "text": "Expected value of a function of a continuous RV\n\n\nHow do we calculate expected values of discrete RVs?\n       \nFor discrete RVs: weight average \\[\\mathbb{E}[X] = \\sum_{i=1}^n x_ip_X(x_i).\\]\n\n\n\nHow do we calculate expected values of continuous RVs?\n       \nFor continuous RVs:"
  },
  {
    "objectID": "lessons copy/13_Expected_Values/28_Expected_Values/28_Expected_Values.html#expected-value-of-the-uniform-distribution",
    "href": "lessons copy/13_Expected_Values/28_Expected_Values/28_Expected_Values.html#expected-value-of-the-uniform-distribution",
    "title": "Chapter 28: Expected Values of Continuous Random Variables",
    "section": "Expected Value of the Uniform Distribution",
    "text": "Expected Value of the Uniform Distribution\n\n\n\n\nExample 1\n\n\nLet \\(f_X(x)= \\frac{1}{b-a}\\), for \\(a \\leq x \\leq b\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons copy/13_Expected_Values/28_Expected_Values/28_Expected_Values.html#expected-value-of-the-exponential-distribution",
    "href": "lessons copy/13_Expected_Values/28_Expected_Values/28_Expected_Values.html#expected-value-of-the-exponential-distribution",
    "title": "Chapter 28: Expected Values of Continuous Random Variables",
    "section": "Expected Value of the Exponential Distribution",
    "text": "Expected Value of the Exponential Distribution\n\n\n\n\nExample 2\n\n\nLet \\(f_X(x)= \\lambda e^{-\\lambda x}\\), for \\(x &gt; 0\\) and \\(\\lambda&gt; 0\\). Find \\(\\mathbb{E}[X]\\).\n\n\n\n\nIntegrating by Parts\n\n\n\\(\\displaystyle\\int_a^b u dv = uv\\bigg|^b_a - \\displaystyle\\int_a^b vdu\\)"
  },
  {
    "objectID": "lessons copy/13_Expected_Values/10_Expected_Values.html",
    "href": "lessons copy/13_Expected_Values/10_Expected_Values.html",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "",
    "text": "Calculate the mean (expected value) of discrete random variables"
  },
  {
    "objectID": "lessons copy/13_Expected_Values/10_Expected_Values.html#learning-objectives",
    "href": "lessons copy/13_Expected_Values/10_Expected_Values.html#learning-objectives",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "",
    "text": "Calculate the mean (expected value) of discrete random variables"
  },
  {
    "objectID": "lessons copy/13_Expected_Values/10_Expected_Values.html#where-are-we",
    "href": "lessons copy/13_Expected_Values/10_Expected_Values.html#where-are-we",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/13_Expected_Values/10_Expected_Values.html#our-good-and-fair-friend-the-6-sided-die",
    "href": "lessons copy/13_Expected_Values/10_Expected_Values.html#our-good-and-fair-friend-the-6-sided-die",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Our good and fair friend, the 6-sided die",
    "text": "Our good and fair friend, the 6-sided die\n\n\n\n\nExample 1\n\n\nSuppose you roll a fair 6-sided die. What value do you expect to get?"
  },
  {
    "objectID": "lessons copy/13_Expected_Values/10_Expected_Values.html#what-is-an-expected-value",
    "href": "lessons copy/13_Expected_Values/10_Expected_Values.html#what-is-an-expected-value",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "What is an expected value?",
    "text": "What is an expected value?\n\n\nDefinition: Expected value\n\n\nThe expected value of a discrete r.v. \\(X\\) that takes on values \\(x_1, x_2, \\ldots, x_n\\) is \\[\\mathbb{E}[X] = \\sum_{i=1}^n x_ip_X(x_i).\\]\n\n\n\nExpected values are not necessarily an actual outcome\n\nIn previous example, we cannot roll a 3.5\nIt could be that our expected value is not in the sample space (\\(E(X) \\notin S\\))\n\nDefinition holds when \\(X\\) takes on countably infinitely many values:\n\n\\[\\mathbb{E}[X] = \\sum_{i=1}^\\infty x_ip_X(x_i)\\]"
  },
  {
    "objectID": "lessons copy/13_Expected_Values/10_Expected_Values.html#our-good-and-not-so-fair-friend-the-6-sided-die",
    "href": "lessons copy/13_Expected_Values/10_Expected_Values.html#our-good-and-not-so-fair-friend-the-6-sided-die",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Our good and not-so-fair friend, the 6-sided die",
    "text": "Our good and not-so-fair friend, the 6-sided die\n\n\n\n\nExample 2\n\n\nSuppose the die is 6-sided, but not fair. And the probabilities of each side is distributed as:\n\n\n\n\\(x\\)\n\\(p_X(x)\\)\n\n\n\n\n1\n0.10\n\n\n2\n0.05\n\n\n3\n0.02\n\n\n4\n0.30\n\n\n5\n0.50\n\n\n6\n0.03\n\n\n\nWhat value do you expect to get on a roll?"
  },
  {
    "objectID": "lessons copy/13_Expected_Values/10_Expected_Values.html#expected-value-of-a-bernoulli-distribution",
    "href": "lessons copy/13_Expected_Values/10_Expected_Values.html#expected-value-of-a-bernoulli-distribution",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Expected value of a Bernoulli distribution",
    "text": "Expected value of a Bernoulli distribution\n\n\n\n\nExample 3\n\n\nSuppose \\[X = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\quad\\mathrm{(success)}\\\\\n            0 & \\quad \\mathrm{with\\ probability}\\ 1-p \\quad\\mathrm{(failure)}\n        \\end{array}\n    \\right.\\] Find the expected value of \\(X\\)."
  },
  {
    "objectID": "lessons copy/13_Expected_Values/10_Expected_Values.html#lets-slightly-change-our-random-variable",
    "href": "lessons copy/13_Expected_Values/10_Expected_Values.html#lets-slightly-change-our-random-variable",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Let’s slightly change our random variable",
    "text": "Let’s slightly change our random variable\n\n\n\n\nExample 5\n\n\nSuppose \\[X = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\\\\n            -1 & \\quad \\mathrm{with\\ probability}\\ 1-p\n        \\end{array}\n    \\right.\\] Find the expected value of \\(X\\)."
  },
  {
    "objectID": "lessons copy/13_Expected_Values/10_Expected_Values.html#bullseye",
    "href": "lessons copy/13_Expected_Values/10_Expected_Values.html#bullseye",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Bullseye! 🎯",
    "text": "Bullseye! 🎯\n\n\n\n\nExample 5\n\n\nSuppose I throw darts at a dartboard until I hit the bullseye, and that my probability of hitting the bullseye is \\(p\\). Suppose further that all of my throws are independent, and that the probability of a bullseye never changes, no matter how many times I throw a dart. How many times should I expect to have to throw the dart until I hit the bullseye?"
  },
  {
    "objectID": "lessons copy/13_Expected_Values/10_Expected_Values.html#ghost",
    "href": "lessons copy/13_Expected_Values/10_Expected_Values.html#ghost",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Ghost! 👻",
    "text": "Ghost! 👻\n\n\n\n\nExample 6\n\n\nA ghost is trick-or-treating. It comes to a house where it is known that there are 30 candies in the bag and only one is a watermelon Jolly Rancher, which is the ghost’s favorite. The ghost takes pieces of candy without replacement until it gets the watermelon Jolly Rancher. How many pieces of candy do we expect the ghost to take?\n\n\nCan we model this with a distribution?"
  },
  {
    "objectID": "lessons copy/13_Expected_Values/10_Expected_Values.html#some-remarks-on-last-two-examples",
    "href": "lessons copy/13_Expected_Values/10_Expected_Values.html#some-remarks-on-last-two-examples",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Some remarks on last two examples",
    "text": "Some remarks on last two examples\nBoth examples are repeated random processes. They are fundamentally different though:\n\nThe bullseye example is “with replacement” since the probability of success remains constant.\nThe ghost trick-or-treating example is without replacement, and thus the probability of success changes with each trial."
  },
  {
    "objectID": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs.html",
    "href": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs.html",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "",
    "text": "Show that a joint pdf consists of two independent, continuous RVs.\nCombine two independent RVs into one joint pdf or CDF."
  },
  {
    "objectID": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs.html#learning-objectives",
    "href": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs.html#learning-objectives",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "",
    "text": "Show that a joint pdf consists of two independent, continuous RVs.\nCombine two independent RVs into one joint pdf or CDF."
  },
  {
    "objectID": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs.html#how-do-we-represent-independent-continuous-rvs-in-a-joint-pdf",
    "href": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs.html#how-do-we-represent-independent-continuous-rvs-in-a-joint-pdf",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "How do we represent independent continuous RVs in a joint pdf?",
    "text": "How do we represent independent continuous RVs in a joint pdf?\n\n\nWhat do we know about independence for events and discrete RVs?\nFor events: If \\(A \\perp B\\)\n\\[P(A \\cap B) = P(A)P(B)\\] \\[P(A|B) = P(A)\\]\nFor discrete RVs: If \\(X \\perp Y\\) \\[p_{X,Y}(x,y) = p_{X}(x)p_{Y}(y)\\] \\[F_{X,Y}(x,y) = F_{X}(x)F_{Y}(y)\\] \\[p_{X|Y}(x|y) = p_{X}(x)\\] \\[p_{Y|X}(y|x) = p_{Y}(y)\\]\n\n\n\nWhat does it mean for continuous r.v.’s to be independent?\nFor continuous RVs: If \\(X \\perp Y\\)"
  },
  {
    "objectID": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs",
    "href": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Constructing a joint pdf from two independent, continuous RVs",
    "text": "Constructing a joint pdf from two independent, continuous RVs\n\n\n\n\nExample 1.1\n\n\nLet \\(X\\) and \\(Y\\) be independent r.v.’s with \\(f_X(x)= \\frac12\\), for \\(0 \\leq x \\leq 2\\) and \\(f_Y(y)= 3y^2\\), for \\(0 \\leq y \\leq 1\\).\n\nFind \\(f_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs-1",
    "href": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs-1",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Constructing a joint pdf from two independent, continuous RVs",
    "text": "Constructing a joint pdf from two independent, continuous RVs\n\n\n\n\nExample 1.2\n\n\nLet \\(X\\) and \\(Y\\) be independent r.v.’s with \\(f_X(x)= \\frac12\\), for \\(0 \\leq x \\leq 2\\) and \\(f_Y(y)= 3y^2\\), for \\(0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)."
  },
  {
    "objectID": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs.html#showing-independence-from-joint-pdf",
    "href": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs.html#showing-independence-from-joint-pdf",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Showing independence from joint pdf",
    "text": "Showing independence from joint pdf\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for \\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\).\n\nAre \\(X\\) and \\(Y\\) independent?"
  },
  {
    "objectID": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs.html#finding-cdf-from-two-independent-rvs",
    "href": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs.html#finding-cdf-from-two-independent-rvs",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Finding CDF from two independent RVs",
    "text": "Finding CDF from two independent RVs\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for \\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(F_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs.html#showing-independence-from-joint-pdf-1",
    "href": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs.html#showing-independence-from-joint-pdf-1",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Showing independence from joint pdf",
    "text": "Showing independence from joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 3\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Are \\(X\\) and \\(Y\\) independent?"
  },
  {
    "objectID": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs.html#final-statement-on-independence",
    "href": "lessons copy/11_Transformations/26_Independent_rvs/26_Independent_rvs.html#final-statement-on-independence",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Final statement on independence",
    "text": "Final statement on independence\n\nIf \\(f_{X,Y}(x,y)= g(x)h(y)\\), where \\(g(x)\\) and \\(h(y)\\) are pdf’s, then \\(X\\) and \\(Y\\) are independent.\n\nThe domain of the joint pdf needs to be independent as well!!\n\n\n       \n\nIf \\(F_{X,Y}(x,y)= G(x)H(y)\\), where \\(G(x)\\) and \\(H(y)\\) are cdf’s, then \\(X\\) and \\(Y\\) are independent.\n\nThe domain of the joint CDF needs to be independent as well!!"
  },
  {
    "objectID": "lessons copy/11_Transformations/27_Conditional_distributions/27_Conditional_distributions.html",
    "href": "lessons copy/11_Transformations/27_Conditional_distributions/27_Conditional_distributions.html",
    "title": "Chapter 27: Conditional Distributions",
    "section": "",
    "text": "Calculate the conditional probability density from a joint pdf"
  },
  {
    "objectID": "lessons copy/11_Transformations/27_Conditional_distributions/27_Conditional_distributions.html#learning-objectives",
    "href": "lessons copy/11_Transformations/27_Conditional_distributions/27_Conditional_distributions.html#learning-objectives",
    "title": "Chapter 27: Conditional Distributions",
    "section": "",
    "text": "Calculate the conditional probability density from a joint pdf"
  },
  {
    "objectID": "lessons copy/11_Transformations/27_Conditional_distributions/27_Conditional_distributions.html#conditional-probabilities-weve-seen-before",
    "href": "lessons copy/11_Transformations/27_Conditional_distributions/27_Conditional_distributions.html#conditional-probabilities-weve-seen-before",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Conditional probabilities we’ve seen before",
    "text": "Conditional probabilities we’ve seen before\n\n\nWhat do we know about conditional probabilities for events and discrete RVs?    \nFor events:\n\\[P(A | B) = \\dfrac{P(A \\cap B)}{P(B)}\\]    \nFor discrete RVs: \\[p_{X|Y}(x|y) = P(X=x|Y=y) = \\dfrac{p_{X,Y}(x,y)}{p_Y(y)}\\]\n\n\n\nWhat does it mean for conditional densities of continuous RVs?\nFor continuous RVs:"
  },
  {
    "objectID": "lessons copy/11_Transformations/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-first-try",
    "href": "lessons copy/11_Transformations/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-first-try",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf: first try!",
    "text": "Example starting from a joint pdf: first try!\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(2&lt;X&lt;10|Y=4)\\)"
  },
  {
    "objectID": "lessons copy/11_Transformations/27_Conditional_distributions/27_Conditional_distributions.html#what-is-a-conditional-density",
    "href": "lessons copy/11_Transformations/27_Conditional_distributions/27_Conditional_distributions.html#what-is-a-conditional-density",
    "title": "Chapter 27: Conditional Distributions",
    "section": "What is a conditional density?",
    "text": "What is a conditional density?\n\n\n\n\nDefinition: Conditional density\n\n\nThe conditional density of a r.v. \\(X\\) given \\(Y=y\\), is \\[f_{X|Y}(x|y)= \\frac{f_{X,Y}(x,y)}{f_Y(y)},\\] for \\(f_Y(y)&gt; 0\\)\n\n\n\n\n\nRemarks\n\nIt follows from the definition for the conditional density \\(f_{X|Y}(x|y)\\), that \\[f_{X,Y}(x,y)= f_{X|Y}(x|y)f_Y(y).\\]\n\n     \n\nFor a fixed value of \\(Y=y\\), the conditional density \\(f_{X|Y}(x|y)\\) is an actual pdf, meaning\n\n\\(f_{X|Y}(x|y)\\geq 0\\) for all \\(x\\) and \\(y\\), and\n\\(\\displaystyle\\int_{-\\infty}^{\\infty} f_{X|Y}(x|y)dx =1\\)."
  },
  {
    "objectID": "lessons copy/11_Transformations/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try-12",
    "href": "lessons copy/11_Transformations/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try-12",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf: second try! (1/2)",
    "text": "Example starting from a joint pdf: second try! (1/2)\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(2&lt;X&lt;10|Y=4)\\)"
  },
  {
    "objectID": "lessons copy/11_Transformations/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try-22",
    "href": "lessons copy/11_Transformations/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try-22",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf: second try! (2/2)",
    "text": "Example starting from a joint pdf: second try! (2/2)"
  },
  {
    "objectID": "lessons copy/11_Transformations/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf",
    "href": "lessons copy/11_Transformations/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf",
    "text": "Example starting from a joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(X&gt;20 |Y=5)\\)"
  },
  {
    "objectID": "lessons copy/11_Transformations/27_Conditional_distributions/27_Conditional_distributions.html#finding-probability-with-conditional-domain-and-pdf",
    "href": "lessons copy/11_Transformations/27_Conditional_distributions/27_Conditional_distributions.html#finding-probability-with-conditional-domain-and-pdf",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Finding probability with conditional domain and pdf",
    "text": "Finding probability with conditional domain and pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 2\n\n\nRandomly choose a point \\(X\\) from the interval \\([0,1]\\), and given \\(X=x\\), randomly choose a point \\(Y\\) from \\([0,x]\\). Find \\(\\mathbb{P}(0 &lt; Y &lt; \\frac14)\\)."
  },
  {
    "objectID": "lessons copy/11_Transformations/27_Conditional_distributions/27_Conditional_distributions.html#independence-and-conditional-distributions",
    "href": "lessons copy/11_Transformations/27_Conditional_distributions/27_Conditional_distributions.html#independence-and-conditional-distributions",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Independence and conditional distributions",
    "text": "Independence and conditional distributions\n    Question What is \\(f_{X|Y}(x|y)\\) if \\(X\\) and \\(Y\\) are independent?\n\\[f_{X|Y}(x|y) = \\dfrac{f_{X,Y}(x,y)}{f_y(y)} = \\dfrac{f_{X}(x)f_y(y)}{f_y(y)} = f_{X}(x)\\]\n       \n\nIf \\(f_{X|Y}(x|y)\\) does not depend on \\(y\\) (including the bounds/domain), then \\(X\\) and \\(Y\\) are independent."
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability.html",
    "href": "lessons copy/01_Probability/01_Probability.html",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "",
    "text": "probability and randomness"
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability.html#what-is-probability-12",
    "href": "lessons copy/01_Probability/01_Probability.html#what-is-probability-12",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "What is probability? (1/2)",
    "text": "What is probability? (1/2)\n\nWe hear the word “probability” pretty often\n\nCommon in news reports, advertisements, sports, medicine, etc.\n\n\n\nResearchers say the probability of living past 110 is on the rise\nCNBC, 2021\n\n\nWe may hear “probability” or similar words like “chance,” “likelihood,” or “odds”\n\n\nScientists fine-tune odds of asteroid Bennu hitting Earth through 2300 with NASA probe’s help\nSpace.com, 2021"
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability.html#before-we-take-one-more-step",
    "href": "lessons copy/01_Probability/01_Probability.html#before-we-take-one-more-step",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Before we take one more step",
    "text": "Before we take one more step\n\nThe following few slides use some undefined words to define new words that in turn define other words\nIt’s confusing!\nWe’re going off assumption that we all have some understanding of probability, so stop me if you are confused!"
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability.html#probability-and-randomness",
    "href": "lessons copy/01_Probability/01_Probability.html#probability-and-randomness",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Probability and randomness",
    "text": "Probability and randomness\n\nProbability requires randomness\nSomething is random if there are many potential outcomes, but there is uncertainty which outcome will occur\n\n \n\nOutcomes can be “equally likely,” meaning each outcome has the same probability of happening\n\nBut random does NOT necessarily mean equally likely\n\nWe often use physical randomness to demonstrate equally likely outcomes\n\nThink: flipping coins, rolling a dice, drawing cards\n\n\n \n\nThe occurrence of outcomes can be uncertain, but there is an underlying distribution of the probability of outcomes\n\nThere is a distribution of outcomes over large number of (hypothetical repetitions)"
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability.html#a-single-coin-flip-then-100-coin-flips",
    "href": "lessons copy/01_Probability/01_Probability.html#a-single-coin-flip-then-100-coin-flips",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "A single coin flip then 100 coin flips",
    "text": "A single coin flip then 100 coin flips\nSeeing Theory, Chapter 1: Basic Probability, Chance Events"
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability.html#how-do-we-simulate-this-in-r",
    "href": "lessons copy/01_Probability/01_Probability.html#how-do-we-simulate-this-in-r",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "How do we simulate this in R?",
    "text": "How do we simulate this in R?\n\nWe know that heads and tails are equally likely for a single flip\n\n\nset.seed(13)\ncoin = c(\"heads\", \"tails\")\nsample(coin, 1)\n\n[1] \"tails\"\n\n\n\nWhen we only flip the coin once, we only only get one outcome (heads or tails)\n\nWe cannot see any distribution of the probability of outcomes"
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability.html#what-if-i-sample-10-coin-flips",
    "href": "lessons copy/01_Probability/01_Probability.html#what-if-i-sample-10-coin-flips",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "What if I sample 10 coin flips?",
    "text": "What if I sample 10 coin flips?\n\nHow many tails do we get? Are we getting closer to a distribution of heads and tails that we expect?\n\n\n\n\nResults and running proportion of H for 10 flips of a fair coin.\n\n\nFlip\nResult\nRunning count of H\nRunning proportion of H\n\n\n\n\n1\nH\n1\n1.000\n\n\n2\nT\n1\n0.500\n\n\n3\nH\n2\n0.667\n\n\n4\nT\n2\n0.500\n\n\n5\nH\n3\n0.600\n\n\n6\nT\n3\n0.500\n\n\n7\nT\n3\n0.429\n\n\n8\nT\n3\n0.375\n\n\n9\nT\n3\n0.333\n\n\n10\nT\n3\n0.300"
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability.html#what-if-i-sample-100-coin-flips",
    "href": "lessons copy/01_Probability/01_Probability.html#what-if-i-sample-100-coin-flips",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "What if I sample 100 coin flips?",
    "text": "What if I sample 100 coin flips?"
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability.html#can-we-simulate-more",
    "href": "lessons copy/01_Probability/01_Probability.html#can-we-simulate-more",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Can we simulate more??",
    "text": "Can we simulate more??\n\nI can start to count the number of tails in the flips\n\n\nsum( sample(coin, 100, replace = T) == \"heads\" )\n\n[1] 42\n\n\n\nAnd I can see the proportion of tails in the flips\n\n\nsum( sample(coin, 100, replace = T) == \"heads\" ) / 100\n\n[1] 0.42\n\n\n\nI can do this with more flips\n\n\nsum( sample(coin, 1000, replace = T) == \"heads\" ) / 1000\n\n[1] 0.531\n\nsum( sample(coin, 10000, replace = T) == \"heads\" ) / 10000\n\n[1] 0.4956\n\nsum( sample(coin, 100000, replace = T) == \"heads\" ) / 100000\n\n[1] 0.50033"
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability.html#whats-the-point",
    "href": "lessons copy/01_Probability/01_Probability.html#whats-the-point",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "What’s the point?",
    "text": "What’s the point?\n\nWe know the probability of a heads is 0.5!\nWhy do we need to simulate 100s or 1000s of coin flips?\nWith enough repetitions, we can use simulations to approximate the probability of an event\nSimulations involve artificial recreation of a random phenomenon"
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability.html#why-are-simulations-important-bigger-picture",
    "href": "lessons copy/01_Probability/01_Probability.html#why-are-simulations-important-bigger-picture",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Why are simulations important? (bigger picture)",
    "text": "Why are simulations important? (bigger picture)\n\nIn the previous example, coding a simulation seemed more educational than necessary\nWe can often calculate probabilities mathematically, but we will eventually get to complex calculations\n\nSimulations can help us (or be necessary) to solve a problem when calculations are complex\n\nSimulations are a great way to check your work!\nSimulation based reasoning is helpful in statistics\n\nYou’ll see this in confidence intervals in Biostatistics courses\n\nSimulations allow you to change assumptions easily and see how they affect your results\nIt is often how statisticians “run” experiments on their methods of hypotheses"
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability.html#outcomes-events-sample-spaces",
    "href": "lessons copy/01_Probability/01_Probability.html#outcomes-events-sample-spaces",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Outcomes, events, sample spaces",
    "text": "Outcomes, events, sample spaces\n\n\nDefinition: Outcome\n\n\nThe possible results in a random phenomenon.\n\n\n\n\nDefinition: Sample Space\n\n\nThe sample space \\(S\\) is the set of all outcomes\n\n\n\n\nDefinition: Event\n\n\nAn event is a collection of some outcomes. An event can include multiple outcomes or no outcomes (a subset of the sample space).\n\n\nWhen thinking about events, think about outcomes that you might be asking the probability of. For example, what is the probability that you get a heads or a tails in one flip? (Answer: 1)"
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability.html#coin-toss-example-1-coin-13",
    "href": "lessons copy/01_Probability/01_Probability.html#coin-toss-example-1-coin-13",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Coin Toss Example: 1 coin (1/3)",
    "text": "Coin Toss Example: 1 coin (1/3)\n\n\n\n\nSingle coin toss\n\n\nSuppose you toss one coin.\n\nWhat are the possible outcomes?\n \nWhat is the sample space?\n \nWhat are the possible events?"
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability.html#coin-toss-example-1-coin-23",
    "href": "lessons copy/01_Probability/01_Probability.html#coin-toss-example-1-coin-23",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Coin Toss Example: 1 coin (2/3)",
    "text": "Coin Toss Example: 1 coin (2/3)\nSuppose you toss one coin.\n\nWhat are the possible outcomes?\n\nHeads (\\(H\\))\nTails (\\(T\\))\n\n\n \n\n\nNote\n\n\nWhen something happens at random, such as a coin toss, there are several possible outcomes, and exactly one of the outcomes will occur."
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability.html#coin-toss-example-1-coin-33",
    "href": "lessons copy/01_Probability/01_Probability.html#coin-toss-example-1-coin-33",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Coin Toss Example: 1 coin (3/3)",
    "text": "Coin Toss Example: 1 coin (3/3)\n\n\n\nWhat is the sample space?\n\n\\(S =\\)\n\n\n \n \n\nWhat are the possible events?\n\n\n\n\n\n\n \n\n\n\n\nNote #1\n\n\nWe use curly brackets (\\(\\{\\}\\)) to denote a set (collecting a list of outcomes or values)\n\n\n\n\nNote #2\n\n\nThe total number of possible events is \\[2^{|S|}\\] where \\(|S|\\) is the total number of outcomes in the sample space. Also, possible events are not necessarily something that can actually occur (i.e. getting a heads and a tails on a single coin flip)"
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability.html#coin-toss-example-2-coins",
    "href": "lessons copy/01_Probability/01_Probability.html#coin-toss-example-2-coins",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Coin Toss Example: 2 coins",
    "text": "Coin Toss Example: 2 coins\nSuppose you toss two coins.\n\nWhat is the sample space? Assume the coins are distinguishable\n\n\\(S =\\)\n\n\n \n\nWhat are some possible events?\n\n\\(A =\\) exactly one \\(H =\\)\n\\(B =\\) at least one \\(H =\\)"
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability.html#more-info-on-events-and-sample-spaces",
    "href": "lessons copy/01_Probability/01_Probability.html#more-info-on-events-and-sample-spaces",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "More info on events and sample spaces",
    "text": "More info on events and sample spaces\n\nWe usually use capital letters from the beginning of the alphabet to denote events. However, other letters might be chosen to be more descriptive.\n\nExamples: \\(A, B, C, A_1, A_2\\)\n\nWe can also define a new event as a combination of other events\n\nExamples: \\(A \\cup B\\) (union), \\(A \\cap B\\) (intersection), \\(A^C\\) (complement)\n\n\n \n\nWe use the notation \\(|S|\\) to denote the size of the sample space.\n\n \n\nThe total number of possible events is \\(2^{|S|}\\), which is the total number of possible subsets of \\(S\\).\n\n \n\nThe empty set, denoted by \\(\\emptyset\\), is the set containing no outcomes."
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability.html#example-keep-sampling-until",
    "href": "lessons copy/01_Probability/01_Probability.html#example-keep-sampling-until",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Example: Keep sampling until…",
    "text": "Example: Keep sampling until…\nSuppose you keep sampling people until you have someone with high blood pressure (BP)\n \nWhat is the sample space?\n\nLet \\(H =\\) denote someone with high BP.\nLet \\(H^C =\\) denote someone with not high blood pressure, such as low or regular BP.\n\n \n\nThen, \\(S =\\)"
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability.html#lets-define-probability-with-events-and-spaces",
    "href": "lessons copy/01_Probability/01_Probability.html#lets-define-probability-with-events-and-spaces",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Let’s define probability with events and spaces",
    "text": "Let’s define probability with events and spaces\nIf \\(S\\) is a finite sample space, with equally likely outcomes, then\n\\[\\mathbb{P}(A) = \\frac{|A|}{|S|}\\]\nIn human speak:\n\nFor equally likely outcomes, the probability that a certain event occurs is: the number of outcomes within the event of interest (\\(|A|\\)) divided by the total number of possible outcomes (\\(|S|\\))\n\n\\[\\mathbb{P}(A) = \\frac{\\text{total number of outcomes in event A}}{\\text{total number of outcomes in sample space}}\\]\n\nThus, it is important to be able to count the outcomes within an event"
  },
  {
    "objectID": "lessons copy/01_Probability/01_Probability.html#a-probability-is-a-function",
    "href": "lessons copy/01_Probability/01_Probability.html#a-probability-is-a-function",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "A probability is a function…",
    "text": "A probability is a function…\n\n\\(\\mathbb{P}(A)\\) is a function with\n\nInput: event \\(A\\) from the sample space \\(S\\), (\\(A \\subseteq S\\))\n\n\\(A \\subseteq S\\) means “A contained within S” or “A is a subset of S”\n\nOutput: a number between 0 and 1 (inclusive)\n\n\n \n\nThe probability function maps an event (input) to value between 0 and 1 (output)\n\nWhen we speak of the probability function, we often call the values between 0 and 1 “probabilities”\n\nExample: “The probability of drawing a heart is 0.25” for \\(P(\\text{heart}) = 0.25\\)\n\n\n\n \n\nThe probability function needs to follow some specific rules (called axioms)!"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/09_Joint_distributions_key_info.html",
    "href": "lessons copy/12_Joint_distributions/09_Joint_distributions_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 02 assignments are graded!\n\nSolutions and videos are posted!\n\nFinish the discrete distributions notes\n\nThen get into joint distributions"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/09_Joint_distributions_key_info.html#announcements",
    "href": "lessons copy/12_Joint_distributions/09_Joint_distributions_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 02 assignments are graded!\n\nSolutions and videos are posted!\n\nFinish the discrete distributions notes\n\nThen get into joint distributions"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/09_Joint_distributions_key_info.html#key-dates",
    "href": "lessons copy/12_Joint_distributions/09_Joint_distributions_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 03 Assignment due this Thursday at 11pm\n\nI updated the homework assignment on the 18th!"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities_key_info.html",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 6 assignment today!\n\nFeel free to turn in solutions later than 11/24 since I took so long to grade\n\nI made quite a few changes to the homeworks\n\nHW 10 is gone\nHW 9 is optional\nInstead of a HW assignment due over late November break\n\nHW 8 will include material from Week 8 and 9 and be due 12/5\n\n\nI have quite a bit of grading to catch up on!\nRealizing I never gave you mid-quarter feedback forms…\n\nLet’s chat about this and our assessment breakdown in the coming weeks\n\nAnything else?"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities_key_info.html#announcements",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 6 assignment today!\n\nFeel free to turn in solutions later than 11/24 since I took so long to grade\n\nI made quite a few changes to the homeworks\n\nHW 10 is gone\nHW 9 is optional\nInstead of a HW assignment due over late November break\n\nHW 8 will include material from Week 8 and 9 and be due 12/5\n\n\nI have quite a bit of grading to catch up on!\nRealizing I never gave you mid-quarter feedback forms…\n\nLet’s chat about this and our assessment breakdown in the coming weeks\n\nAnything else?"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities_key_info.html#key-dates",
    "href": "lessons copy/12_Joint_distributions/25_Joint_densities/25_Joint_densities_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 7 due\nSunday: HW 6 solutions due"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/09_Joint_distributions.html",
    "href": "lessons copy/12_Joint_distributions/09_Joint_distributions.html",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "",
    "text": "Calculate probabilities for a pair of discrete random variables\nCalculate a joint, marginal, and conditional probability mass function (pmf)\nCalculate a joint, marginal, and conditional cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#learning-objectives",
    "href": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#learning-objectives",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "",
    "text": "Calculate probabilities for a pair of discrete random variables\nCalculate a joint, marginal, and conditional probability mass function (pmf)\nCalculate a joint, marginal, and conditional cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#where-are-we",
    "href": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#where-are-we",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#what-is-a-joint-pmf",
    "href": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#what-is-a-joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is a joint pmf?",
    "text": "What is a joint pmf?\n\n\nDefinition: joint pmf\n\n\nThe joint pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[p_{X,Y}(x,y) = \\mathbb{P}(X=x\\ and\\ Y=y) = \\mathbb{P}(X=x, Y=y)\\]"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#this-chapters-main-example",
    "href": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#this-chapters-main-example",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "This chapter’s main example",
    "text": "This chapter’s main example\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#joint-pmf",
    "href": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Joint pmf",
    "text": "Joint pmf\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#marginal-pmfs",
    "href": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#marginal-pmfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Marginal pmf’s",
    "text": "Marginal pmf’s\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#remarks-on-the-joint-pmf",
    "href": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#remarks-on-the-joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the joint pmf",
    "text": "Remarks on the joint pmf\nSome properties of joint pmf’s:\n\nA joint pmf \\(p_{X,Y}(x,y)\\) must satisfy the following properties:\n\n\\(p_{X,Y}(x,y)\\geq 0\\) for all \\(x, y\\).\n\\(\\sum \\limits_{\\{all\\ x\\}} \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)=1\\).\n\nMarginal pmf’s:\n\n\\(p_X(x) = \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)\\)\n\\(p_Y(y) = \\sum \\limits_{\\{all\\ x\\}} p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#what-is-a-joint-cdf",
    "href": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#what-is-a-joint-cdf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is a joint CDF?",
    "text": "What is a joint CDF?\n\n\nDefinition: joint CDF\n\n\nThe joint CDF of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[F_{X,Y}(x,y) = \\mathbb{P}(X \\leq x\\ and\\ Y \\leq y) = \\mathbb{P}(X \\leq x, Y \\leq y)\\]"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#joint-cdfs",
    "href": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#joint-cdfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Joint CDFs",
    "text": "Joint CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#marginal-cdfs",
    "href": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#marginal-cdfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Marginal CDFs",
    "text": "Marginal CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#remarks-on-the-joint-and-marginal-cdf",
    "href": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#remarks-on-the-joint-and-marginal-cdf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the joint and marginal CDF",
    "text": "Remarks on the joint and marginal CDF\n\n\\(F_X(x)\\): right most columns of the CDf table (where the \\(Y\\) values are largest)\n\\(F_Y(y)\\): bottom row of the table (where X values are largest)\n\\(F_X(x)=\\lim\\limits_{y\\rightarrow\\infty}F_{X, Y}(x,y)\\)\n\\(F_Y(y)=\\lim\\limits_{x\\rightarrow\\infty}F_{X, Y}(x,y)\\)"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#independence-and-conditioning",
    "href": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#independence-and-conditioning",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Independence and Conditioning",
    "text": "Independence and Conditioning\nRecall that for events \\(A\\) and \\(B\\),\n\n\\(\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}\\)\n\\(A\\) and \\(B\\) are independent if and only if\n\n\\(\\mathbb{P}(A|B) = \\mathbb{P}(A)\\)\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A)\\cdot\\mathbb{P}(B)\\)\n\n\nIndependence and conditioning are defined similarly for r.v.’s, since \\[p_X(x) = \\mathbb{P}(X=x)\\ \\mathrm{and}\\ \\ p_{X,Y}(x,y) = \\mathbb{P}(X = x ,Y = y).\\]"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#what-is-the-conditional-pmf",
    "href": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#what-is-the-conditional-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is the conditional pmf?",
    "text": "What is the conditional pmf?\n\n\nDefinition: conditional pmf\n\n\nThe conditional pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is defined as \\[p_{X|Y}(x|y) = \\mathbb{P}(X = x |Y = y) = \\frac{\\mathbb{P}(X = x\\ and\\ Y = y)}{\\mathbb{P}(Y = y)}\n=\\frac{p_{X,Y}(x,y) }{p_{Y}(y) }\\] if \\(p_{Y}(y) &gt; 0\\)."
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#remarks-on-the-conditional-pmf",
    "href": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#remarks-on-the-conditional-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the conditional pmf",
    "text": "Remarks on the conditional pmf\nThe following properties follow from the conditional pmf definition:\n\nIf \\(X \\perp Y\\) (independent)\n\n\\(p_{X|Y}(x|y) = p_X(x)\\) for all \\(x\\) and \\(y\\)\n\\(p_{X,Y}(x,y) = p_X(x)p_Y(y)\\) for all \\(x\\) and \\(y\\)\nWhich also implies (\\(\\Rightarrow\\)): \\(F_{X,Y}(x,y) = F_X(x)F_Y(y)\\) for all \\(x\\) and \\(y\\)\n\nIf \\(X_1, X_2, …, X_n\\) are independent\n\n\\[p_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1=x_1, X_2=x_2, …, X_n=x_n)=\\prod\\limits_{i=1}^np_{X_i}(x_i)\\]\n\\[F_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1\\leq x_1, X_2\\leq x_2, …, X_n\\leq x_n)=\\prod\\limits_{i=1}^nP(X_i \\leq x_i) = \\prod\\limits_{i=1}^nF_{X_i}(x_i)\\]"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#conditional-pmfs",
    "href": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#conditional-pmfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Conditional pmf’s",
    "text": "Conditional pmf’s\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?\n\n\n\n\n\nRemark:\n\nTo show that \\(X\\) and \\(Y\\) are not independent, we just need to find one counter example\nHowever, to show that they are independent, we need to verify this for all possible pairs of \\(x\\) and \\(y\\)"
  },
  {
    "objectID": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#hypothetical-4-sided-die",
    "href": "lessons copy/12_Joint_distributions/09_Joint_distributions.html#hypothetical-4-sided-die",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Hypothetical 4-sided die",
    "text": "Hypothetical 4-sided die\n\n\nExample 3\n\n\n\nSuppose you have a 4-sided die, and you roll the 4-sided die until the first 4 appears.\nLet \\(X\\) be the number of rolls required until (and including) the first 4.\nAfter the first 4, you keep rolling it again until you roll a 3.\nLet \\(Y\\) be the number of rolls, after the first 4, required until (and including) the 3.\n\n\nFind \\(p_{X,Y}(x,y)\\).\nUsing \\(p_{X,Y}(x,y)\\), find \\(p_{Y}(y)\\).\nFind \\(p_{X}(x)\\).\nAre \\(X\\) and \\(Y\\) are independent? Why or why not?\nFind \\(F_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "lessons copy/15_Variance/12_Variance_muddy_points.html",
    "href": "lessons copy/15_Variance/12_Variance_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy Points from Fall 2023:\n\n1. Proof of variance formula\nHere is the variance formula that we worked through on slide 9 of Chapter 12’s notes.\n\n\n\n\n\n\nLemma 6: “Computation formula” for variance\n\n\n\nThe variance of a r.v. \\(X\\), can be computed as \\[\\begin{align}\\sigma_X^2 & =Var(X) \\\\ & = \\mathbb{E}[X^2]-\\mu_X^2 \\\\ & = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2\\end{align}\\]\n\n\nI stepped through this quite quickly and made some implicit steps. So let’s revisit it with explicit steps!\n       \n\n\n2. What progression are we following in the course??\nSomeone asked if this is our progression: RV is function \\(\\to\\) Expected value is function to describe mean of RV \\(\\to\\) Use functions within expected value to set up variance\nBasically, yes! The random variable is a function of a random process. The RV inherits that randomness.\nFrom there, we’ve been working towards calculating the probability of a realized value ($x$) of the RV. The probability can be different for different realized values (as it links back to the random process).\nWe also want to construct ways to describe our random variables. We may want to figure out what to expect from our random variable (which translates to the mean value of the RV). Since our RV is rooted in a random process, we may want to get an idea of how spread out our realized values are. We use our expected value (mean) as an anchor in our spread. Variance is one way to measure this spread."
  },
  {
    "objectID": "lessons copy/15_Variance/12_Variance.html",
    "href": "lessons copy/15_Variance/12_Variance.html",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "",
    "text": "Calculate the variance and standard deviation of discrete random variables\nCalculate the variance of sums of discrete random variables\nCalculate the variance of functions of discrete random variables"
  },
  {
    "objectID": "lessons copy/15_Variance/12_Variance.html#learning-objectives",
    "href": "lessons copy/15_Variance/12_Variance.html#learning-objectives",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "",
    "text": "Calculate the variance and standard deviation of discrete random variables\nCalculate the variance of sums of discrete random variables\nCalculate the variance of functions of discrete random variables"
  },
  {
    "objectID": "lessons copy/15_Variance/12_Variance.html#where-are-we",
    "href": "lessons copy/15_Variance/12_Variance.html#where-are-we",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/15_Variance/12_Variance.html#lets-start-building-the-variance-through-expected-values-of-functions",
    "href": "lessons copy/15_Variance/12_Variance.html#lets-start-building-the-variance-through-expected-values-of-functions",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Let’s start building the variance through expected values of functions",
    "text": "Let’s start building the variance through expected values of functions\n\n\n\n\nExample 1\n\n\nLet \\(g\\) be a function and let \\(g(x) = ax+b\\), for real-valued constants \\(a\\) and \\(b\\). What is \\(\\mathbb{E}[g(X)]\\)?"
  },
  {
    "objectID": "lessons copy/15_Variance/12_Variance.html#what-is-the-expected-value-of-a-function",
    "href": "lessons copy/15_Variance/12_Variance.html#what-is-the-expected-value-of-a-function",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "What is the expected value of a function?",
    "text": "What is the expected value of a function?\n\n\nDefinition: Expected value of function of RV\n\n\nFor any function \\(g\\) and discrete r.v. \\(X\\), the expected value of \\(g(X)\\) is \\[\\mathbb{E}[g(X)] = \\sum_{\\{all\\ x\\}}\\ g(x) p_X(x).\\]"
  },
  {
    "objectID": "lessons copy/15_Variance/12_Variance.html#lets-revisit-the-card-example-12",
    "href": "lessons copy/15_Variance/12_Variance.html#lets-revisit-the-card-example-12",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Let’s revisit the card example (1/2)",
    "text": "Let’s revisit the card example (1/2)\n\n\n\n\nExample 2\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw.\n\nFind \\(\\mathbb{E}[X^2]\\).\n\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "lessons copy/15_Variance/12_Variance.html#lets-revisit-the-card-example-22",
    "href": "lessons copy/15_Variance/12_Variance.html#lets-revisit-the-card-example-22",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Let’s revisit the card example (2/2)",
    "text": "Let’s revisit the card example (2/2)\n\n\n\n\nExample 2\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw.\n\nFind \\(\\mathbb{E}\\big[\\big(X-\\frac{1}{2}\\big)^2\\big]\\).\n\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "lessons copy/15_Variance/12_Variance.html#variance-of-a-rv",
    "href": "lessons copy/15_Variance/12_Variance.html#variance-of-a-rv",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Variance of a RV",
    "text": "Variance of a RV\n\n\nDefinition: Variance of RV\n\n\nThe variance of a r.v. \\(X\\), with (finite) expected value \\(\\mu_X=\\mathbb{E}[X]\\) is \\[\\sigma_X^2=Var(X)=\\mathbb{E}[(X-\\mu_X)^2] = \\mathbb{E}[(X-\\mathbb{E}[X])^2]\\]\n\n\n\n\nDefinition: Standard deviation of RV\n\n\nThe standard deviation of a r.v. \\(X\\) is \\[\\sigma_X = SD(X) = \\sqrt{\\sigma_X^2}=\\sqrt{Var(X)}.\\]"
  },
  {
    "objectID": "lessons copy/15_Variance/12_Variance.html#questions",
    "href": "lessons copy/15_Variance/12_Variance.html#questions",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Questions",
    "text": "Questions\nQuestions: Why do we square the difference in the variance definition? \\((X-\\mu_X)^2\\)\n\nWhy not define the measure of spread as \\(\\mathbb{E}[X-\\mu_X] = \\mathbb{E}[X-\\mathbb{E}[X]]\\)?\nWhy not use \\(\\mathbb{E}[|X-\\mu_X|]\\)?"
  },
  {
    "objectID": "lessons copy/15_Variance/12_Variance.html#lets-calculate-the-variance-and-prove-it",
    "href": "lessons copy/15_Variance/12_Variance.html#lets-calculate-the-variance-and-prove-it",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Let’s calculate the variance and prove it!",
    "text": "Let’s calculate the variance and prove it!\n\n\n\n\nLemma 6: “Computation formula” for Variance\n\n\nThe variance of a r.v. \\(X\\), can be computed as \\[\\begin{align}\n\\sigma_X^2 & =Var(X) \\\\ & = \\mathbb{E}[X^2]-\\mu_X^2 \\\\ & = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2\n\\end{align}\\]"
  },
  {
    "objectID": "lessons copy/15_Variance/12_Variance.html#variance-of-a-function-with-a-single-rv",
    "href": "lessons copy/15_Variance/12_Variance.html#variance-of-a-function-with-a-single-rv",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Variance of a function with a single RV",
    "text": "Variance of a function with a single RV\n\n\nLemma 7\n\n\nFor a r.v. \\(X\\) and constants \\(a\\) and \\(b\\), \\[Var(aX+b) = a^2Var(X).\\]\n\n\nProof will be exercise in homework. It’s fun! In a mathy kinda way."
  },
  {
    "objectID": "lessons copy/15_Variance/12_Variance.html#important-results-for-independent-rvs",
    "href": "lessons copy/15_Variance/12_Variance.html#important-results-for-independent-rvs",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Important results for independent RVs",
    "text": "Important results for independent RVs\n\n\nTheorem 8\n\n\nFor independent r.v.’s \\(X\\) and \\(Y\\), and functions \\(g\\) and \\(h\\), \\[\\mathbb{E}[g(X)h(Y)] = \\mathbb{E}[g(X)]\\mathbb{E}[h(Y)].\\]\n\n\n\n\nCorollary 1\n\n\nFor independent r.v.’s \\(X\\) and \\(Y\\), \\[\\mathbb{E}[XY] = \\mathbb{E}[X]\\mathbb{E}[Y].\\]"
  },
  {
    "objectID": "lessons copy/15_Variance/12_Variance.html#variance-of-sum-of-independent-discrete-rvs",
    "href": "lessons copy/15_Variance/12_Variance.html#variance-of-sum-of-independent-discrete-rvs",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Variance of sum of independent discrete RVs",
    "text": "Variance of sum of independent discrete RVs\n\n\nTheorem 9: Variance of sum of independent discrete r.v.’s\n\n\nFor independent discrete r.v.’s \\(X_i\\) and constants \\(a_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n a_iX_i\\Bigg) = \\sum_{i=1}^n a_i^2Var(X_i).\\]\n\n\nSimpler version:\n\\[Var(a_1 X + a_2 Y) = Var(a_1X) + Var(a_2 Y) = a_1^2 Var(X) + a_2^2 Var(Y)\\]"
  },
  {
    "objectID": "lessons copy/15_Variance/12_Variance.html#corollaries",
    "href": "lessons copy/15_Variance/12_Variance.html#corollaries",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Corollaries",
    "text": "Corollaries\n\n\nCorollary 2\n\n\nFor independent discrete r.v.’s \\(X_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n X_i\\Bigg) = \\sum_{i=1}^n Var(X_i).\\]\n\n\n\n\nCorollary 3\n\n\nFor independent identically distributed (i.i.d.) discrete r.v.’s \\(X_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n X_i\\Bigg) = n Var(X_1).\\]"
  },
  {
    "objectID": "lessons copy/15_Variance/12_Variance.html#lets-look-at-a-ghost-problem-with-replacement",
    "href": "lessons copy/15_Variance/12_Variance.html#lets-look-at-a-ghost-problem-with-replacement",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Let’s look at a ghost problem with replacement",
    "text": "Let’s look at a ghost problem with replacement\n\n\n\n\nExample 3.2\n\n\nThe ghost is trick-or-treating at a different house now. In this case it is known that the bag of candy has 10 chocolates, 20 lollipops, and 30 laffy taffies. The ghost grabs a handful of five pieces of candy. What is the variance for the number of chocolates the ghost takes? Let’s solve this for the cases with replacement.\n\n\n\n\nRecall probability with replacement:\n\\[\np_X(x) = {n \\choose k}p^k(1-p)^{n-k}\n\\]"
  },
  {
    "objectID": "lessons copy/15_Variance/12_Variance.html#back-to-our-hotel-example-from-chapter-11",
    "href": "lessons copy/15_Variance/12_Variance.html#back-to-our-hotel-example-from-chapter-11",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Back to our hotel example from Chapter 11",
    "text": "Back to our hotel example from Chapter 11\n\n\n\n\nExample 4\n\n\nA tour group is planning a visit to the city of Minneapolis and needs to book 30 hotel rooms. The average price of a room is $200 with standard deviation $10. In addition, there is a 10% tourism tax for each room. What is the standard deviation of the cost for the 30 hotel rooms? Assume rooms are independent.\n\n\nProblem to do at home if we don’t have enough time."
  },
  {
    "objectID": "lessons copy/00_Intro/00_Intro_key_info.html",
    "href": "lessons copy/00_Intro/00_Intro_key_info.html",
    "title": "Key Info and Announcements",
    "section": "",
    "text": "Welcome! Here is where I will put announcements for class!\nHomework 0 is due THIS THURSDAY at 11pm!"
  },
  {
    "objectID": "lessons copy/00_Intro/00_Intro_key_info.html#announcements",
    "href": "lessons copy/00_Intro/00_Intro_key_info.html#announcements",
    "title": "Key Info and Announcements",
    "section": "",
    "text": "Welcome! Here is where I will put announcements for class!\nHomework 0 is due THIS THURSDAY at 11pm!"
  },
  {
    "objectID": "lessons copy/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html",
    "href": "lessons copy/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "",
    "text": "Calculate probability of a sample mean using a population mean and variance with unknown distribution\nUse the Central Limit Theorem to construct the Normal approximation of the Binomial and Poisson distributions"
  },
  {
    "objectID": "lessons copy/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#learning-objectives",
    "href": "lessons copy/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#learning-objectives",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "",
    "text": "Calculate probability of a sample mean using a population mean and variance with unknown distribution\nUse the Central Limit Theorem to construct the Normal approximation of the Binomial and Poisson distributions"
  },
  {
    "objectID": "lessons copy/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#the-central-limit-theorem",
    "href": "lessons copy/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#the-central-limit-theorem",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\n\n\nTheorem 1: Central Limit Theorem (CLT)\n\n\nLet \\(X_i\\) be iid rv’s with common mean \\(\\mu\\) and variance \\(\\sigma^2\\), for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\rightarrow \\text{N}(n\\mu, n\\sigma^2)\\]"
  },
  {
    "objectID": "lessons copy/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#extension-of-the-clt",
    "href": "lessons copy/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#extension-of-the-clt",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "Extension of the CLT",
    "text": "Extension of the CLT\n\n\nCorollary 1\n\n\nLet \\(X_i\\) be iid rv’s with common mean \\(\\mu\\) and variance \\(\\sigma^2\\), for \\(i=1,2,\\ldots,n\\). Then \\[\\overline{X}=\\frac{\\sum_{i=1}^n X_i}{n}  \\rightarrow \\text{N}\\Bigg(\\mu, \\dfrac{\\sigma^2}{n}\\Bigg)\\]"
  },
  {
    "objectID": "lessons copy/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#example-of-corollary-in-use",
    "href": "lessons copy/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#example-of-corollary-in-use",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "Example of Corollary in use",
    "text": "Example of Corollary in use\n\n\n\n\nExample 1\n\n\nAccording to a large US study, the mean resting heart rate of adult women is about 74 beats per minutes (bpm), with standard deviation 13 bpm (NHANES 2003-2004).\n\nFind the probability that the average resting heart rate for a random sample of 36 adult women is more than 3 bpm away from the mean.\nRepeat the previous question for a single adult woman."
  },
  {
    "objectID": "lessons copy/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#example-of-clt-for-exponential-distribution",
    "href": "lessons copy/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#example-of-clt-for-exponential-distribution",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "Example of CLT for exponential distribution",
    "text": "Example of CLT for exponential distribution\n\n\n\n\nExample 2\n\n\nLet \\(X_i \\sim Exp(\\lambda)\\) be iid RVs for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\rightarrow\\]"
  },
  {
    "objectID": "lessons copy/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#clt-for-discrete-rvs",
    "href": "lessons copy/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#clt-for-discrete-rvs",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "CLT for Discrete RVs",
    "text": "CLT for Discrete RVs\n\n\n\nBinomial rv’s: Let \\(X \\sim Bin(n,p)\\)\n\n\\(X = \\displaystyle\\sum_{i=1}^n X_i\\), where \\(X_i\\) are iid \\(\\text{Bernoulli}(p)\\)\nRule of thumb: \\(np\\geq10\\) and \\(n(1-p)\\geq 10\\) to use Normal approximation\n\n\n\n\n\n\nPoisson rv’s: Let \\(X \\sim Poisson(\\lambda)\\)\n\n\\(X = \\displaystyle\\sum_{i=1}^n X_i\\), where \\(X_i\\) are iid \\(\\text{Poiss}(1)\\)\nRecall from Chapter 18 that if \\(X_i \\sim Poiss(\\lambda_i)\\) and \\(X_i\\) independent, then \\(\\sum_{i=1}^n X_i \\sim Poiss(\\sum_{i=1}^n \\lambda_i)\\)\nRule of thumb: \\(\\lambda \\geq10\\) to use Normal approximation"
  },
  {
    "objectID": "lessons copy/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#at-home-example",
    "href": "lessons copy/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#at-home-example",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "At home example",
    "text": "At home example\n\n\nExample 3\n\n\nSuppose that the probability of developing a specific type of breast cancer in women aged 40-49 is 0.001. Assume the occurrences of cancer are independent. Suppose you have data from a random sample of 20,000 women aged 40-49.\n\nHow many of the 20,000 women would you expect to develop this type of breast cancer, and what is the standard deviation?\nFind the exact probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to find the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to approximate the following probabilities, where \\(X\\) is the number of women that will develop this type of breast cancer.\n\n\\(\\mathbb{P}(15 \\leq X \\leq 22)\\)\n\\(\\mathbb{P}(X &gt; 20)\\)\n\\(\\mathbb{P}(X &lt; 20)\\)\n\nFind the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer - not using the CLT!\nUse the CLT to approximate the approximate probability in the previous question!"
  },
  {
    "objectID": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html",
    "href": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "",
    "text": "Learn the definition of a moment-generating function.\nFind the moment-generating function of a binomial random variable.\nUse a moment-generating function to find the mean and variance of a random variable."
  },
  {
    "objectID": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#learning-objectives",
    "href": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#learning-objectives",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "",
    "text": "Learn the definition of a moment-generating function.\nFind the moment-generating function of a binomial random variable.\nUse a moment-generating function to find the mean and variance of a random variable."
  },
  {
    "objectID": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#where-are-we",
    "href": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#where-are-we",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#what-are-moments",
    "href": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#what-are-moments",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "What are moments?",
    "text": "What are moments?\n\n\nDefinition 1\n\n\nThe \\(j^{th}\\) moment of a r.v. \\(X\\) is \\(\\mathbb{E}[X^j]\\)\n\n\n\n\nExample 1\n\n\n\\(1^{st}-4^{th}\\) moments"
  },
  {
    "objectID": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#what-is-a-moment-generating-function-mgf",
    "href": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#what-is-a-moment-generating-function-mgf",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "What is a moment generating function (mgf)??",
    "text": "What is a moment generating function (mgf)??\n\n\nDefinition 3\n\n\nIf \\(X\\) is a r.v., then the moment generating function (mgf) associated with \\(X\\) is: \\[M_X(t)= \\mathbb{E}[e^{tX}]\\]\n\n\nRemarks\n\n\n\nFor a discrete r.v., the mgf of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\sum_{all \\ x}e^{tx}p_X(x)\\]\nFor a continuous r.v., the mgf of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\int_{-\\infty}^{\\infty}e^{tx}f_X(x)dx\\]\n\n\n\nThe mgf \\(M_X(t)\\) is a function of \\(t\\), not of \\(X\\), and it might not be defined (i.e. finite) for all values of \\(t\\). We just need it to be defined for \\(t=0\\)."
  },
  {
    "objectID": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#example",
    "href": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#example",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Example",
    "text": "Example\n\n\n\n\nExample 4\n\n\nWhat is \\(M_X(t)\\) for \\(t=0\\)?"
  },
  {
    "objectID": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#theorem",
    "href": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#theorem",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Theorem",
    "text": "Theorem\n\n\nTheorem 5\n\n\nThe moment generating function uniquely specifies a probability distribution.\n\n\n\n\nTheorem 6\n\n\n\\[\\mathbb{E}[X^r] = M_X^{(r)}(0)\\]\n\\((r)\\) in this equation is the \\(r\\)th derivative with respect to \\(t\\)\n\n\n\nWhen \\(r=1\\), we are taking the first derivative\nWhen \\(r=4\\), we are taking the fourth derivative"
  },
  {
    "objectID": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-a-probability-distribution",
    "href": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-a-probability-distribution",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Using the mgf to uniquely describe a probability distribution",
    "text": "Using the mgf to uniquely describe a probability distribution\n\n\n\n\nExample 7\n\n\nLet \\(X \\sim Poisson(\\lambda)\\)\n\nFind the mgf of \\(X\\)\nFind \\(\\mathbb{E}[X]\\)\nFind \\(Var(X)\\)"
  },
  {
    "objectID": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#theorem-1",
    "href": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#theorem-1",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Theorem",
    "text": "Theorem\nRemark: Finding the mean and variance is sometimes easier with the following trick\n\n\nTheorem 8\n\n\nLet \\(R_X(t) = \\ln[M_X(t)]\\). Then,\n\\[\\mu = \\mathbb{E}[X] = R_X'(0) \\text{, and}\\] \\[\\sigma^2 = Var(X) = R_X''(0)\\]\n\n\n\nProof."
  },
  {
    "objectID": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-r_xt-to-uniquely-describe-a-probability-distribution",
    "href": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-r_xt-to-uniquely-describe-a-probability-distribution",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Using \\(R_X(t)\\) to uniquely describe a probability distribution",
    "text": "Using \\(R_X(t)\\) to uniquely describe a probability distribution\n\n\n\n\nExample 9\n\n\nLet \\(X \\sim Poisson(\\lambda)\\).\n\nFind \\(\\mathbb{E}[X]\\) using \\(R_X(t)\\)\nFind \\(Var(X)\\) using \\(R_X(t)\\)"
  },
  {
    "objectID": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-the-standard-normal-distribution",
    "href": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-the-standard-normal-distribution",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Using the mgf to uniquely describe the standard normal distribution",
    "text": "Using the mgf to uniquely describe the standard normal distribution\n\n\n\n\nExample 10\n\n\nLet \\(Z\\) be a standard normal random variable, i.e. \\(Z \\sim N(0,1)\\).\n\nFind the mgf of \\(Z\\)\nFind \\(\\mathbb{E}[Z]\\)\nFind \\(Var(Z)\\)"
  },
  {
    "objectID": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#mgfs-of-sums-of-independent-rvs",
    "href": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#mgfs-of-sums-of-independent-rvs",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Mgf’s of sums of independent RV’s",
    "text": "Mgf’s of sums of independent RV’s\n\n\nTheorem 9\n\n\nIf \\(X\\) and \\(Y\\) are independent RV’s with respective mgf’s \\(M_X(t)\\) and \\(M_Y(t)\\), then\n\\[M_{X+Y}(t) = E[e^{t(X+Y)}] = E[e^{tX} e^{tY}] = E[e^{tX}]E[e^{tY}]=M_{X}(t)M_{Y}(t)\\]"
  },
  {
    "objectID": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#main-takeaways",
    "href": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#main-takeaways",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Main takeaways",
    "text": "Main takeaways\n\nMgf’s are a purely mathematically definition\n\nWe can’t really relate it to our real world analysis\n\nThey are helpful mathematically because they are unique to a probability distribution\n\nWe can find the unique mgf from for a probability distribution\nAnd we can find a distribution from an mgf\n\nMgf’s can sometimes make it easier to find the mean and variance of an RV\nMgf’s are most helpful when we are finding a joint distribution that is a sum or transformation of two RV’s\n\nMake the calculation easier!\n\nMgf’s are often used to prove certain distribution are sums of other ones!"
  },
  {
    "objectID": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#more-resources",
    "href": "lessons copy/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#more-resources",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "More resources",
    "text": "More resources\n\nhttps://online.stat.psu.edu/stat414/book/export/html/676\nhttps://www.youtube.com/watch/ez_vq23xWrQ\nhttps://www.youtube.com/watch/2p9J9ChTeFI\nhttps://www.youtube.com/watch/A5bWU8xcQkE\nhttps://www.youtube.com/watch/QeUrTGFTFm4\nhttps://www.youtube.com/watch/HhrkwyyRtgI"
  },
  {
    "objectID": "lessons copy/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html",
    "href": "lessons copy/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Homework 7 presentations due soon!\n\nI will check your HW 7 solutions ASAP!\n\nDepending on how far we get today and Wednesday, I might cancel the 12/9 class\nAnything else?"
  },
  {
    "objectID": "lessons copy/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#announcements",
    "href": "lessons copy/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Homework 7 presentations due soon!\n\nI will check your HW 7 solutions ASAP!\n\nDepending on how far we get today and Wednesday, I might cancel the 12/9 class\nAnything else?"
  },
  {
    "objectID": "lessons copy/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#key-dates",
    "href": "lessons copy/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 8 assignment due\nSunday: HW 7 presentations due at 11pm"
  },
  {
    "objectID": "lessons copy/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html",
    "href": "lessons copy/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "",
    "text": "Calculate the mean (expected value) of a joint distribution of continuous RV"
  },
  {
    "objectID": "lessons copy/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#learning-objectives",
    "href": "lessons copy/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#learning-objectives",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "",
    "text": "Calculate the mean (expected value) of a joint distribution of continuous RV"
  },
  {
    "objectID": "lessons copy/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#remark-on-expected-value-of-one-rv-from-joint-pdf",
    "href": "lessons copy/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#remark-on-expected-value-of-one-rv-from-joint-pdf",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "Remark on expected value of one RV from joint pdf",
    "text": "Remark on expected value of one RV from joint pdf\nIf you are given \\(f_{X,Y}(x,y)\\) and want to calculate \\(\\mathbb{E}[X]\\), you have two options:\n\nFind \\(f_X(x)\\) and use it to calculate \\(\\mathbb{E}[X]\\).\nOr, calculate \\(\\mathbb{E}[X]\\) using the joint density: \\[\\mathbb{E}[X] = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}x f_{X,Y}(x,y)dydx.\\]"
  },
  {
    "objectID": "lessons copy/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-1-expected-value-from-a-joint-distribution",
    "href": "lessons copy/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-1-expected-value-from-a-joint-distribution",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "Option 1: Expected value from a joint distribution",
    "text": "Option 1: Expected value from a joint distribution\n\n\n\n\nExample 3\n\n\nLet \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons copy/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-2-expected-value-from-a-joint-distribution",
    "href": "lessons copy/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-2-expected-value-from-a-joint-distribution",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "Option 2: Expected value from a joint distribution",
    "text": "Option 2: Expected value from a joint distribution\n\n\n\n\nExample 1\n\n\nLet \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs_key_info.html",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 videos should be in!\n\nSome presentations today\n\nNeed to grade HW 4 solutions and HW 5 assignment STILL\n\nHappy to be flexible on the HW 5 solutions deadline\n\nAnything else?"
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs_key_info.html#announcements",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 videos should be in!\n\nSome presentations today\n\nNeed to grade HW 4 solutions and HW 5 assignment STILL\n\nHappy to be flexible on the HW 5 solutions deadline\n\nAnything else?"
  },
  {
    "objectID": "lessons copy/17_Cont_RVs/31_35_Cont_RVs_key_info.html#key-dates",
    "href": "lessons copy/17_Cont_RVs/31_35_Cont_RVs_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 6 due\nSunday: HW 5 solutions due\n\nFLEXIBLE"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs_key_info.html",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 01 assignments are graded!\n\nSolutions and videos are posted!"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs_key_info.html#announcements",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 01 assignments are graded!\n\nSolutions and videos are posted!"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs_key_info.html#key-dates",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 02 Assignment due this Thursday at 11pm\nNo HW 01 Solutions"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "",
    "text": "Distinguish between Bernoulli, Binomial, Geometric, Hypergeometric, Discrete Uniform, Negative Binomial, and Poisson distributions when reading a story.\nIdentify the variable and the parameters in a story, and state what the variable and parameters mean.\nUse the formulas for the pmf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#learning-objectives",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#learning-objectives",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "",
    "text": "Distinguish between Bernoulli, Binomial, Geometric, Hypergeometric, Discrete Uniform, Negative Binomial, and Poisson distributions when reading a story.\nIdentify the variable and the parameters in a story, and state what the variable and parameters mean.\nUse the formulas for the pmf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#where-are-we",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#where-are-we",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-bernoulli-rvs",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-bernoulli-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Bernoulli RVs",
    "text": "Properties of Bernoulli RVs\n\nScenario: One trial, with outcome success or failure\nShorthand: \\(X \\sim \\text{Bernoulli}(p)\\)\n\n\\[\nX = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\quad \\\\\n            0 & \\quad \\mathrm{with\\ probability}\\ 1-p \\quad\n        \\end{array}\n    \\right.\n\\]\n\\[\np_X(x) = P(X=x) = p^x(1-p)^{1-x} \\text{ for } x=0,1\n\\]\n\\[\\text{E}(X) = p\\]\n\\[\\text{Var}(X) = pq = p(1-p)\\]"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#bernoulli-example-1",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#bernoulli-example-1",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bernoulli Example 1",
    "text": "Bernoulli Example 1\n\n\n\n\nExample 1\n\n\n\nWe roll a fair 6-sided die.\nWe get $1 if we roll a 5, and nothing otherwise.\nLet \\(X\\) be how much money we get.\nFind the mean and variance of \\(X\\)."
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-binomial-rvs",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-binomial-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Binomial RVs",
    "text": "Properties of Binomial RVs\n\nScenario: There are \\(n\\) independent trials, each resulting in a success or failure, with constant probability, \\(p\\), in each trial. We are counting the number of successes (or failures).\nShorthand: \\(X \\sim \\text{Binomial}(n, p)\\)\n\n\\[\nX = \\text{Number of successes of } n \\text{ independent trials}\n\\]\n\\[\np_X(x) = P(X=x) = {n \\choose x}p^x(1-p)^{n-x} \\text{ for } x=0,1,2,  ..., n\n\\]\n\\[\\text{E}(X) = np\\] \\[\\text{Var}(X) = npq = np(1-p)\\]"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#our-beloved-fair-sided-die",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#our-beloved-fair-sided-die",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Our beloved fair-sided die",
    "text": "Our beloved fair-sided die\n\n\n\n\nExample 2\n\n\n\nSuppose we roll a fair 6-sided die 50 times.\nWe get $1 every time we roll a 5, and nothing otherwise.\nLet \\(X\\) be how much money we get on the 50 rolls.\nFind the mean and variance of \\(X\\)."
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#geometric-rvs",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#geometric-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Geometric RVs",
    "text": "Geometric RVs\n\nScenario: There are repeated independent trials, each resulting in a success or failure, with constant probability of success for each trial. We are counting the number of trials until the first success.\nShorthand: \\(X \\sim \\text{Geo}(p)\\) or \\(X \\sim \\text{Geometric}(p)\\) or \\(X \\sim \\text{G}(p)\\)\n\n\n\n\n\n\n\n\n\\(X =\\) Number of trials needed for first success (count \\(x\\) includes the success)\n\\(X =\\) Number of failures before first success (count \\(x\\) does not include the success)\n\n\n\n\n\\(p _\nX( x ) = P(X=x) = (1-p)^{x-1}p\\)\nfor \\(x=1,2, 3,...\\)\n\\[F_\nX(x ) = P(X\\leq x) = 1-(1-p)^x\\]\nfor \\(x=1,2, 3,...\\)\n\\(p _X (x)= P(X=x) = (1-p)^{x}p\\)\nfor \\(x=0, 1,2,...\\)\n\\[F_X ( x\n)\n= P(X\\leq x) = 1-(1-p)^{x+1}\\]\nfor \\(x=0, 1,2,...\\)\n\n\n\\(E(X)=\\dfrac{1}{p}\\)\n\\(Var(X)= \\dfrac{1-p}{p^2}\\)\n\\(E(X)=\\dfrac{1-p}{p}\\)\n\\(Var(X) = \\dfrac{1-p}{p^2}\\)"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-14",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-14",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (1/4)",
    "text": "Bullseye (1/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the pmf for the number of throws needed to hit the bullseye?\nWhat are the mean and variance for the number of throws needed to hit the bullseye?\nFind the probability that our first bullseye:\n\nis on one of the first fifty tries\nis after the \\(50^{th}\\) try, given that it did not happen on the first 20 tries"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-24",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-24",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (2/4)",
    "text": "Bullseye (2/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the pmf for the number of throws needed to hit the bullseye?"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-34",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-34",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (3/4)",
    "text": "Bullseye (3/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat are the mean and variance for the number of throws needed to hit the bullseye?"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-44",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-44",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (4/4)",
    "text": "Bullseye (4/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nFind the probability that our first bullseye:\n\nis on one of the first fifty tries\nis after the \\(50^{th}\\) try, given that it did not happen on the first 20 tries"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#memoryless-property-for-geometric-rvs",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#memoryless-property-for-geometric-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Memoryless property for Geometric RVs",
    "text": "Memoryless property for Geometric RVs\nIf we know \\(X\\) is greater than some number (aka given \\(X &gt;j\\)), then the probability of \\(X &gt; k+j\\) is just the probability that \\(X&gt;k\\).\n \n\\(P(X &gt; k+j |X &gt; j) = P(X &gt; k)\\) \\[ P(X &gt; k+j |X &gt; j) = \\dfrac{P(X&gt;k+j \\text{ and } X&gt;j)}{P(X&gt;j)} = \\dfrac{P(X&gt;k+j)}{P(X&gt;j)} = \\dfrac{(1-p)^{k+j}}{(1-p)^{j}} = (1-p)^{k} \\]"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-negative-binomial-rvs",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-negative-binomial-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Negative Binomial RVs",
    "text": "Properties of Negative Binomial RVs\n\nScenario: There are repeated independent trials, each resulting in a success or failure, with constant probability of success for each trial. We are counting the number of trials until the \\(r^{th}\\) success.\nShorthand: \\(X \\sim \\text{NegBin}(p, r)\\) or \\(X \\sim \\text{NB}(p, r)\\)\nNegative binomial is sum of \\(r\\) geometric distributions\n\n\\[\nX = \\text{Number of independent trials until } r^{th} \\text{ success}\n\\]\n\\[ p_X(x) = P(X=x) = {x-1 \\choose r-1}(1-p)^{x-r}p^r \\text{ for } x = r, r+1, r+2, ...\\]\n\\[ E(X) = \\dfrac{r}{p}\\]\n\\[Var(X) = \\dfrac{rq}{p^2} = \\dfrac{r(1-p)}{p^2}\\]"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#hitting-more-than-1-bullseye",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#hitting-more-than-1-bullseye",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Hitting more than 1 bullseye",
    "text": "Hitting more than 1 bullseye\n\n\n\n\nExample 1\n\n\nConsider again the bullseye example, where we throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the expected value and variance of the number of throws needed to hit 5 bullseyes?"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#hitting-more-than-1-bullseye-1",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#hitting-more-than-1-bullseye-1",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Hitting more than 1 bullseye",
    "text": "Hitting more than 1 bullseye\n\n\n\n\nExample 1\n\n\nConsider again the bullseye example, where we throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the probability that the \\(5^{th}\\) bullseye is on the \\(20^{th}\\) throw?"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-poisson-rvs",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-poisson-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Poisson RVs",
    "text": "Properties of Poisson RVs\n\nScenario: We are counting the number of successes in a fixed time period, which has a constant rate of successes\nShorthand: \\(X \\sim \\text{Poisson}(\\lambda)\\) or \\(X \\sim \\text{Pois}(\\lambda)\\)\n\n\\[\nX = \\text{Number of successes in a given period}\n\\]\n\\[ p_X(x) = P(X=x) = \\dfrac{e^{-\\lambda}\\lambda^x}{x!} \\text{ for } x = 0, 1, 2,3, ...\\]\n\\[ \\text{E}(X) = \\lambda\\]\n\\[\\text{Var}(X) = \\lambda\\]"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#distinguishing-between-binomial-and-poisson-rvs",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#distinguishing-between-binomial-and-poisson-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Distinguishing between Binomial and Poisson RVs",
    "text": "Distinguishing between Binomial and Poisson RVs\n\nRecall that if \\(X\\sim \\text{Binomial}(n,p)\\), then\n\n\\(X\\) models the number of successes …\nin \\(n\\) independent (Bernoulli) trials …\nthat each have the same probability of success \\(p\\).\n\nPoisson r.v.’s are similar,\n\nexcept that instead of having \\(n\\) discrete independent trials,\nthere is a fixed time period (or space) during which the successes happen"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#examples-of-poisson-rvs",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#examples-of-poisson-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Examples of Poisson RVs",
    "text": "Examples of Poisson RVs\n\nNumber of visitors to an emergency room in an hour during a weekend night\nNumber of study participants enrolled in a study per week\nNumber of pedestrians walking through a square mile\nAny more?"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#emergency-room-visitors",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#emergency-room-visitors",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Emergency Room Visitors",
    "text": "Emergency Room Visitors\n\n\n\n\nExample 1\n\n\nSuppose an emergency room has an average of 50 visitors per day. Find the following probabilities.\n\nProbability of 30 visitors in a day.\nProbability of 8 visitors in an hour.\nProbability of at least 8 visitors in an hour."
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#combining-independent-poisson-distributions",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#combining-independent-poisson-distributions",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Combining independent Poisson distributions",
    "text": "Combining independent Poisson distributions\n\n\nTheorem 1\n\n\nIf \\(X\\sim Pois(\\lambda_1)\\) and \\(Y\\sim Pois(\\lambda_2)\\) are independent of each other, then \\(Z=X+Y\\sim Pois(\\lambda_1 + \\lambda_2)\\)."
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#two-emergency-rooms",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#two-emergency-rooms",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Two emergency rooms",
    "text": "Two emergency rooms\n\n\n\n\nExample 2\n\n\nSuppose emergency room 1 has an average of 50 visitors per day, and emergency room 2 has an average of 70 visitors per day, independently of each other. What is the probability distribution to model of the total number of visitors to both?"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#poisson-approximation-of-the-binomial",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#poisson-approximation-of-the-binomial",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Poisson Approximation of the Binomial",
    "text": "Poisson Approximation of the Binomial\nBoth Poisson and Binomial r.v.’s are counting the number of successes\n\nIf for a Binomial r.v.\n\nthe number of trials \\(n\\) is very large, and\nthe probability of success \\(p\\) is close to 0 or 1,\n\nThen the Poisson distribution can be used to approximate Binomial probabilities\n\nand we use \\(\\lambda = np\\)\n\nRule of thumb: We can use the Poisson approximation when \\(\\dfrac{1}{10} \\leq np(1-p) \\leq 10\\)"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#medical-lab-errors",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#medical-lab-errors",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Medical lab errors",
    "text": "Medical lab errors\n\n\n\n\nExample 3\n\n\nSuppose that in the long run, errors in a medical testing lab are made 0.1% of the time. Find the probability that fewer than 4 mistakes are made in the next 2,000 tests.\n\nFind the probability using the Binomial distribution.\nApproximate the probability in part (1) using the Poisson distribution.\n\n\n\n\nTo do for extra practice - will also see a similar problem in BSTA 511"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#hypergeometric-rvs",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#hypergeometric-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Hypergeometric RVs",
    "text": "Hypergeometric RVs\n\nScenario: There are a fixed number of successes and failures (which are known in advance), from which we make \\(n\\) draws without replacement. We are counting the number of successes from the \\(n\\) trials.\n\nThere is a finite population of \\(N\\) items\nEach item in the population is either a success or a failure, and there are \\(M\\) successes total.\nWe randomly select (sample) \\(n\\) items from the population without replacement\n\nShorthand: \\(X \\sim \\text{Hypergeo}(M, N, n)\\)\n\n\n\n\\[\nX = \\text{Number of successes in } n \\text{ draws}\n\\]\n\\[\np_X(x) = P(X=x) = \\dfrac{{M \\choose x}{N-M \\choose n-x}}{{N \\choose n}}\n\\] \\[\\text{ for } x \\text{ integer-valued } \\\\ \\max(0, n-(N-M)) \\leq x \\leq \\min(n, M)\\]\n\n\\[\\text{E}(X) =\\dfrac{nM}{N}\\]\n\\[\\text{Var}(X) = n \\dfrac{M}{N} \\bigg(1- \\dfrac{M}{N} \\bigg)\\bigg(\\dfrac{N-n}{N-1} \\bigg)\\]"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#wolf-population",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#wolf-population",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Wolf population",
    "text": "Wolf population\n\n\n\n\nExample 4\n\n\nA wildlife biologist is using mark-recapture to research a wolf population. Suppose a specific study region is known to have 24 wolves, of which 11 have already been tagged. If 5 wolves are randomly captured, what is the probability that 3 of them have already been tagged?"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#binomial-approximation-of-the-hypergeometric-rv",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#binomial-approximation-of-the-hypergeometric-rv",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Binomial approximation of the hypergeometric RV",
    "text": "Binomial approximation of the hypergeometric RV\nSuppose a hypergeometric RV \\(X\\) has the following properties:\n\nthe population size \\(N\\) is really big,\nthe number of successes \\(M\\) in the population is relatively large,\n\n\\(\\frac{M}{N}\\) shouldn’t be close to 0 or 1\n\nand the number of items \\(n\\) selected is small\nRule of thumb: \\(\\dfrac{n}{N}&lt;0.05\\) or \\(N&gt;20n\\)\n\nThen, in this case, making \\(n\\) draws from the population doesn’t change the probability of success much, and the hypergeometric RV. can be approximated by a binomial RV"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#wolf-population-revisited",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#wolf-population-revisited",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Wolf population revisited",
    "text": "Wolf population revisited\n\n\n\n\nExample 5\n\n\nSuppose a specific study region is known to have 2400 wolves, of which 1100 have already been tagged.\n\nIf 50 wolves are randomly captured, what is the probability that 20 of them have already been tagged?\nApproximate the probability in part (1) using the binomial distribution."
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#discrete-uniform-rvs",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#discrete-uniform-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Discrete Uniform RVs",
    "text": "Discrete Uniform RVs\n\nScenario: There are \\(N\\) possible outcomes, which are all equally likely.\nShorthand: \\(X \\sim \\text{Uniform}(N)\\)\n\n\\[\nX = \\text{Outcome of interest, with } x=1, 2, ..., N\n\\]\n\\[\np_X(x) = P(X=x) = \\dfrac{1}{N} \\text{ for } x=1, 2, 3, ..., N\n\\]\n\\[\\text{E}(X) =\\dfrac{N+1}{2}\\]\n\\[\\text{Var}(X) = \\dfrac{N^2 -1}{12}\\]"
  },
  {
    "objectID": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#what-discrete-uniform-rvs-have-we-seen-already",
    "href": "lessons copy/16_Discrete_RVs/14_20_Discrete_RVs.html#what-discrete-uniform-rvs-have-we-seen-already",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "What discrete uniform RVs have we seen already?",
    "text": "What discrete uniform RVs have we seen already?\n\n\n\n\nExample 6\n\n\nExamples of discrete uniform RVs"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "",
    "text": "Find derivatives of continuous functions with one variable\nFind antiderivatives and integrals of functions with one variable"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#learning-objectives",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#learning-objectives",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "",
    "text": "Find derivatives of continuous functions with one variable\nFind antiderivatives and integrals of functions with one variable"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#where-are-we",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#where-are-we",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.1\n\n\n\\(f(x) = 2\\)\n\n\n\n\nDerivative of a constant\n\n\n\\[\\dfrac{d}{dx} c = 0\\]"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-1",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-1",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.2\n\n\n\\(f(x) = 2x\\)"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-2",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-2",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.3\n\n\n\\(f(x) = 2x+2\\)"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-3",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-3",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.4\n\n\n\\(f(x) = x^2\\)\n\n\n\n\nDerivative of \\(x\\) to a constant\n\n\n\\[\\dfrac{d}{dx} x^n = nx^{n-1}\\]"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-4",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-4",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.5\n\n\n\\(f(x) = 3\\sqrt{x}+\\frac2x+5\\)"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-5",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-5",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.6\n\n\n\\(f(x) = e^x\\)\n\n\n\n\nDerivative of exponential function\n\n\n\\(\\dfrac{d}{dx} e^x = e^x\\)"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-6",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-6",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.7\n\n\n\\(f(x) = \\ln(x)\\)\n\n\n\n\nDerivative of logarithm\n\n\n\\(\\dfrac{d}{dx} ln(x) = \\dfrac{1}{x}\\)"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-7",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-7",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.8\n\n\n\\(f(x) = x^2 e^x\\)\n\n\n\n\nProduct Rule\n\n\n\\(\\dfrac{d}{dx} f(x)g(x) = f'(x)g(x) + f(x)g'(x)\\)"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-8",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-8",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.9\n\n\n\\(f(x) = \\dfrac{x^5}{2x+7}\\)\n\n\n\n\nQuotient Rule\n\n\n\\(\\dfrac{d}{dx} \\dfrac{f(x)}{g(x)} = \\dfrac{g(x)f'(x) - f(x)g'(x)}{\\big(g(x)\\big)^2}\\)"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-9",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-9",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.10\n\n\n\\(f(x) = e^{-2x+7}\\)\n\n\n\n\nChain Rule\n\n\n\\(\\dfrac{d}{dx} f\\big(g(x)\\big)= f'\\big(g(x)\\big)g'(x)\\)"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-10",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-10",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.11\n\n\n\\(f(x) = \\ln(x^2)\\)"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.1\n\n\n\\(f(x) = 2\\)"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-1",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-1",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.2\n\n\n\\(f(x) = x\\)\n\n\n\n\nIntegration of x to a constant\n\n\n\\(\\displaystyle\\int x^n dx = \\dfrac{x^{n+1}}{n+1} + c\\)"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-2",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-2",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.3\n\n\n\\(f(x) = \\frac1x\\)"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-3",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-3",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.4\n\n\n\\(f(x) = x^{3/2}\\)"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-4",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-4",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.5\n\n\n\\(f(x) = e^x\\)"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-5",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-5",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.6\n\n\n\\(f(x) = e^{-x}\\)"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-6",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-6",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.7\n\n\n\\(f(x) = e^{-2x}\\)"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.1\n\n\n\\(\\displaystyle\\int_0^1 (2x+x^5)dx\\)"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-1",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-1",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.2\n\n\n\\(\\displaystyle\\int_2^3 e^{-x}dx\\)\n\n\n\n\nU-substitution\n\n\n\\(\\displaystyle\\int f\\big(g(x)\\big) g'(x) dx = \\displaystyle\\int f(u) dx\\)"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-2",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-2",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.3\n\n\n\\(\\displaystyle\\int_2^3 x e^{x^2}dx\\)"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-3",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-3",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.4\n\n\n\\(\\displaystyle\\int_0^{\\infty} x e^{-x}dx\\)\n\n\n\n\nIntegrating by Parts\n\n\n\\(\\displaystyle\\int f(x) g'(x) dx = f(x)g(x) -\\)\n\\(\\displaystyle\\int f'(x) g(x) dx\\)\nOR\n\\(\\displaystyle\\int_a^b u dv = uv\\bigg|^b_a - \\displaystyle\\int_a^b vdu\\)"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-4",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-4",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.5\n\n\n\\(\\displaystyle\\int_1^2 x^2 \\ln(x)dx\\)"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-5",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-5",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.6\n\n\n\\(\\displaystyle\\int_1^2 \\ln(x)dx\\)"
  },
  {
    "objectID": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-6",
    "href": "lessons copy/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-6",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.7\n\n\n\\(\\displaystyle\\int_1^2 x^2 e^{x}dx\\)"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro_key_info.html",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "For homework 1, you will need to the textbook! There is a link in the Syllabus and a pdf in our shared OneDrive folder.\n\nWhat’s out shared OneDrive folder?? OHSU uses OneDrive as cloud storage. Everyone should be able to access OneDrive with their OHSU email, in addition to many other Microsoft apps.  \nIn our shared folder, I put files that I cannot share publicly. You’ll see homework solutions, recordings, and textbooks in there. For the most part, I will place links on our website directly to the files. I don’t always do the best job of this, so please take a look at those files as well. \n\nDue days\n\nI don’t want anyone to feel anxious about when exactly HW 1 is due. Almost everyone has voted, and it looks like Thursdays will be the best day for homework assignments.\n\nA result of the voting and the notes about work schedules\n\nConsequently, I want to give you more than a week after assignments are due to turn in the solutions, so solutions will be due two Sundays after the assignment is due (10 days after).\nFor example, the assignment for HW 1 is due 10/10 at 11pm and the solutions for HW 1 will be due 10/20 at 11pm.\n\nHomework solution groups!!\n\nI added a link to a Microsoft form in Homework 1\nPlease specify who you would like to partner with\n\nOffice hours\n\nLet’s discuss\nLooks like Thursdays 1-2:30pm is best or 1-2pm on Tuesday"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro_key_info.html#announcements",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro/22_Counting_Intro_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "For homework 1, you will need to the textbook! There is a link in the Syllabus and a pdf in our shared OneDrive folder.\n\nWhat’s out shared OneDrive folder?? OHSU uses OneDrive as cloud storage. Everyone should be able to access OneDrive with their OHSU email, in addition to many other Microsoft apps.  \nIn our shared folder, I put files that I cannot share publicly. You’ll see homework solutions, recordings, and textbooks in there. For the most part, I will place links on our website directly to the files. I don’t always do the best job of this, so please take a look at those files as well. \n\nDue days\n\nI don’t want anyone to feel anxious about when exactly HW 1 is due. Almost everyone has voted, and it looks like Thursdays will be the best day for homework assignments.\n\nA result of the voting and the notes about work schedules\n\nConsequently, I want to give you more than a week after assignments are due to turn in the solutions, so solutions will be due two Sundays after the assignment is due (10 days after).\nFor example, the assignment for HW 1 is due 10/10 at 11pm and the solutions for HW 1 will be due 10/20 at 11pm.\n\nHomework solution groups!!\n\nI added a link to a Microsoft form in Homework 1\nPlease specify who you would like to partner with\n\nOffice hours\n\nLet’s discuss\nLooks like Thursdays 1-2:30pm is best or 1-2pm on Tuesday"
  },
  {
    "objectID": "lessons copy/07_Random_Variables/07_Random_Variables_key_info.html",
    "href": "lessons copy/07_Random_Variables/07_Random_Variables_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "For office hours, we decided to do appointments!\n\nHere’s my Calendly: https://calendly.com/nickywakim/15min\nI have it set up mostly for Tuesdays and Thursdays\nIt requires a day’s notice for appointments - mainly so I can plan my next day\n\nDid you turn in HW 01 Assignment?\n\nI’m missing one! So double check!\nThen I’ll post the solutions!"
  },
  {
    "objectID": "lessons copy/07_Random_Variables/07_Random_Variables_key_info.html#announcements",
    "href": "lessons copy/07_Random_Variables/07_Random_Variables_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "For office hours, we decided to do appointments!\n\nHere’s my Calendly: https://calendly.com/nickywakim/15min\nI have it set up mostly for Tuesdays and Thursdays\nIt requires a day’s notice for appointments - mainly so I can plan my next day\n\nDid you turn in HW 01 Assignment?\n\nI’m missing one! So double check!\nThen I’ll post the solutions!"
  },
  {
    "objectID": "lessons copy/07_Random_Variables/07_Random_Variables_key_info.html#key-dates",
    "href": "lessons copy/07_Random_Variables/07_Random_Variables_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 02 Assignment due this Thursday at 11pm\nNo HW 01 Solutions"
  },
  {
    "objectID": "lessons copy/02_Lang_prob/02_Lang_prob_muddy_points.html",
    "href": "lessons copy/02_Lang_prob/02_Lang_prob_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "1. Why is the number of possible events \\(2^{|S|}\\)?\nIn class, we were wondering why/if \\(2^{|S|}\\) is the general formula for calculating the total number of possible events. We were specifically wondering if the \\(2\\) came from the fact that we had two options (heads and tails) for our outcome. Let’s work through the example of a 6-sided die to explain this further. The sample space is \\(S=\\{1, 2, 3, 4, 5, 6\\}\\). So is the total number of possible events \\(2^6\\) or \\(6^6\\) or something else? We can actually think about an event by using an indicator variable for each outcome of the sample space. An indicator variable is just a way to give us a yes/no answer to a question. So in this case, we are wondering: is this outcome a part of our event? If our event is \\(\\{1\\}\\) then for the outcome \\(1\\), the answer is “yes, the outcome is part of the event. For outcomes \\(2-6\\), the answer is”no, the outcome is not apart of the event.”\n\nFor each outcome, we have a “yes” or “no” answer. We can look at another example of an event. Let’s say our event is rolling an even number:\n\nFor \\(2\\), \\(4\\), and \\(6\\), the answer is “yes.” We can define the indicator variable for whether an outcome is in an event or not. The indicator gives a 1 or 0 for yes and no respectively.\n\nAs stated above, the \\(2\\) in \\(2^6\\) comes from the \\(2\\) options from our indicator. Each side has two options, and there are \\(6\\) sides. Thus, \\(2^6\\) possible events.\n\n\n2. What is an event??\nI think this will become clearer when we start thinking about events in the context of probability. When we think of events outside of probability, we may think of something we actually do or something that happens, like going to a concert or coming to class or missing the streetcar. In this case, we think of the event as the single thing (out of all the options) that actually occured. For example, if I’m taking the streetcar to class, I can think of two definitive options of what might occur: I miss the streetcar or I get on the streetcar. Only one of these things can occur, which I may call an event colloquially.\nIt is important to make the distinction with events defined within probability. Events are not necessarily a single thing that occurred. Instead it can be a collection of things that may occur. In the example of the streetcar, I can define my event to include both options. Thus, my event is that I make the streetcar or I miss it. Both of these things cannot happen simultaneously, but if I want to calculate the probability that I miss or make the streetcar, then it is helpful to have the event defined.\n\nAnd what is the difference between event and outcome?\nAn outcome is a single result. The two options in the above example, missing the streetcar or getting on the streetcar, are two potential outcomes. Events are the collection of 0, 1, or more outcomes. So the possible events are: the empty set, missing the streetcar, getting on the streetcar, or the set of missing the streetcar and getting on the streetcar.\n\n\n\n3. Confusion on the Venn Diagram for the high blood pressure example\nThis is in reference to the Chapter 1 notes on “BP example variation (3/3)” slide. I explained the event that at least one subject does not have high blood pressure using a venn diagram. In this venn diagram, I assumed \\(n=4\\), and I wanted to show that the union of complements is equal to the complement of unions: \\(\\bigcup\\limits_{i=1}^{n}H_i^C = \\Big(\\bigcap\\limits_{i=1}^{n}H_i\\Big)^C\\).\n\n Now we can look at \\(\\bigcup\\limits_{i=1}^{4}H_i^C\\). We first need to define \\(H_i^c\\)\n\n\n\n\n\n4. Proofs of propositions\nFurther explanations of the propositions can be found in the textbook from pages 24-27. For many of the explanations in class, I was working to produce a union of disjoint events, so that the probability could easily be calculated. Proposition 3 and 4 were specifically mentioned, so I will include some writing notes on them here:\n\nProposition 3\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\nIn this proposition, I want to define event \\(B\\) as a union of disjoint events so that I can show \\(P(B)\\) is the sum of \\(P(A)\\) and some greater-than-or-equal-to 0 probability event. If the following is my venn diagram of A and B:\n\n\n\n\n\nThen I can define B as the union of disjoint events: \nIf we then take the probability of each side of the equation \\(B = A \\cup (A^c \\cap B)\\), we get \\[P(B) = P\\big(A \\cup (A^c \\cap B)\\big)\\]\nSince events \\(A\\) and \\(A^c \\cap B\\) are disjoint, the probability of their union is just: \\[P(A) + P(A^c \\cap B)\\]\nThus, our equation is now \\[P(B) = P(A) + P(A^c \\cap B)\\]\nFrom Axiom 1, we know for event \\(A^c \\cap B\\), \\(P(A^c \\cap B) \\geq 0\\).\nSo the probability of event B is the sum of the probability of event A and an event that is \\(\\geq\\) 0. This means \\(P(B) \\geq P(A)\\).\n\n\nProposition 4\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)\n\n\nFrom the pictures above, we can see some similar disjoint events.\nIf we look back at \\(A \\cup B\\), we can start manipulating the right side of the equation:\n\n \n\n\n\n5. Example at end of Chapter 2 slides (Venn Diagram)\nI will post this in the previous week’s Muddy Points as well. Please follow this link for my work through of the example. And here is the PDF with my work.\nSub-question: why don’t we just multiply the probability of A and B to get the intersection? This is a specific property of probability when A and B are independent. Only when A and B are independent can we conclude that \\(P(A \\cap B) = P(A)P(B)\\).\n\n\n6. Partition of events\nWe’ve been working with event partitions throughout Chapter 2, but we have not formally identified them. Partitions are advantageous to define for two reasons:\n\nThe partitions may be easier to calculate. We can then use the partitions to reconstruct other probabilities that may be more difficult to calculate\nPartitions have nice properties as a consequence of being disjoint. For example, the probability of the union of partitions is the sum of the probabilities across each partition: \\[P\\bigg(\\bigcup_{i=1}^n A_i\\bigg) = P(A_1)P(A_2)P(A_3) \\cdot \\cdot \\cdot P(A_n)\\]"
  },
  {
    "objectID": "lessons copy/09_pdfs/09_pmfs.html",
    "href": "lessons copy/09_pdfs/09_pmfs.html",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "",
    "text": "Distinguish between discrete and continuous random variables.\nCalculate probabilities for continuous random variables.\nCalculate and graph a density (i.e., probability density function, PDF).\nCalculate and graph a CDF (i.e., a cumulative distribution function)"
  },
  {
    "objectID": "lessons copy/09_pdfs/09_pmfs.html#learning-objectives",
    "href": "lessons copy/09_pdfs/09_pmfs.html#learning-objectives",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "",
    "text": "Distinguish between discrete and continuous random variables.\nCalculate probabilities for continuous random variables.\nCalculate and graph a density (i.e., probability density function, PDF).\nCalculate and graph a CDF (i.e., a cumulative distribution function)"
  },
  {
    "objectID": "lessons copy/09_pdfs/09_pmfs.html#discrete-vs.-continuous-rvs",
    "href": "lessons copy/09_pdfs/09_pmfs.html#discrete-vs.-continuous-rvs",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Discrete vs. Continuous RVs",
    "text": "Discrete vs. Continuous RVs\n\n\n\nFor a discrete RV, the set of possible values is either finite or can be put into a countably infinite list.\n \nContinuous RVs take on values from continuous intervals, or unions of continuous intervals\n\n\n\n\n\nFigure from Introduction to Probability TB (pg. 301)"
  },
  {
    "objectID": "lessons copy/09_pdfs/09_pmfs.html#how-to-define-probabilities-for-continuous-rvs",
    "href": "lessons copy/09_pdfs/09_pmfs.html#how-to-define-probabilities-for-continuous-rvs",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "How to define probabilities for continuous RVs?",
    "text": "How to define probabilities for continuous RVs?\n\n\nDiscrete RV \\(X\\):\n\nlibrary(ggplot2)\ndata = data.frame(x = seq(0, 10, 1), y = seq(0, 0.5, 0.05))\nggplot(data, aes(x = x, y = y)) +\n  labs(x = \"x\", y = \"Probability\") +\n  theme_minimal() +\n  theme(text = element_text(size=28))\n\n\n\n\n\n\n\n\n\npmf: \\(p_X(x) = P(X=x)\\)\n\n\nContinuous RV \\(X\\):\n\nlibrary(ggplot2)\ndata = data.frame(x = seq(0, 10, 1), y = seq(0, 1, 0.1))\nggplot(data, aes(x = x, y = y)) +\n  labs(x = \"x\", y = \"Density\") +\n  theme_minimal() +\n  theme(text = element_text(size=28))\n\n\n\n\n\n\n\n\n\ndensity: \\(f_X(x)\\)\nprobability: \\(P(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\)"
  },
  {
    "objectID": "lessons copy/09_pdfs/09_pmfs.html#what-is-a-probability-density-function",
    "href": "lessons copy/09_pdfs/09_pmfs.html#what-is-a-probability-density-function",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "What is a probability density function?",
    "text": "What is a probability density function?\n\n\nProbability density function\n\n\nThe probability distribution, or probability density function (pdf), of a continuous random variable \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\),\n\\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\]\n\n\nRemarks:\n\nNote that \\(f_X(x) \\neq \\mathbb{P}(X=x)\\)!!!\nIn order for \\(f_X(x)\\) to be a pdf, it needs to satisfy the properties\n\n\\(f_X(x) \\geq 0\\) for all \\(x\\)\n\\(\\int_{-\\infty}^{\\infty} f_X(x)dx=1\\)"
  },
  {
    "objectID": "lessons copy/09_pdfs/09_pmfs.html#lets-demonstrate-the-pdf-with-an-example-15",
    "href": "lessons copy/09_pdfs/09_pmfs.html#lets-demonstrate-the-pdf-with-an-example-15",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (1/5)",
    "text": "Let’s demonstrate the PDF with an example (1/5)\n\n\n\n\nExample 1.1\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind the value of \\(a\\) so that \\(f_X(x)\\) is a pdf."
  },
  {
    "objectID": "lessons copy/09_pdfs/09_pmfs.html#lets-demonstrate-the-pdf-with-an-example-25",
    "href": "lessons copy/09_pdfs/09_pmfs.html#lets-demonstrate-the-pdf-with-an-example-25",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (2/5)",
    "text": "Let’s demonstrate the PDF with an example (2/5)\n\n\n\n\nExample 1.2\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(2.7 \\leq X \\leq 2.9)\\)."
  },
  {
    "objectID": "lessons copy/09_pdfs/09_pmfs.html#lets-demonstrate-the-pdf-with-an-example-35",
    "href": "lessons copy/09_pdfs/09_pmfs.html#lets-demonstrate-the-pdf-with-an-example-35",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (3/5)",
    "text": "Let’s demonstrate the PDF with an example (3/5)\n\n\n\n\nExample 1.3\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(2.7 &lt; X \\leq 2.9)\\)."
  },
  {
    "objectID": "lessons copy/09_pdfs/09_pmfs.html#lets-demonstrate-the-pdf-with-an-example-45",
    "href": "lessons copy/09_pdfs/09_pmfs.html#lets-demonstrate-the-pdf-with-an-example-45",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (4/5)",
    "text": "Let’s demonstrate the PDF with an example (4/5)\n\n\n\n\nExample 1.4\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(X = 2.9)\\)."
  },
  {
    "objectID": "lessons copy/09_pdfs/09_pmfs.html#lets-demonstrate-the-pdf-with-an-example-55",
    "href": "lessons copy/09_pdfs/09_pmfs.html#lets-demonstrate-the-pdf-with-an-example-55",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (5/5)",
    "text": "Let’s demonstrate the PDF with an example (5/5)\n\n\n\n\nExample 1.5\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(X \\leq 2.8)\\)."
  },
  {
    "objectID": "lessons copy/09_pdfs/24_01_Continuous_rv_muddy_points.html",
    "href": "lessons copy/09_pdfs/24_01_Continuous_rv_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n1. Why we are allowed to “split” the operator d/dx into two pieces as if it were a fraction when it’s an operator\nHere is a pretty helpful StackExchange post talking about this!\n\n\n2. How to know what to use as \\(u\\) and \\(dv\\) for integration by parts\nI have two approaches to identifying \\(u\\) and \\(dv\\):\n\nTry to find a \\(u\\) that will eventually differentiate into a constant. This usually works unless you’re left with a \\(dv\\) that is hard to integrate.\n\nFor example, \\(u=x^6\\). the first derivative, \\(u'=6x^5\\), which may lead us to do another integration by parts, but eventually, at the 6th derivative, we get 720. This means, in our integration by parts, we eventually get an integral that only has \\(x\\) in the function once.\n\nIn this example, \\(x^6\\) would result in many integration by parts. I feel like we don’t typically see that many in our work.\n\nIn Example 3.5 in Calculus Review, setting \\(u=x^2\\) is a bad idea because we don’t really know how to integrate \\(dv=ln(x)\\) into \\(v\\).\n\nTry to find a \\(u\\) where \\(du\\) is the reciprocal of \\(v\\) or \\(du\\) cancels with \\(v\\).\n\nLook again at Example 3.5 in the notes! Hint: What is the derivative of \\(ln(x)\\)? And what does \\(\\dfrac{1}{x}x^3\\) equal?\n\n\n\n\n3. Looking for more practice in calculus?\nI just stumbled upon this website! Just a bunch of calculus practice problems! Might be some help."
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#learning-objectives",
    "href": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#learning-objectives",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate probabilities for a pair of discrete random variables\nCalculate a joint, marginal, and conditional probability mass function (pmf)\nCalculate a joint, marginal, and conditional cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#where-are-we",
    "href": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#where-are-we",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#what-is-a-joint-pmf",
    "href": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#what-is-a-joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is a joint pmf?",
    "text": "What is a joint pmf?\n\n\nDefinition: joint pmf\n\n\nThe joint pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[p_{X,Y}(x,y) = \\mathbb{P}(X=x\\ and\\ Y=y) = \\mathbb{P}(X=x, Y=y)\\]"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#this-chapters-main-example",
    "href": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#this-chapters-main-example",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "This chapter’s main example",
    "text": "This chapter’s main example\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#joint-pmf",
    "href": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Joint pmf",
    "text": "Joint pmf\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#marginal-pmfs",
    "href": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#marginal-pmfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Marginal pmf’s",
    "text": "Marginal pmf’s\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#remarks-on-the-joint-pmf",
    "href": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#remarks-on-the-joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the joint pmf",
    "text": "Remarks on the joint pmf\nSome properties of joint pmf’s:\n\nA joint pmf \\(p_{X,Y}(x,y)\\) must satisfy the following properties:\n\n\\(p_{X,Y}(x,y)\\geq 0\\) for all \\(x, y\\).\n\\(\\sum \\limits_{\\{all\\ x\\}} \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)=1\\).\n\nMarginal pmf’s:\n\n\\(p_X(x) = \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)\\)\n\\(p_Y(y) = \\sum \\limits_{\\{all\\ x\\}} p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#what-is-a-joint-cdf",
    "href": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#what-is-a-joint-cdf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is a joint CDF?",
    "text": "What is a joint CDF?\n\n\nDefinition: joint CDF\n\n\nThe joint CDF of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[F_{X,Y}(x,y) = \\mathbb{P}(X \\leq x\\ and\\ Y \\leq y) = \\mathbb{P}(X \\leq x, Y \\leq y)\\]"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#joint-cdfs",
    "href": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#joint-cdfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Joint CDFs",
    "text": "Joint CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#marginal-cdfs",
    "href": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#marginal-cdfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Marginal CDFs",
    "text": "Marginal CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#remarks-on-the-joint-and-marginal-cdf",
    "href": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#remarks-on-the-joint-and-marginal-cdf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the joint and marginal CDF",
    "text": "Remarks on the joint and marginal CDF\n\n\\(F_X(x)\\): right most columns of the CDf table (where the \\(Y\\) values are largest)\n\\(F_Y(y)\\): bottom row of the table (where X values are largest)\n\\(F_X(x)=\\lim\\limits_{y\\rightarrow\\infty}F_{X, Y}(x,y)\\)\n\\(F_Y(y)=\\lim\\limits_{x\\rightarrow\\infty}F_{X, Y}(x,y)\\)"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#independence-and-conditioning",
    "href": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#independence-and-conditioning",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Independence and Conditioning",
    "text": "Independence and Conditioning\nRecall that for events \\(A\\) and \\(B\\),\n\n\\(\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}\\)\n\\(A\\) and \\(B\\) are independent if and only if\n\n\\(\\mathbb{P}(A|B) = \\mathbb{P}(A)\\)\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A)\\cdot\\mathbb{P}(B)\\)\n\n\nIndependence and conditioning are defined similarly for r.v.’s, since \\[p_X(x) = \\mathbb{P}(X=x)\\ \\mathrm{and}\\ \\ p_{X,Y}(x,y) = \\mathbb{P}(X = x ,Y = y).\\]"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#what-is-the-conditional-pmf",
    "href": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#what-is-the-conditional-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is the conditional pmf?",
    "text": "What is the conditional pmf?\n\n\nDefinition: conditional pmf\n\n\nThe conditional pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is defined as \\[p_{X|Y}(x|y) = \\mathbb{P}(X = x |Y = y) = \\frac{\\mathbb{P}(X = x\\ and\\ Y = y)}{\\mathbb{P}(Y = y)}\n=\\frac{p_{X,Y}(x,y) }{p_{Y}(y) }\\] if \\(p_{Y}(y) &gt; 0\\)."
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#remarks-on-the-conditional-pmf",
    "href": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#remarks-on-the-conditional-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the conditional pmf",
    "text": "Remarks on the conditional pmf\nThe following properties follow from the conditional pmf definition:\n\nIf \\(X \\perp Y\\) (independent)\n\n\\(p_{X|Y}(x|y) = p_X(x)\\) for all \\(x\\) and \\(y\\)\n\\(p_{X,Y}(x,y) = p_X(x)p_Y(y)\\) for all \\(x\\) and \\(y\\)\nWhich also implies (\\(\\Rightarrow\\)): \\(F_{X,Y}(x,y) = F_X(x)F_Y(y)\\) for all \\(x\\) and \\(y\\)\n\nIf \\(X_1, X_2, …, X_n\\) are independent\n\n\\[p_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1=x_1, X_2=x_2, …, X_n=x_n)=\\prod\\limits_{i=1}^np_{X_i}(x_i)\\]\n\\[F_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1\\leq x_1, X_2\\leq x_2, …, X_n\\leq x_n)=\\prod\\limits_{i=1}^nP(X_i \\leq x_i) = \\prod\\limits_{i=1}^nF_{X_i}(x_i)\\]"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#conditional-pmfs",
    "href": "lessons copy/11_Transformations_Joint_distributions/11_Transformations.html#conditional-pmfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Conditional pmf’s",
    "text": "Conditional pmf’s\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?\n\n\n\n\n\nRemark:\n\nTo show that \\(X\\) and \\(Y\\) are not independent, we just need to find one counter example\nHowever, to show that they are independent, we need to verify this for all possible pairs of \\(x\\) and \\(y\\)"
  },
  {
    "objectID": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning.html#learning-objectives",
    "href": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning.html#learning-objectives",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nShow that a joint pdf consists of two independent, continuous RVs.\nCombine two independent RVs into one joint pdf or CDF."
  },
  {
    "objectID": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning.html#how-do-we-represent-independent-continuous-rvs-in-a-joint-pdf",
    "href": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning.html#how-do-we-represent-independent-continuous-rvs-in-a-joint-pdf",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "How do we represent independent continuous RVs in a joint pdf?",
    "text": "How do we represent independent continuous RVs in a joint pdf?\n\n\nWhat do we know about independence for events and discrete RVs?\nFor events: If \\(A \\perp B\\)\n\\[P(A \\cap B) = P(A)P(B)\\] \\[P(A|B) = P(A)\\]\nFor discrete RVs: If \\(X \\perp Y\\) \\[p_{X,Y}(x,y) = p_{X}(x)p_{Y}(y)\\] \\[F_{X,Y}(x,y) = F_{X}(x)F_{Y}(y)\\] \\[p_{X|Y}(x|y) = p_{X}(x)\\] \\[p_{Y|X}(y|x) = p_{Y}(y)\\]\n\n\n\nWhat does it mean for continuous r.v.’s to be independent?\nFor continuous RVs: If \\(X \\perp Y\\)"
  },
  {
    "objectID": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs",
    "href": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Constructing a joint pdf from two independent, continuous RVs",
    "text": "Constructing a joint pdf from two independent, continuous RVs\n\n\n\n\nExample 1.1\n\n\nLet \\(X\\) and \\(Y\\) be independent r.v.’s with \\(f_X(x)= \\frac12\\), for \\(0 \\leq x \\leq 2\\) and \\(f_Y(y)= 3y^2\\), for \\(0 \\leq y \\leq 1\\).\n\nFind \\(f_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs-1",
    "href": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs-1",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Constructing a joint pdf from two independent, continuous RVs",
    "text": "Constructing a joint pdf from two independent, continuous RVs\n\n\n\n\nExample 1.2\n\n\nLet \\(X\\) and \\(Y\\) be independent r.v.’s with \\(f_X(x)= \\frac12\\), for \\(0 \\leq x \\leq 2\\) and \\(f_Y(y)= 3y^2\\), for \\(0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)."
  },
  {
    "objectID": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning.html#showing-independence-from-joint-pdf",
    "href": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning.html#showing-independence-from-joint-pdf",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Showing independence from joint pdf",
    "text": "Showing independence from joint pdf\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for \\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\).\n\nAre \\(X\\) and \\(Y\\) independent?"
  },
  {
    "objectID": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning.html#finding-cdf-from-two-independent-rvs",
    "href": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning.html#finding-cdf-from-two-independent-rvs",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Finding CDF from two independent RVs",
    "text": "Finding CDF from two independent RVs\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for \\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(F_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning.html#showing-independence-from-joint-pdf-1",
    "href": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning.html#showing-independence-from-joint-pdf-1",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Showing independence from joint pdf",
    "text": "Showing independence from joint pdf\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 3\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Are \\(X\\) and \\(Y\\) independent?"
  },
  {
    "objectID": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning.html#final-statement-on-independence",
    "href": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning.html#final-statement-on-independence",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Final statement on independence",
    "text": "Final statement on independence\n\nIf \\(f_{X,Y}(x,y)= g(x)h(y)\\), where \\(g(x)\\) and \\(h(y)\\) are pdf’s, then \\(X\\) and \\(Y\\) are independent.\n\nThe domain of the joint pdf needs to be independent as well!!\n\n\n       \n\nIf \\(F_{X,Y}(x,y)= G(x)H(y)\\), where \\(G(x)\\) and \\(H(y)\\) are cdf’s, then \\(X\\) and \\(Y\\) are independent.\n\nThe domain of the joint CDF needs to be independent as well!!"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro.html",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro.html",
    "title": "Chapter 22: Introduction to Counting",
    "section": "",
    "text": "Define permutations and combinations\nCharacterize difference between sampling with and without replacement\nCharacterize difference between sampling when order matters and when order does not matter\nCalculate the probability of sampling any combination of the following: with or without replacement and order does or does not matter"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro.html#learning-objectives",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro.html#learning-objectives",
    "title": "Chapter 22: Introduction to Counting",
    "section": "",
    "text": "Define permutations and combinations\nCharacterize difference between sampling with and without replacement\nCharacterize difference between sampling when order matters and when order does not matter\nCalculate the probability of sampling any combination of the following: with or without replacement and order does or does not matter"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro.html#where-are-we",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro.html#where-are-we",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro.html#basic-counting-examples-13",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro.html#basic-counting-examples-13",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Basic Counting Examples (1/3)",
    "text": "Basic Counting Examples (1/3)\n\n\nExample 1\n\n\nSuppose we have 10 (distinguishable) subjects for study.\n\nHow many possible ways are there to order them?\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?\n\nHow many ways to order them without replacement and only need 6?\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro.html#basic-counting-examples-23",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro.html#basic-counting-examples-23",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Basic Counting Examples (2/3)",
    "text": "Basic Counting Examples (2/3)\nSuppose we have 10 (distinguishable) subjects for study.\n\n\n\n\nExample 1.1\n\n\nHow many possible ways are there to order them?\n\n\n \n\n\nExample 1.2\n\n\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro.html#basic-counting-examples-33",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro.html#basic-counting-examples-33",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Basic Counting Examples (3/3)",
    "text": "Basic Counting Examples (3/3)\nSuppose we have 10 (distinguishable) subjects for study.\n\n\n\n\nExample 1.3\n\n\nHow many ways to order them without replacement and only need 6?\n\n\n \n\n\nExample 1.4\n\n\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro.html#permutations-and-combinations-1",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro.html#permutations-and-combinations-1",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Permutations and Combinations",
    "text": "Permutations and Combinations\n\n\nDefinition: Permutations\n\n\nPermutations are the number of ways to arrange in order \\(r\\) distinct objects when there are \\(n\\) total.\n\\[nPr = \\frac{n!}{(n-r)!}\\]\n\n\n\n\nDefinition: Combinations\n\n\nCombinations are the number of ways to choose (order doesn’t matter) \\(r\\) objects from \\(n\\) without replacement.\n\\[nCr = \\textrm{\"n choose r\"} = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro.html#some-combinations-properties",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro.html#some-combinations-properties",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Some combinations properties",
    "text": "Some combinations properties\n\n\n\n\n\n\n\nProperty\nProof\n\n\n\n\n\\[\\binom{n}{r} = \\binom{n}{n-r}\\]\n\\(\\binom{n}{r} = \\dfrac{n!}{r!(n-r)!}\\) and \\(\\binom{n}{n-r} = \\dfrac{n!}{(n-r)!(n-(n-r))!} = \\dfrac{n!}{(n-r)!r!}\\)\n\n\n\\[\\binom{n}{1} = n\\]\n\\[\\binom{n}{1} = \\dfrac{n!}{1!(n-1)!}=\\dfrac{n\\cdot(n-1)\\cdot(n-2)\\cdots1}{1! \\cdot (n-1)\\cdot(n-2)\\cdots1} = \\dfrac{n\\cdot(n-1)!}{1\\cdot (n-1)!} = \\dfrac{n}{1}=n\\]\n\n\n\\[\\binom{n}{0} = 1\\]\n\\[\\binom{n}{0} = \\dfrac{n!}{0!(n-0)!}=\\dfrac{n!}{1\\cdot n!} = 1\\]"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro.html#table-of-different-cases",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro.html#table-of-different-cases",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Table of different cases",
    "text": "Table of different cases\nSee table on pg. 277 of textbook\n\n\\(n\\) = total number of objects\n\\(r\\) = number objects needed\n\n\n\n\n\n\n\n\n\nwith replacement\nwithout replacement\n\n\n\n\norder matters\n\\[n^r\\]\n\\[n\\text{P}r = \\frac{n!}{(n-r)!}\\]\n\n\norder doesn’t matter\n\\[ \\binom{n+r-1}{r}\\]\n\\[n\\text{C}r = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro.html#enumerating-events-and-sample-space",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro.html#enumerating-events-and-sample-space",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Enumerating Events and Sample Space",
    "text": "Enumerating Events and Sample Space\n\nRecall, \\(P(A) = \\dfrac{|A|}{|S|}\\)\n\nWithin combinatorics, we can use the previous equations to help enumerate the event and sample space\nBut \\(A\\) might be a combination of enumerations\n\n\n \n\nFor example in the following example drawing 2 spades when order does not matter, we actually need to enumerate the other cards that are NOT spades. So the event is choosing 2 spades out of 13 AND choosing 0 other cards of 39 cards (13 hearts + 13 clubs + 13 diamonds).\nThus the probability is actually:\n\n\\[ P(\\text{two spades}) = \\dfrac{{13 \\choose 2}{39 \\choose 0}}{{52 \\choose 2}} \\]\n\nNote that \\(13 + 39 = 52\\) and \\(2+ 0 = 2\\). So the numerator’s \\(n\\)’s add up to the denominator’s \\(n\\) and the numerator’s \\(r\\)’s add up to the denominator’s \\(r\\)’s"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro.html#more-examples-order-matters-vs.-not-12",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro.html#more-examples-order-matters-vs.-not-12",
    "title": "Chapter 22: Introduction to Counting",
    "section": "More examples: order matters vs. not (1/2)",
    "text": "More examples: order matters vs. not (1/2)\n\n\n\n\nExample 2\n\n\nSuppose we draw 2 cards from a standard deck without replacement. What is the probability that both are spades when\n\norder matters?\norder doesn’t matter?"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities_muddy_points.html",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n1. How do pdf, CDF, and probability interact with each other?\nLet’s say we have a pdf, \\(f_X(x) = \\dfrac{1}{9}x^2\\) for \\(0 \\leq x \\leq 3\\). This is just a function. The pdf is not used on its own to report any probability. We must integrate over the pdf to find a probability.\n\nlibrary(\"ggplot2\")\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3)\n\n\n\n\n\n\n\n\nThe total area under the pdf is 1. This makes our pdf valid.\n\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 3),\n                geom = \"area\", \n                aes(fill = \"red\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 1\", color = \"black\")\n\n\n\n\n\n\n\n\nIf we only look at a proportion of the area under the pdf, then we start constructing our probabilities. For example, we can look at probability that we have a value between 0 and 1.5.\n\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 1.5),\n                geom = \"area\", \n                aes(fill = \"blue\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 0.125\", color = \"black\")\n\n\n\n\n\n\n\n\nInstead of calculating the EXACT probability for each value between 0 and 3, we can find the CDF of the pdf.\nThe CDF is: \\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;3 \\quad \\\\\n            \\dfrac{1}{27}x^3 & \\quad 0 \\leq x \\leq 3\\quad \\\\\n            1 & \\quad x&gt;3 \\quad\n        \\end{array}\n    \\right.\n\\]\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nWhen \\(x=1.5\\), we can calculate the probability using the CDF. Remember that \\(F_X(x) = P(X \\leq x)\\). So we can say \\(P(X \\leq 1.5) = F_X(1.5) = \\dfrac{1}{27}(1.5)^3\\), which equals 0.125.\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\") +\n  geom_point(aes(x=1.5, y=.125), colour=\"blue\", size=3) +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"CDF = 0.125\", color = \"black\")\n\nWarning in geom_point(aes(x = 1.5, y = 0.125), colour = \"blue\", size = 3): All aesthetics have length 1, but the data has 2 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\nWe can also calculate the probability with an integral: \\(P(X \\leq 1.5) = \\displaystyle\\int_0^{1.5} \\dfrac{1}{9}x^2 dx\\).\nWe can also find the probability that X is between two numbers. \\(P(1\\leq X \\leq 1.5) = F_X(1.5) - F_X(1)\\) or \\(P(1\\leq X \\leq 1.5) = \\displaystyle\\int_1^{1.5} \\dfrac{1}{9}x^2 dx\\).\n\n\n2. Joint vs marginal vs conditional: How are we calculating the probability?\nIf we start at a joint probability \\(f_{X,Y}(x,y)\\)…. we can look at a few probabilities:\n\nJoint probability: \\(P(a \\leq X \\leq b, c \\leq Y \\leq d)\\)\n\\[P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=c}^{y=d} f_{X,Y}(x,y) dydx\\]\nMarginal probability: \\(P(a \\leq X \\leq b)\\)\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b} f_{X}(x) dx\\]\nOR\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=-\\inf}^{y=\\inf} f_{X,Y}(x,y) dydx\\]\nConditional probability: \\(P(a \\leq X \\leq b | Y = c)\\)\n\\[P(a \\leq X \\leq b | Y=c) = \\displaystyle\\int_{x=a}^{x=b} f_{X|Y}(x|y=c) dx\\]\nYou cannot calculate \\(P(a \\leq X \\leq b | Y = c)\\) by \\(\\dfrac{P(a \\leq X \\leq b, Y=c)}{P(Y = c)}\\) because \\(P(Y = c)\\) is 0. Instead, we need to find \\(f_{X|Y}(x|y=c)\\) by \\(\\dfrac{f_{X,Y}(x,y=c)}{f_{Y}(y=c)}\\) and THEN integrate over X.\n\n\n\n3. What are we actually finding by solving the double integral. In the first example, we found the probability was 1/16 after integrating but what does 1/16 mean in relation to the random variables X and Y?\nIt means that the volume contained by \\(0\\leq X \\leq 1\\), \\(0\\leq Y \\leq 1/2\\), and their joint pdf is 1/16 of the total volume contained by \\(0\\leq X \\leq 2\\), \\(0\\leq Y \\leq 1\\), and their joint pdf. The probability for a joint pdf is now a measure of the proportion of the volume.\nThis is not be confused with a probability from marginal pdf or pdf from one RV. The probability for marginal/single RV pdfs is the proportion of the area under the pdf for a specific range of values.\n\n\n4. Here’s a 3D plot of one of our joint pdf’s\n\\[\nf_{X,Y}(x,y) = 5e^{-x-3y} \\text{ for } 0 \\leq y \\leq x/2\n\\]\n\nlibrary(plotly)\n\nx = seq(0, 5, 0.1)\ny = seq(0, max(x)/2, 0.1/2)\nfn = expand.grid(x=x,y=y)\nfn$z = ifelse(fn$y&lt;fn$x/2, 5*exp( (-1)*fn$x - 3*fn$y), NA)\n\nz = matrix(fn$z, ncol = 51, nrow = 51, byrow = T)\n\nfig &lt;- plot_ly(x = x, y=y, z=z) %&gt;% add_surface()\n\nfig"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/11_Transformations_key_info.html",
    "href": "lessons copy/11_Transformations_Joint_distributions/11_Transformations_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 02 assignments are graded!\n\nSolutions and videos are posted!\n\nFinish the discrete distributions notes\n\nThen get into joint distributions"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/11_Transformations_key_info.html#announcements",
    "href": "lessons copy/11_Transformations_Joint_distributions/11_Transformations_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 02 assignments are graded!\n\nSolutions and videos are posted!\n\nFinish the discrete distributions notes\n\nThen get into joint distributions"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/11_Transformations_key_info.html#key-dates",
    "href": "lessons copy/11_Transformations_Joint_distributions/11_Transformations_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 03 Assignment due this Thursday at 11pm\n\nI updated the homework assignment on the 18th!"
  },
  {
    "objectID": "lessons copy/08_pmfs/08_pmfs.html",
    "href": "lessons copy/08_pmfs/08_pmfs.html",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "",
    "text": "Calculate probabilities for discrete random variables\nCalculate and graph a probability mass function (pmf)\nCalculate and graph a cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons copy/08_pmfs/08_pmfs.html#learning-objectives",
    "href": "lessons copy/08_pmfs/08_pmfs.html#learning-objectives",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "",
    "text": "Calculate probabilities for discrete random variables\nCalculate and graph a probability mass function (pmf)\nCalculate and graph a cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons copy/08_pmfs/08_pmfs.html#where-are-we",
    "href": "lessons copy/08_pmfs/08_pmfs.html#where-are-we",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/08_pmfs/08_pmfs.html#what-is-a-probability-mass-function",
    "href": "lessons copy/08_pmfs/08_pmfs.html#what-is-a-probability-mass-function",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "What is a probability mass function?",
    "text": "What is a probability mass function?\n\n\nDefinition: probability distribution or probability mass function (pmf)\n\n\nThe probability distribution or probability mass function (pmf) of a discrete r.v. \\(X\\) is defined for every number \\(x\\) by \\[p_X(x) = \\mathbb{P}(X=x) = \\mathbb{P}(\\mathrm{all }\\ \\omega\\in S:X(\\omega) = x)\\]"
  },
  {
    "objectID": "lessons copy/08_pmfs/08_pmfs.html#lets-demonstrate-this-definition-with-our-coin-toss",
    "href": "lessons copy/08_pmfs/08_pmfs.html#lets-demonstrate-this-definition-with-our-coin-toss",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Let’s demonstrate this definition with our coin toss",
    "text": "Let’s demonstrate this definition with our coin toss\n\n\n\n\nExample 1\n\n\nSuppose we toss 3 coins with probability of tails \\(p\\). If \\(X\\) is the random variable counting the number of tails, what are the probabilities of each value of \\(X\\)?"
  },
  {
    "objectID": "lessons copy/08_pmfs/08_pmfs.html#remarks-on-the-pmf",
    "href": "lessons copy/08_pmfs/08_pmfs.html#remarks-on-the-pmf",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Remarks on the pmf",
    "text": "Remarks on the pmf\n\n\nProperties of pmf\n\n\nA pmf \\(p_X(x)\\) must satisfy the following properties:\n\n\\(0 \\leq p_X(x) \\leq 1\\) for all \\(x\\).\n\\(\\sum \\limits_{\\{all\\ x\\}}p_X(x)=1\\).\n\n\n\n\nSome distributions depend on parameters\n\nEach value of a parameter gives a different pmf\nIn previous example, the number of coins tossed was a parameter\n\nWe tossed 3 coins\nIf we tossed 4 coins, we’d get a different pmf!\n\nThe collection of all pmf’s for different values of the parameters is called a family of pmf’s"
  },
  {
    "objectID": "lessons copy/08_pmfs/08_pmfs.html#binomial-family-of-rvs",
    "href": "lessons copy/08_pmfs/08_pmfs.html#binomial-family-of-rvs",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Binomial family of RVs",
    "text": "Binomial family of RVs\n\n\n\n\nExample 2\n\n\nSuppose you toss \\(n\\) coins, each with probability of tails \\(p\\). If \\(X\\) is the number of tails, what is the pmf of \\(X\\)?"
  },
  {
    "objectID": "lessons copy/08_pmfs/08_pmfs.html#bernoulli-family-of-rvs",
    "href": "lessons copy/08_pmfs/08_pmfs.html#bernoulli-family-of-rvs",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Bernoulli family of RVs",
    "text": "Bernoulli family of RVs\n\n\n\n\nExample 3\n\n\nSuppose you toss 1 coin, with probability of tails \\(p\\). If \\(X\\) is the number of tails, what is the pmf of \\(X\\)?"
  },
  {
    "objectID": "lessons copy/08_pmfs/08_pmfs.html#household-size-15",
    "href": "lessons copy/08_pmfs/08_pmfs.html#household-size-15",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (1/5)",
    "text": "Household size (1/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nWhat is the sample space for household sizes?\nDefine the random variable for household sizes.\nDo the values in the table create a pmf? Why or why not?\nMake a plot of the pmf.\nWrite the cdf as a function.\nGraph the cdf of household sizes in 2019."
  },
  {
    "objectID": "lessons copy/08_pmfs/08_pmfs.html#household-size-25",
    "href": "lessons copy/08_pmfs/08_pmfs.html#household-size-25",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (2/5)",
    "text": "Household size (2/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nWhat is the sample space for household sizes?\nDefine the random variable for household sizes."
  },
  {
    "objectID": "lessons copy/08_pmfs/08_pmfs.html#household-size-35",
    "href": "lessons copy/08_pmfs/08_pmfs.html#household-size-35",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (3/5)",
    "text": "Household size (3/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nDo the values in the table create a pmf? Why or why not?\nMake a plot of the pmf"
  },
  {
    "objectID": "lessons copy/08_pmfs/08_pmfs.html#what-is-a-cumulative-distribution-function",
    "href": "lessons copy/08_pmfs/08_pmfs.html#what-is-a-cumulative-distribution-function",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "What is a cumulative distribution function?",
    "text": "What is a cumulative distribution function?\n\n\nDefinition: cumulative distribution function (CDF)\n\n\nThe cumulative distribution function (cdf) of a discrete r.v. \\(X\\) with pmf \\(p_X(x)\\), is defined for every value \\(x\\) by \\[F_X(x) = \\mathbb{P}(X \\leq x) = \\sum \\limits_{\\{all\\ y:\\ y\\leq x\\}}p_X(y)\\]"
  },
  {
    "objectID": "lessons copy/08_pmfs/08_pmfs.html#household-size-45",
    "href": "lessons copy/08_pmfs/08_pmfs.html#household-size-45",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (4/5)",
    "text": "Household size (4/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nWrite the cdf as a function."
  },
  {
    "objectID": "lessons copy/08_pmfs/08_pmfs.html#household-size-55",
    "href": "lessons copy/08_pmfs/08_pmfs.html#household-size-55",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (5/5)",
    "text": "Household size (5/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nGraph the cdf of household sizes in 2019."
  },
  {
    "objectID": "lessons copy/08_pmfs/08_pmfs.html#properties-of-discrete-cdfs",
    "href": "lessons copy/08_pmfs/08_pmfs.html#properties-of-discrete-cdfs",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Properties of discrete CDFs",
    "text": "Properties of discrete CDFs\n\n\\(F(x)\\) is increasing or flat (never decreasing)\n\\(\\min\\limits_x F(x) = 0\\)\n\\(\\max\\limits_xF(x)=1\\)\nCDF is a step function"
  },
  {
    "objectID": "lessons copy/12_Independence_Conditioning/27_Conditional_distributions.html",
    "href": "lessons copy/12_Independence_Conditioning/27_Conditional_distributions.html",
    "title": "Chapter 27: Conditional Distributions",
    "section": "",
    "text": "Calculate the conditional probability density from a joint pdf"
  },
  {
    "objectID": "lessons copy/12_Independence_Conditioning/27_Conditional_distributions.html#learning-objectives",
    "href": "lessons copy/12_Independence_Conditioning/27_Conditional_distributions.html#learning-objectives",
    "title": "Chapter 27: Conditional Distributions",
    "section": "",
    "text": "Calculate the conditional probability density from a joint pdf"
  },
  {
    "objectID": "lessons copy/12_Independence_Conditioning/27_Conditional_distributions.html#conditional-probabilities-weve-seen-before",
    "href": "lessons copy/12_Independence_Conditioning/27_Conditional_distributions.html#conditional-probabilities-weve-seen-before",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Conditional probabilities we’ve seen before",
    "text": "Conditional probabilities we’ve seen before\n\n\nWhat do we know about conditional probabilities for events and discrete RVs?    \nFor events:\n\\[P(A | B) = \\dfrac{P(A \\cap B)}{P(B)}\\]    \nFor discrete RVs: \\[p_{X|Y}(x|y) = P(X=x|Y=y) = \\dfrac{p_{X,Y}(x,y)}{p_Y(y)}\\]\n\n\n\nWhat does it mean for conditional densities of continuous RVs?\nFor continuous RVs:"
  },
  {
    "objectID": "lessons copy/12_Independence_Conditioning/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-first-try",
    "href": "lessons copy/12_Independence_Conditioning/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-first-try",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf: first try!",
    "text": "Example starting from a joint pdf: first try!\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(2&lt;X&lt;10|Y=4)\\)"
  },
  {
    "objectID": "lessons copy/12_Independence_Conditioning/27_Conditional_distributions.html#what-is-a-conditional-density",
    "href": "lessons copy/12_Independence_Conditioning/27_Conditional_distributions.html#what-is-a-conditional-density",
    "title": "Chapter 27: Conditional Distributions",
    "section": "What is a conditional density?",
    "text": "What is a conditional density?\n\n\n\n\nDefinition: Conditional density\n\n\nThe conditional density of a r.v. \\(X\\) given \\(Y=y\\), is \\[f_{X|Y}(x|y)= \\frac{f_{X,Y}(x,y)}{f_Y(y)},\\] for \\(f_Y(y)&gt; 0\\)\n\n\n\n\n\nRemarks\n\nIt follows from the definition for the conditional density \\(f_{X|Y}(x|y)\\), that \\[f_{X,Y}(x,y)= f_{X|Y}(x|y)f_Y(y).\\]\n\n     \n\nFor a fixed value of \\(Y=y\\), the conditional density \\(f_{X|Y}(x|y)\\) is an actual pdf, meaning\n\n\\(f_{X|Y}(x|y)\\geq 0\\) for all \\(x\\) and \\(y\\), and\n\\(\\displaystyle\\int_{-\\infty}^{\\infty} f_{X|Y}(x|y)dx =1\\)."
  },
  {
    "objectID": "lessons copy/12_Independence_Conditioning/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try-12",
    "href": "lessons copy/12_Independence_Conditioning/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try-12",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf: second try! (1/2)",
    "text": "Example starting from a joint pdf: second try! (1/2)\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(2&lt;X&lt;10|Y=4)\\)"
  },
  {
    "objectID": "lessons copy/12_Independence_Conditioning/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try-22",
    "href": "lessons copy/12_Independence_Conditioning/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try-22",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf: second try! (2/2)",
    "text": "Example starting from a joint pdf: second try! (2/2)"
  },
  {
    "objectID": "lessons copy/12_Independence_Conditioning/27_Conditional_distributions.html#example-starting-from-a-joint-pdf",
    "href": "lessons copy/12_Independence_Conditioning/27_Conditional_distributions.html#example-starting-from-a-joint-pdf",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf",
    "text": "Example starting from a joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(X&gt;20 |Y=5)\\)"
  },
  {
    "objectID": "lessons copy/12_Independence_Conditioning/27_Conditional_distributions.html#finding-probability-with-conditional-domain-and-pdf",
    "href": "lessons copy/12_Independence_Conditioning/27_Conditional_distributions.html#finding-probability-with-conditional-domain-and-pdf",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Finding probability with conditional domain and pdf",
    "text": "Finding probability with conditional domain and pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 2\n\n\nRandomly choose a point \\(X\\) from the interval \\([0,1]\\), and given \\(X=x\\), randomly choose a point \\(Y\\) from \\([0,x]\\). Find \\(\\mathbb{P}(0 &lt; Y &lt; \\frac14)\\)."
  },
  {
    "objectID": "lessons copy/12_Independence_Conditioning/27_Conditional_distributions.html#independence-and-conditional-distributions",
    "href": "lessons copy/12_Independence_Conditioning/27_Conditional_distributions.html#independence-and-conditional-distributions",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Independence and conditional distributions",
    "text": "Independence and conditional distributions\n    Question What is \\(f_{X|Y}(x|y)\\) if \\(X\\) and \\(Y\\) are independent?\n\\[f_{X|Y}(x|y) = \\dfrac{f_{X,Y}(x,y)}{f_y(y)} = \\dfrac{f_{X}(x)f_y(y)}{f_y(y)} = f_{X}(x)\\]\n       \n\nIf \\(f_{X|Y}(x|y)\\) does not depend on \\(y\\) (including the bounds/domain), then \\(X\\) and \\(Y\\) are independent."
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/03_Independent_Events_muddy_points.html",
    "href": "lessons copy/04_Rules_of_prob/03_Independent_Events_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "1. How do I know if two events are independent?\nMy main piece of advice for independence is to rely on the math to show it, not logic! Don’t go into a problem thinking “Logically, these two events are independent.” If the problem does not say “Assume independence,” then we need to show it mathematically.\nSame goes with the definition of independence. When we say “knowing the outcome of one provides no information about the outcome of the other,” we once again need to show this mathematically, not just using logic. We translate the previous statement to \\[P(A) = P(A|B)\\] And we need to show this mathematically!\n\n\n2. Disjoint vs. Independent Events\nHere is a pretty good video breaking down disjoint (mutually exclusive) events and independent events. It includes examples as well."
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "",
    "text": "Calculate conditional probability of an event using Bayes’ Theorem\nUtilize additional probability rules in probability calculations, specifically the Higher Order Multiplication Rule and the Law of Total Probabilities"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#learning-objectives",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#learning-objectives",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "",
    "text": "Calculate conditional probability of an event using Bayes’ Theorem\nUtilize additional probability rules in probability calculations, specifically the Higher Order Multiplication Rule and the Law of Total Probabilities"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#where-are-we",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#where-are-we",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#introduction",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#introduction",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Introduction",
    "text": "Introduction\n\nSo we learned about conditional probabilities\n\nWe learned how the occurrence of event A affects event B (B conditional on A)\n\nCan we figure out information on how the occurrence of event B affects event A?\nWe can use the conditional probability (\\(\\mathbb{P}(A|B)\\)) to get information on the flipped conditional probability (\\(\\mathbb{P}(B|A)\\))"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#bayes-rule-for-two-events",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#bayes-rule-for-two-events",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Bayes’ Rule for two events",
    "text": "Bayes’ Rule for two events\n\n\n\n\nTheorem: Bayes’ Rule (for two events)\n\n\nFor any two events \\(A\\) and \\(B\\) with nonzero probabilties,\n\\[\\mathbb{P}(A| B) =\n\\frac{\\mathbb{P}(A) \\cdot \\mathbb{P}(B|A)}\n{\\mathbb{P}(B)}\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#calculating-probability-with-higher-order-multiplication-rule",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#calculating-probability-with-higher-order-multiplication-rule",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with Higher Order Multiplication Rule",
    "text": "Calculating probability with Higher Order Multiplication Rule\n\n\n\n\nExample 1\n\n\nSuppose we draw 5 cards from a standard shuffled deck of 52 cards. What is the probability of a flush, that is all the cards are of the same suit (including straight flushes)?\n\n\n\n\n\nHigher Order Multiplication Rule\n\n\n\\[\\mathbb{P}(A_1\\cap A_2 \\cap  \\ldots \\cap A_n)=\\mathbb{P}(A_1)\\cdot\\mathbb{P}(A_2|A_1) \\cdot \\\\\n\\mathbb{P}(A_3|A_1A_2)\\ldots \\cdot\\mathbb{P}(A_n|A_1A_2\\ldots A_{n-1})\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#calculating-probability-with-law-of-total-probability",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#calculating-probability-with-law-of-total-probability",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with Law of Total Probability",
    "text": "Calculating probability with Law of Total Probability\n\n\n\n\nExample 2\n\n\nSuppose 1% of people assigned female at birth (AFAB) and 5% of people assigned male at birth (AMAB) are color-blind. Assume person born is equally likely AFAB or AMAB (not including intersex). What is the probability that a person chosen at random is color-blind?\n\n\n\n\n\nLaw of Total Probability for 2 Events\n\n\nFor events \\(A\\) and \\(B\\),\n\\[%\\left(\n\\begin{array}{ccl}\n\\mathbb{P}(B)&=&\\mathbb{P}(B \\cap A) + \\mathbb{P}(B \\cap A^C)\\\\\n           &=& \\mathbb{P}(B|A) \\cdot \\mathbb{P}(A)+ \\mathbb{P}(B | A^C)\\cdot \\mathbb{P}(A^C)\n\\end{array}\n%\\right)\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#general-law-of-total-proability",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#general-law-of-total-proability",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "General Law of Total Proability",
    "text": "General Law of Total Proability\n\n\nLaw of Total Probability (general)\n\n\nIf \\(\\{A_i\\}_{i=1}^{n} = \\{A_1, A_2, \\ldots, A_n\\}\\) form a partition of the sample space, then for event \\(B\\),\n\\[%\\left(\n\\begin{array}{ccl}\n\\mathbb{P}(B)&=& \\sum_{i=1}^{n} \\mathbb{P}(B \\cap A_i)\\\\\n           &=& \\sum_{i=1}^{n} \\mathbb{P}(B|A_i) \\cdot \\mathbb{P}(A_i)\n\\end{array}\n%\\right)\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with generalized Law of Total Probability",
    "text": "Calculating probability with generalized Law of Total Probability"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability-1",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability-1",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with generalized Law of Total Probability",
    "text": "Calculating probability with generalized Law of Total Probability\n\n\n\n\nExample 3\n\n\nIndividuals are diagnosed with a particular type of cancer that can take on three different disease forms,* \\(D_1\\), \\(D_2\\), and \\(D_3\\). It is known that amongst people diagnosed with this particular type of cancer,\n\n20% of people will eventually be diagnosed with form \\(D_1\\),\n30% with form \\(D_2\\), and\n50% with form \\(D_3\\).\n\nThe probability of requiring chemotherapy (\\(C\\)) differs among the three forms of disease:\n\n80% with \\(D_1\\),\n30% with \\(D_2\\), and\n10% with \\(D_3\\).\n\nBased solely on the preliminary test of being diagnosed with the cancer, what is the probability of requiring chemotherapy (the event C)?\n\n\n\nSkipping in class! Let me know if you would like me to post solutions to this if you work through it!"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#lets-revisit-the-color-blind-example",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#lets-revisit-the-color-blind-example",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Let’s revisit the color-blind example",
    "text": "Let’s revisit the color-blind example\n\n\n\n\nExample 4\n\n\nRecall the color-blind example (Example 2), where\n\na person is AMAB with probability 0.5,\nAMAB people are color-blind with probability 0.05, and\nall people are color-blind with probability 0.03.\n\nAssuming people are AMAB or AFAB, find the probability that a color-blind person is AMAB."
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#calculate-probability-with-both-rules",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#calculate-probability-with-both-rules",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculate probability with both rules",
    "text": "Calculate probability with both rules\n\n\n\n\nExample 5\n\n\nSuppose\n\n1% of people who are AFAB aged 40-50 years have breast cancer,\nan AFAB person with breast cancer has a 90% chance of a positive test from a mammogram, and\nan AFAB person has a 10% chance of a false-positive result from a mammogram.\n\nWhat is the probability that an AFAB person has breast cancer given that they just had a positive test?"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#bayes-rule",
    "href": "lessons copy/04_Rules_of_prob/05_Bayes_Theorem.html#bayes-rule",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Bayes’ Rule",
    "text": "Bayes’ Rule\n\n\nTheorem: Bayes’ Rule\n\n\nIf \\(\\{A_i\\}_{i=1}^{n}\\) form a partition of the sample space \\(S\\), with \\(\\mathbb{P}(A_i)&gt;0\\) for \\(i=1\\ldots n\\) and \\(\\mathbb{P}(B)&gt;0\\), then\n\\[\\mathbb{P}(A_j | B) =\n\\frac{\\mathbb{P}(B|A_j) \\cdot \\mathbb{P}(A_j)}\n{\\sum_{i=1}^{n} \\mathbb{P}(B|A_i) \\cdot \\mathbb{P}(A_i)}\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability.html",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability.html",
    "title": "Chapter 4: Conditional Probability",
    "section": "",
    "text": "Use set process to calculate probability of event of interest\nCalculate the probability of an event occurring, given that another event occurred.\nDefine keys facts for conditional probabilities using notation."
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability.html#learning-objectives",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability.html#learning-objectives",
    "title": "Chapter 4: Conditional Probability",
    "section": "",
    "text": "Use set process to calculate probability of event of interest\nCalculate the probability of an event occurring, given that another event occurred.\nDefine keys facts for conditional probabilities using notation."
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability.html#where-are-we",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability.html#where-are-we",
    "title": "Chapter 4: Conditional Probability",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability.html#general-process-for-probability-word-problems",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability.html#general-process-for-probability-word-problems",
    "title": "Chapter 4: Conditional Probability",
    "section": "General Process for Probability Word Problems",
    "text": "General Process for Probability Word Problems\n\nClearly define your events of interest\nTranslate question to probability using defined events OR Venn Diagram\nAsk yourself:\n\nAre we sampling with or without replacement?\nDoes order matter?\n\nUse axioms, properties, partitions, facts, etc. to define the end probability calculation into smaller parts\n\nIf probabilities are given to you, Venn Diagrams may help you parse out the events and probability calculations\nIf you need to find probabilities with counting, pictures or diagrams might help here\n\nWrite out a concluding statement that gives the probability context\n(For own check) Make sure the calculated probability follows the axioms. Is is between 0 and 1?"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability.html#lets-revisit-our-deck-of-cards",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability.html#lets-revisit-our-deck-of-cards",
    "title": "Chapter 4: Conditional Probability",
    "section": "Let’s revisit our deck of cards",
    "text": "Let’s revisit our deck of cards\n\n\n\n\nExample 1\n\n\nSuppose we randomly draw 2 cards from a standard deck of cards. What is the probability that we draw a spade then a heart?\n\n\nLet\n\nLet \\(A =\\) event \\(1^{st}\\) card is spades\nLet \\(B =\\) event \\(2^{nd}\\) card is heart"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability.html#conditional-probability-facts-12",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability.html#conditional-probability-facts-12",
    "title": "Chapter 4: Conditional Probability",
    "section": "Conditional Probability facts (1/2)",
    "text": "Conditional Probability facts (1/2)\n\n\n\n\nFact 1: General Multiplication Rule\n\n\n\\[\\mathbb{P}(A\\cap B)=\\mathbb{P}(A)\\cdot\\mathbb{P}(B|A)\\]\n\n\n\n\n\nFact 2: Conditional Probability Definition\n\n\n\\[\\mathbb{P}(A|B)=\\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)}\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability.html#conditional-probability-facts-22",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability.html#conditional-probability-facts-22",
    "title": "Chapter 4: Conditional Probability",
    "section": "Conditional Probability facts (2/2)",
    "text": "Conditional Probability facts (2/2)\n\n\n\n\nFact 3\n\n\nIf \\(A\\) and \\(B\\) are independent events (\\(A \\unicode{x2AEB}B\\)), then \\[\\mathbb{P}(A|B) = \\mathbb{P}(A)\\]\n\n\n\n\n\nFact 4\n\n\n\\(\\mathbb{P}(A|B)\\) is a probability, meaning that it satisfies the probability axioms. In particular, \\[\\mathbb{P}(A|B) + \\mathbb{P}(A^C|B) = 1\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability.html#monty-hall-problem",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability.html#monty-hall-problem",
    "title": "Chapter 4: Conditional Probability",
    "section": "Monty Hall Problem",
    "text": "Monty Hall Problem\nSurvivor Season 42\nWith the Wiki page on it!"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability.html#conditional-probability-with-two-dice",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability.html#conditional-probability-with-two-dice",
    "title": "Chapter 4: Conditional Probability",
    "section": "Conditional probability with two dice",
    "text": "Conditional probability with two dice\n\n\n\n\nExample 2\n\n\nTwo dice (red and blue) are rolled. If the dice do not show the same face, what is the probability that one of the dice is a 1?"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability_key_info.html",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "For office hours, we decided to do appointments!\n\nHere’s my Calendly: https://calendly.com/nickywakim/15min\nI teach on Mondays and Wednesdays so I am keeping most of my meetings to Tuesdays and Thursdays\nFor my EPI class, I have scheduled office hours on Mondays 4-5pm in VPT 627\n\nI will give priority to EPI students, but you can drop by for those as well\n\n\nI think all the dates in the schedule were correct except for next week"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability_key_info.html#announcements",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "For office hours, we decided to do appointments!\n\nHere’s my Calendly: https://calendly.com/nickywakim/15min\nI teach on Mondays and Wednesdays so I am keeping most of my meetings to Tuesdays and Thursdays\nFor my EPI class, I have scheduled office hours on Mondays 4-5pm in VPT 627\n\nI will give priority to EPI students, but you can drop by for those as well\n\n\nI think all the dates in the schedule were correct except for next week"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Conditional_Probability_key_info.html#key-dates",
    "href": "lessons copy/04_Rules_of_prob/04_Conditional_Probability_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 1 Assignment due this Thursday at 11pm"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/03_Independent_Events.html",
    "href": "lessons copy/04_Rules_of_prob/03_Independent_Events.html",
    "title": "Chapter 3: Independent Events",
    "section": "",
    "text": "Define independence of 2-3 events given probability notation\nCalculate whether two or more events are independent"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/03_Independent_Events.html#learning-objectives",
    "href": "lessons copy/04_Rules_of_prob/03_Independent_Events.html#learning-objectives",
    "title": "Chapter 3: Independent Events",
    "section": "",
    "text": "Define independence of 2-3 events given probability notation\nCalculate whether two or more events are independent"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/03_Independent_Events.html#where-are-we",
    "href": "lessons copy/04_Rules_of_prob/03_Independent_Events.html#where-are-we",
    "title": "Chapter 3: Independent Events",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/03_Independent_Events.html#independent-events",
    "href": "lessons copy/04_Rules_of_prob/03_Independent_Events.html#independent-events",
    "title": "Chapter 3: Independent Events",
    "section": "Independent Events",
    "text": "Independent Events\n\n\nDefinition: Independence\n\n\nEvents \\(A\\) and \\(B\\) are independent if \\[\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B).\\]\n\n\nNotation: For shorthand, we sometimes write \\(A \\mathrel{\\unicode{x2AEB}} B,\\) to denote that \\(A\\) and \\(B\\) are independent events.\n \n\nAlso note: \\[\\begin{aligned} \\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B) & \\implies A \\mathrel{\\unicode{x2AEB}} B \\\\\nA \\mathrel{\\unicode{x2AEB}} B & \\implies \\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B) \\end{aligned}\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/03_Independent_Events.html#example-of-two-dice",
    "href": "lessons copy/04_Rules_of_prob/03_Independent_Events.html#example-of-two-dice",
    "title": "Chapter 3: Independent Events",
    "section": "Example of two dice",
    "text": "Example of two dice\n\n\nExample 1\n\n\nTwo dice (red and blue) are rolled. Let \\(A =\\) event a total of 7 appears, and \\(B =\\) event red die is a six. Are events \\(A\\) and \\(B\\) independent?"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/03_Independent_Events.html#independence-of-3-events",
    "href": "lessons copy/04_Rules_of_prob/03_Independent_Events.html#independence-of-3-events",
    "title": "Chapter 3: Independent Events",
    "section": "Independence of 3 Events",
    "text": "Independence of 3 Events\n\n\nDefinition: Independence of 3 Events\n\n\nEvents \\(A\\), \\(B\\), and \\(C\\) are mutually independent if\n\n\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot \\mathbb{P}(B)\\)\n\\(\\mathbb{P}(A \\cap C) = \\mathbb{P}(A) \\cdot \\mathbb{P}(C)\\)\n\\(\\mathbb{P}(B \\cap C) = \\mathbb{P}(B) \\cdot \\mathbb{P}(C)\\)\n\n\\(\\mathbb{P}(A \\cap B \\cap C) = \\mathbb{P}(A) \\cdot \\mathbb{P}(B) \\cdot \\mathbb{P}(C)\\)\n\n\n\nRemark:\nOn your homework you will show that \\((1) \\not \\Rightarrow (2)\\) and \\((2) \\not \\Rightarrow (1)\\)."
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/03_Independent_Events.html#probability-at-least-one-smoker",
    "href": "lessons copy/04_Rules_of_prob/03_Independent_Events.html#probability-at-least-one-smoker",
    "title": "Chapter 3: Independent Events",
    "section": "Probability at least one smoker",
    "text": "Probability at least one smoker\n\n\n\n\nExample 2\n\n\nSuppose you take a random sample of \\(n\\) people, of which people are smokers and non-smokers independently of each other. Let\n\n\\(A_i =\\) event person \\(i\\) is a smoker, for \\(i=1, \\ldots ,n\\), and\n\\(p_i =\\) probability person \\(i\\) is a smoker, for \\(i=1, \\ldots ,n\\).\n\nFind the probability that at least one person in the random sample is a smoker."
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/03_Independent_Events.html#building-geometric-series",
    "href": "lessons copy/04_Rules_of_prob/03_Independent_Events.html#building-geometric-series",
    "title": "Chapter 3: Independent Events",
    "section": "Building geometric series",
    "text": "Building geometric series\n\n\nExample 3\n\n\n\\(A, B,\\) and \\(C\\) toss a fair coin in order. The first to throw heads wins. What are their respective chances of winning?\n\n\nLet\n\n\\(A_H\\) and \\(A_T\\) be the events player A tosses heads and tails, respectively.\nSimilarly define \\(B_H\\), \\(B_T\\), \\(C_H\\), and \\(C_T\\)."
  },
  {
    "objectID": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning_key_info.html",
    "href": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 presentations are graded! You did great!\nHW 7 assignment: I’ll grade tonight!\nAnything else?"
  },
  {
    "objectID": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning_key_info.html#announcements",
    "href": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 presentations are graded! You did great!\nHW 7 assignment: I’ll grade tonight!\nAnything else?"
  },
  {
    "objectID": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning_key_info.html#key-dates",
    "href": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: NONE due\nSunday: HW 7 solutions due (feel free to take an additional 3 days)"
  },
  {
    "objectID": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning_muddy_points.html",
    "href": "lessons copy/12_Independence_Conditioning/12_Independence_conditioning_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n2. Joint vs marginal vs conditional: How are we calculating the probability?\nIf we start at a joint probability \\(f_{X,Y}(x,y)\\)…. we can look at a few probabilities:\n\nJoint probability: \\(P(a \\leq X \\leq b, c \\leq Y \\leq d)\\)\n\\[P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=c}^{y=d} f_{X,Y}(x,y) dydx\\]\nMarginal probability: \\(P(a \\leq X \\leq b)\\)\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b} f_{X}(x) dx\\]\nOR\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=-\\inf}^{y=\\inf} f_{X,Y}(x,y) dydx\\]\nConditional probability: \\(P(a \\leq X \\leq b | Y = c)\\)\n\\[P(a \\leq X \\leq b | Y=c) = \\displaystyle\\int_{x=a}^{x=b} f_{X|Y}(x|y=c) dx\\]\nYou cannot calculate \\(P(a \\leq X \\leq b | Y = c)\\) by \\(\\dfrac{P(a \\leq X \\leq b, Y=c)}{P(Y = c)}\\) because \\(P(Y = c)\\) is 0. Instead, we need to find \\(f_{X|Y}(x|y=c)\\) by \\(\\dfrac{f_{X,Y}(x,y=c)}{f_{Y}(y=c)}\\) and THEN integrate over X.\n\n\n\n4. Here’s a 3D plot of one of our joint pdf’s\n\\[\nf_{X,Y}(x,y) = 5e^{-x-3y} \\text{ for } 0 \\leq y \\leq x/2\n\\]\n\nlibrary(plotly)\n\nx = seq(0, 5, 0.1)\ny = seq(0, max(x)/2, 0.1/2)\nfn = expand.grid(x=x,y=y)\nfn$z = ifelse(fn$y&lt;fn$x/2, 5*exp( (-1)*fn$x - 3*fn$y), NA)\n\nz = matrix(fn$z, ncol = 51, nrow = 51, byrow = T)\n\nfig &lt;- plot_ly(x = x, y=y, z=z) %&gt;% add_surface()\n\nfig"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html",
    "title": "Chapter 25: Joint densities",
    "section": "",
    "text": "Solve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#learning-objectives",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#learning-objectives",
    "title": "Chapter 25: Joint densities",
    "section": "",
    "text": "Solve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-13",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-13",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (1/3)",
    "text": "Double Integrals Mini Lesson (1/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 1\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} xy dydx\\)"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-23",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-23",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (2/3)",
    "text": "Double Integrals Mini Lesson (2/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 2\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} (x+y) dydx\\)"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-33",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-33",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (3/3)",
    "text": "Double Integrals Mini Lesson (3/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 3\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} e^{x+y} dydx\\)"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "title": "Chapter 25: Joint densities",
    "section": "How to define the joint pdf for continuous RVs?",
    "text": "How to define the joint pdf for continuous RVs?\n\n\nFor a single continuous RV \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\), \\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\]\n\nFor two continuous RVs (\\(X\\) and \\(Y\\)), we can define the joint pdf, \\(f_{X,Y}(x,y)\\), such that for all real values \\(a,b, c, d\\) with \\(a \\leq b\\) and \\(c \\leq d\\), \\[\\mathbb{P}(a \\leq X \\leq b, c \\leq Y \\leq d) = \\int_a^b \\int_c^d f_{X,Y}(x,y)dydx\\]"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#important-properties-of-the-joint-pdf",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#important-properties-of-the-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Important properties of the joint pdf",
    "text": "Important properties of the joint pdf\n\nNote that \\(f_{X,Y}(x,y)\\neq \\mathbb{P}(X=x, Y=y)\\)!!!\nIn order for \\(f_{X,Y}(x,y)\\) to be a pdf, it needs to satisfy the properties\n\n\\(f_{X,Y}(x,y)\\geq 0\\) for all \\(x,y\\)\n\\(\\displaystyle\\int_{-\\infty}^{\\infty}\\displaystyle\\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dxdy=1\\)"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "title": "Chapter 25: Joint densities",
    "section": "What is the joint cumulative distribution function?",
    "text": "What is the joint cumulative distribution function?\n\n\nDefinition: Joint cumulative distribution function (Joint CDF)\n\n\nThe joint cumulative distribution function (cdf) of continuous random variables \\(X\\) and \\(Y\\), is the function \\(F_{X,Y}(x,y)\\), such that for all real values of \\(x\\) and \\(y\\), \\[F_{X,Y}(x,y)= \\mathbb{P}(X \\leq x, Y \\leq y) = \\int_{-\\infty}^x\\int_{-\\infty}^y f_{X,Y}(s,t)dtds\\]\n\n\nRemarks:\n\nThe definition above for \\(F_{X,Y}(x,y)\\) is a function of \\(x\\) and \\(y\\).\nThe joint cdf at the point \\((a,b)\\), is \\[F_{X,Y}(a,b) = \\mathbb{P}(X \\leq a, Y \\leq b) = \\int_{-\\infty}^a\\int_{-\\infty}^b f_{X,Y}(s,t)dtds\\]"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#what-are-the-marginal-pdfs",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#what-are-the-marginal-pdfs",
    "title": "Chapter 25: Joint densities",
    "section": "What are the marginal pdf’s?",
    "text": "What are the marginal pdf’s?\n\n\nDefinition: Marginal pdf’s\n\n\nSuppose \\(X\\) and \\(Y\\) are continuous r.v.’s, with joint pdf \\(f_{X,Y}(x,y)\\). Then the marginal probability density functions are \\[\\begin{aligned}\nf_X(x)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dy\\\\\nf_Y(y)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dx\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#common-steps-for-solving-problems",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#common-steps-for-solving-problems",
    "title": "Chapter 25: Joint densities",
    "section": "Common steps for solving problems",
    "text": "Common steps for solving problems\n\nSet up the domain of the pdf with a picture\nTranslate to needed integrands\n\nFor probability: shade in the area of interest, then translate\nFor expected value: translate domain\n\nSet up integral: \\(dxdy\\) or \\(dydx\\)?\nSolve integral!"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#example-of-joint-pdf",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#example-of-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)."
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#example-of-joint-pdf-1",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#example-of-joint-pdf-1",
    "title": "Chapter 25: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "title": "Chapter 25: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(\\mathbb{P}(Y &lt; 3)\\)."
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.1\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nFind \\(\\mathbb{P}(|X-Y| &lt; 2)\\)"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "title": "Chapter 25: Joint densities",
    "section": "Finding the pdf of a transformation",
    "text": "Finding the pdf of a transformation\n\nLet \\(M\\) be a transformation of \\(X\\) and \\(Y\\)\nWhen we have a transformation of \\(X\\) and \\(Y\\), \\(M\\), we need to follow a specific process to find the pdf of \\(M\\)\n\nWe follow this process:\n\nStart with the joint pdf for \\(X\\) and \\(Y\\)\n\naka \\(f_{X,Y}(x, y)\\)\n\nTranslate the domain of \\(X\\) and \\(Y\\) to \\(M\\)\nFind the CDF of \\(M\\)\n\naka \\(F_M(m)\\) or \\(P(M \\leq m)\\)\n\nTake the derivative of the CDF of \\(M\\) to find the pdf of \\(M\\)\n\naka \\(f_M(m) = \\dfrac{d}{dm}F_M(m)\\)"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more-1",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more-1",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.2\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(M = \\max(X,Y)\\). Find the pdf for \\(M\\), that is \\(f_M(m)\\)."
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more-2",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more-2",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 3.3\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(Z = \\min(X,Y)\\). Find the pdf for \\(Z\\), that is \\(f_Z(z)\\)."
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-further",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-further",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even further!",
    "text": "Let’s complicate this even further!\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 4\n\n\nLet \\(X\\) and \\(Y\\) have joint density \\(f_{X,Y}(x,y)= \\frac85(x+y)\\) in the region \\(0 &lt; x &lt; 1,\\ \\frac12 &lt; y &lt;1\\). Find the pdf of the r.v. \\(Z\\), where \\(Z=XY\\)."
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities_key_info.html",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 6 assignment today!\n\nFeel free to turn in solutions later than 11/24 since I took so long to grade\n\nI made quite a few changes to the homeworks\n\nHW 10 is gone\nHW 9 is optional\nInstead of a HW assignment due over late November break\n\nHW 8 will include material from Week 8 and 9 and be due 12/5\n\n\nI have quite a bit of grading to catch up on!\nRealizing I never gave you mid-quarter feedback forms…\n\nLet’s chat about this and our assessment breakdown in the coming weeks\n\nAnything else?"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities_key_info.html#announcements",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 6 assignment today!\n\nFeel free to turn in solutions later than 11/24 since I took so long to grade\n\nI made quite a few changes to the homeworks\n\nHW 10 is gone\nHW 9 is optional\nInstead of a HW assignment due over late November break\n\nHW 8 will include material from Week 8 and 9 and be due 12/5\n\n\nI have quite a bit of grading to catch up on!\nRealizing I never gave you mid-quarter feedback forms…\n\nLet’s chat about this and our assessment breakdown in the coming weeks\n\nAnything else?"
  },
  {
    "objectID": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities_key_info.html#key-dates",
    "href": "lessons copy/11_Transformations_Joint_distributions/25_Joint_densities_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 7 due\nSunday: HW 6 solutions due"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro_key_info.html",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "For homework 1, you will need to the textbook! There is a link in the Syllabus and a pdf in our shared OneDrive folder.\n\nWhat’s out shared OneDrive folder?? OHSU uses OneDrive as cloud storage. Everyone should be able to access OneDrive with their OHSU email, in addition to many other Microsoft apps.  \nIn our shared folder, I put files that I cannot share publicly. You’ll see homework solutions, recordings, and textbooks in there. For the most part, I will place links on our website directly to the files. I don’t always do the best job of this, so please take a look at those files as well. \n\nDue days\n\nI don’t want anyone to feel anxious about when exactly HW 1 is due. Almost everyone has voted, and it looks like Thursdays will be the best day for homework assignments.\n\nA result of the voting and the notes about work schedules\n\nConsequently, I want to give you more than a week after assignments are due to turn in the solutions, so solutions will be due two Sundays after the assignment is due (10 days after).\nFor example, the assignment for HW 1 is due 10/10 at 11pm and the solutions for HW 1 will be due 10/20 at 11pm.\n\nHomework solution groups!!\n\nI added a link to a Microsoft form in Homework 1\nPlease specify who you would like to partner with\n\nOffice hours\n\nLet’s discuss\nLooks like Thursdays 1-2:30pm is best or 1-2pm on Tuesday"
  },
  {
    "objectID": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro_key_info.html#announcements",
    "href": "lessons copy/05_Equally_likely_outcomes/22_Counting_Intro_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "For homework 1, you will need to the textbook! There is a link in the Syllabus and a pdf in our shared OneDrive folder.\n\nWhat’s out shared OneDrive folder?? OHSU uses OneDrive as cloud storage. Everyone should be able to access OneDrive with their OHSU email, in addition to many other Microsoft apps.  \nIn our shared folder, I put files that I cannot share publicly. You’ll see homework solutions, recordings, and textbooks in there. For the most part, I will place links on our website directly to the files. I don’t always do the best job of this, so please take a look at those files as well. \n\nDue days\n\nI don’t want anyone to feel anxious about when exactly HW 1 is due. Almost everyone has voted, and it looks like Thursdays will be the best day for homework assignments.\n\nA result of the voting and the notes about work schedules\n\nConsequently, I want to give you more than a week after assignments are due to turn in the solutions, so solutions will be due two Sundays after the assignment is due (10 days after).\nFor example, the assignment for HW 1 is due 10/10 at 11pm and the solutions for HW 1 will be due 10/20 at 11pm.\n\nHomework solution groups!!\n\nI added a link to a Microsoft form in Homework 1\nPlease specify who you would like to partner with\n\nOffice hours\n\nLet’s discuss\nLooks like Thursdays 1-2:30pm is best or 1-2pm on Tuesday"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#learning-objectives",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#learning-objectives",
    "title": "Lesson 4: Rules of probability",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nDefine independence of 2-3 events given probability notation\nCalculate whether two or more events are independent"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#where-are-we",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#where-are-we",
    "title": "Lesson 4: Rules of probability",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#independent-events",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#independent-events",
    "title": "Lesson 4: Rules of probability",
    "section": "Independent Events",
    "text": "Independent Events\n\n\nDefinition: Independence\n\n\nEvents \\(A\\) and \\(B\\) are independent if \\[\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B).\\]\n\n\nNotation: For shorthand, we sometimes write \\(A \\mathrel{\\unicode{x2AEB}} B,\\) to denote that \\(A\\) and \\(B\\) are independent events.\n \n\nAlso note: \\[\\begin{aligned} \\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B) & \\implies A \\mathrel{\\unicode{x2AEB}} B \\\\\nA \\mathrel{\\unicode{x2AEB}} B & \\implies \\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B) \\end{aligned}\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#example-of-two-dice",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#example-of-two-dice",
    "title": "Lesson 4: Rules of probability",
    "section": "Example of two dice",
    "text": "Example of two dice\n\n\nExample 1\n\n\nTwo dice (red and blue) are rolled. Let \\(A =\\) event a total of 7 appears, and \\(B =\\) event red die is a six. Are events \\(A\\) and \\(B\\) independent?"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#independence-of-3-events",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#independence-of-3-events",
    "title": "Lesson 4: Rules of probability",
    "section": "Independence of 3 Events",
    "text": "Independence of 3 Events\n\n\nDefinition: Independence of 3 Events\n\n\nEvents \\(A\\), \\(B\\), and \\(C\\) are mutually independent if\n\n\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot \\mathbb{P}(B)\\)\n\\(\\mathbb{P}(A \\cap C) = \\mathbb{P}(A) \\cdot \\mathbb{P}(C)\\)\n\\(\\mathbb{P}(B \\cap C) = \\mathbb{P}(B) \\cdot \\mathbb{P}(C)\\)\n\n\\(\\mathbb{P}(A \\cap B \\cap C) = \\mathbb{P}(A) \\cdot \\mathbb{P}(B) \\cdot \\mathbb{P}(C)\\)\n\n\n\nRemark:\nOn your homework you will show that \\((1) \\not \\Rightarrow (2)\\) and \\((2) \\not \\Rightarrow (1)\\)."
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#probability-at-least-one-smoker",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#probability-at-least-one-smoker",
    "title": "Lesson 4: Rules of probability",
    "section": "Probability at least one smoker",
    "text": "Probability at least one smoker\n\n\n\n\nExample 2\n\n\nSuppose you take a random sample of \\(n\\) people, of which people are smokers and non-smokers independently of each other. Let\n\n\\(A_i =\\) event person \\(i\\) is a smoker, for \\(i=1, \\ldots ,n\\), and\n\\(p_i =\\) probability person \\(i\\) is a smoker, for \\(i=1, \\ldots ,n\\).\n\nFind the probability that at least one person in the random sample is a smoker."
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#learning-objectives-1",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#learning-objectives-1",
    "title": "Lesson 4: Rules of probability",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nUse set process to calculate probability of event of interest\nCalculate the probability of an event occurring, given that another event occurred.\nDefine keys facts for conditional probabilities using notation."
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#where-are-we-1",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#where-are-we-1",
    "title": "Lesson 4: Rules of probability",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#general-process-for-probability-word-problems",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#general-process-for-probability-word-problems",
    "title": "Lesson 4: Rules of probability",
    "section": "General Process for Probability Word Problems",
    "text": "General Process for Probability Word Problems\n\nClearly define your events of interest\nTranslate question to probability using defined events OR Venn Diagram\nAsk yourself:\n\nAre we sampling with or without replacement?\nDoes order matter?\n\nUse axioms, properties, partitions, facts, etc. to define the end probability calculation into smaller parts\n\nIf probabilities are given to you, Venn Diagrams may help you parse out the events and probability calculations\nIf you need to find probabilities with counting, pictures or diagrams might help here\n\nWrite out a concluding statement that gives the probability context\n(For own check) Make sure the calculated probability follows the axioms. Is is between 0 and 1?"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#lets-revisit-our-deck-of-cards",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#lets-revisit-our-deck-of-cards",
    "title": "Lesson 4: Rules of probability",
    "section": "Let’s revisit our deck of cards",
    "text": "Let’s revisit our deck of cards\n\n\n\n\nExample 1\n\n\nSuppose we randomly draw 2 cards from a standard deck of cards. What is the probability that we draw a spade then a heart?\n\n\nLet\n\nLet \\(A =\\) event \\(1^{st}\\) card is spades\nLet \\(B =\\) event \\(2^{nd}\\) card is heart"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#conditional-probability-facts-12",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#conditional-probability-facts-12",
    "title": "Lesson 4: Rules of probability",
    "section": "Conditional Probability facts (1/2)",
    "text": "Conditional Probability facts (1/2)\n\n\n\n\nFact 1: General Multiplication Rule\n\n\n\\[\\mathbb{P}(A\\cap B)=\\mathbb{P}(A)\\cdot\\mathbb{P}(B|A)\\]\n\n\n\n\n\nFact 2: Conditional Probability Definition\n\n\n\\[\\mathbb{P}(A|B)=\\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)}\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#conditional-probability-facts-22",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#conditional-probability-facts-22",
    "title": "Lesson 4: Rules of probability",
    "section": "Conditional Probability facts (2/2)",
    "text": "Conditional Probability facts (2/2)\n\n\n\n\nFact 3\n\n\nIf \\(A\\) and \\(B\\) are independent events (\\(A \\unicode{x2AEB}B\\)), then \\[\\mathbb{P}(A|B) = \\mathbb{P}(A)\\]\n\n\n\n\n\nFact 4\n\n\n\\(\\mathbb{P}(A|B)\\) is a probability, meaning that it satisfies the probability axioms. In particular, \\[\\mathbb{P}(A|B) + \\mathbb{P}(A^C|B) = 1\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#monty-hall-problem",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#monty-hall-problem",
    "title": "Lesson 4: Rules of probability",
    "section": "Monty Hall Problem",
    "text": "Monty Hall Problem\nSurvivor Season 42\nWith the Wiki page on it!"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#conditional-probability-with-two-dice",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#conditional-probability-with-two-dice",
    "title": "Lesson 4: Rules of probability",
    "section": "Conditional probability with two dice",
    "text": "Conditional probability with two dice\n\n\n\n\nExample 2\n\n\nTwo dice (red and blue) are rolled. If the dice do not show the same face, what is the probability that one of the dice is a 1?"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#learning-objectives-2",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#learning-objectives-2",
    "title": "Lesson 4: Rules of probability",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate conditional probability of an event using Bayes’ Theorem\nUtilize additional probability rules in probability calculations, specifically the Higher Order Multiplication Rule and the Law of Total Probabilities"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#where-are-we-2",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#where-are-we-2",
    "title": "Lesson 4: Rules of probability",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#introduction",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#introduction",
    "title": "Lesson 4: Rules of probability",
    "section": "Introduction",
    "text": "Introduction\n\nSo we learned about conditional probabilities\n\nWe learned how the occurrence of event A affects event B (B conditional on A)\n\nCan we figure out information on how the occurrence of event B affects event A?\nWe can use the conditional probability (\\(\\mathbb{P}(A|B)\\)) to get information on the flipped conditional probability (\\(\\mathbb{P}(B|A)\\))"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#bayes-rule-for-two-events",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#bayes-rule-for-two-events",
    "title": "Lesson 4: Rules of probability",
    "section": "Bayes’ Rule for two events",
    "text": "Bayes’ Rule for two events\n\n\n\n\nTheorem: Bayes’ Rule (for two events)\n\n\nFor any two events \\(A\\) and \\(B\\) with nonzero probabilties,\n\\[\\mathbb{P}(A| B) =\n\\frac{\\mathbb{P}(A) \\cdot \\mathbb{P}(B|A)}\n{\\mathbb{P}(B)}\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#calculating-probability-with-higher-order-multiplication-rule",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#calculating-probability-with-higher-order-multiplication-rule",
    "title": "Lesson 4: Rules of probability",
    "section": "Calculating probability with Higher Order Multiplication Rule",
    "text": "Calculating probability with Higher Order Multiplication Rule\n\n\n\n\nExample 1\n\n\nSuppose we draw 5 cards from a standard shuffled deck of 52 cards. What is the probability of a flush, that is all the cards are of the same suit (including straight flushes)?\n\n\n\n\n\nHigher Order Multiplication Rule\n\n\n\\[\\mathbb{P}(A_1\\cap A_2 \\cap  \\ldots \\cap A_n)=\\mathbb{P}(A_1)\\cdot\\mathbb{P}(A_2|A_1) \\cdot \\\\\n\\mathbb{P}(A_3|A_1A_2)\\ldots \\cdot\\mathbb{P}(A_n|A_1A_2\\ldots A_{n-1})\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#calculating-probability-with-law-of-total-probability",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#calculating-probability-with-law-of-total-probability",
    "title": "Lesson 4: Rules of probability",
    "section": "Calculating probability with Law of Total Probability",
    "text": "Calculating probability with Law of Total Probability\n\n\n\n\nExample 2\n\n\nSuppose 1% of people assigned female at birth (AFAB) and 5% of people assigned male at birth (AMAB) are color-blind. Assume person born is equally likely AFAB or AMAB (not including intersex). What is the probability that a person chosen at random is color-blind?\n\n\n\n\n\nLaw of Total Probability for 2 Events\n\n\nFor events \\(A\\) and \\(B\\),\n\\[%\\left(\n\\begin{array}{ccl}\n\\mathbb{P}(B)&=&\\mathbb{P}(B \\cap A) + \\mathbb{P}(B \\cap A^C)\\\\\n           &=& \\mathbb{P}(B|A) \\cdot \\mathbb{P}(A)+ \\mathbb{P}(B | A^C)\\cdot \\mathbb{P}(A^C)\n\\end{array}\n%\\right)\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#general-law-of-total-proability",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#general-law-of-total-proability",
    "title": "Lesson 4: Rules of probability",
    "section": "General Law of Total Proability",
    "text": "General Law of Total Proability\n\n\nLaw of Total Probability (general)\n\n\nIf \\(\\{A_i\\}_{i=1}^{n} = \\{A_1, A_2, \\ldots, A_n\\}\\) form a partition of the sample space, then for event \\(B\\),\n\\[%\\left(\n\\begin{array}{ccl}\n\\mathbb{P}(B)&=& \\sum_{i=1}^{n} \\mathbb{P}(B \\cap A_i)\\\\\n           &=& \\sum_{i=1}^{n} \\mathbb{P}(B|A_i) \\cdot \\mathbb{P}(A_i)\n\\end{array}\n%\\right)\\]"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#calculating-probability-with-generalized-law-of-total-probability",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#calculating-probability-with-generalized-law-of-total-probability",
    "title": "Lesson 4: Rules of probability",
    "section": "Calculating probability with generalized Law of Total Probability",
    "text": "Calculating probability with generalized Law of Total Probability"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#lets-revisit-the-color-blind-example",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#lets-revisit-the-color-blind-example",
    "title": "Lesson 4: Rules of probability",
    "section": "Let’s revisit the color-blind example",
    "text": "Let’s revisit the color-blind example\n\n\n\n\nExample 4\n\n\nRecall the color-blind example (Example 2), where\n\na person is AMAB with probability 0.5,\nAMAB people are color-blind with probability 0.05, and\nall people are color-blind with probability 0.03.\n\nAssuming people are AMAB or AFAB, find the probability that a color-blind person is AMAB."
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#calculate-probability-with-both-rules",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#calculate-probability-with-both-rules",
    "title": "Lesson 4: Rules of probability",
    "section": "Calculate probability with both rules",
    "text": "Calculate probability with both rules\n\n\n\n\nExample 5\n\n\nSuppose\n\n1% of people who are AFAB aged 40-50 years have breast cancer,\nan AFAB person with breast cancer has a 90% chance of a positive test from a mammogram, and\nan AFAB person has a 10% chance of a false-positive result from a mammogram.\n\nWhat is the probability that an AFAB person has breast cancer given that they just had a positive test?"
  },
  {
    "objectID": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#bayes-rule",
    "href": "lessons copy/04_Rules_of_prob/04_Rules_of_prob.html#bayes-rule",
    "title": "Lesson 4: Rules of probability",
    "section": "Bayes’ Rule",
    "text": "Bayes’ Rule\n\n\nTheorem: Bayes’ Rule\n\n\nIf \\(\\{A_i\\}_{i=1}^{n}\\) form a partition of the sample space \\(S\\), with \\(\\mathbb{P}(A_i)&gt;0\\) for \\(i=1\\ldots n\\) and \\(\\mathbb{P}(B)&gt;0\\), then\n\\[\\mathbb{P}(A_j | B) =\n\\frac{\\mathbb{P}(B|A_j) \\cdot \\mathbb{P}(A_j)}\n{\\sum_{i=1}^{n} \\mathbb{P}(B|A_i) \\cdot \\mathbb{P}(A_i)}\\]"
  },
  {
    "objectID": "lessons/09_pdfs/24_01_Continuous_rv_muddy_points.html",
    "href": "lessons/09_pdfs/24_01_Continuous_rv_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n1. Why we are allowed to “split” the operator d/dx into two pieces as if it were a fraction when it’s an operator\nHere is a pretty helpful StackExchange post talking about this!\n\n\n2. How to know what to use as \\(u\\) and \\(dv\\) for integration by parts\nI have two approaches to identifying \\(u\\) and \\(dv\\):\n\nTry to find a \\(u\\) that will eventually differentiate into a constant. This usually works unless you’re left with a \\(dv\\) that is hard to integrate.\n\nFor example, \\(u=x^6\\). the first derivative, \\(u'=6x^5\\), which may lead us to do another integration by parts, but eventually, at the 6th derivative, we get 720. This means, in our integration by parts, we eventually get an integral that only has \\(x\\) in the function once.\n\nIn this example, \\(x^6\\) would result in many integration by parts. I feel like we don’t typically see that many in our work.\n\nIn Example 3.5 in Calculus Review, setting \\(u=x^2\\) is a bad idea because we don’t really know how to integrate \\(dv=ln(x)\\) into \\(v\\).\n\nTry to find a \\(u\\) where \\(du\\) is the reciprocal of \\(v\\) or \\(du\\) cancels with \\(v\\).\n\nLook again at Example 3.5 in the notes! Hint: What is the derivative of \\(ln(x)\\)? And what does \\(\\dfrac{1}{x}x^3\\) equal?\n\n\n\n\n3. Looking for more practice in calculus?\nI just stumbled upon this website! Just a bunch of calculus practice problems! Might be some help."
  },
  {
    "objectID": "lessons/09_pdfs/09_pmfs.html",
    "href": "lessons/09_pdfs/09_pmfs.html",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "",
    "text": "Distinguish between discrete and continuous random variables.\nCalculate probabilities for continuous random variables.\nCalculate and graph a density (i.e., probability density function, PDF).\nCalculate and graph a CDF (i.e., a cumulative distribution function)"
  },
  {
    "objectID": "lessons/09_pdfs/09_pmfs.html#learning-objectives",
    "href": "lessons/09_pdfs/09_pmfs.html#learning-objectives",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "",
    "text": "Distinguish between discrete and continuous random variables.\nCalculate probabilities for continuous random variables.\nCalculate and graph a density (i.e., probability density function, PDF).\nCalculate and graph a CDF (i.e., a cumulative distribution function)"
  },
  {
    "objectID": "lessons/09_pdfs/09_pmfs.html#discrete-vs.-continuous-rvs",
    "href": "lessons/09_pdfs/09_pmfs.html#discrete-vs.-continuous-rvs",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Discrete vs. Continuous RVs",
    "text": "Discrete vs. Continuous RVs\n\n\n\nFor a discrete RV, the set of possible values is either finite or can be put into a countably infinite list.\n \nContinuous RVs take on values from continuous intervals, or unions of continuous intervals\n\n\n\n\n\nFigure from Introduction to Probability TB (pg. 301)"
  },
  {
    "objectID": "lessons/09_pdfs/09_pmfs.html#how-to-define-probabilities-for-continuous-rvs",
    "href": "lessons/09_pdfs/09_pmfs.html#how-to-define-probabilities-for-continuous-rvs",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "How to define probabilities for continuous RVs?",
    "text": "How to define probabilities for continuous RVs?\n\n\nDiscrete RV \\(X\\):\n\nlibrary(ggplot2)\ndata = data.frame(x = seq(0, 10, 1), y = seq(0, 0.5, 0.05))\nggplot(data, aes(x = x, y = y)) +\n  labs(x = \"x\", y = \"Probability\") +\n  theme_minimal() +\n  theme(text = element_text(size=28))\n\n\n\n\n\n\n\n\n\npmf: \\(p_X(x) = P(X=x)\\)\n\n\nContinuous RV \\(X\\):\n\nlibrary(ggplot2)\ndata = data.frame(x = seq(0, 10, 1), y = seq(0, 1, 0.1))\nggplot(data, aes(x = x, y = y)) +\n  labs(x = \"x\", y = \"Density\") +\n  theme_minimal() +\n  theme(text = element_text(size=28))\n\n\n\n\n\n\n\n\n\ndensity: \\(f_X(x)\\)\nprobability: \\(P(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\)"
  },
  {
    "objectID": "lessons/09_pdfs/09_pmfs.html#what-is-a-probability-density-function",
    "href": "lessons/09_pdfs/09_pmfs.html#what-is-a-probability-density-function",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "What is a probability density function?",
    "text": "What is a probability density function?\n\n\nProbability density function\n\n\nThe probability distribution, or probability density function (pdf), of a continuous random variable \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\),\n\\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\]\n\n\nRemarks:\n\nNote that \\(f_X(x) \\neq \\mathbb{P}(X=x)\\)!!!\nIn order for \\(f_X(x)\\) to be a pdf, it needs to satisfy the properties\n\n\\(f_X(x) \\geq 0\\) for all \\(x\\)\n\\(\\int_{-\\infty}^{\\infty} f_X(x)dx=1\\)"
  },
  {
    "objectID": "lessons/09_pdfs/09_pmfs.html#lets-demonstrate-the-pdf-with-an-example-15",
    "href": "lessons/09_pdfs/09_pmfs.html#lets-demonstrate-the-pdf-with-an-example-15",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (1/5)",
    "text": "Let’s demonstrate the PDF with an example (1/5)\n\n\n\n\nExample 1.1\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind the value of \\(a\\) so that \\(f_X(x)\\) is a pdf."
  },
  {
    "objectID": "lessons/09_pdfs/09_pmfs.html#lets-demonstrate-the-pdf-with-an-example-25",
    "href": "lessons/09_pdfs/09_pmfs.html#lets-demonstrate-the-pdf-with-an-example-25",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (2/5)",
    "text": "Let’s demonstrate the PDF with an example (2/5)\n\n\n\n\nExample 1.2\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(2.7 \\leq X \\leq 2.9)\\)."
  },
  {
    "objectID": "lessons/09_pdfs/09_pmfs.html#lets-demonstrate-the-pdf-with-an-example-35",
    "href": "lessons/09_pdfs/09_pmfs.html#lets-demonstrate-the-pdf-with-an-example-35",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (3/5)",
    "text": "Let’s demonstrate the PDF with an example (3/5)\n\n\n\n\nExample 1.3\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(2.7 &lt; X \\leq 2.9)\\)."
  },
  {
    "objectID": "lessons/09_pdfs/09_pmfs.html#lets-demonstrate-the-pdf-with-an-example-45",
    "href": "lessons/09_pdfs/09_pmfs.html#lets-demonstrate-the-pdf-with-an-example-45",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (4/5)",
    "text": "Let’s demonstrate the PDF with an example (4/5)\n\n\n\n\nExample 1.4\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(X = 2.9)\\)."
  },
  {
    "objectID": "lessons/09_pdfs/09_pmfs.html#lets-demonstrate-the-pdf-with-an-example-55",
    "href": "lessons/09_pdfs/09_pmfs.html#lets-demonstrate-the-pdf-with-an-example-55",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (5/5)",
    "text": "Let’s demonstrate the PDF with an example (5/5)\n\n\n\n\nExample 1.5\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(X \\leq 2.8)\\)."
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/22_Counting_Intro_key_info.html",
    "href": "lessons/05_Equally_likely_outcomes/22_Counting_Intro_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "For homework 1, you will need to the textbook! There is a link in the Syllabus and a pdf in our shared OneDrive folder.\n\nWhat’s out shared OneDrive folder?? OHSU uses OneDrive as cloud storage. Everyone should be able to access OneDrive with their OHSU email, in addition to many other Microsoft apps.  \nIn our shared folder, I put files that I cannot share publicly. You’ll see homework solutions, recordings, and textbooks in there. For the most part, I will place links on our website directly to the files. I don’t always do the best job of this, so please take a look at those files as well. \n\nDue days\n\nI don’t want anyone to feel anxious about when exactly HW 1 is due. Almost everyone has voted, and it looks like Thursdays will be the best day for homework assignments.\n\nA result of the voting and the notes about work schedules\n\nConsequently, I want to give you more than a week after assignments are due to turn in the solutions, so solutions will be due two Sundays after the assignment is due (10 days after).\nFor example, the assignment for HW 1 is due 10/10 at 11pm and the solutions for HW 1 will be due 10/20 at 11pm.\n\nHomework solution groups!!\n\nI added a link to a Microsoft form in Homework 1\nPlease specify who you would like to partner with\n\nOffice hours\n\nLet’s discuss\nLooks like Thursdays 1-2:30pm is best or 1-2pm on Tuesday"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/22_Counting_Intro_key_info.html#announcements",
    "href": "lessons/05_Equally_likely_outcomes/22_Counting_Intro_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "For homework 1, you will need to the textbook! There is a link in the Syllabus and a pdf in our shared OneDrive folder.\n\nWhat’s out shared OneDrive folder?? OHSU uses OneDrive as cloud storage. Everyone should be able to access OneDrive with their OHSU email, in addition to many other Microsoft apps.  \nIn our shared folder, I put files that I cannot share publicly. You’ll see homework solutions, recordings, and textbooks in there. For the most part, I will place links on our website directly to the files. I don’t always do the best job of this, so please take a look at those files as well. \n\nDue days\n\nI don’t want anyone to feel anxious about when exactly HW 1 is due. Almost everyone has voted, and it looks like Thursdays will be the best day for homework assignments.\n\nA result of the voting and the notes about work schedules\n\nConsequently, I want to give you more than a week after assignments are due to turn in the solutions, so solutions will be due two Sundays after the assignment is due (10 days after).\nFor example, the assignment for HW 1 is due 10/10 at 11pm and the solutions for HW 1 will be due 10/20 at 11pm.\n\nHomework solution groups!!\n\nI added a link to a Microsoft form in Homework 1\nPlease specify who you would like to partner with\n\nOffice hours\n\nLet’s discuss\nLooks like Thursdays 1-2:30pm is best or 1-2pm on Tuesday"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "",
    "text": "Find derivatives of continuous functions with one variable\nFind antiderivatives and integrals of functions with one variable"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#learning-objectives",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#learning-objectives",
    "title": "Calculus Review",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nFind derivatives of continuous functions with one variable\nFind antiderivatives and integrals of functions with one variable"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#where-are-we",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#where-are-we",
    "title": "Calculus Review",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function",
    "title": "Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.1\n\n\n\\(f(x) = 2\\)\n\n\n\n\nDerivative of a constant\n\n\n\\[\\dfrac{d}{dx} c = 0\\]"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-1",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-1",
    "title": "Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.2\n\n\n\\(f(x) = 2x\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-2",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-2",
    "title": "Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.3\n\n\n\\(f(x) = 2x+2\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-3",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-3",
    "title": "Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.4\n\n\n\\(f(x) = x^2\\)\n\n\n\n\nDerivative of \\(x\\) to a constant\n\n\n\\[\\dfrac{d}{dx} x^n = nx^{n-1}\\]"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-4",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-4",
    "title": "Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.5\n\n\n\\(f(x) = 3\\sqrt{x}+\\frac2x+5\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-5",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-5",
    "title": "Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.6\n\n\n\\(f(x) = e^x\\)\n\n\n\n\nDerivative of exponential function\n\n\n\\(\\dfrac{d}{dx} e^x = e^x\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-6",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-6",
    "title": "Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.7\n\n\n\\(f(x) = \\ln(x)\\)\n\n\n\n\nDerivative of logarithm\n\n\n\\(\\dfrac{d}{dx} ln(x) = \\dfrac{1}{x}\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-7",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-7",
    "title": "Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.8\n\n\n\\(f(x) = x^2 e^x\\)\n\n\n\n\nProduct Rule\n\n\n\\(\\dfrac{d}{dx} f(x)g(x) = f'(x)g(x) + f(x)g'(x)\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-8",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-8",
    "title": "Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.9\n\n\n\\(f(x) = \\dfrac{x^5}{2x+7}\\)\n\n\n\n\nQuotient Rule\n\n\n\\(\\dfrac{d}{dx} \\dfrac{f(x)}{g(x)} = \\dfrac{g(x)f'(x) - f(x)g'(x)}{\\big(g(x)\\big)^2}\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-9",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-9",
    "title": "Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.10\n\n\n\\(f(x) = e^{-2x+7}\\)\n\n\n\n\nChain Rule\n\n\n\\(\\dfrac{d}{dx} f\\big(g(x)\\big)= f'\\big(g(x)\\big)g'(x)\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-10",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-10",
    "title": "Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.11\n\n\n\\(f(x) = \\ln(x^2)\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function",
    "title": "Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.1\n\n\n\\(f(x) = 2\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-1",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-1",
    "title": "Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.2\n\n\n\\(f(x) = x\\)\n\n\n\n\nIntegration of x to a constant\n\n\n\\(\\displaystyle\\int x^n dx = \\dfrac{x^{n+1}}{n+1} + c\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-2",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-2",
    "title": "Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.3\n\n\n\\(f(x) = \\frac1x\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-3",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-3",
    "title": "Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.4\n\n\n\\(f(x) = x^{3/2}\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-4",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-4",
    "title": "Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.5\n\n\n\\(f(x) = e^x\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-5",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-5",
    "title": "Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.6\n\n\n\\(f(x) = e^{-x}\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-6",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-6",
    "title": "Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.7\n\n\n\\(f(x) = e^{-2x}\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral",
    "title": "Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.1\n\n\n\\(\\displaystyle\\int_0^1 (2x+x^5)dx\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-1",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-1",
    "title": "Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.2\n\n\n\\(\\displaystyle\\int_2^3 e^{-x}dx\\)\n\n\n\n\nU-substitution\n\n\n\\(\\displaystyle\\int f\\big(g(x)\\big) g'(x) dx = \\displaystyle\\int f(u) dx\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-2",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-2",
    "title": "Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.3\n\n\n\\(\\displaystyle\\int_2^3 x e^{x^2}dx\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-3",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-3",
    "title": "Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.4\n\n\n\\(\\displaystyle\\int_0^{\\infty} x e^{-x}dx\\)\n\n\n\n\nIntegrating by Parts\n\n\n\\(\\displaystyle\\int f(x) g'(x) dx = f(x)g(x) -\\)\n\\(\\displaystyle\\int f'(x) g(x) dx\\)\nOR\n\\(\\displaystyle\\int_a^b u dv = uv\\bigg|^b_a - \\displaystyle\\int_a^b vdu\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-4",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-4",
    "title": "Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.5\n\n\n\\(\\displaystyle\\int_1^2 x^2 \\ln(x)dx\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-5",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-5",
    "title": "Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.6\n\n\n\\(\\displaystyle\\int_1^2 \\ln(x)dx\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-6",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-6",
    "title": "Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.7\n\n\n\\(\\displaystyle\\int_1^2 x^2 e^{x}dx\\)"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "",
    "text": "Distinguish between Bernoulli, Binomial, Geometric, Hypergeometric, Discrete Uniform, Negative Binomial, and Poisson distributions when reading a story.\nIdentify the variable and the parameters in a story, and state what the variable and parameters mean.\nUse the formulas for the pmf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#learning-objectives",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#learning-objectives",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "",
    "text": "Distinguish between Bernoulli, Binomial, Geometric, Hypergeometric, Discrete Uniform, Negative Binomial, and Poisson distributions when reading a story.\nIdentify the variable and the parameters in a story, and state what the variable and parameters mean.\nUse the formulas for the pmf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#where-are-we",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#where-are-we",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-bernoulli-rvs",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-bernoulli-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Bernoulli RVs",
    "text": "Properties of Bernoulli RVs\n\nScenario: One trial, with outcome success or failure\nShorthand: \\(X \\sim \\text{Bernoulli}(p)\\)\n\n\\[\nX = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\quad \\\\\n            0 & \\quad \\mathrm{with\\ probability}\\ 1-p \\quad\n        \\end{array}\n    \\right.\n\\]\n\\[\np_X(x) = P(X=x) = p^x(1-p)^{1-x} \\text{ for } x=0,1\n\\]\n\\[\\text{E}(X) = p\\]\n\\[\\text{Var}(X) = pq = p(1-p)\\]"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#bernoulli-example-1",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#bernoulli-example-1",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bernoulli Example 1",
    "text": "Bernoulli Example 1\n\n\n\n\nExample 1\n\n\n\nWe roll a fair 6-sided die.\nWe get $1 if we roll a 5, and nothing otherwise.\nLet \\(X\\) be how much money we get.\nFind the mean and variance of \\(X\\)."
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-binomial-rvs",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-binomial-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Binomial RVs",
    "text": "Properties of Binomial RVs\n\nScenario: There are \\(n\\) independent trials, each resulting in a success or failure, with constant probability, \\(p\\), in each trial. We are counting the number of successes (or failures).\nShorthand: \\(X \\sim \\text{Binomial}(n, p)\\)\n\n\\[\nX = \\text{Number of successes of } n \\text{ independent trials}\n\\]\n\\[\np_X(x) = P(X=x) = {n \\choose x}p^x(1-p)^{n-x} \\text{ for } x=0,1,2,  ..., n\n\\]\n\\[\\text{E}(X) = np\\] \\[\\text{Var}(X) = npq = np(1-p)\\]"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#our-beloved-fair-sided-die",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#our-beloved-fair-sided-die",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Our beloved fair-sided die",
    "text": "Our beloved fair-sided die\n\n\n\n\nExample 2\n\n\n\nSuppose we roll a fair 6-sided die 50 times.\nWe get $1 every time we roll a 5, and nothing otherwise.\nLet \\(X\\) be how much money we get on the 50 rolls.\nFind the mean and variance of \\(X\\)."
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#geometric-rvs",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#geometric-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Geometric RVs",
    "text": "Geometric RVs\n\nScenario: There are repeated independent trials, each resulting in a success or failure, with constant probability of success for each trial. We are counting the number of trials until the first success.\nShorthand: \\(X \\sim \\text{Geo}(p)\\) or \\(X \\sim \\text{Geometric}(p)\\) or \\(X \\sim \\text{G}(p)\\)\n\n\n\n\n\n\n\n\n\\(X =\\) Number of trials needed for first success (count \\(x\\) includes the success)\n\\(X =\\) Number of failures before first success (count \\(x\\) does not include the success)\n\n\n\n\n\\(p _\nX( x ) = P(X=x) = (1-p)^{x-1}p\\)\nfor \\(x=1,2, 3,...\\)\n\\[F_\nX(x ) = P(X\\leq x) = 1-(1-p)^x\\]\nfor \\(x=1,2, 3,...\\)\n\\(p _X (x)= P(X=x) = (1-p)^{x}p\\)\nfor \\(x=0, 1,2,...\\)\n\\[F_X ( x\n)\n= P(X\\leq x) = 1-(1-p)^{x+1}\\]\nfor \\(x=0, 1,2,...\\)\n\n\n\\(E(X)=\\dfrac{1}{p}\\)\n\\(Var(X)= \\dfrac{1-p}{p^2}\\)\n\\(E(X)=\\dfrac{1-p}{p}\\)\n\\(Var(X) = \\dfrac{1-p}{p^2}\\)"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-14",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-14",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (1/4)",
    "text": "Bullseye (1/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the pmf for the number of throws needed to hit the bullseye?\nWhat are the mean and variance for the number of throws needed to hit the bullseye?\nFind the probability that our first bullseye:\n\nis on one of the first fifty tries\nis after the \\(50^{th}\\) try, given that it did not happen on the first 20 tries"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-24",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-24",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (2/4)",
    "text": "Bullseye (2/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the pmf for the number of throws needed to hit the bullseye?"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-34",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-34",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (3/4)",
    "text": "Bullseye (3/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat are the mean and variance for the number of throws needed to hit the bullseye?"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-44",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-44",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (4/4)",
    "text": "Bullseye (4/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nFind the probability that our first bullseye:\n\nis on one of the first fifty tries\nis after the \\(50^{th}\\) try, given that it did not happen on the first 20 tries"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#memoryless-property-for-geometric-rvs",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#memoryless-property-for-geometric-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Memoryless property for Geometric RVs",
    "text": "Memoryless property for Geometric RVs\nIf we know \\(X\\) is greater than some number (aka given \\(X &gt;j\\)), then the probability of \\(X &gt; k+j\\) is just the probability that \\(X&gt;k\\).\n \n\\(P(X &gt; k+j |X &gt; j) = P(X &gt; k)\\) \\[ P(X &gt; k+j |X &gt; j) = \\dfrac{P(X&gt;k+j \\text{ and } X&gt;j)}{P(X&gt;j)} = \\dfrac{P(X&gt;k+j)}{P(X&gt;j)} = \\dfrac{(1-p)^{k+j}}{(1-p)^{j}} = (1-p)^{k} \\]"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-negative-binomial-rvs",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-negative-binomial-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Negative Binomial RVs",
    "text": "Properties of Negative Binomial RVs\n\nScenario: There are repeated independent trials, each resulting in a success or failure, with constant probability of success for each trial. We are counting the number of trials until the \\(r^{th}\\) success.\nShorthand: \\(X \\sim \\text{NegBin}(p, r)\\) or \\(X \\sim \\text{NB}(p, r)\\)\nNegative binomial is sum of \\(r\\) geometric distributions\n\n\\[\nX = \\text{Number of independent trials until } r^{th} \\text{ success}\n\\]\n\\[ p_X(x) = P(X=x) = {x-1 \\choose r-1}(1-p)^{x-r}p^r \\text{ for } x = r, r+1, r+2, ...\\]\n\\[ E(X) = \\dfrac{r}{p}\\]\n\\[Var(X) = \\dfrac{rq}{p^2} = \\dfrac{r(1-p)}{p^2}\\]"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#hitting-more-than-1-bullseye",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#hitting-more-than-1-bullseye",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Hitting more than 1 bullseye",
    "text": "Hitting more than 1 bullseye\n\n\n\n\nExample 1\n\n\nConsider again the bullseye example, where we throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the expected value and variance of the number of throws needed to hit 5 bullseyes?"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#hitting-more-than-1-bullseye-1",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#hitting-more-than-1-bullseye-1",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Hitting more than 1 bullseye",
    "text": "Hitting more than 1 bullseye\n\n\n\n\nExample 1\n\n\nConsider again the bullseye example, where we throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the probability that the \\(5^{th}\\) bullseye is on the \\(20^{th}\\) throw?"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-poisson-rvs",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-poisson-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Poisson RVs",
    "text": "Properties of Poisson RVs\n\nScenario: We are counting the number of successes in a fixed time period, which has a constant rate of successes\nShorthand: \\(X \\sim \\text{Poisson}(\\lambda)\\) or \\(X \\sim \\text{Pois}(\\lambda)\\)\n\n\\[\nX = \\text{Number of successes in a given period}\n\\]\n\\[ p_X(x) = P(X=x) = \\dfrac{e^{-\\lambda}\\lambda^x}{x!} \\text{ for } x = 0, 1, 2,3, ...\\]\n\\[ \\text{E}(X) = \\lambda\\]\n\\[\\text{Var}(X) = \\lambda\\]"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#distinguishing-between-binomial-and-poisson-rvs",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#distinguishing-between-binomial-and-poisson-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Distinguishing between Binomial and Poisson RVs",
    "text": "Distinguishing between Binomial and Poisson RVs\n\nRecall that if \\(X\\sim \\text{Binomial}(n,p)\\), then\n\n\\(X\\) models the number of successes …\nin \\(n\\) independent (Bernoulli) trials …\nthat each have the same probability of success \\(p\\).\n\nPoisson r.v.’s are similar,\n\nexcept that instead of having \\(n\\) discrete independent trials,\nthere is a fixed time period (or space) during which the successes happen"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#examples-of-poisson-rvs",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#examples-of-poisson-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Examples of Poisson RVs",
    "text": "Examples of Poisson RVs\n\nNumber of visitors to an emergency room in an hour during a weekend night\nNumber of study participants enrolled in a study per week\nNumber of pedestrians walking through a square mile\nAny more?"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#emergency-room-visitors",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#emergency-room-visitors",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Emergency Room Visitors",
    "text": "Emergency Room Visitors\n\n\n\n\nExample 1\n\n\nSuppose an emergency room has an average of 50 visitors per day. Find the following probabilities.\n\nProbability of 30 visitors in a day.\nProbability of 8 visitors in an hour.\nProbability of at least 8 visitors in an hour."
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#combining-independent-poisson-distributions",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#combining-independent-poisson-distributions",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Combining independent Poisson distributions",
    "text": "Combining independent Poisson distributions\n\n\nTheorem 1\n\n\nIf \\(X\\sim Pois(\\lambda_1)\\) and \\(Y\\sim Pois(\\lambda_2)\\) are independent of each other, then \\(Z=X+Y\\sim Pois(\\lambda_1 + \\lambda_2)\\)."
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#two-emergency-rooms",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#two-emergency-rooms",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Two emergency rooms",
    "text": "Two emergency rooms\n\n\n\n\nExample 2\n\n\nSuppose emergency room 1 has an average of 50 visitors per day, and emergency room 2 has an average of 70 visitors per day, independently of each other. What is the probability distribution to model of the total number of visitors to both?"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#poisson-approximation-of-the-binomial",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#poisson-approximation-of-the-binomial",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Poisson Approximation of the Binomial",
    "text": "Poisson Approximation of the Binomial\nBoth Poisson and Binomial r.v.’s are counting the number of successes\n\nIf for a Binomial r.v.\n\nthe number of trials \\(n\\) is very large, and\nthe probability of success \\(p\\) is close to 0 or 1,\n\nThen the Poisson distribution can be used to approximate Binomial probabilities\n\nand we use \\(\\lambda = np\\)\n\nRule of thumb: We can use the Poisson approximation when \\(\\dfrac{1}{10} \\leq np(1-p) \\leq 10\\)"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#medical-lab-errors",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#medical-lab-errors",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Medical lab errors",
    "text": "Medical lab errors\n\n\n\n\nExample 3\n\n\nSuppose that in the long run, errors in a medical testing lab are made 0.1% of the time. Find the probability that fewer than 4 mistakes are made in the next 2,000 tests.\n\nFind the probability using the Binomial distribution.\nApproximate the probability in part (1) using the Poisson distribution.\n\n\n\n\nTo do for extra practice - will also see a similar problem in BSTA 511"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#hypergeometric-rvs",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#hypergeometric-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Hypergeometric RVs",
    "text": "Hypergeometric RVs\n\nScenario: There are a fixed number of successes and failures (which are known in advance), from which we make \\(n\\) draws without replacement. We are counting the number of successes from the \\(n\\) trials.\n\nThere is a finite population of \\(N\\) items\nEach item in the population is either a success or a failure, and there are \\(M\\) successes total.\nWe randomly select (sample) \\(n\\) items from the population without replacement\n\nShorthand: \\(X \\sim \\text{Hypergeo}(M, N, n)\\)\n\n\n\n\\[\nX = \\text{Number of successes in } n \\text{ draws}\n\\]\n\\[\np_X(x) = P(X=x) = \\dfrac{{M \\choose x}{N-M \\choose n-x}}{{N \\choose n}}\n\\] \\[\\text{ for } x \\text{ integer-valued } \\\\ \\max(0, n-(N-M)) \\leq x \\leq \\min(n, M)\\]\n\n\\[\\text{E}(X) =\\dfrac{nM}{N}\\]\n\\[\\text{Var}(X) = n \\dfrac{M}{N} \\bigg(1- \\dfrac{M}{N} \\bigg)\\bigg(\\dfrac{N-n}{N-1} \\bigg)\\]"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#wolf-population",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#wolf-population",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Wolf population",
    "text": "Wolf population\n\n\n\n\nExample 4\n\n\nA wildlife biologist is using mark-recapture to research a wolf population. Suppose a specific study region is known to have 24 wolves, of which 11 have already been tagged. If 5 wolves are randomly captured, what is the probability that 3 of them have already been tagged?"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#binomial-approximation-of-the-hypergeometric-rv",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#binomial-approximation-of-the-hypergeometric-rv",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Binomial approximation of the hypergeometric RV",
    "text": "Binomial approximation of the hypergeometric RV\nSuppose a hypergeometric RV \\(X\\) has the following properties:\n\nthe population size \\(N\\) is really big,\nthe number of successes \\(M\\) in the population is relatively large,\n\n\\(\\frac{M}{N}\\) shouldn’t be close to 0 or 1\n\nand the number of items \\(n\\) selected is small\nRule of thumb: \\(\\dfrac{n}{N}&lt;0.05\\) or \\(N&gt;20n\\)\n\nThen, in this case, making \\(n\\) draws from the population doesn’t change the probability of success much, and the hypergeometric RV. can be approximated by a binomial RV"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#wolf-population-revisited",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#wolf-population-revisited",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Wolf population revisited",
    "text": "Wolf population revisited\n\n\n\n\nExample 5\n\n\nSuppose a specific study region is known to have 2400 wolves, of which 1100 have already been tagged.\n\nIf 50 wolves are randomly captured, what is the probability that 20 of them have already been tagged?\nApproximate the probability in part (1) using the binomial distribution."
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#discrete-uniform-rvs",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#discrete-uniform-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Discrete Uniform RVs",
    "text": "Discrete Uniform RVs\n\nScenario: There are \\(N\\) possible outcomes, which are all equally likely.\nShorthand: \\(X \\sim \\text{Uniform}(N)\\)\n\n\\[\nX = \\text{Outcome of interest, with } x=1, 2, ..., N\n\\]\n\\[\np_X(x) = P(X=x) = \\dfrac{1}{N} \\text{ for } x=1, 2, 3, ..., N\n\\]\n\\[\\text{E}(X) =\\dfrac{N+1}{2}\\]\n\\[\\text{Var}(X) = \\dfrac{N^2 -1}{12}\\]"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#what-discrete-uniform-rvs-have-we-seen-already",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs.html#what-discrete-uniform-rvs-have-we-seen-already",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "What discrete uniform RVs have we seen already?",
    "text": "What discrete uniform RVs have we seen already?\n\n\n\n\nExample 6\n\n\nExamples of discrete uniform RVs"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs_key_info.html",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 01 assignments are graded!\n\nSolutions and videos are posted!"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs_key_info.html#announcements",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 01 assignments are graded!\n\nSolutions and videos are posted!"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs_key_info.html#key-dates",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 02 Assignment due this Thursday at 11pm\nNo HW 01 Solutions"
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs_key_info.html",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 videos should be in!\n\nSome presentations today\n\nNeed to grade HW 4 solutions and HW 5 assignment STILL\n\nHappy to be flexible on the HW 5 solutions deadline\n\nAnything else?"
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs_key_info.html#announcements",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 videos should be in!\n\nSome presentations today\n\nNeed to grade HW 4 solutions and HW 5 assignment STILL\n\nHappy to be flexible on the HW 5 solutions deadline\n\nAnything else?"
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs_key_info.html#key-dates",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 6 due\nSunday: HW 5 solutions due\n\nFLEXIBLE"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities_muddy_points.html",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n1. How do pdf, CDF, and probability interact with each other?\nLet’s say we have a pdf, \\(f_X(x) = \\dfrac{1}{9}x^2\\) for \\(0 \\leq x \\leq 3\\). This is just a function. The pdf is not used on its own to report any probability. We must integrate over the pdf to find a probability.\n\nlibrary(\"ggplot2\")\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3)\n\n\n\n\n\n\n\n\nThe total area under the pdf is 1. This makes our pdf valid.\n\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 3),\n                geom = \"area\", \n                aes(fill = \"red\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 1\", color = \"black\")\n\n\n\n\n\n\n\n\nIf we only look at a proportion of the area under the pdf, then we start constructing our probabilities. For example, we can look at probability that we have a value between 0 and 1.5.\n\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 1.5),\n                geom = \"area\", \n                aes(fill = \"blue\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 0.125\", color = \"black\")\n\n\n\n\n\n\n\n\nInstead of calculating the EXACT probability for each value between 0 and 3, we can find the CDF of the pdf.\nThe CDF is: \\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;3 \\quad \\\\\n            \\dfrac{1}{27}x^3 & \\quad 0 \\leq x \\leq 3\\quad \\\\\n            1 & \\quad x&gt;3 \\quad\n        \\end{array}\n    \\right.\n\\]\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nWhen \\(x=1.5\\), we can calculate the probability using the CDF. Remember that \\(F_X(x) = P(X \\leq x)\\). So we can say \\(P(X \\leq 1.5) = F_X(1.5) = \\dfrac{1}{27}(1.5)^3\\), which equals 0.125.\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\") +\n  geom_point(aes(x=1.5, y=.125), colour=\"blue\", size=3) +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"CDF = 0.125\", color = \"black\")\n\nWarning in geom_point(aes(x = 1.5, y = 0.125), colour = \"blue\", size = 3): All aesthetics have length 1, but the data has 2 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\nWe can also calculate the probability with an integral: \\(P(X \\leq 1.5) = \\displaystyle\\int_0^{1.5} \\dfrac{1}{9}x^2 dx\\).\nWe can also find the probability that X is between two numbers. \\(P(1\\leq X \\leq 1.5) = F_X(1.5) - F_X(1)\\) or \\(P(1\\leq X \\leq 1.5) = \\displaystyle\\int_1^{1.5} \\dfrac{1}{9}x^2 dx\\).\n\n\n2. Joint vs marginal vs conditional: How are we calculating the probability?\nIf we start at a joint probability \\(f_{X,Y}(x,y)\\)…. we can look at a few probabilities:\n\nJoint probability: \\(P(a \\leq X \\leq b, c \\leq Y \\leq d)\\)\n\\[P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=c}^{y=d} f_{X,Y}(x,y) dydx\\]\nMarginal probability: \\(P(a \\leq X \\leq b)\\)\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b} f_{X}(x) dx\\]\nOR\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=-\\inf}^{y=\\inf} f_{X,Y}(x,y) dydx\\]\nConditional probability: \\(P(a \\leq X \\leq b | Y = c)\\)\n\\[P(a \\leq X \\leq b | Y=c) = \\displaystyle\\int_{x=a}^{x=b} f_{X|Y}(x|y=c) dx\\]\nYou cannot calculate \\(P(a \\leq X \\leq b | Y = c)\\) by \\(\\dfrac{P(a \\leq X \\leq b, Y=c)}{P(Y = c)}\\) because \\(P(Y = c)\\) is 0. Instead, we need to find \\(f_{X|Y}(x|y=c)\\) by \\(\\dfrac{f_{X,Y}(x,y=c)}{f_{Y}(y=c)}\\) and THEN integrate over X.\n\n\n\n3. What are we actually finding by solving the double integral. In the first example, we found the probability was 1/16 after integrating but what does 1/16 mean in relation to the random variables X and Y?\nIt means that the volume contained by \\(0\\leq X \\leq 1\\), \\(0\\leq Y \\leq 1/2\\), and their joint pdf is 1/16 of the total volume contained by \\(0\\leq X \\leq 2\\), \\(0\\leq Y \\leq 1\\), and their joint pdf. The probability for a joint pdf is now a measure of the proportion of the volume.\nThis is not be confused with a probability from marginal pdf or pdf from one RV. The probability for marginal/single RV pdfs is the proportion of the area under the pdf for a specific range of values.\n\n\n4. Here’s a 3D plot of one of our joint pdf’s\n\\[\nf_{X,Y}(x,y) = 5e^{-x-3y} \\text{ for } 0 \\leq y \\leq x/2\n\\]\n\nlibrary(plotly)\n\nx = seq(0, 5, 0.1)\ny = seq(0, max(x)/2, 0.1/2)\nfn = expand.grid(x=x,y=y)\nfn$z = ifelse(fn$y&lt;fn$x/2, 5*exp( (-1)*fn$x - 3*fn$y), NA)\n\nz = matrix(fn$z, ncol = 51, nrow = 51, byrow = T)\n\nfig &lt;- plot_ly(x = x, y=y, z=z) %&gt;% add_surface()\n\nfig"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/11_Transformations_key_info.html",
    "href": "lessons/11_Transformations_Joint_distributions/11_Transformations_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 02 assignments are graded!\n\nSolutions and videos are posted!\n\nFinish the discrete distributions notes\n\nThen get into joint distributions"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/11_Transformations_key_info.html#announcements",
    "href": "lessons/11_Transformations_Joint_distributions/11_Transformations_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 02 assignments are graded!\n\nSolutions and videos are posted!\n\nFinish the discrete distributions notes\n\nThen get into joint distributions"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/11_Transformations_key_info.html#key-dates",
    "href": "lessons/11_Transformations_Joint_distributions/11_Transformations_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 03 Assignment due this Thursday at 11pm\n\nI updated the homework assignment on the 18th!"
  },
  {
    "objectID": "lessons/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance_muddy_points.html",
    "href": "lessons/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n2. How do we set the bounds on a double integral?\nWhen the domain of the RVs are not dependent on each other, then we use the bounds as is. In example 2 of Chapter 26 notes, we have the joint pdf \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for\\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\). If we wanted to calculate something like \\(E(X)\\), then we could use the bounds as they are. Below is the domain for \\(x\\) and \\(y\\):\n\n\n\n\n\nHere is the integral for the expected value where we integrate over the whole domain of \\(x\\) and \\(y\\):\n\\[ E(X) = \\displaystyle\\int_0^1 \\displaystyle\\int_0^1 x (18 x^2 y^5 )dy dx \\]If we want to find the probability \\(P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75)\\), then we can look at the specific values of the probability:\n\n\n\n\n\nNote the blue lines above indicate how we integrate over \\(y\\) first from 0.5 to 0.75 and the green lines indicate how integrate over \\(x\\) first from 0.25 to 0.5. It seems like we’ve integrated over an area that isn’t within our specified probability. However, the integrated area is ONLY the overlap of the \\(x\\) and \\(y\\) bounds for the probability.\n\\[P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.25}^{0.5} \\displaystyle\\int_{0.5}^{0.75} 18 x^2 y^5 dy dx\\]\nLet’s use the same pdf, but now the domain of the two RVs is dependent on one another. We have the joint pdf \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for\\(0 \\leq x \\leq y\\leq1\\)\nIf we wanted to calculate something like \\(E(X)\\), then we need to account for fact that \\(x\\) must be less than of equal to \\(y\\). We can look back at the domain for this:\n\n\n\n\n\nNote the blue lines above still indicate how we integrate over \\(y\\) first from \\(x\\) to 1, and the green lines indicate how integrate over \\(x\\) first from 0 to 1. Once again, it seems like we’ve integrated over an area that isn’t within the domain. However, the integrated area is ONLY the overlap of the \\(x\\) and \\(y\\) bounds. Thus, once we’ve restricted \\(y\\) to the area between \\(x\\) and 1, we no longer need to restrict \\(x\\) to the are of 0 to \\(y\\).\n\\[ E(X) = \\displaystyle\\int_0^1 \\displaystyle\\int_x^1 x (18 x^2 y^5 )dy dx \\] If we want to find the probability \\(P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75)\\), then we should look back at our domain. For now, we are focusing on the orange area:\n\n\n\n\n\nBecause the orange area is totally within our domain, we can leave our integral our bounds as the exact values we specified:\n\\[P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.25}^{0.5} \\displaystyle\\int_{0.5}^{0.75} 18 x^2 y^5 dy dx\\]\nHowever, if we want the probability \\(P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75)\\), we would focus on the pink area above. We would limit one of our integrals to the \\(y=x\\) equation:\n\\[P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.5}^{0.75} \\displaystyle\\int_{x}^{0.75} 18 x^2 y^5 dy dx\\]\nOR\n\\[P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.5}^{0.75} \\displaystyle\\int_{0.5}^{y} 18 x^2 y^5 dx dy\\]\nThe key to these probabilities is that the bounds with the other variable is on the inside integral! Otherwise we end up with a answer that includes a RV."
  },
  {
    "objectID": "lessons/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html",
    "href": "lessons/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "",
    "text": "Calculate the mean (expected value) of sums of discrete random variables"
  },
  {
    "objectID": "lessons/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#learning-objectives",
    "href": "lessons/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#learning-objectives",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "",
    "text": "Calculate the mean (expected value) of sums of discrete random variables"
  },
  {
    "objectID": "lessons/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#where-are-we",
    "href": "lessons/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#where-are-we",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#revisiting-our-two-card-draw",
    "href": "lessons/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#revisiting-our-two-card-draw",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Revisiting our two card draw",
    "text": "Revisiting our two card draw\n\n\n\n\nExample 1\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw. Find \\(\\mathbb{E}[X]\\).\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "lessons/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#what-if-we-draw-a-lot-of-cards",
    "href": "lessons/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#what-if-we-draw-a-lot-of-cards",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "What if we draw A LOT of cards?",
    "text": "What if we draw A LOT of cards?\n\n\n\n\nExample 2\n\n\nWhat is the expected number of hearts in Example 1 if you draw 200 cards?\n\n\n\n\nRecall Binomial RV with \\(n=200\\):\n\\[p_X(x) = {200 \\choose x}p^x(1-p)^{200-x}\\] \\[\\text{  for } x = 0, 1, 2, ..., 200\\]"
  },
  {
    "objectID": "lessons/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#sum-of-discrete-rvs",
    "href": "lessons/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#sum-of-discrete-rvs",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Sum of discrete RVs",
    "text": "Sum of discrete RVs\n\n\nTheorem 11.1: Sum of discrete RVs\n\n\nFor discrete r.v.’s \\(X_i\\) and constants \\(a_i\\), \\(i=1,2,\\dots, n\\), \\[\\mathbb{E}\\Bigg[\\sum_{i=1}^n a_iX_i\\Bigg] = \\sum_{i=1}^n a_i\\mathbb{E}[X_i] .\\] Remark: The theorem holds for infinitely r.v.’s \\(X_i\\) as well.\n\n\n\nFor two RVs, \\(X\\) and \\(Y\\):\n\nWe can say \\(E[X+Y] = E[X] + E[Y]\\)\n… and constant numbers \\(a\\) and \\(b\\), we can also say \\(E[aX+bY] = aE[X] + bE[Y]\\)\nWe can also also say \\(E[X-Y] = E[X] - E[Y]\\), since \\(b=-1\\)"
  },
  {
    "objectID": "lessons/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#corollaries-from-thm-11.1",
    "href": "lessons/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#corollaries-from-thm-11.1",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Corollaries from Thm 11.1",
    "text": "Corollaries from Thm 11.1\n\n\n\n\nCorollary 11.1.1\n\n\nFor a discrete r.v. \\(X\\), and constants \\(a\\) and \\(b\\), \\[\\mathbb{E}[aX+b] = a\\mathbb{E}[X] + b.\\]\n\n\n\n\n\nCorollary 11.1.2\n\n\nIf \\(X_i\\), \\(i=1,2,\\dots, n\\), are identically distributed r.v.’s, then \\[\\mathbb{E}\\bigg[\\sum_{i=1}^n X_i\\bigg] = n\\mathbb{E}[X_1] .\\]"
  },
  {
    "objectID": "lessons/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#cost-of-hotel-rooms",
    "href": "lessons/14_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#cost-of-hotel-rooms",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Cost of hotel rooms",
    "text": "Cost of hotel rooms\n\n\n\n\nExample 4\n\n\nA tour group is planning a visit to the city of Minneapolis and needs to book 30 hotel rooms. The average price of a room is $200. In addition, there is a 10% tourism tax for each room. What is the expected cost for the 30 hotel rooms?"
  },
  {
    "objectID": "lessons/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html",
    "href": "lessons/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "",
    "text": "Calculate probability of a sample mean using a Normally distributed population"
  },
  {
    "objectID": "lessons/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#learning-objectives",
    "href": "lessons/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#learning-objectives",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "",
    "text": "Calculate probability of a sample mean using a Normally distributed population"
  },
  {
    "objectID": "lessons/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#sum-of-normal-rvs",
    "href": "lessons/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#sum-of-normal-rvs",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "Sum of Normal RVs",
    "text": "Sum of Normal RVs\n\n\nTheorem 1\n\n\nLet \\(X\\sim N(\\mu, \\sigma^2)\\), and let \\(Y=aX+b\\), where \\(a\\) and \\(b\\) are constants. Then \\[Y \\sim N(a\\mu+b, a^2\\sigma^2)\\]\n\n\n\n\nTheorem 2\n\n\nLet \\(X_i \\sim N(\\mu_i, \\sigma_i^2)\\) be independent normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\sim N\\Bigg(\\sum_{i=1}^n \\mu_i , \\sum_{i=1}^n \\sigma^2_i\\Bigg)\\]"
  },
  {
    "objectID": "lessons/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#special-cases",
    "href": "lessons/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#special-cases",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "Special Cases",
    "text": "Special Cases\n\nLet \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\sim N\\big(n\\mu, n \\sigma^2\\big)\\]\nLet \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\bar{X}=\\frac{\\sum_{i=1}^n X_i}{n} \\sim N\\big(\\mu, \\sigma^2 / n\\big)\\]\nLet \\(X\\sim N(\\mu_X,\\sigma_X^2)\\), and \\(Y\\sim N(\\mu_Y,\\sigma_Y^2)\\). Then \\[X-Y \\sim N\\big(\\mu_X - \\mu_Y, \\sigma^2_X + \\sigma^2_Y \\big)\\]"
  },
  {
    "objectID": "lessons/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#detecting-and-solving-sums-of-normal-rvs-from-a-word-problem",
    "href": "lessons/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#detecting-and-solving-sums-of-normal-rvs-from-a-word-problem",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "Detecting and solving sums of Normal RVs from a word problem",
    "text": "Detecting and solving sums of Normal RVs from a word problem\n\n\n\n\nExample 1\n\n\nGlaucoma is an eye disease that is manifested by high intraocular pressure (IOP). The distribution of IOP in the general population is approximately normal with mean 16 mmHg and standard deviation 3 mmHg.\n\nSuppose a patient has 40 IOP readings. What is the probability that their average reading is greater than 20.32 mmHg, assuming their eyes are healthy?\nRepeat the previous question for a patient with 10 IOP readings."
  },
  {
    "objectID": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html",
    "href": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "LAST CLASS!!!!\nHomework 7and 6 solutions are graded\nHW 7 meetings are up on Calendly\n\nSee my announcement from Sakai\n\nI will be finalizing and posting HW 9 tomorrow\n\nOptional!\n\nPlease do your course evals!!\n\nEspecially in a small class\n\nFriday 12/13 is the absolute deadline for turning in materials if you are completing the course! _ Check Sakai that I have all your HW grades in!\nAnything else?"
  },
  {
    "objectID": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html#announcements",
    "href": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "LAST CLASS!!!!\nHomework 7and 6 solutions are graded\nHW 7 meetings are up on Calendly\n\nSee my announcement from Sakai\n\nI will be finalizing and posting HW 9 tomorrow\n\nOptional!\n\nPlease do your course evals!!\n\nEspecially in a small class\n\nFriday 12/13 is the absolute deadline for turning in materials if you are completing the course! _ Check Sakai that I have all your HW grades in!\nAnything else?"
  },
  {
    "objectID": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html#key-dates",
    "href": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday (12/5): HW 8 assignment due\nSunday (12/8): HW 7 presentations due at 11pm\n\nI can be pretty flexible until 12/13\n\nThursday (12/12): Optional HW 9 assignment due\nFriday (12/13): HW 8 solutions due"
  },
  {
    "objectID": "lessons/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html",
    "href": "lessons/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "",
    "text": "Calculate probability of a sample mean using a population mean and variance with unknown distribution\nUse the Central Limit Theorem to construct the Normal approximation of the Binomial and Poisson distributions"
  },
  {
    "objectID": "lessons/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#learning-objectives",
    "href": "lessons/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#learning-objectives",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "",
    "text": "Calculate probability of a sample mean using a population mean and variance with unknown distribution\nUse the Central Limit Theorem to construct the Normal approximation of the Binomial and Poisson distributions"
  },
  {
    "objectID": "lessons/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#the-central-limit-theorem",
    "href": "lessons/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#the-central-limit-theorem",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\n\n\nTheorem 1: Central Limit Theorem (CLT)\n\n\nLet \\(X_i\\) be iid rv’s with common mean \\(\\mu\\) and variance \\(\\sigma^2\\), for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\rightarrow \\text{N}(n\\mu, n\\sigma^2)\\]"
  },
  {
    "objectID": "lessons/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#extension-of-the-clt",
    "href": "lessons/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#extension-of-the-clt",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "Extension of the CLT",
    "text": "Extension of the CLT\n\n\nCorollary 1\n\n\nLet \\(X_i\\) be iid rv’s with common mean \\(\\mu\\) and variance \\(\\sigma^2\\), for \\(i=1,2,\\ldots,n\\). Then \\[\\overline{X}=\\frac{\\sum_{i=1}^n X_i}{n}  \\rightarrow \\text{N}\\Bigg(\\mu, \\dfrac{\\sigma^2}{n}\\Bigg)\\]"
  },
  {
    "objectID": "lessons/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#example-of-corollary-in-use",
    "href": "lessons/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#example-of-corollary-in-use",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "Example of Corollary in use",
    "text": "Example of Corollary in use\n\n\n\n\nExample 1\n\n\nAccording to a large US study, the mean resting heart rate of adult women is about 74 beats per minutes (bpm), with standard deviation 13 bpm (NHANES 2003-2004).\n\nFind the probability that the average resting heart rate for a random sample of 36 adult women is more than 3 bpm away from the mean.\nRepeat the previous question for a single adult woman."
  },
  {
    "objectID": "lessons/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#example-of-clt-for-exponential-distribution",
    "href": "lessons/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#example-of-clt-for-exponential-distribution",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "Example of CLT for exponential distribution",
    "text": "Example of CLT for exponential distribution\n\n\n\n\nExample 2\n\n\nLet \\(X_i \\sim Exp(\\lambda)\\) be iid RVs for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\rightarrow\\]"
  },
  {
    "objectID": "lessons/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#clt-for-discrete-rvs",
    "href": "lessons/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#clt-for-discrete-rvs",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "CLT for Discrete RVs",
    "text": "CLT for Discrete RVs\n\n\n\nBinomial rv’s: Let \\(X \\sim Bin(n,p)\\)\n\n\\(X = \\displaystyle\\sum_{i=1}^n X_i\\), where \\(X_i\\) are iid \\(\\text{Bernoulli}(p)\\)\nRule of thumb: \\(np\\geq10\\) and \\(n(1-p)\\geq 10\\) to use Normal approximation\n\n\n\n\n\n\nPoisson rv’s: Let \\(X \\sim Poisson(\\lambda)\\)\n\n\\(X = \\displaystyle\\sum_{i=1}^n X_i\\), where \\(X_i\\) are iid \\(\\text{Poiss}(1)\\)\nRecall from Chapter 18 that if \\(X_i \\sim Poiss(\\lambda_i)\\) and \\(X_i\\) independent, then \\(\\sum_{i=1}^n X_i \\sim Poiss(\\sum_{i=1}^n \\lambda_i)\\)\nRule of thumb: \\(\\lambda \\geq10\\) to use Normal approximation"
  },
  {
    "objectID": "lessons/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#at-home-example",
    "href": "lessons/18_Central_Limit_Theorem/37_Central_Limit_Theorem.html#at-home-example",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "At home example",
    "text": "At home example\n\n\nExample 3\n\n\nSuppose that the probability of developing a specific type of breast cancer in women aged 40-49 is 0.001. Assume the occurrences of cancer are independent. Suppose you have data from a random sample of 20,000 women aged 40-49.\n\nHow many of the 20,000 women would you expect to develop this type of breast cancer, and what is the standard deviation?\nFind the exact probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to find the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to approximate the following probabilities, where \\(X\\) is the number of women that will develop this type of breast cancer.\n\n\\(\\mathbb{P}(15 \\leq X \\leq 22)\\)\n\\(\\mathbb{P}(X &gt; 20)\\)\n\\(\\mathbb{P}(X &lt; 20)\\)\n\nFind the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer - not using the CLT!\nUse the CLT to approximate the approximate probability in the previous question!"
  },
  {
    "objectID": "lessons/15_Variance/12_Variance.html",
    "href": "lessons/15_Variance/12_Variance.html",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "",
    "text": "Calculate the variance and standard deviation of discrete random variables\nCalculate the variance of sums of discrete random variables\nCalculate the variance of functions of discrete random variables"
  },
  {
    "objectID": "lessons/15_Variance/12_Variance.html#learning-objectives",
    "href": "lessons/15_Variance/12_Variance.html#learning-objectives",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "",
    "text": "Calculate the variance and standard deviation of discrete random variables\nCalculate the variance of sums of discrete random variables\nCalculate the variance of functions of discrete random variables"
  },
  {
    "objectID": "lessons/15_Variance/12_Variance.html#where-are-we",
    "href": "lessons/15_Variance/12_Variance.html#where-are-we",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/15_Variance/12_Variance.html#lets-start-building-the-variance-through-expected-values-of-functions",
    "href": "lessons/15_Variance/12_Variance.html#lets-start-building-the-variance-through-expected-values-of-functions",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Let’s start building the variance through expected values of functions",
    "text": "Let’s start building the variance through expected values of functions\n\n\n\n\nExample 1\n\n\nLet \\(g\\) be a function and let \\(g(x) = ax+b\\), for real-valued constants \\(a\\) and \\(b\\). What is \\(\\mathbb{E}[g(X)]\\)?"
  },
  {
    "objectID": "lessons/15_Variance/12_Variance.html#what-is-the-expected-value-of-a-function",
    "href": "lessons/15_Variance/12_Variance.html#what-is-the-expected-value-of-a-function",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "What is the expected value of a function?",
    "text": "What is the expected value of a function?\n\n\nDefinition: Expected value of function of RV\n\n\nFor any function \\(g\\) and discrete r.v. \\(X\\), the expected value of \\(g(X)\\) is \\[\\mathbb{E}[g(X)] = \\sum_{\\{all\\ x\\}}\\ g(x) p_X(x).\\]"
  },
  {
    "objectID": "lessons/15_Variance/12_Variance.html#lets-revisit-the-card-example-12",
    "href": "lessons/15_Variance/12_Variance.html#lets-revisit-the-card-example-12",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Let’s revisit the card example (1/2)",
    "text": "Let’s revisit the card example (1/2)\n\n\n\n\nExample 2\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw.\n\nFind \\(\\mathbb{E}[X^2]\\).\n\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "lessons/15_Variance/12_Variance.html#lets-revisit-the-card-example-22",
    "href": "lessons/15_Variance/12_Variance.html#lets-revisit-the-card-example-22",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Let’s revisit the card example (2/2)",
    "text": "Let’s revisit the card example (2/2)\n\n\n\n\nExample 2\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw.\n\nFind \\(\\mathbb{E}\\big[\\big(X-\\frac{1}{2}\\big)^2\\big]\\).\n\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "lessons/15_Variance/12_Variance.html#variance-of-a-rv",
    "href": "lessons/15_Variance/12_Variance.html#variance-of-a-rv",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Variance of a RV",
    "text": "Variance of a RV\n\n\nDefinition: Variance of RV\n\n\nThe variance of a r.v. \\(X\\), with (finite) expected value \\(\\mu_X=\\mathbb{E}[X]\\) is \\[\\sigma_X^2=Var(X)=\\mathbb{E}[(X-\\mu_X)^2] = \\mathbb{E}[(X-\\mathbb{E}[X])^2]\\]\n\n\n\n\nDefinition: Standard deviation of RV\n\n\nThe standard deviation of a r.v. \\(X\\) is \\[\\sigma_X = SD(X) = \\sqrt{\\sigma_X^2}=\\sqrt{Var(X)}.\\]"
  },
  {
    "objectID": "lessons/15_Variance/12_Variance.html#questions",
    "href": "lessons/15_Variance/12_Variance.html#questions",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Questions",
    "text": "Questions\nQuestions: Why do we square the difference in the variance definition? \\((X-\\mu_X)^2\\)\n\nWhy not define the measure of spread as \\(\\mathbb{E}[X-\\mu_X] = \\mathbb{E}[X-\\mathbb{E}[X]]\\)?\nWhy not use \\(\\mathbb{E}[|X-\\mu_X|]\\)?"
  },
  {
    "objectID": "lessons/15_Variance/12_Variance.html#lets-calculate-the-variance-and-prove-it",
    "href": "lessons/15_Variance/12_Variance.html#lets-calculate-the-variance-and-prove-it",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Let’s calculate the variance and prove it!",
    "text": "Let’s calculate the variance and prove it!\n\n\n\n\nLemma 6: “Computation formula” for Variance\n\n\nThe variance of a r.v. \\(X\\), can be computed as \\[\\begin{align}\n\\sigma_X^2 & =Var(X) \\\\ & = \\mathbb{E}[X^2]-\\mu_X^2 \\\\ & = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2\n\\end{align}\\]"
  },
  {
    "objectID": "lessons/15_Variance/12_Variance.html#variance-of-a-function-with-a-single-rv",
    "href": "lessons/15_Variance/12_Variance.html#variance-of-a-function-with-a-single-rv",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Variance of a function with a single RV",
    "text": "Variance of a function with a single RV\n\n\nLemma 7\n\n\nFor a r.v. \\(X\\) and constants \\(a\\) and \\(b\\), \\[Var(aX+b) = a^2Var(X).\\]\n\n\nProof will be exercise in homework. It’s fun! In a mathy kinda way."
  },
  {
    "objectID": "lessons/15_Variance/12_Variance.html#important-results-for-independent-rvs",
    "href": "lessons/15_Variance/12_Variance.html#important-results-for-independent-rvs",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Important results for independent RVs",
    "text": "Important results for independent RVs\n\n\nTheorem 8\n\n\nFor independent r.v.’s \\(X\\) and \\(Y\\), and functions \\(g\\) and \\(h\\), \\[\\mathbb{E}[g(X)h(Y)] = \\mathbb{E}[g(X)]\\mathbb{E}[h(Y)].\\]\n\n\n\n\nCorollary 1\n\n\nFor independent r.v.’s \\(X\\) and \\(Y\\), \\[\\mathbb{E}[XY] = \\mathbb{E}[X]\\mathbb{E}[Y].\\]"
  },
  {
    "objectID": "lessons/15_Variance/12_Variance.html#variance-of-sum-of-independent-discrete-rvs",
    "href": "lessons/15_Variance/12_Variance.html#variance-of-sum-of-independent-discrete-rvs",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Variance of sum of independent discrete RVs",
    "text": "Variance of sum of independent discrete RVs\n\n\nTheorem 9: Variance of sum of independent discrete r.v.’s\n\n\nFor independent discrete r.v.’s \\(X_i\\) and constants \\(a_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n a_iX_i\\Bigg) = \\sum_{i=1}^n a_i^2Var(X_i).\\]\n\n\nSimpler version:\n\\[Var(a_1 X + a_2 Y) = Var(a_1X) + Var(a_2 Y) = a_1^2 Var(X) + a_2^2 Var(Y)\\]"
  },
  {
    "objectID": "lessons/15_Variance/12_Variance.html#corollaries",
    "href": "lessons/15_Variance/12_Variance.html#corollaries",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Corollaries",
    "text": "Corollaries\n\n\nCorollary 2\n\n\nFor independent discrete r.v.’s \\(X_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n X_i\\Bigg) = \\sum_{i=1}^n Var(X_i).\\]\n\n\n\n\nCorollary 3\n\n\nFor independent identically distributed (i.i.d.) discrete r.v.’s \\(X_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n X_i\\Bigg) = n Var(X_1).\\]"
  },
  {
    "objectID": "lessons/15_Variance/12_Variance.html#lets-look-at-a-ghost-problem-with-replacement",
    "href": "lessons/15_Variance/12_Variance.html#lets-look-at-a-ghost-problem-with-replacement",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Let’s look at a ghost problem with replacement",
    "text": "Let’s look at a ghost problem with replacement\n\n\n\n\nExample 3.2\n\n\nThe ghost is trick-or-treating at a different house now. In this case it is known that the bag of candy has 10 chocolates, 20 lollipops, and 30 laffy taffies. The ghost grabs a handful of five pieces of candy. What is the variance for the number of chocolates the ghost takes? Let’s solve this for the cases with replacement.\n\n\n\n\nRecall probability with replacement:\n\\[\np_X(x) = {n \\choose k}p^k(1-p)^{n-k}\n\\]"
  },
  {
    "objectID": "lessons/15_Variance/12_Variance.html#back-to-our-hotel-example-from-chapter-11",
    "href": "lessons/15_Variance/12_Variance.html#back-to-our-hotel-example-from-chapter-11",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Back to our hotel example from Chapter 11",
    "text": "Back to our hotel example from Chapter 11\n\n\n\n\nExample 4\n\n\nA tour group is planning a visit to the city of Minneapolis and needs to book 30 hotel rooms. The average price of a room is $200 with standard deviation $10. In addition, there is a 10% tourism tax for each room. What is the standard deviation of the cost for the 30 hotel rooms? Assume rooms are independent.\n\n\nProblem to do at home if we don’t have enough time."
  },
  {
    "objectID": "lessons/15_Variance/12_Variance_muddy_points.html",
    "href": "lessons/15_Variance/12_Variance_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy Points from Fall 2023:\n\n1. Proof of variance formula\nHere is the variance formula that we worked through on slide 9 of Chapter 12’s notes.\n\n\n\n\n\n\nLemma 6: “Computation formula” for variance\n\n\n\nThe variance of a r.v. \\(X\\), can be computed as \\[\\begin{align}\\sigma_X^2 & =Var(X) \\\\ & = \\mathbb{E}[X^2]-\\mu_X^2 \\\\ & = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2\\end{align}\\]\n\n\nI stepped through this quite quickly and made some implicit steps. So let’s revisit it with explicit steps!\n       \n\n\n2. What progression are we following in the course??\nSomeone asked if this is our progression: RV is function \\(\\to\\) Expected value is function to describe mean of RV \\(\\to\\) Use functions within expected value to set up variance\nBasically, yes! The random variable is a function of a random process. The RV inherits that randomness.\nFrom there, we’ve been working towards calculating the probability of a realized value ($x$) of the RV. The probability can be different for different realized values (as it links back to the random process).\nWe also want to construct ways to describe our random variables. We may want to figure out what to expect from our random variable (which translates to the mean value of the RV). Since our RV is rooted in a random process, we may want to get an idea of how spread out our realized values are. We use our expected value (mean) as an anchor in our spread. Variance is one way to measure this spread."
  },
  {
    "objectID": "lessons/10_CDFs/10_CDFs.html",
    "href": "lessons/10_CDFs/10_CDFs.html",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "",
    "text": "Cumulative distribution function\n\n\nThe cumulative distribution function (cdf) of a continuous random variable \\(X\\), is the function \\(F_X(x)\\), such that for all real values of \\(x\\), \\[F_X(x)= \\mathbb{P}(X \\leq x) = \\int_{-\\infty}^x f_X(s)ds\\]\n\n\nRemarks: In general, \\(F_X(x)\\) is increasing and\n\n\\(\\lim_{x\\rightarrow -\\infty} F_X(x)= 0\\)\n\\(\\lim_{x\\rightarrow \\infty} F_X(x)= 1\\)\n\\(P(X &gt; a) = 1 - P(X \\leq a) = 1 - F_X(a)\\)\n\\(P(a \\leq X \\leq b) = F_X(b) - F_X(a)\\)"
  },
  {
    "objectID": "lessons/10_CDFs/10_CDFs.html#what-is-a-cumulative-distribution-function",
    "href": "lessons/10_CDFs/10_CDFs.html#what-is-a-cumulative-distribution-function",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "",
    "text": "Cumulative distribution function\n\n\nThe cumulative distribution function (cdf) of a continuous random variable \\(X\\), is the function \\(F_X(x)\\), such that for all real values of \\(x\\), \\[F_X(x)= \\mathbb{P}(X \\leq x) = \\int_{-\\infty}^x f_X(s)ds\\]\n\n\nRemarks: In general, \\(F_X(x)\\) is increasing and\n\n\\(\\lim_{x\\rightarrow -\\infty} F_X(x)= 0\\)\n\\(\\lim_{x\\rightarrow \\infty} F_X(x)= 1\\)\n\\(P(X &gt; a) = 1 - P(X \\leq a) = 1 - F_X(a)\\)\n\\(P(a \\leq X \\leq b) = F_X(b) - F_X(a)\\)"
  },
  {
    "objectID": "lessons/10_CDFs/10_CDFs.html#lets-demonstrate-the-cdf-with-an-example",
    "href": "lessons/10_CDFs/10_CDFs.html#lets-demonstrate-the-cdf-with-an-example",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the CDF with an example",
    "text": "Let’s demonstrate the CDF with an example\n\n\n\n\nExample 2\n\n\nLet \\(f_X(x)= 2\\), for \\(2.5 \\leq x \\leq 3\\). Find \\(F_X(x)\\)."
  },
  {
    "objectID": "lessons/10_CDFs/10_CDFs.html#derivatives-of-the-cdf",
    "href": "lessons/10_CDFs/10_CDFs.html#derivatives-of-the-cdf",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Derivatives of the CDF",
    "text": "Derivatives of the CDF\n\n\nTheorem 1\n\n\nIf \\(X\\) is a continuous random variable with pdf \\(f_X(x)\\) and cdf \\(F_X(x)\\), then for all real values of \\(x\\) at which \\(F'_X(x)\\) exists, \\[\\frac{d}{dx} F_X(x)= F'_X(x) = f_X(x)\\]"
  },
  {
    "objectID": "lessons/10_CDFs/10_CDFs.html#finding-the-pdf-from-a-cdf",
    "href": "lessons/10_CDFs/10_CDFs.html#finding-the-pdf-from-a-cdf",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Finding the PDF from a CDF",
    "text": "Finding the PDF from a CDF\n\n\n\n\nExample 3\n\n\nLet \\(X\\) be a RV with cdf \\[F_X(x)= \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x &lt; 2.5 \\\\\n            2x-5 & \\quad 2.5 \\leq x \\leq 3 \\\\\n            1 & \\quad x &gt; 3\n        \\end{array}\n    \\right.\\] Find the pdf \\(f_X(x)\\)."
  },
  {
    "objectID": "lessons/10_CDFs/10_CDFs.html#lets-go-through-another-example-17",
    "href": "lessons/10_CDFs/10_CDFs.html#lets-go-through-another-example-17",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (1/7)",
    "text": "Let’s go through another example (1/7)\n\n\n\n\nExample 4\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nShow \\(f_X(x)\\) is a pdf.\nFind \\(\\mathbb{P}(1 \\leq X \\leq 3)\\).\nFind \\(F_X(x)\\).\nGiven \\(F_X(x)\\), find \\(f_X(x)\\).\nFind \\(\\mathbb{P}(X \\geq 1 | X \\leq 3)\\).\nFind the median of the distribution of \\(X\\)."
  },
  {
    "objectID": "lessons/10_CDFs/10_CDFs.html#lets-go-through-another-example-27",
    "href": "lessons/10_CDFs/10_CDFs.html#lets-go-through-another-example-27",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (2/7)",
    "text": "Let’s go through another example (2/7)\n\n\n\n\nExample 4.1\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nShow \\(f_X(x)\\) is a pdf."
  },
  {
    "objectID": "lessons/10_CDFs/10_CDFs.html#lets-go-through-another-example-37",
    "href": "lessons/10_CDFs/10_CDFs.html#lets-go-through-another-example-37",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (3/7)",
    "text": "Let’s go through another example (3/7)\n\n\n\n\n\n\nDo this problem at home for extra practice.\n\n\n\n\n\n\n\nExample 4.2\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nFind \\(\\mathbb{P}(1 \\leq X \\leq 3)\\)."
  },
  {
    "objectID": "lessons/10_CDFs/10_CDFs.html#lets-go-through-another-example-47",
    "href": "lessons/10_CDFs/10_CDFs.html#lets-go-through-another-example-47",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (4/7)",
    "text": "Let’s go through another example (4/7)\n\n\n\n\nExample 4.3\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nFind \\(F_X(x)\\)."
  },
  {
    "objectID": "lessons/10_CDFs/10_CDFs.html#lets-go-through-another-example-57",
    "href": "lessons/10_CDFs/10_CDFs.html#lets-go-through-another-example-57",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (5/7)",
    "text": "Let’s go through another example (5/7)\n\n\n\n\n\n\nDo this problem at home for extra practice.\n\n\n\n\n\n\n\nExample 4.4\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nGiven \\(F_X(x)\\), find \\(f_X(x)\\)."
  },
  {
    "objectID": "lessons/10_CDFs/10_CDFs.html#lets-go-through-another-example-67",
    "href": "lessons/10_CDFs/10_CDFs.html#lets-go-through-another-example-67",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (6/7)",
    "text": "Let’s go through another example (6/7)\n\n\n\n\nExample 4.5\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nFind \\(\\mathbb{P}(X \\geq 1 | X \\leq 3)\\)."
  },
  {
    "objectID": "lessons/10_CDFs/10_CDFs.html#lets-go-through-another-example-77",
    "href": "lessons/10_CDFs/10_CDFs.html#lets-go-through-another-example-77",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (7/7)",
    "text": "Let’s go through another example (7/7)\n\n\n\n\nExample 4.6\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nFind the median of the distribution of \\(X\\)."
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning_muddy_points.html",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "If we start at a joint probability \\(f_{X,Y}(x,y)\\)…. we can look at a few probabilities:\n\nJoint probability: \\(P(a \\leq X \\leq b, c \\leq Y \\leq d)\\)\n\\[P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=c}^{y=d} f_{X,Y}(x,y) dydx\\]\nMarginal probability: \\(P(a \\leq X \\leq b)\\)\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b} f_{X}(x) dx\\]\nOR\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=-\\inf}^{y=\\inf} f_{X,Y}(x,y) dydx\\]\nConditional probability: \\(P(a \\leq X \\leq b | Y = c)\\)\n\\[P(a \\leq X \\leq b | Y=c) = \\displaystyle\\int_{x=a}^{x=b} f_{X|Y}(x|y=c) dx\\]\nYou cannot calculate \\(P(a \\leq X \\leq b | Y = c)\\) by \\(\\dfrac{P(a \\leq X \\leq b, Y=c)}{P(Y = c)}\\) because \\(P(Y = c)\\) is 0. Instead, we need to find \\(f_{X|Y}(x|y=c)\\) by \\(\\dfrac{f_{X,Y}(x,y=c)}{f_{Y}(y=c)}\\) and THEN integrate over X."
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning_key_info.html",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Did everyone turn in their midquarter feedback?\nQuiz 2 opens on Wednesday\n\nLessons 7-9: pmfs, pdfs, and CDFs\n\nFinish up example from last class"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning_key_info.html#announcements",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Did everyone turn in their midquarter feedback?\nQuiz 2 opens on Wednesday\n\nLessons 7-9: pmfs, pdfs, and CDFs\n\nFinish up example from last class"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning_key_info.html#key-dates",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHomework 5 due this Sunday\nQuiz 2 due this Sunday\n\nOpens Wednesday!"
  },
  {
    "objectID": "lessons/13_Expected_Values/28_Expected_Values/28_Expected_Values_key_info.html",
    "href": "lessons/13_Expected_Values/28_Expected_Values/28_Expected_Values_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Wow! Week 7…\nHW 3 video/presentation\n\nTomorrow! 11/12 at 11pm: recordings due if you are making that\nCalendly is up!! Please see me original announcement\n\nNeed to grade HW 4 solutions and HW 5 assignment\nAnything else?"
  },
  {
    "objectID": "lessons/13_Expected_Values/28_Expected_Values/28_Expected_Values_key_info.html#announcements",
    "href": "lessons/13_Expected_Values/28_Expected_Values/28_Expected_Values_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Wow! Week 7…\nHW 3 video/presentation\n\nTomorrow! 11/12 at 11pm: recordings due if you are making that\nCalendly is up!! Please see me original announcement\n\nNeed to grade HW 4 solutions and HW 5 assignment\nAnything else?"
  },
  {
    "objectID": "lessons/13_Expected_Values/28_Expected_Values/28_Expected_Values_key_info.html#key-dates",
    "href": "lessons/13_Expected_Values/28_Expected_Values/28_Expected_Values_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 6 due\nSunday: HW 5 solutions due"
  },
  {
    "objectID": "lessons/13_Expected_Values/10_Expected_Values_key_info.html",
    "href": "lessons/13_Expected_Values/10_Expected_Values_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 03 assignment today\nGroup evals will be taken off the assessment breakdown\nMid-quarter feedback will be put on HW 05"
  },
  {
    "objectID": "lessons/13_Expected_Values/10_Expected_Values_key_info.html#announcements",
    "href": "lessons/13_Expected_Values/10_Expected_Values_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 03 assignment today\nGroup evals will be taken off the assessment breakdown\nMid-quarter feedback will be put on HW 05"
  },
  {
    "objectID": "lessons/13_Expected_Values/10_Expected_Values_key_info.html#key-dates",
    "href": "lessons/13_Expected_Values/10_Expected_Values_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 04 assignment due Thursday\nHW 03 solutions due Sunday\n\nAnd we will have a presentation on this one!"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/03_Independent_Events.html",
    "href": "lessons/04_Rules_of_prob/03_Independent_Events.html",
    "title": "Chapter 3: Independent Events",
    "section": "",
    "text": "Define independence of 2-3 events given probability notation\nCalculate whether two or more events are independent"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/03_Independent_Events.html#learning-objectives",
    "href": "lessons/04_Rules_of_prob/03_Independent_Events.html#learning-objectives",
    "title": "Chapter 3: Independent Events",
    "section": "",
    "text": "Define independence of 2-3 events given probability notation\nCalculate whether two or more events are independent"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/03_Independent_Events.html#where-are-we",
    "href": "lessons/04_Rules_of_prob/03_Independent_Events.html#where-are-we",
    "title": "Chapter 3: Independent Events",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/03_Independent_Events.html#independent-events",
    "href": "lessons/04_Rules_of_prob/03_Independent_Events.html#independent-events",
    "title": "Chapter 3: Independent Events",
    "section": "Independent Events",
    "text": "Independent Events\n\n\nDefinition: Independence\n\n\nEvents \\(A\\) and \\(B\\) are independent if \\[\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B).\\]\n\n\nNotation: For shorthand, we sometimes write \\(A \\mathrel{\\unicode{x2AEB}} B,\\) to denote that \\(A\\) and \\(B\\) are independent events.\n \n\nAlso note: \\[\\begin{aligned} \\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B) & \\implies A \\mathrel{\\unicode{x2AEB}} B \\\\\nA \\mathrel{\\unicode{x2AEB}} B & \\implies \\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B) \\end{aligned}\\]"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/03_Independent_Events.html#example-of-two-dice",
    "href": "lessons/04_Rules_of_prob/03_Independent_Events.html#example-of-two-dice",
    "title": "Chapter 3: Independent Events",
    "section": "Example of two dice",
    "text": "Example of two dice\n\n\nExample 1\n\n\nTwo dice (red and blue) are rolled. Let \\(A =\\) event a total of 7 appears, and \\(B =\\) event red die is a six. Are events \\(A\\) and \\(B\\) independent?"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/03_Independent_Events.html#independence-of-3-events",
    "href": "lessons/04_Rules_of_prob/03_Independent_Events.html#independence-of-3-events",
    "title": "Chapter 3: Independent Events",
    "section": "Independence of 3 Events",
    "text": "Independence of 3 Events\n\n\nDefinition: Independence of 3 Events\n\n\nEvents \\(A\\), \\(B\\), and \\(C\\) are mutually independent if\n\n\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot \\mathbb{P}(B)\\)\n\\(\\mathbb{P}(A \\cap C) = \\mathbb{P}(A) \\cdot \\mathbb{P}(C)\\)\n\\(\\mathbb{P}(B \\cap C) = \\mathbb{P}(B) \\cdot \\mathbb{P}(C)\\)\n\n\\(\\mathbb{P}(A \\cap B \\cap C) = \\mathbb{P}(A) \\cdot \\mathbb{P}(B) \\cdot \\mathbb{P}(C)\\)\n\n\n\nRemark:\nOn your homework you will show that \\((1) \\not \\Rightarrow (2)\\) and \\((2) \\not \\Rightarrow (1)\\)."
  },
  {
    "objectID": "lessons/04_Rules_of_prob/03_Independent_Events.html#probability-at-least-one-smoker",
    "href": "lessons/04_Rules_of_prob/03_Independent_Events.html#probability-at-least-one-smoker",
    "title": "Chapter 3: Independent Events",
    "section": "Probability at least one smoker",
    "text": "Probability at least one smoker\n\n\n\n\nExample 2\n\n\nSuppose you take a random sample of \\(n\\) people, of which people are smokers and non-smokers independently of each other. Let\n\n\\(A_i =\\) event person \\(i\\) is a smoker, for \\(i=1, \\ldots ,n\\), and\n\\(p_i =\\) probability person \\(i\\) is a smoker, for \\(i=1, \\ldots ,n\\).\n\nFind the probability that at least one person in the random sample is a smoker."
  },
  {
    "objectID": "lessons/04_Rules_of_prob/03_Independent_Events.html#building-geometric-series",
    "href": "lessons/04_Rules_of_prob/03_Independent_Events.html#building-geometric-series",
    "title": "Chapter 3: Independent Events",
    "section": "Building geometric series",
    "text": "Building geometric series\n\n\nExample 3\n\n\n\\(A, B,\\) and \\(C\\) toss a fair coin in order. The first to throw heads wins. What are their respective chances of winning?\n\n\nLet\n\n\\(A_H\\) and \\(A_T\\) be the events player A tosses heads and tails, respectively.\nSimilarly define \\(B_H\\), \\(B_T\\), \\(C_H\\), and \\(C_T\\)."
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html",
    "title": "Lesson 4: Rules of probability",
    "section": "",
    "text": "Define independence of 2-3 events given probability notation\nCalculate whether two or more events are independent\nUse set process to calculate probability of event of interest\nCalculate the probability of an event occurring, given that another event occurred.\nDefine keys facts for conditional probabilities using notation.\nCalculate conditional probability of an event using Bayes’ Theorem\nUtilize additional probability rules in probability calculations, specifically the Higher Order Multiplication Rule and the Law of Total Probabilities\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition: Independence\n\n\nEvents \\(A\\) and \\(B\\) are independent if \\[\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B).\\]\n\n\nNotation: For shorthand, we sometimes write \\(A \\mathrel{\\unicode{x2AEB}} B,\\) to denote that \\(A\\) and \\(B\\) are independent events.\n \n\nAlso note: \\[\\begin{aligned} \\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B) & \\implies A \\mathrel{\\unicode{x2AEB}} B \\\\\nA \\mathrel{\\unicode{x2AEB}} B & \\implies \\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B) \\end{aligned}\\]\n\n\n\n\n\n\nExample 1\n\n\nTwo dice (red and blue) are rolled. Let \\(A =\\) event a total of 7 appears, and \\(B =\\) event red die is a six. Are events \\(A\\) and \\(B\\) independent?\n\n\n\n\n\n\n\nDefinition: Independence of 3 Events\n\n\nEvents \\(A\\), \\(B\\), and \\(C\\) are mutually independent if\n\n\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot \\mathbb{P}(B)\\)\n\\(\\mathbb{P}(A \\cap C) = \\mathbb{P}(A) \\cdot \\mathbb{P}(C)\\)\n\\(\\mathbb{P}(B \\cap C) = \\mathbb{P}(B) \\cdot \\mathbb{P}(C)\\)\n\n\\(\\mathbb{P}(A \\cap B \\cap C) = \\mathbb{P}(A) \\cdot \\mathbb{P}(B) \\cdot \\mathbb{P}(C)\\)\n\n\n\nRemark:\nOn your homework you will show that \\((1) \\not \\Rightarrow (2)\\) and \\((2) \\not \\Rightarrow (1)\\).\n\n\n\n\n\n\n\nExample 2\n\n\nSuppose you take a random sample of \\(n\\) people, of which people are smokers and non-smokers independently of each other. Let\n\n\\(A_i =\\) event person \\(i\\) is a smoker, for \\(i=1, \\ldots ,n\\), and\n\\(p_i =\\) probability person \\(i\\) is a smoker, for \\(i=1, \\ldots ,n\\).\n\nFind the probability that at least one person in the random sample is a smoker.\n\n\n\n\n\n\n\n\n\nExample 3\n\n\n\\(A, B,\\) and \\(C\\) toss a fair coin in order. The first to throw heads wins. What are their respective chances of winning?\n\n\nLet\n\n\\(A_H\\) and \\(A_T\\) be the events player A tosses heads and tails, respectively.\nSimilarly define \\(B_H\\), \\(B_T\\), \\(C_H\\), and \\(C_T\\)."
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#independent-events",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#independent-events",
    "title": "Lesson 4: Rules of probability",
    "section": "Independent Events",
    "text": "Independent Events\n\n\nDefinition: Independence\n\n\nEvents \\(A\\) and \\(B\\) are independent if \\[\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B).\\]\n\n\nNotation: For shorthand, we sometimes write \\(A \\mathrel{\\unicode{x2AEB}} B,\\) to denote that \\(A\\) and \\(B\\) are independent events.\n \n\nAlso note: \\[\\begin{aligned} \\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B) & \\implies A \\mathrel{\\unicode{x2AEB}} B \\\\\nA \\mathrel{\\unicode{x2AEB}} B & \\implies \\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B) \\end{aligned}\\]"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#example-of-two-dice",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#example-of-two-dice",
    "title": "Lesson 4: Rules of probability",
    "section": "Example of two dice",
    "text": "Example of two dice\n\n\nExample 1\n\n\nTwo dice (green and blue) are rolled. Let \\(A =\\) event a total of 7 appears, and \\(B =\\) event green die is a six. Are events \\(A\\) and \\(B\\) independent?"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#independence-of-3-events",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#independence-of-3-events",
    "title": "Lesson 4: Rules of probability",
    "section": "Independence of 3 Events",
    "text": "Independence of 3 Events\n\n\nDefinition: Independence of 3 Events\n\n\nEvents \\(A\\), \\(B\\), and \\(C\\) are mutually independent if\n\n\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot \\mathbb{P}(B)\\)\n\\(\\mathbb{P}(A \\cap C) = \\mathbb{P}(A) \\cdot \\mathbb{P}(C)\\)\n\\(\\mathbb{P}(B \\cap C) = \\mathbb{P}(B) \\cdot \\mathbb{P}(C)\\)\n\n\\(\\mathbb{P}(A \\cap B \\cap C) = \\mathbb{P}(A) \\cdot \\mathbb{P}(B) \\cdot \\mathbb{P}(C)\\)\n\n\n\nRemark:\nOn your homework you will show that \\((1) \\not \\Rightarrow (2)\\) and \\((2) \\not \\Rightarrow (1)\\)."
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#probability-at-least-one-smoker",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#probability-at-least-one-smoker",
    "title": "Lesson 4: Rules of probability",
    "section": "Probability at least one smoker",
    "text": "Probability at least one smoker\n\n\n\n\nExample 2\n\n\nSuppose you take a random sample of \\(n\\) people, of which people are smokers and non-smokers independently of each other. Let\n\n\\(A_i =\\) event person \\(i\\) is a smoker, for \\(i=1, \\ldots ,n\\), and\n\\(p_i =\\) probability person \\(i\\) is a smoker, for \\(i=1, \\ldots ,n\\).\n\nFind the probability that at least one person in the random sample is a smoker."
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#building-geometric-series",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#building-geometric-series",
    "title": "Lesson 4: Rules of probability",
    "section": "",
    "text": "Example 3\n\n\n\\(A, B,\\) and \\(C\\) toss a fair coin in order. The first to throw heads wins. What are their respective chances of winning?\n\n\nLet\n\n\\(A_H\\) and \\(A_T\\) be the events player A tosses heads and tails, respectively.\nSimilarly define \\(B_H\\), \\(B_T\\), \\(C_H\\), and \\(C_T\\)."
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#general-process-for-probability-word-problems",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#general-process-for-probability-word-problems",
    "title": "Lesson 4: Rules of probability",
    "section": "General Process for Probability Word Problems",
    "text": "General Process for Probability Word Problems\n\nClearly define your events of interest\nTranslate question to probability using defined events OR Venn Diagram\nAsk yourself:\n\nAre we sampling with or without replacement?\nDoes order matter?\n\nUse axioms, properties, partitions, facts, etc. to define the end probability calculation into smaller parts\n\nIf probabilities are given to you, Venn Diagrams may help you parse out the events and probability calculations\nIf you need to find probabilities with counting, pictures or diagrams might help here\n\nWrite out a concluding statement that gives the probability context\n(For own check) Make sure the calculated probability follows the axioms. Is is between 0 and 1?"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#lets-revisit-our-deck-of-cards",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#lets-revisit-our-deck-of-cards",
    "title": "Lesson 4: Rules of probability",
    "section": "Let’s revisit our deck of cards",
    "text": "Let’s revisit our deck of cards\n\n\n\n\nExample 1\n\n\nSuppose we randomly draw 2 cards from a standard deck of cards. What is the probability that we draw a spade then a heart?\n\n\nLet\n\nLet \\(A =\\) event \\(1^{st}\\) card is spades\nLet \\(B =\\) event \\(2^{nd}\\) card is heart"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#conditional-probability-facts-12",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#conditional-probability-facts-12",
    "title": "Lesson 4: Rules of probability",
    "section": "Conditional Probability facts (1/2)",
    "text": "Conditional Probability facts (1/2)\n\n\n\n\nFact 1: General Multiplication Rule\n\n\n\\[\\mathbb{P}(A\\cap B)=\\mathbb{P}(A)\\cdot\\mathbb{P}(B|A)\\]\n\n\n\n\n\nFact 2: Conditional Probability Definition\n\n\n\\[\\mathbb{P}(A|B)=\\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)}\\]"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#conditional-probability-facts-22",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#conditional-probability-facts-22",
    "title": "Lesson 4: Rules of probability",
    "section": "Conditional Probability facts (2/2)",
    "text": "Conditional Probability facts (2/2)\n\n\n\n\nFact 3\n\n\nIf \\(A\\) and \\(B\\) are independent events (\\(A \\unicode{x2AEB}B\\)), then \\[\\mathbb{P}(A|B) = \\mathbb{P}(A)\\]\n\n\n\n\n\nFact 4\n\n\n\\(\\mathbb{P}(A|B)\\) is a probability, meaning that it satisfies the probability axioms. In particular, \\[\\mathbb{P}(A|B) + \\mathbb{P}(A^C|B) = 1\\]"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#monty-hall-problem",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#monty-hall-problem",
    "title": "Lesson 4: Rules of probability",
    "section": "Monty Hall Problem",
    "text": "Monty Hall Problem\nSurvivor Season 42\nWith the Wiki page on it!"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#conditional-probability-with-two-dice",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#conditional-probability-with-two-dice",
    "title": "Lesson 4: Rules of probability",
    "section": "Conditional probability with two dice",
    "text": "Conditional probability with two dice\n\n\n\n\nExample 3\n\n\nTwo dice (green and blue) are rolled. If the dice do not show the same face, what is the probability that one of the dice is a 1?"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#introduction",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#introduction",
    "title": "Lesson 4: Rules of probability",
    "section": "Introduction",
    "text": "Introduction\n\nSo we learned about conditional probabilities\n\nWe learned how the occurrence of event A affects event B (B conditional on A)\n\nCan we figure out information on how the occurrence of event B affects event A?\nWe can use the conditional probability (\\(\\mathbb{P}(A|B)\\)) to get information on the flipped conditional probability (\\(\\mathbb{P}(B|A)\\))"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#bayes-rule-for-two-events",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#bayes-rule-for-two-events",
    "title": "Lesson 4: Rules of probability",
    "section": "Bayes’ Rule for two events",
    "text": "Bayes’ Rule for two events\n\nWe can use the conditional probability (\\(\\mathbb{P}(A|B)\\)) to get information on the flipped conditional probability (\\(\\mathbb{P}(B|A)\\))\n\n\n\n\n\nTheorem: Bayes’ Rule (for two events)\n\n\nFor any two events \\(A\\) and \\(B\\) with nonzero probabilties,\n\\[\\mathbb{P}(A| B) =\n\\frac{\\mathbb{P}(A) \\cdot \\mathbb{P}(B|A)}\n{\\mathbb{P}(B)}\\]"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#calculating-probability-with-higher-order-multiplication-rule",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#calculating-probability-with-higher-order-multiplication-rule",
    "title": "Lesson 4: Rules of probability",
    "section": "Calculating probability with Higher Order Multiplication Rule",
    "text": "Calculating probability with Higher Order Multiplication Rule\n\n\n\n\nExample 4\n\n\nSuppose we draw 5 cards from a standard shuffled deck of 52 cards. What is the probability of a flush, that is all the cards are of the same suit (including straight flushes)?\n\n\n\n\n\nHigher Order Multiplication Rule\n\n\n\\[\\begin{aligned} \\mathbb{P}(A_1\\cap & A_2 \\cap  \\ldots \\cap A_n)= \\\\ & \\mathbb{P}(A_1)\\cdot\\mathbb{P}(A_2|A_1) \\cdot \\\\\n& \\mathbb{P}(A_3|A_1A_2)\\ldots \\cdot\\mathbb{P}(A_n|A_1A_2\\ldots A_{n-1})\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#calculating-probability-with-law-of-total-probability",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#calculating-probability-with-law-of-total-probability",
    "title": "Lesson 4: Rules of probability",
    "section": "Calculating probability with Law of Total Probability",
    "text": "Calculating probability with Law of Total Probability\n\n\n\n\nExample 5\n\n\nSuppose 1% of people assigned female at birth (AFAB) and 5% of people assigned male at birth (AMAB) are color-blind. Assume person born is equally likely AFAB or AMAB (not including intersex). What is the probability that a person chosen at random is color-blind?\n\n\n\n\n\nLaw of Total Probability for 2 Events\n\n\nFor events \\(A\\) and \\(B\\),\n\\[%\\left(\n\\begin{array}{ccl}\n\\mathbb{P}(B)&=&\\mathbb{P}(B \\cap A) + \\mathbb{P}(B \\cap A^C)\\\\\n           &=& \\mathbb{P}(B|A) \\cdot \\mathbb{P}(A)+ \\mathbb{P}(B | A^C)\\cdot \\mathbb{P}(A^C)\n\\end{array}\n%\\right)\\]"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#general-law-of-total-proability",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#general-law-of-total-proability",
    "title": "Lesson 4: Rules of probability",
    "section": "General Law of Total Proability",
    "text": "General Law of Total Proability\n\n\nLaw of Total Probability (general)\n\n\nIf \\(\\{A_i\\}_{i=1}^{n} = \\{A_1, A_2, \\ldots, A_n\\}\\) form a partition of the sample space, then for event \\(B\\),\n\\[%\\left(\n\\begin{array}{ccl}\n\\mathbb{P}(B)&=& \\sum_{i=1}^{n} \\mathbb{P}(B \\cap A_i)\\\\\n           &=& \\sum_{i=1}^{n} \\mathbb{P}(B|A_i) \\cdot \\mathbb{P}(A_i)\n\\end{array}\n%\\right)\\]"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#calculating-probability-with-generalized-law-of-total-probability",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#calculating-probability-with-generalized-law-of-total-probability",
    "title": "Lesson 4: Rules of probability",
    "section": "Calculating probability with generalized Law of Total Probability",
    "text": "Calculating probability with generalized Law of Total Probability"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#calculating-probability-with-generalized-law-of-total-probability-1",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#calculating-probability-with-generalized-law-of-total-probability-1",
    "title": "Lesson 4: Rules of probability",
    "section": "Calculating probability with generalized Law of Total Probability",
    "text": "Calculating probability with generalized Law of Total Probability\n\n\n\n\nExample 3\n\n\nIndividuals are diagnosed with a particular type of cancer that can take on three different disease forms,* \\(D_1\\), \\(D_2\\), and \\(D_3\\). It is known that amongst people diagnosed with this particular type of cancer,\n\n20% of people will eventually be diagnosed with form \\(D_1\\),\n30% with form \\(D_2\\), and\n50% with form \\(D_3\\).\n\nThe probability of requiring chemotherapy (\\(C\\)) differs among the three forms of disease:\n\n80% with \\(D_1\\),\n30% with \\(D_2\\), and\n10% with \\(D_3\\).\n\nBased solely on the preliminary test of being diagnosed with the cancer, what is the probability of requiring chemotherapy (the event C)?\n\n\n\nSkipping in class! Let me know if you would like me to post solutions to this if you work through it!"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#lets-revisit-the-color-blind-example",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#lets-revisit-the-color-blind-example",
    "title": "Lesson 4: Rules of probability",
    "section": "Let’s revisit the color-blind example",
    "text": "Let’s revisit the color-blind example\n\n\n\n\nExample 4\n\n\nRecall the color-blind example (Example 2), where\n\na person is AMAB with probability 0.5,\nAMAB people are color-blind with probability 0.05, and\nall people are color-blind with probability 0.03.\n\nAssuming people are AMAB or AFAB, find the probability that a color-blind person is AMAB."
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#calculate-probability-with-both-rules",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#calculate-probability-with-both-rules",
    "title": "Lesson 4: Rules of probability",
    "section": "Calculate probability with both rules",
    "text": "Calculate probability with both rules\n\n\n\n\nExample 6\n\n\nSuppose\n\n1% of people who are AFAB aged 40-50 years have breast cancer,\nan AFAB person with breast cancer has a 90% chance of a positive test from a mammogram, and\nan AFAB person has a 10% chance of a false-positive result from a mammogram.\n\nWhat is the probability that an AFAB person has breast cancer given that they just had a positive test?"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#bayes-rule",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#bayes-rule",
    "title": "Lesson 4: Rules of probability",
    "section": "Bayes’ Rule",
    "text": "Bayes’ Rule\n\n\nTheorem: Bayes’ Rule\n\n\nIf \\(\\{A_i\\}_{i=1}^{n}\\) form a partition of the sample space \\(S\\), with \\(\\mathbb{P}(A_i)&gt;0\\) for \\(i=1\\ldots n\\) and \\(\\mathbb{P}(B)&gt;0\\), then\n\\[\\mathbb{P}(A_j | B) =\n\\frac{\\mathbb{P}(B|A_j) \\cdot \\mathbb{P}(A_j)}\n{\\sum_{i=1}^{n} \\mathbb{P}(B|A_i) \\cdot \\mathbb{P}(A_i)}\\]"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Conditional_Probability.html",
    "href": "lessons/04_Rules_of_prob/04_Conditional_Probability.html",
    "title": "Chapter 4: Conditional Probability",
    "section": "",
    "text": "Use set process to calculate probability of event of interest\nCalculate the probability of an event occurring, given that another event occurred.\nDefine keys facts for conditional probabilities using notation."
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Conditional_Probability.html#learning-objectives",
    "href": "lessons/04_Rules_of_prob/04_Conditional_Probability.html#learning-objectives",
    "title": "Chapter 4: Conditional Probability",
    "section": "",
    "text": "Use set process to calculate probability of event of interest\nCalculate the probability of an event occurring, given that another event occurred.\nDefine keys facts for conditional probabilities using notation."
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Conditional_Probability.html#where-are-we",
    "href": "lessons/04_Rules_of_prob/04_Conditional_Probability.html#where-are-we",
    "title": "Chapter 4: Conditional Probability",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Conditional_Probability.html#general-process-for-probability-word-problems",
    "href": "lessons/04_Rules_of_prob/04_Conditional_Probability.html#general-process-for-probability-word-problems",
    "title": "Chapter 4: Conditional Probability",
    "section": "General Process for Probability Word Problems",
    "text": "General Process for Probability Word Problems\n\nClearly define your events of interest\nTranslate question to probability using defined events OR Venn Diagram\nAsk yourself:\n\nAre we sampling with or without replacement?\nDoes order matter?\n\nUse axioms, properties, partitions, facts, etc. to define the end probability calculation into smaller parts\n\nIf probabilities are given to you, Venn Diagrams may help you parse out the events and probability calculations\nIf you need to find probabilities with counting, pictures or diagrams might help here\n\nWrite out a concluding statement that gives the probability context\n(For own check) Make sure the calculated probability follows the axioms. Is is between 0 and 1?"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Conditional_Probability.html#lets-revisit-our-deck-of-cards",
    "href": "lessons/04_Rules_of_prob/04_Conditional_Probability.html#lets-revisit-our-deck-of-cards",
    "title": "Chapter 4: Conditional Probability",
    "section": "Let’s revisit our deck of cards",
    "text": "Let’s revisit our deck of cards\n\n\n\n\nExample 1\n\n\nSuppose we randomly draw 2 cards from a standard deck of cards. What is the probability that we draw a spade then a heart?\n\n\nLet\n\nLet \\(A =\\) event \\(1^{st}\\) card is spades\nLet \\(B =\\) event \\(2^{nd}\\) card is heart"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Conditional_Probability.html#conditional-probability-facts-12",
    "href": "lessons/04_Rules_of_prob/04_Conditional_Probability.html#conditional-probability-facts-12",
    "title": "Chapter 4: Conditional Probability",
    "section": "Conditional Probability facts (1/2)",
    "text": "Conditional Probability facts (1/2)\n\n\n\n\nFact 1: General Multiplication Rule\n\n\n\\[\\mathbb{P}(A\\cap B)=\\mathbb{P}(A)\\cdot\\mathbb{P}(B|A)\\]\n\n\n\n\n\nFact 2: Conditional Probability Definition\n\n\n\\[\\mathbb{P}(A|B)=\\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)}\\]"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Conditional_Probability.html#conditional-probability-facts-22",
    "href": "lessons/04_Rules_of_prob/04_Conditional_Probability.html#conditional-probability-facts-22",
    "title": "Chapter 4: Conditional Probability",
    "section": "Conditional Probability facts (2/2)",
    "text": "Conditional Probability facts (2/2)\n\n\n\n\nFact 3\n\n\nIf \\(A\\) and \\(B\\) are independent events (\\(A \\unicode{x2AEB}B\\)), then \\[\\mathbb{P}(A|B) = \\mathbb{P}(A)\\]\n\n\n\n\n\nFact 4\n\n\n\\(\\mathbb{P}(A|B)\\) is a probability, meaning that it satisfies the probability axioms. In particular, \\[\\mathbb{P}(A|B) + \\mathbb{P}(A^C|B) = 1\\]"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Conditional_Probability.html#monty-hall-problem",
    "href": "lessons/04_Rules_of_prob/04_Conditional_Probability.html#monty-hall-problem",
    "title": "Chapter 4: Conditional Probability",
    "section": "Monty Hall Problem",
    "text": "Monty Hall Problem\nSurvivor Season 42\nWith the Wiki page on it!"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Conditional_Probability.html#conditional-probability-with-two-dice",
    "href": "lessons/04_Rules_of_prob/04_Conditional_Probability.html#conditional-probability-with-two-dice",
    "title": "Chapter 4: Conditional Probability",
    "section": "Conditional probability with two dice",
    "text": "Conditional probability with two dice\n\n\n\n\nExample 2\n\n\nTwo dice (red and blue) are rolled. If the dice do not show the same face, what is the probability that one of the dice is a 1?"
  },
  {
    "objectID": "lessons_old/27_Conditional_distributions/27_Conditional_distributions.html",
    "href": "lessons_old/27_Conditional_distributions/27_Conditional_distributions.html",
    "title": "Chapter 27: Conditional Distributions",
    "section": "",
    "text": "Calculate the conditional probability density from a joint pdf"
  },
  {
    "objectID": "lessons_old/27_Conditional_distributions/27_Conditional_distributions.html#learning-objectives",
    "href": "lessons_old/27_Conditional_distributions/27_Conditional_distributions.html#learning-objectives",
    "title": "Chapter 27: Conditional Distributions",
    "section": "",
    "text": "Calculate the conditional probability density from a joint pdf"
  },
  {
    "objectID": "lessons_old/27_Conditional_distributions/27_Conditional_distributions.html#conditional-probabilities-weve-seen-before",
    "href": "lessons_old/27_Conditional_distributions/27_Conditional_distributions.html#conditional-probabilities-weve-seen-before",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Conditional probabilities we’ve seen before",
    "text": "Conditional probabilities we’ve seen before\n\n\nWhat do we know about conditional probabilities for events and discrete RVs?    \nFor events:\n\\[P(A | B) = \\dfrac{P(A \\cap B)}{P(B)}\\]    \nFor discrete RVs: \\[p_{X|Y}(x|y) = P(X=x|Y=y) = \\dfrac{p_{X,Y}(x,y)}{p_Y(y)}\\]\n\n\n\nWhat does it mean for conditional densities of continuous RVs?\nFor continuous RVs:"
  },
  {
    "objectID": "lessons_old/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-first-try",
    "href": "lessons_old/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-first-try",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf: first try!",
    "text": "Example starting from a joint pdf: first try!\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(2&lt;X&lt;10|Y=4)\\)"
  },
  {
    "objectID": "lessons_old/27_Conditional_distributions/27_Conditional_distributions.html#what-is-a-conditional-density",
    "href": "lessons_old/27_Conditional_distributions/27_Conditional_distributions.html#what-is-a-conditional-density",
    "title": "Chapter 27: Conditional Distributions",
    "section": "What is a conditional density?",
    "text": "What is a conditional density?\n\n\n\n\nDefinition: Conditional density\n\n\nThe conditional density of a r.v. \\(X\\) given \\(Y=y\\), is \\[f_{X|Y}(x|y)= \\frac{f_{X,Y}(x,y)}{f_Y(y)},\\] for \\(f_Y(y)&gt; 0\\)\n\n\n\n\n\nRemarks\n\nIt follows from the definition for the conditional density \\(f_{X|Y}(x|y)\\), that \\[f_{X,Y}(x,y)= f_{X|Y}(x|y)f_Y(y).\\]\n\n     \n\nFor a fixed value of \\(Y=y\\), the conditional density \\(f_{X|Y}(x|y)\\) is an actual pdf, meaning\n\n\\(f_{X|Y}(x|y)\\geq 0\\) for all \\(x\\) and \\(y\\), and\n\\(\\displaystyle\\int_{-\\infty}^{\\infty} f_{X|Y}(x|y)dx =1\\)."
  },
  {
    "objectID": "lessons_old/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try-12",
    "href": "lessons_old/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try-12",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf: second try! (1/2)",
    "text": "Example starting from a joint pdf: second try! (1/2)\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(2&lt;X&lt;10|Y=4)\\)"
  },
  {
    "objectID": "lessons_old/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try-22",
    "href": "lessons_old/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try-22",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf: second try! (2/2)",
    "text": "Example starting from a joint pdf: second try! (2/2)"
  },
  {
    "objectID": "lessons_old/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf",
    "href": "lessons_old/27_Conditional_distributions/27_Conditional_distributions.html#example-starting-from-a-joint-pdf",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf",
    "text": "Example starting from a joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(X&gt;20 |Y=5)\\)"
  },
  {
    "objectID": "lessons_old/27_Conditional_distributions/27_Conditional_distributions.html#finding-probability-with-conditional-domain-and-pdf",
    "href": "lessons_old/27_Conditional_distributions/27_Conditional_distributions.html#finding-probability-with-conditional-domain-and-pdf",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Finding probability with conditional domain and pdf",
    "text": "Finding probability with conditional domain and pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 2\n\n\nRandomly choose a point \\(X\\) from the interval \\([0,1]\\), and given \\(X=x\\), randomly choose a point \\(Y\\) from \\([0,x]\\). Find \\(\\mathbb{P}(0 &lt; Y &lt; \\frac14)\\)."
  },
  {
    "objectID": "lessons_old/27_Conditional_distributions/27_Conditional_distributions.html#independence-and-conditional-distributions",
    "href": "lessons_old/27_Conditional_distributions/27_Conditional_distributions.html#independence-and-conditional-distributions",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Independence and conditional distributions",
    "text": "Independence and conditional distributions\n    Question What is \\(f_{X|Y}(x|y)\\) if \\(X\\) and \\(Y\\) are independent?\n\\[f_{X|Y}(x|y) = \\dfrac{f_{X,Y}(x,y)}{f_y(y)} = \\dfrac{f_{X}(x)f_y(y)}{f_y(y)} = f_{X}(x)\\]\n       \n\nIf \\(f_{X|Y}(x|y)\\) does not depend on \\(y\\) (including the bounds/domain), then \\(X\\) and \\(Y\\) are independent."
  },
  {
    "objectID": "lessons_old/03_Independent_Events/03_Independent_Events.html",
    "href": "lessons_old/03_Independent_Events/03_Independent_Events.html",
    "title": "Chapter 3: Independent Events",
    "section": "",
    "text": "Define independence of 2-3 events given probability notation\nCalculate whether two or more events are independent"
  },
  {
    "objectID": "lessons_old/03_Independent_Events/03_Independent_Events.html#learning-objectives",
    "href": "lessons_old/03_Independent_Events/03_Independent_Events.html#learning-objectives",
    "title": "Chapter 3: Independent Events",
    "section": "",
    "text": "Define independence of 2-3 events given probability notation\nCalculate whether two or more events are independent"
  },
  {
    "objectID": "lessons_old/03_Independent_Events/03_Independent_Events.html#where-are-we",
    "href": "lessons_old/03_Independent_Events/03_Independent_Events.html#where-are-we",
    "title": "Chapter 3: Independent Events",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons_old/03_Independent_Events/03_Independent_Events.html#independent-events",
    "href": "lessons_old/03_Independent_Events/03_Independent_Events.html#independent-events",
    "title": "Chapter 3: Independent Events",
    "section": "Independent Events",
    "text": "Independent Events\n\n\nDefinition: Independence\n\n\nEvents \\(A\\) and \\(B\\) are independent if \\[\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B).\\]\n\n\nNotation: For shorthand, we sometimes write \\(A \\mathrel{\\unicode{x2AEB}} B,\\) to denote that \\(A\\) and \\(B\\) are independent events.\n \n\nAlso note: \\[\\begin{aligned} \\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B) & \\implies A \\mathrel{\\unicode{x2AEB}} B \\\\\nA \\mathrel{\\unicode{x2AEB}} B & \\implies \\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot  \\mathbb{P}(B) \\end{aligned}\\]"
  },
  {
    "objectID": "lessons_old/03_Independent_Events/03_Independent_Events.html#example-of-two-dice",
    "href": "lessons_old/03_Independent_Events/03_Independent_Events.html#example-of-two-dice",
    "title": "Chapter 3: Independent Events",
    "section": "Example of two dice",
    "text": "Example of two dice\n\n\nExample 1\n\n\nTwo dice (red and blue) are rolled. Let \\(A =\\) event a total of 7 appears, and \\(B =\\) event red die is a six. Are events \\(A\\) and \\(B\\) independent?"
  },
  {
    "objectID": "lessons_old/03_Independent_Events/03_Independent_Events.html#independence-of-3-events",
    "href": "lessons_old/03_Independent_Events/03_Independent_Events.html#independence-of-3-events",
    "title": "Chapter 3: Independent Events",
    "section": "Independence of 3 Events",
    "text": "Independence of 3 Events\n\n\nDefinition: Independence of 3 Events\n\n\nEvents \\(A\\), \\(B\\), and \\(C\\) are mutually independent if\n\n\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\cdot \\mathbb{P}(B)\\)\n\\(\\mathbb{P}(A \\cap C) = \\mathbb{P}(A) \\cdot \\mathbb{P}(C)\\)\n\\(\\mathbb{P}(B \\cap C) = \\mathbb{P}(B) \\cdot \\mathbb{P}(C)\\)\n\n\\(\\mathbb{P}(A \\cap B \\cap C) = \\mathbb{P}(A) \\cdot \\mathbb{P}(B) \\cdot \\mathbb{P}(C)\\)\n\n\n\nRemark:\nOn your homework you will show that \\((1) \\not \\Rightarrow (2)\\) and \\((2) \\not \\Rightarrow (1)\\)."
  },
  {
    "objectID": "lessons_old/03_Independent_Events/03_Independent_Events.html#probability-at-least-one-smoker",
    "href": "lessons_old/03_Independent_Events/03_Independent_Events.html#probability-at-least-one-smoker",
    "title": "Chapter 3: Independent Events",
    "section": "Probability at least one smoker",
    "text": "Probability at least one smoker\n\n\n\n\nExample 2\n\n\nSuppose you take a random sample of \\(n\\) people, of which people are smokers and non-smokers independently of each other. Let\n\n\\(A_i =\\) event person \\(i\\) is a smoker, for \\(i=1, \\ldots ,n\\), and\n\\(p_i =\\) probability person \\(i\\) is a smoker, for \\(i=1, \\ldots ,n\\).\n\nFind the probability that at least one person in the random sample is a smoker."
  },
  {
    "objectID": "lessons_old/03_Independent_Events/03_Independent_Events.html#building-geometric-series",
    "href": "lessons_old/03_Independent_Events/03_Independent_Events.html#building-geometric-series",
    "title": "Chapter 3: Independent Events",
    "section": "Building geometric series",
    "text": "Building geometric series\n\n\nExample 3\n\n\n\\(A, B,\\) and \\(C\\) toss a fair coin in order. The first to throw heads wins. What are their respective chances of winning?\n\n\nLet\n\n\\(A_H\\) and \\(A_T\\) be the events player A tosses heads and tails, respectively.\nSimilarly define \\(B_H\\), \\(B_T\\), \\(C_H\\), and \\(C_T\\)."
  },
  {
    "objectID": "lessons_old/02_Lang_prob/02_Lang_prob_muddy_points.html",
    "href": "lessons_old/02_Lang_prob/02_Lang_prob_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "1. Why is the number of possible events \\(2^{|S|}\\)?\nIn class, we were wondering why/if \\(2^{|S|}\\) is the general formula for calculating the total number of possible events. We were specifically wondering if the \\(2\\) came from the fact that we had two options (heads and tails) for our outcome. Let’s work through the example of a 6-sided die to explain this further. The sample space is \\(S=\\{1, 2, 3, 4, 5, 6\\}\\). So is the total number of possible events \\(2^6\\) or \\(6^6\\) or something else? We can actually think about an event by using an indicator variable for each outcome of the sample space. An indicator variable is just a way to give us a yes/no answer to a question. So in this case, we are wondering: is this outcome a part of our event? If our event is \\(\\{1\\}\\) then for the outcome \\(1\\), the answer is “yes, the outcome is part of the event. For outcomes \\(2-6\\), the answer is”no, the outcome is not apart of the event.”\n\nFor each outcome, we have a “yes” or “no” answer. We can look at another example of an event. Let’s say our event is rolling an even number:\n\nFor \\(2\\), \\(4\\), and \\(6\\), the answer is “yes.” We can define the indicator variable for whether an outcome is in an event or not. The indicator gives a 1 or 0 for yes and no respectively.\n\nAs stated above, the \\(2\\) in \\(2^6\\) comes from the \\(2\\) options from our indicator. Each side has two options, and there are \\(6\\) sides. Thus, \\(2^6\\) possible events.\n\n\n2. What is an event??\nI think this will become clearer when we start thinking about events in the context of probability. When we think of events outside of probability, we may think of something we actually do or something that happens, like going to a concert or coming to class or missing the streetcar. In this case, we think of the event as the single thing (out of all the options) that actually occured. For example, if I’m taking the streetcar to class, I can think of two definitive options of what might occur: I miss the streetcar or I get on the streetcar. Only one of these things can occur, which I may call an event colloquially.\nIt is important to make the distinction with events defined within probability. Events are not necessarily a single thing that occurred. Instead it can be a collection of things that may occur. In the example of the streetcar, I can define my event to include both options. Thus, my event is that I make the streetcar or I miss it. Both of these things cannot happen simultaneously, but if I want to calculate the probability that I miss or make the streetcar, then it is helpful to have the event defined.\n\nAnd what is the difference between event and outcome?\nAn outcome is a single result. The two options in the above example, missing the streetcar or getting on the streetcar, are two potential outcomes. Events are the collection of 0, 1, or more outcomes. So the possible events are: the empty set, missing the streetcar, getting on the streetcar, or the set of missing the streetcar and getting on the streetcar.\n\n\n\n3. Confusion on the Venn Diagram for the high blood pressure example\nThis is in reference to the Chapter 1 notes on “BP example variation (3/3)” slide. I explained the event that at least one subject does not have high blood pressure using a venn diagram. In this venn diagram, I assumed \\(n=4\\), and I wanted to show that the union of complements is equal to the complement of unions: \\(\\bigcup\\limits_{i=1}^{n}H_i^C = \\Big(\\bigcap\\limits_{i=1}^{n}H_i\\Big)^C\\).\n\n Now we can look at \\(\\bigcup\\limits_{i=1}^{4}H_i^C\\). We first need to define \\(H_i^c\\)\n\n\n\n\n\n4. Proofs of propositions\nFurther explanations of the propositions can be found in the textbook from pages 24-27. For many of the explanations in class, I was working to produce a union of disjoint events, so that the probability could easily be calculated. Proposition 3 and 4 were specifically mentioned, so I will include some writing notes on them here:\n\nProposition 3\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\nIn this proposition, I want to define event \\(B\\) as a union of disjoint events so that I can show \\(P(B)\\) is the sum of \\(P(A)\\) and some greater-than-or-equal-to 0 probability event. If the following is my venn diagram of A and B:\n\n\n\n\n\nThen I can define B as the union of disjoint events: \nIf we then take the probability of each side of the equation \\(B = A \\cup (A^c \\cap B)\\), we get \\[P(B) = P\\big(A \\cup (A^c \\cap B)\\big)\\]\nSince events \\(A\\) and \\(A^c \\cap B\\) are disjoint, the probability of their union is just: \\[P(A) + P(A^c \\cap B)\\]\nThus, our equation is now \\[P(B) = P(A) + P(A^c \\cap B)\\]\nFrom Axiom 1, we know for event \\(A^c \\cap B\\), \\(P(A^c \\cap B) \\geq 0\\).\nSo the probability of event B is the sum of the probability of event A and an event that is \\(\\geq\\) 0. This means \\(P(B) \\geq P(A)\\).\n\n\nProposition 4\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)\n\n\nFrom the pictures above, we can see some similar disjoint events.\nIf we look back at \\(A \\cup B\\), we can start manipulating the right side of the equation:\n\n \n\n\n\n5. Example at end of Chapter 2 slides (Venn Diagram)\nI will post this in the previous week’s Muddy Points as well. Please follow this link for my work through of the example. And here is the PDF with my work.\nSub-question: why don’t we just multiply the probability of A and B to get the intersection? This is a specific property of probability when A and B are independent. Only when A and B are independent can we conclude that \\(P(A \\cap B) = P(A)P(B)\\).\n\n\n6. Partition of events\nWe’ve been working with event partitions throughout Chapter 2, but we have not formally identified them. Partitions are advantageous to define for two reasons:\n\nThe partitions may be easier to calculate. We can then use the partitions to reconstruct other probabilities that may be more difficult to calculate\nPartitions have nice properties as a consequence of being disjoint. For example, the probability of the union of partitions is the sum of the probabilities across each partition: \\[P\\bigg(\\bigcup_{i=1}^n A_i\\bigg) = P(A_1)P(A_2)P(A_3) \\cdot \\cdot \\cdot P(A_n)\\]"
  },
  {
    "objectID": "lessons_old/07_Random_Variables/07_Random_Variables_key_info.html",
    "href": "lessons_old/07_Random_Variables/07_Random_Variables_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "For office hours, we decided to do appointments!\n\nHere’s my Calendly: https://calendly.com/nickywakim/15min\nI have it set up mostly for Tuesdays and Thursdays\nIt requires a day’s notice for appointments - mainly so I can plan my next day\n\nDid you turn in HW 01 Assignment?\n\nI’m missing one! So double check!\nThen I’ll post the solutions!"
  },
  {
    "objectID": "lessons_old/07_Random_Variables/07_Random_Variables_key_info.html#announcements",
    "href": "lessons_old/07_Random_Variables/07_Random_Variables_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "For office hours, we decided to do appointments!\n\nHere’s my Calendly: https://calendly.com/nickywakim/15min\nI have it set up mostly for Tuesdays and Thursdays\nIt requires a day’s notice for appointments - mainly so I can plan my next day\n\nDid you turn in HW 01 Assignment?\n\nI’m missing one! So double check!\nThen I’ll post the solutions!"
  },
  {
    "objectID": "lessons_old/07_Random_Variables/07_Random_Variables_key_info.html#key-dates",
    "href": "lessons_old/07_Random_Variables/07_Random_Variables_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 02 Assignment due this Thursday at 11pm\nNo HW 01 Solutions"
  },
  {
    "objectID": "lessons_old/22_Counting_Intro/22_Counting_Intro_key_info.html",
    "href": "lessons_old/22_Counting_Intro/22_Counting_Intro_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "For homework 1, you will need to the textbook! There is a link in the Syllabus and a pdf in our shared OneDrive folder.\n\nWhat’s out shared OneDrive folder?? OHSU uses OneDrive as cloud storage. Everyone should be able to access OneDrive with their OHSU email, in addition to many other Microsoft apps.  \nIn our shared folder, I put files that I cannot share publicly. You’ll see homework solutions, recordings, and textbooks in there. For the most part, I will place links on our website directly to the files. I don’t always do the best job of this, so please take a look at those files as well. \n\nDue days\n\nI don’t want anyone to feel anxious about when exactly HW 1 is due. Almost everyone has voted, and it looks like Thursdays will be the best day for homework assignments.\n\nA result of the voting and the notes about work schedules\n\nConsequently, I want to give you more than a week after assignments are due to turn in the solutions, so solutions will be due two Sundays after the assignment is due (10 days after).\nFor example, the assignment for HW 1 is due 10/10 at 11pm and the solutions for HW 1 will be due 10/20 at 11pm.\n\nHomework solution groups!!\n\nI added a link to a Microsoft form in Homework 1\nPlease specify who you would like to partner with\n\nOffice hours\n\nLet’s discuss\nLooks like Thursdays 1-2:30pm is best or 1-2pm on Tuesday"
  },
  {
    "objectID": "lessons_old/22_Counting_Intro/22_Counting_Intro_key_info.html#announcements",
    "href": "lessons_old/22_Counting_Intro/22_Counting_Intro_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "For homework 1, you will need to the textbook! There is a link in the Syllabus and a pdf in our shared OneDrive folder.\n\nWhat’s out shared OneDrive folder?? OHSU uses OneDrive as cloud storage. Everyone should be able to access OneDrive with their OHSU email, in addition to many other Microsoft apps.  \nIn our shared folder, I put files that I cannot share publicly. You’ll see homework solutions, recordings, and textbooks in there. For the most part, I will place links on our website directly to the files. I don’t always do the best job of this, so please take a look at those files as well. \n\nDue days\n\nI don’t want anyone to feel anxious about when exactly HW 1 is due. Almost everyone has voted, and it looks like Thursdays will be the best day for homework assignments.\n\nA result of the voting and the notes about work schedules\n\nConsequently, I want to give you more than a week after assignments are due to turn in the solutions, so solutions will be due two Sundays after the assignment is due (10 days after).\nFor example, the assignment for HW 1 is due 10/10 at 11pm and the solutions for HW 1 will be due 10/20 at 11pm.\n\nHomework solution groups!!\n\nI added a link to a Microsoft form in Homework 1\nPlease specify who you would like to partner with\n\nOffice hours\n\nLet’s discuss\nLooks like Thursdays 1-2:30pm is best or 1-2pm on Tuesday"
  },
  {
    "objectID": "lessons_old/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html",
    "href": "lessons_old/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "",
    "text": "Calculate the mean (expected value) of a joint distribution of continuous RV"
  },
  {
    "objectID": "lessons_old/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#learning-objectives",
    "href": "lessons_old/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#learning-objectives",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "",
    "text": "Calculate the mean (expected value) of a joint distribution of continuous RV"
  },
  {
    "objectID": "lessons_old/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#remark-on-expected-value-of-one-rv-from-joint-pdf",
    "href": "lessons_old/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#remark-on-expected-value-of-one-rv-from-joint-pdf",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "Remark on expected value of one RV from joint pdf",
    "text": "Remark on expected value of one RV from joint pdf\nIf you are given \\(f_{X,Y}(x,y)\\) and want to calculate \\(\\mathbb{E}[X]\\), you have two options:\n\nFind \\(f_X(x)\\) and use it to calculate \\(\\mathbb{E}[X]\\).\nOr, calculate \\(\\mathbb{E}[X]\\) using the joint density: \\[\\mathbb{E}[X] = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}x f_{X,Y}(x,y)dydx.\\]"
  },
  {
    "objectID": "lessons_old/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-1-expected-value-from-a-joint-distribution",
    "href": "lessons_old/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-1-expected-value-from-a-joint-distribution",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "Option 1: Expected value from a joint distribution",
    "text": "Option 1: Expected value from a joint distribution\n\n\n\n\nExample 3\n\n\nLet \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons_old/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-2-expected-value-from-a-joint-distribution",
    "href": "lessons_old/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-2-expected-value-from-a-joint-distribution",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "Option 2: Expected value from a joint distribution",
    "text": "Option 2: Expected value from a joint distribution\n\n\n\n\nExample 1\n\n\nLet \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons_old/26_Independent_rvs/26_Independent_rvs.html",
    "href": "lessons_old/26_Independent_rvs/26_Independent_rvs.html",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "",
    "text": "Show that a joint pdf consists of two independent, continuous RVs.\nCombine two independent RVs into one joint pdf or CDF."
  },
  {
    "objectID": "lessons_old/26_Independent_rvs/26_Independent_rvs.html#learning-objectives",
    "href": "lessons_old/26_Independent_rvs/26_Independent_rvs.html#learning-objectives",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "",
    "text": "Show that a joint pdf consists of two independent, continuous RVs.\nCombine two independent RVs into one joint pdf or CDF."
  },
  {
    "objectID": "lessons_old/26_Independent_rvs/26_Independent_rvs.html#how-do-we-represent-independent-continuous-rvs-in-a-joint-pdf",
    "href": "lessons_old/26_Independent_rvs/26_Independent_rvs.html#how-do-we-represent-independent-continuous-rvs-in-a-joint-pdf",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "How do we represent independent continuous RVs in a joint pdf?",
    "text": "How do we represent independent continuous RVs in a joint pdf?\n\n\nWhat do we know about independence for events and discrete RVs?\nFor events: If \\(A \\perp B\\)\n\\[P(A \\cap B) = P(A)P(B)\\] \\[P(A|B) = P(A)\\]\nFor discrete RVs: If \\(X \\perp Y\\) \\[p_{X,Y}(x,y) = p_{X}(x)p_{Y}(y)\\] \\[F_{X,Y}(x,y) = F_{X}(x)F_{Y}(y)\\] \\[p_{X|Y}(x|y) = p_{X}(x)\\] \\[p_{Y|X}(y|x) = p_{Y}(y)\\]\n\n\n\nWhat does it mean for continuous r.v.’s to be independent?\nFor continuous RVs: If \\(X \\perp Y\\)"
  },
  {
    "objectID": "lessons_old/26_Independent_rvs/26_Independent_rvs.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs",
    "href": "lessons_old/26_Independent_rvs/26_Independent_rvs.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Constructing a joint pdf from two independent, continuous RVs",
    "text": "Constructing a joint pdf from two independent, continuous RVs\n\n\n\n\nExample 1.1\n\n\nLet \\(X\\) and \\(Y\\) be independent r.v.’s with \\(f_X(x)= \\frac12\\), for \\(0 \\leq x \\leq 2\\) and \\(f_Y(y)= 3y^2\\), for \\(0 \\leq y \\leq 1\\).\n\nFind \\(f_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "lessons_old/26_Independent_rvs/26_Independent_rvs.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs-1",
    "href": "lessons_old/26_Independent_rvs/26_Independent_rvs.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs-1",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Constructing a joint pdf from two independent, continuous RVs",
    "text": "Constructing a joint pdf from two independent, continuous RVs\n\n\n\n\nExample 1.2\n\n\nLet \\(X\\) and \\(Y\\) be independent r.v.’s with \\(f_X(x)= \\frac12\\), for \\(0 \\leq x \\leq 2\\) and \\(f_Y(y)= 3y^2\\), for \\(0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)."
  },
  {
    "objectID": "lessons_old/26_Independent_rvs/26_Independent_rvs.html#showing-independence-from-joint-pdf",
    "href": "lessons_old/26_Independent_rvs/26_Independent_rvs.html#showing-independence-from-joint-pdf",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Showing independence from joint pdf",
    "text": "Showing independence from joint pdf\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for \\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\).\n\nAre \\(X\\) and \\(Y\\) independent?"
  },
  {
    "objectID": "lessons_old/26_Independent_rvs/26_Independent_rvs.html#finding-cdf-from-two-independent-rvs",
    "href": "lessons_old/26_Independent_rvs/26_Independent_rvs.html#finding-cdf-from-two-independent-rvs",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Finding CDF from two independent RVs",
    "text": "Finding CDF from two independent RVs\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for \\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(F_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "lessons_old/26_Independent_rvs/26_Independent_rvs.html#showing-independence-from-joint-pdf-1",
    "href": "lessons_old/26_Independent_rvs/26_Independent_rvs.html#showing-independence-from-joint-pdf-1",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Showing independence from joint pdf",
    "text": "Showing independence from joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 3\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Are \\(X\\) and \\(Y\\) independent?"
  },
  {
    "objectID": "lessons_old/26_Independent_rvs/26_Independent_rvs.html#final-statement-on-independence",
    "href": "lessons_old/26_Independent_rvs/26_Independent_rvs.html#final-statement-on-independence",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "Final statement on independence",
    "text": "Final statement on independence\n\nIf \\(f_{X,Y}(x,y)= g(x)h(y)\\), where \\(g(x)\\) and \\(h(y)\\) are pdf’s, then \\(X\\) and \\(Y\\) are independent.\n\nThe domain of the joint pdf needs to be independent as well!!\n\n\n       \n\nIf \\(F_{X,Y}(x,y)= G(x)H(y)\\), where \\(G(x)\\) and \\(H(y)\\) are cdf’s, then \\(X\\) and \\(Y\\) are independent.\n\nThe domain of the joint CDF needs to be independent as well!!"
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities_muddy_points.html",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n1. How do pdf, CDF, and probability interact with each other?\nLet’s say we have a pdf, \\(f_X(x) = \\dfrac{1}{9}x^2\\) for \\(0 \\leq x \\leq 3\\). This is just a function. The pdf is not used on its own to report any probability. We must integrate over the pdf to find a probability.\n\nlibrary(\"ggplot2\")\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3)\n\n\n\n\n\n\n\n\nThe total area under the pdf is 1. This makes our pdf valid.\n\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 3),\n                geom = \"area\", \n                aes(fill = \"red\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 1\", color = \"black\")\n\n\n\n\n\n\n\n\nIf we only look at a proportion of the area under the pdf, then we start constructing our probabilities. For example, we can look at probability that we have a value between 0 and 1.5.\n\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 1.5),\n                geom = \"area\", \n                aes(fill = \"blue\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 0.125\", color = \"black\")\n\n\n\n\n\n\n\n\nInstead of calculating the EXACT probability for each value between 0 and 3, we can find the CDF of the pdf.\nThe CDF is: \\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;3 \\quad \\\\\n            \\dfrac{1}{27}x^3 & \\quad 0 \\leq x \\leq 3\\quad \\\\\n            1 & \\quad x&gt;3 \\quad\n        \\end{array}\n    \\right.\n\\]\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nWhen \\(x=1.5\\), we can calculate the probability using the CDF. Remember that \\(F_X(x) = P(X \\leq x)\\). So we can say \\(P(X \\leq 1.5) = F_X(1.5) = \\dfrac{1}{27}(1.5)^3\\), which equals 0.125.\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\") +\n  geom_point(aes(x=1.5, y=.125), colour=\"blue\", size=3) +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"CDF = 0.125\", color = \"black\")\n\nWarning in geom_point(aes(x = 1.5, y = 0.125), colour = \"blue\", size = 3): All aesthetics have length 1, but the data has 2 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\nWe can also calculate the probability with an integral: \\(P(X \\leq 1.5) = \\displaystyle\\int_0^{1.5} \\dfrac{1}{9}x^2 dx\\).\nWe can also find the probability that X is between two numbers. \\(P(1\\leq X \\leq 1.5) = F_X(1.5) - F_X(1)\\) or \\(P(1\\leq X \\leq 1.5) = \\displaystyle\\int_1^{1.5} \\dfrac{1}{9}x^2 dx\\).\n\n\n2. Joint vs marginal vs conditional: How are we calculating the probability?\nIf we start at a joint probability \\(f_{X,Y}(x,y)\\)…. we can look at a few probabilities:\n\nJoint probability: \\(P(a \\leq X \\leq b, c \\leq Y \\leq d)\\)\n\\[P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=c}^{y=d} f_{X,Y}(x,y) dydx\\]\nMarginal probability: \\(P(a \\leq X \\leq b)\\)\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b} f_{X}(x) dx\\]\nOR\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=-\\inf}^{y=\\inf} f_{X,Y}(x,y) dydx\\]\nConditional probability: \\(P(a \\leq X \\leq b | Y = c)\\)\n\\[P(a \\leq X \\leq b | Y=c) = \\displaystyle\\int_{x=a}^{x=b} f_{X|Y}(x|y=c) dx\\]\nYou cannot calculate \\(P(a \\leq X \\leq b | Y = c)\\) by \\(\\dfrac{P(a \\leq X \\leq b, Y=c)}{P(Y = c)}\\) because \\(P(Y = c)\\) is 0. Instead, we need to find \\(f_{X|Y}(x|y=c)\\) by \\(\\dfrac{f_{X,Y}(x,y=c)}{f_{Y}(y=c)}\\) and THEN integrate over X.\n\n\n\n3. What are we actually finding by solving the double integral. In the first example, we found the probability was 1/16 after integrating but what does 1/16 mean in relation to the random variables X and Y?\nIt means that the volume contained by \\(0\\leq X \\leq 1\\), \\(0\\leq Y \\leq 1/2\\), and their joint pdf is 1/16 of the total volume contained by \\(0\\leq X \\leq 2\\), \\(0\\leq Y \\leq 1\\), and their joint pdf. The probability for a joint pdf is now a measure of the proportion of the volume.\nThis is not be confused with a probability from marginal pdf or pdf from one RV. The probability for marginal/single RV pdfs is the proportion of the area under the pdf for a specific range of values.\n\n\n4. Here’s a 3D plot of one of our joint pdf’s\n\\[\nf_{X,Y}(x,y) = 5e^{-x-3y} \\text{ for } 0 \\leq y \\leq x/2\n\\]\n\nlibrary(plotly)\n\nx = seq(0, 5, 0.1)\ny = seq(0, max(x)/2, 0.1/2)\nfn = expand.grid(x=x,y=y)\nfn$z = ifelse(fn$y&lt;fn$x/2, 5*exp( (-1)*fn$x - 3*fn$y), NA)\n\nz = matrix(fn$z, ncol = 51, nrow = 51, byrow = T)\n\nfig &lt;- plot_ly(x = x, y=y, z=z) %&gt;% add_surface()\n\nfig"
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities.html",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities.html",
    "title": "Chapter 25: Joint densities",
    "section": "",
    "text": "Solve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities.html#learning-objectives",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities.html#learning-objectives",
    "title": "Chapter 25: Joint densities",
    "section": "",
    "text": "Solve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities.html#double-integrals-mini-lesson-13",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities.html#double-integrals-mini-lesson-13",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (1/3)",
    "text": "Double Integrals Mini Lesson (1/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 1\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} xy dydx\\)"
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities.html#double-integrals-mini-lesson-23",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities.html#double-integrals-mini-lesson-23",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (2/3)",
    "text": "Double Integrals Mini Lesson (2/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 2\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} (x+y) dydx\\)"
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities.html#double-integrals-mini-lesson-33",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities.html#double-integrals-mini-lesson-33",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (3/3)",
    "text": "Double Integrals Mini Lesson (3/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 3\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} e^{x+y} dydx\\)"
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "title": "Chapter 25: Joint densities",
    "section": "How to define the joint pdf for continuous RVs?",
    "text": "How to define the joint pdf for continuous RVs?\n\n\nFor a single continuous RV \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\), \\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\]\n\nFor two continuous RVs (\\(X\\) and \\(Y\\)), we can define the joint pdf, \\(f_{X,Y}(x,y)\\), such that for all real values \\(a,b, c, d\\) with \\(a \\leq b\\) and \\(c \\leq d\\), \\[\\mathbb{P}(a \\leq X \\leq b, c \\leq Y \\leq d) = \\int_a^b \\int_c^d f_{X,Y}(x,y)dydx\\]"
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities.html#important-properties-of-the-joint-pdf",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities.html#important-properties-of-the-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Important properties of the joint pdf",
    "text": "Important properties of the joint pdf\n\nNote that \\(f_{X,Y}(x,y)\\neq \\mathbb{P}(X=x, Y=y)\\)!!!\nIn order for \\(f_{X,Y}(x,y)\\) to be a pdf, it needs to satisfy the properties\n\n\\(f_{X,Y}(x,y)\\geq 0\\) for all \\(x,y\\)\n\\(\\displaystyle\\int_{-\\infty}^{\\infty}\\displaystyle\\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dxdy=1\\)"
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "title": "Chapter 25: Joint densities",
    "section": "What is the joint cumulative distribution function?",
    "text": "What is the joint cumulative distribution function?\n\n\nDefinition: Joint cumulative distribution function (Joint CDF)\n\n\nThe joint cumulative distribution function (cdf) of continuous random variables \\(X\\) and \\(Y\\), is the function \\(F_{X,Y}(x,y)\\), such that for all real values of \\(x\\) and \\(y\\), \\[F_{X,Y}(x,y)= \\mathbb{P}(X \\leq x, Y \\leq y) = \\int_{-\\infty}^x\\int_{-\\infty}^y f_{X,Y}(s,t)dtds\\]\n\n\nRemarks:\n\nThe definition above for \\(F_{X,Y}(x,y)\\) is a function of \\(x\\) and \\(y\\).\nThe joint cdf at the point \\((a,b)\\), is \\[F_{X,Y}(a,b) = \\mathbb{P}(X \\leq a, Y \\leq b) = \\int_{-\\infty}^a\\int_{-\\infty}^b f_{X,Y}(s,t)dtds\\]"
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities.html#what-are-the-marginal-pdfs",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities.html#what-are-the-marginal-pdfs",
    "title": "Chapter 25: Joint densities",
    "section": "What are the marginal pdf’s?",
    "text": "What are the marginal pdf’s?\n\n\nDefinition: Marginal pdf’s\n\n\nSuppose \\(X\\) and \\(Y\\) are continuous r.v.’s, with joint pdf \\(f_{X,Y}(x,y)\\). Then the marginal probability density functions are \\[\\begin{aligned}\nf_X(x)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dy\\\\\nf_Y(y)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dx\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities.html#common-steps-for-solving-problems",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities.html#common-steps-for-solving-problems",
    "title": "Chapter 25: Joint densities",
    "section": "Common steps for solving problems",
    "text": "Common steps for solving problems\n\nSet up the domain of the pdf with a picture\nTranslate to needed integrands\n\nFor probability: shade in the area of interest, then translate\nFor expected value: translate domain\n\nSet up integral: \\(dxdy\\) or \\(dydx\\)?\nSolve integral!"
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities.html#example-of-joint-pdf",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities.html#example-of-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)."
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities.html#example-of-joint-pdf-1",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities.html#example-of-joint-pdf-1",
    "title": "Chapter 25: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "title": "Chapter 25: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(\\mathbb{P}(Y &lt; 3)\\)."
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-more",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-more",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.1\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nFind \\(\\mathbb{P}(|X-Y| &lt; 2)\\)"
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "title": "Chapter 25: Joint densities",
    "section": "Finding the pdf of a transformation",
    "text": "Finding the pdf of a transformation\n\nLet \\(M\\) be a transformation of \\(X\\) and \\(Y\\)\nWhen we have a transformation of \\(X\\) and \\(Y\\), \\(M\\), we need to follow a specific process to find the pdf of \\(M\\)\n\nWe follow this process:\n\nStart with the joint pdf for \\(X\\) and \\(Y\\)\n\naka \\(f_{X,Y}(x, y)\\)\n\nTranslate the domain of \\(X\\) and \\(Y\\) to \\(M\\)\nFind the CDF of \\(M\\)\n\naka \\(F_M(m)\\) or \\(P(M \\leq m)\\)\n\nTake the derivative of the CDF of \\(M\\) to find the pdf of \\(M\\)\n\naka \\(f_M(m) = \\dfrac{d}{dm}F_M(m)\\)"
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-more-1",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-more-1",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.2\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(M = \\max(X,Y)\\). Find the pdf for \\(M\\), that is \\(f_M(m)\\)."
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-more-2",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-more-2",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 3.3\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(Z = \\min(X,Y)\\). Find the pdf for \\(Z\\), that is \\(f_Z(z)\\)."
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-further",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities.html#lets-complicate-this-even-further",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even further!",
    "text": "Let’s complicate this even further!\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 4\n\n\nLet \\(X\\) and \\(Y\\) have joint density \\(f_{X,Y}(x,y)= \\frac85(x+y)\\) in the region \\(0 &lt; x &lt; 1,\\ \\frac12 &lt; y &lt;1\\). Find the pdf of the r.v. \\(Z\\), where \\(Z=XY\\)."
  },
  {
    "objectID": "lessons_old/43_02_Moment_Generating_Functions/43_Moment_Generating_Functions_Part2.html",
    "href": "lessons_old/43_02_Moment_Generating_Functions/43_Moment_Generating_Functions_Part2.html",
    "title": "Chapter 43: Moment Generating Functions Part 2",
    "section": "",
    "text": "Chapter 43: Moment Generating Functions Part 2\nRecap: What is an mgf?\n\nExample 1.   Let \\(X\\) be a random variable with mgf \\[M_X(t)= \\frac{1}{5}e^t + \\frac{3}{10}e^{2t} + \\frac{1}{2}e^{3t}.\\] Find the pmf or pdf of \\(X\\).\n\n\nExample 2.   Let \\(X\\) be a normal random variable with mean \\(\\mu\\) and variance \\(\\sigma^2\\), i.e. \\(X \\sim N(\\mu,\\sigma^2)\\).\n\nFind the mgf of \\(X\\).\nFind \\(\\mathbb{E}[X]\\).\nFind \\(Var(X)\\).\n\n\n\n\nTheorem 3.   Let \\(X\\) have mgf \\(M_X(t)\\), and let \\(Y=aX+b\\), where \\(a\\) and \\(b\\) are constants. Then \\[M_Y(t)=\\]\n\n\nProof. Proof. ◻\n\nQuestion: Do linear transformations always preserve the distribution type?\nI.e., if \\(X\\) has a certain probability distribution, does \\(aX+b\\) always have the same distribution type?\n\n\nExample 4.   Let \\(X \\sim U[0,1]\\), and \\(Y = 2X+3\\). Is \\(Y\\) also a uniform rv? If so, what are its parameters?\n\n\nExample 5.   Let \\(X \\sim Exp(\\lambda=5)\\), and \\(Y = 2X+3\\). Is \\(Y\\) also an exponential rv? If so, what is its parameter?\n\nMgf’s of Sums of Independent rv’s\n\n\nTheorem 6.   Let \\(X_1, X_2, \\ldots, X_n\\) be independent rv’s with respective mgf’s \\(M_{X_i}(t)\\), for \\(i=1,2,\\ldots,n\\). Let \\(Y=\\sum_{i=1}^n a_iX_i\\), where \\(a_i\\) are constants. Then \\[M_Y(t)= %\\Pi_{i=1}^n M_{X_i}(a_it).\\]\n\n\nProof. Proof. ◻\n\n\n\nExample 7.   Let \\(X_i \\sim N(\\mu_i, \\sigma_i^2)\\) be independent normal rv’s. What is the distribution of  \\(Y=\\sum_{i=1}^n X_i\\)?\n\n\n\nExample 8.   Let \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). What is the distribution of  \\(\\bar{X}=\\frac{\\sum_{i=1}^n X_i}{n}\\)?\n\n\nExample 9.   Let \\(Z\\) be a standard normal random variable, i.e. \\(Z \\sim N(0,1)\\). Show that \\(Z^2 \\sim \\chi_1^2\\), i.e. is a chi-squared rv with 1 degree of freedom."
  },
  {
    "objectID": "lessons_old/10_Expected_Values/10_Expected_Values_key_info.html",
    "href": "lessons_old/10_Expected_Values/10_Expected_Values_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 03 assignment today\nGroup evals will be taken off the assessment breakdown\nMid-quarter feedback will be put on HW 05"
  },
  {
    "objectID": "lessons_old/10_Expected_Values/10_Expected_Values_key_info.html#announcements",
    "href": "lessons_old/10_Expected_Values/10_Expected_Values_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 03 assignment today\nGroup evals will be taken off the assessment breakdown\nMid-quarter feedback will be put on HW 05"
  },
  {
    "objectID": "lessons_old/10_Expected_Values/10_Expected_Values_key_info.html#key-dates",
    "href": "lessons_old/10_Expected_Values/10_Expected_Values_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 04 assignment due Thursday\nHW 03 solutions due Sunday\n\nAnd we will have a presentation on this one!"
  },
  {
    "objectID": "lessons_old/28_Expected_Values/28_Expected_Values.html",
    "href": "lessons_old/28_Expected_Values/28_Expected_Values.html",
    "title": "Chapter 28: Expected Values of Continuous Random Variables",
    "section": "",
    "text": "Calculate the mean (expected value) of a continuous RV"
  },
  {
    "objectID": "lessons_old/28_Expected_Values/28_Expected_Values.html#learning-objectives",
    "href": "lessons_old/28_Expected_Values/28_Expected_Values.html#learning-objectives",
    "title": "Chapter 28: Expected Values of Continuous Random Variables",
    "section": "",
    "text": "Calculate the mean (expected value) of a continuous RV"
  },
  {
    "objectID": "lessons_old/28_Expected_Values/28_Expected_Values.html#expected-value-of-a-function-of-a-continuous-rv",
    "href": "lessons_old/28_Expected_Values/28_Expected_Values.html#expected-value-of-a-function-of-a-continuous-rv",
    "title": "Chapter 28: Expected Values of Continuous Random Variables",
    "section": "Expected value of a function of a continuous RV",
    "text": "Expected value of a function of a continuous RV\n\n\nHow do we calculate expected values of discrete RVs?\n       \nFor discrete RVs: weight average \\[\\mathbb{E}[X] = \\sum_{i=1}^n x_ip_X(x_i).\\]\n\n\n\nHow do we calculate expected values of continuous RVs?\n       \nFor continuous RVs:"
  },
  {
    "objectID": "lessons_old/28_Expected_Values/28_Expected_Values.html#expected-value-of-the-uniform-distribution",
    "href": "lessons_old/28_Expected_Values/28_Expected_Values.html#expected-value-of-the-uniform-distribution",
    "title": "Chapter 28: Expected Values of Continuous Random Variables",
    "section": "Expected Value of the Uniform Distribution",
    "text": "Expected Value of the Uniform Distribution\n\n\n\n\nExample 1\n\n\nLet \\(f_X(x)= \\frac{1}{b-a}\\), for \\(a \\leq x \\leq b\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons_old/28_Expected_Values/28_Expected_Values.html#expected-value-of-the-exponential-distribution",
    "href": "lessons_old/28_Expected_Values/28_Expected_Values.html#expected-value-of-the-exponential-distribution",
    "title": "Chapter 28: Expected Values of Continuous Random Variables",
    "section": "Expected Value of the Exponential Distribution",
    "text": "Expected Value of the Exponential Distribution\n\n\n\n\nExample 2\n\n\nLet \\(f_X(x)= \\lambda e^{-\\lambda x}\\), for \\(x &gt; 0\\) and \\(\\lambda&gt; 0\\). Find \\(\\mathbb{E}[X]\\).\n\n\n\n\nIntegrating by Parts\n\n\n\\(\\displaystyle\\int_a^b u dv = uv\\bigg|^b_a - \\displaystyle\\int_a^b vdu\\)"
  },
  {
    "objectID": "lessons_old/09_Joint_distributions/09_Joint_distributions_key_info.html",
    "href": "lessons_old/09_Joint_distributions/09_Joint_distributions_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 02 assignments are graded!\n\nSolutions and videos are posted!\n\nFinish the discrete distributions notes\n\nThen get into joint distributions"
  },
  {
    "objectID": "lessons_old/09_Joint_distributions/09_Joint_distributions_key_info.html#announcements",
    "href": "lessons_old/09_Joint_distributions/09_Joint_distributions_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 02 assignments are graded!\n\nSolutions and videos are posted!\n\nFinish the discrete distributions notes\n\nThen get into joint distributions"
  },
  {
    "objectID": "lessons_old/09_Joint_distributions/09_Joint_distributions_key_info.html#key-dates",
    "href": "lessons_old/09_Joint_distributions/09_Joint_distributions_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 03 Assignment due this Thursday at 11pm\n\nI updated the homework assignment on the 18th!"
  },
  {
    "objectID": "lessons_old/00_Intro/00_Intro.html",
    "href": "lessons_old/00_Intro/00_Intro.html",
    "title": "Welcome to BSTA 550!",
    "section": "",
    "text": "Call me “Nicky,” “Dr. W,” “Professor Wakim,” or any combo!\nAssistant Professor of Biostatistics\n \nGrew up in DC area (Virginia side!)\nMoved here from Michigan around 2 years ago\nTwo sweet kitties\nVolleyball, pickleball, ceramics, strolling around my neighborhood\nBut also sleeping, TV, and reading\nProud plant mamma\nA few other things about myself that I will share non-publicly\n\n\n\n\n Video"
  },
  {
    "objectID": "lessons_old/00_Intro/00_Intro.html#nicky-wakim-sheher",
    "href": "lessons_old/00_Intro/00_Intro.html#nicky-wakim-sheher",
    "title": "Welcome to BSTA 550!",
    "section": "",
    "text": "Call me “Nicky,” “Dr. W,” “Professor Wakim,” or any combo!\nAssistant Professor of Biostatistics\n \nGrew up in DC area (Virginia side!)\nMoved here from Michigan around 2 years ago\nTwo sweet kitties\nVolleyball, pickleball, ceramics, strolling around my neighborhood\nBut also sleeping, TV, and reading\nProud plant mamma\nA few other things about myself that I will share non-publicly\n\n\n\n\n Video"
  },
  {
    "objectID": "lessons_old/00_Intro/00_Intro.html#some-important-tasks",
    "href": "lessons_old/00_Intro/00_Intro.html#some-important-tasks",
    "title": "Welcome to BSTA 550!",
    "section": "Some important tasks",
    "text": "Some important tasks\n\nJoin the Slack page!\nStar the class website: https://nwakim.github.io/BSTA_550_F24/\nComplete the WhenIsGood for office hours\nComplete Homework 0 by this Thursday at 11pm!\n\nIncludes some items above\nThink about what day of the week you would like your homeworks due\n\nHighly suggest that you make an appointment with a learning specialist through Student Academic Success Center!"
  },
  {
    "objectID": "lessons_old/00_Intro/00_Intro.html#lets-visit-the-website-homepage",
    "href": "lessons_old/00_Intro/00_Intro.html#lets-visit-the-website-homepage",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website: Homepage",
    "text": "Let’s visit the website: Homepage\n\n\n\nHomepage"
  },
  {
    "objectID": "lessons_old/00_Intro/00_Intro.html#lets-visit-the-website-syllabus",
    "href": "lessons_old/00_Intro/00_Intro.html#lets-visit-the-website-syllabus",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website: Syllabus",
    "text": "Let’s visit the website: Syllabus\n\nCourse learning objectives\nTextbook in shared folder!\nResources: PennState STAT 414 site!\nR: not a big worry in our class, you will get a lot of help in BSTA 511\nAssessments and grade breakdowns\nHomework: 3 parts + grading\nFeedback: in the form of exit tickets, group evals, midterm feedback, and final course\nHow to succeed in this course: resources and assignments explained\nLate work policy / Attendance policy\nChatGPT and other AI technology\nCourse expectations: a few ways that I will show you respect and commitment to you as students\n\nAnd a few ways I expect from you!\n\nCommunicating with me: give me 24 hours to reply M-F\n\nOnline communication is not my strength!"
  },
  {
    "objectID": "lessons_old/00_Intro/00_Intro.html#lets-visit-the-website-schedule-12",
    "href": "lessons_old/00_Intro/00_Intro.html#lets-visit-the-website-schedule-12",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website: Schedule (1/2)",
    "text": "Let’s visit the website: Schedule (1/2)\n\nWeeks, class info, exams, homeworks"
  },
  {
    "objectID": "lessons_old/00_Intro/00_Intro.html#lets-visit-the-website-schedule-22",
    "href": "lessons_old/00_Intro/00_Intro.html#lets-visit-the-website-schedule-22",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website: Schedule (2/2)",
    "text": "Let’s visit the website: Schedule (2/2)\n\n\n\n\nKey Info\nI will post announcements and other important class related info here. For example, if I change a due date or discuss a common mistake in homework, I will put it here.\n\n\n\nSlides QMD\nThese are the basic slides that will open in your browser.\n\n\n\nSlides PDF\nThese are the slides in pdf form for easy note taking. I’m not always the best at posting these before class, so make sure you know how to save your own copy of pdf slides!\n\n\n\nSlides Notes\nThese are the annotated slides in pdf form. In class, I add my own notes to slides. After class, I will post them here.\n\n\n\nExit tix\nThese are links to that day’s exit ticket.\n\n\n\nRecording\nI record our classes. This will be a link to the OneDrive folder containing this recording.\n\n\n\nMuddy Points\nYou will have a chance to ask questions about class in your exit tickets. If I notice a trend in confusion, I will add explanations to these “Muddy Points”"
  },
  {
    "objectID": "lessons_old/00_Intro/00_Intro.html#lets-visit-the-website-search",
    "href": "lessons_old/00_Intro/00_Intro.html#lets-visit-the-website-search",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website: Search",
    "text": "Let’s visit the website: Search"
  },
  {
    "objectID": "lessons_old/00_Intro/00_Intro.html#lets-visit-the-website-homework",
    "href": "lessons_old/00_Intro/00_Intro.html#lets-visit-the-website-homework",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website: Homework!",
    "text": "Let’s visit the website: Homework!"
  },
  {
    "objectID": "lessons_old/00_Intro/00_Intro.html#decision-on-homework-due-dates",
    "href": "lessons_old/00_Intro/00_Intro.html#decision-on-homework-due-dates",
    "title": "Welcome to BSTA 550!",
    "section": "Decision on Homework due dates",
    "text": "Decision on Homework due dates\n\nI have some set due dates in the schedule\nPlease look at your other classes, your calendar, etc\nConsider what day of the week you would like to turn in your assignment, solutions, and video/meeting\nQuestion in HW 0 to cast your vote and share your opinion"
  },
  {
    "objectID": "lessons_old/00_Intro/00_Intro.html#structure-for-this-course",
    "href": "lessons_old/00_Intro/00_Intro.html#structure-for-this-course",
    "title": "Welcome to BSTA 550!",
    "section": "Structure for this course",
    "text": "Structure for this course\n\nLearning the basic tools to understand statistics\nIt is going to feel useless at times, but I swear it is not!\nThis class will help you build a toolbox that allows to analyze data while understanding the inner theory at play"
  },
  {
    "objectID": "lessons_old/00_Intro/00_Intro.html#what-we-will-cover",
    "href": "lessons_old/00_Intro/00_Intro.html#what-we-will-cover",
    "title": "Welcome to BSTA 550!",
    "section": "What we will cover",
    "text": "What we will cover"
  },
  {
    "objectID": "lessons_old/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html",
    "href": "lessons_old/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "",
    "text": "Calculate expected value of functions of RVs\nCalculate variance of RVs"
  },
  {
    "objectID": "lessons_old/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#learning-objectives",
    "href": "lessons_old/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#learning-objectives",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "",
    "text": "Calculate expected value of functions of RVs\nCalculate variance of RVs"
  },
  {
    "objectID": "lessons_old/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#expected-value-of-a-function-of-a-continuous-rv",
    "href": "lessons_old/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#expected-value-of-a-function-of-a-continuous-rv",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Expected value of a function of a continuous RV",
    "text": "Expected value of a function of a continuous RV\n\n\nHow do we calculate the expected value of a function of a discrete RV or joint RVs?\n   \nFor discrete RVs:\n\\[\\mathbb{E}[g(X)] = \\sum_{\\{all\\ x\\}}\\ g(x) p_X(x).\\] \\[\\mathbb{E}[g(X, Y)] = \\sum_{\\{all\\ x\\}}\\sum_{\\{all\\ y\\}}\\ g(x,y) p_{X,Y}(x,y).\\]\n\n\n\nHow do we calculate the expected value of a function of a continuous RV or joint RVs?\n   \nFor continuous RVs:"
  },
  {
    "objectID": "lessons_old/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#important-properties-of-expected-values-of-functions-of-continuous-rvs",
    "href": "lessons_old/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#important-properties-of-expected-values-of-functions-of-continuous-rvs",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Important properties of expected values of functions of continuous RVs",
    "text": "Important properties of expected values of functions of continuous RVs\n\n\n\n\nFunction of RV with two constants\n\n\n\\(\\mathbb{E}[aX+b] =a\\mathbb{E}[X]+b\\)\n\n\n\n\nFunction of two RVs added\n\n\n\\(\\mathbb{E}[X+Y] =\\mathbb{E}[X]+\\mathbb{E}[Y]\\)\n\n\n\n\nExpected value of sum of independent RVs pt 1\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are continuous RVs and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\[\\mathbb{E}\\Bigg[\\sum_{i=1}^{n} a_i X_i\\Bigg] = \\sum_{i=1}^{n}a_i\\mathbb{E}[X_i]\\]\n\n\n\n\n\nExpected value of multiplication of function of independent RVs\n\n\nIf \\(X\\) and \\(Y\\) are independent continuous RVs, and \\(g\\) and \\(h\\) are functions, then \\[\\mathbb{E}[g(X)h(Y)] =\\mathbb{E}[g(X)]\\mathbb{E}[h(Y)]\\]\n\n\n\n\nExpected value of multiplication of independent RVs\n\n\nIf \\(X\\) and \\(Y\\) are independent continuous RVs, then \\[\\mathbb{E}[XY] = \\mathbb{E}[X] \\mathbb{E}[Y] \\]"
  },
  {
    "objectID": "lessons_old/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-continuous-rvs",
    "href": "lessons_old/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-continuous-rvs",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Variance of continuous RVs",
    "text": "Variance of continuous RVs\n\n\nHow do we calculate the variance of a discrete RV?\n   \nFor discrete RVs:\n\\[\n\\begin{align}\nVar(X) & =\n\\mathbb{E}[(X-\\mu_X)^2] \\\\ & = \\mathbb{E}[(X-\\mathbb{E}[X])^2] \\\\ &= \\mathbb{E}[X^2]-(\\mathbb{E}[X])^2 \\\\ & = \\sum_{\\{all\\ x\\}}(x-\\mu_x)^2 p_{X}(x)\n\\end{align}\n\\]\n\n\n\nHow do we calculate the variance of a continuous RV?\n    \nFor continuous RVs:"
  },
  {
    "objectID": "lessons_old/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-an-uniform-distribution",
    "href": "lessons_old/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-an-uniform-distribution",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Variance of an Uniform distribution",
    "text": "Variance of an Uniform distribution\n\n\n\n\nExample 2\n\n\nLet \\(f_X(x)= \\frac{1}{b-a}\\), for \\(a \\leq x \\leq b\\). Find \\(Var[X]\\)."
  },
  {
    "objectID": "lessons_old/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-exponential-distribution",
    "href": "lessons_old/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-exponential-distribution",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Variance of exponential distribution",
    "text": "Variance of exponential distribution\n\n\nIn the homework:\n\n\nExample 3\n\n\nLet \\(f_X(x)= \\lambda e^{-\\lambda x}\\), for \\(x &gt; 0\\) and \\(\\lambda&gt; 0\\). Find \\(Var[X]\\)."
  },
  {
    "objectID": "lessons_old/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#important-properties-of-variances-of-continuous-rvs",
    "href": "lessons_old/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#important-properties-of-variances-of-continuous-rvs",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Important properties of variances of continuous RVs",
    "text": "Important properties of variances of continuous RVs\n\n\n\n\nFunction of RV with two constants\n\n\n\\[Var[aX+b] = a^2Var[X]\\]\n\n\n\n\n\nVariance of sum of independent RVs pt 1\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous RVs and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\[Var\\Bigg(\\sum_{i=1}^{n} a_i X_i\\Bigg) =\\sum_{i=1}^{n} a^2_i Var(X_i)\\]\n\n\n\n\nVariance of sum of independent RVs pt 2\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous RVs, then \\[Var\\Bigg(\\sum_{i=1}^{n} X_i\\Bigg) = \\sum_{i=1}^{n} Var(X_i)\\]"
  },
  {
    "objectID": "lessons_old/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#find-the-mean-and-sd-from-word-problem",
    "href": "lessons_old/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#find-the-mean-and-sd-from-word-problem",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Find the mean and sd from word problem",
    "text": "Find the mean and sd from word problem\n\n\n\n\nExample 4\n\n\nA machine manufactures cubes with a side length that varies uniformly from 1 to 2 inches. Assume the sides of the base and height are equal. The cost to make a cube is 10 ¢ per cubic inch, and 5 ¢ cents for the general cost per cube. Find the mean and standard deviation of the cost to make 10 cubes."
  },
  {
    "objectID": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html",
    "href": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "LAST CLASS!!!!\nHomework 7and 6 solutions are graded\nHW 7 meetings are up on Calendly\n\nSee my announcement from Sakai\n\nI will be finalizing and posting HW 9 tomorrow\n\nOptional!\n\nPlease do your course evals!!\n\nEspecially in a small class\n\nFriday 12/13 is the absolute deadline for turning in materials if you are completing the course! _ Check Sakai that I have all your HW grades in!\nAnything else?"
  },
  {
    "objectID": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html#announcements",
    "href": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "LAST CLASS!!!!\nHomework 7and 6 solutions are graded\nHW 7 meetings are up on Calendly\n\nSee my announcement from Sakai\n\nI will be finalizing and posting HW 9 tomorrow\n\nOptional!\n\nPlease do your course evals!!\n\nEspecially in a small class\n\nFriday 12/13 is the absolute deadline for turning in materials if you are completing the course! _ Check Sakai that I have all your HW grades in!\nAnything else?"
  },
  {
    "objectID": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html#key-dates",
    "href": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday (12/5): HW 8 assignment due\nSunday (12/8): HW 7 presentations due at 11pm\n\nI can be pretty flexible until 12/13\n\nThursday (12/12): Optional HW 9 assignment due\nFriday (12/13): HW 8 solutions due"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability_key_info.html",
    "href": "lessons_old/01_Probability/01_Probability_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Slack is working for a few people??\n\nhttps://join.slack.com/t/bsta550/shared_invite/zt-2qtfo9s8j-j6ozEaYdT7yy1KuHoT9Mhw"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability_key_info.html#announcements",
    "href": "lessons_old/01_Probability/01_Probability_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Slack is working for a few people??\n\nhttps://join.slack.com/t/bsta550/shared_invite/zt-2qtfo9s8j-j6ozEaYdT7yy1KuHoT9Mhw"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability_muddy_points.html",
    "href": "lessons_old/01_Probability/01_Probability_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "The muddy points from this year were a subset of the ones from last year, so I just decided to copy those below!"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability_muddy_points.html#proofs-of-propositions",
    "href": "lessons_old/01_Probability/01_Probability_muddy_points.html#proofs-of-propositions",
    "title": "Muddy Points",
    "section": "1. Proofs of propositions",
    "text": "1. Proofs of propositions\nFurther explanations of the propositions can be found in the textbook from pages 24-27. For many of the explanations in class, I was working to produce a union of disjoint events, so that the probability could easily be calculated. Proposition 3 and 4 were specifically mentioned, so I will include some writing notes on them here:\n\nProposition 3\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\nIn this proposition, I want to define event \\(B\\) as a union of disjoint events so that I can show \\(P(B)\\) is the sum of \\(P(A)\\) and some greater-than-or-equal-to 0 probability event. If the following is my venn diagram of A and B:\n\n\n\n\n\nThen I can define B as the union of disjoint events: \nIf we then take the probability of each side of the equation \\(B = A \\cup (A^c \\cap B)\\), we get \\[P(B) = P\\big(A \\cup (A^c \\cap B)\\big)\\]\nSince events \\(A\\) and \\(A^c \\cap B\\) are disjoint, the probability of their union is just: \\[P(A) + P(A^c \\cap B)\\]\nThus, our equation is now \\[P(B) = P(A) + P(A^c \\cap B)\\]\nFrom Axiom 1, we know for event \\(A^c \\cap B\\), \\(P(A^c \\cap B) \\geq 0\\).\nSo the probability of event B is the sum of the probability of event A and an event that is \\(\\geq\\) 0. This means \\(P(B) \\geq P(A)\\).\n\n\nProposition 4\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)\n\n\nFrom the pictures above, we can see some similar disjoint events.\nIf we look back at \\(A \\cup B\\), we can start manipulating the right side of the equation:"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability_muddy_points.html#example-at-end-of-chapter-2-slides-venn-diagram",
    "href": "lessons_old/01_Probability/01_Probability_muddy_points.html#example-at-end-of-chapter-2-slides-venn-diagram",
    "title": "Muddy Points",
    "section": "2. Example at end of Chapter 2 slides (Venn Diagram)",
    "text": "2. Example at end of Chapter 2 slides (Venn Diagram)\nI will post this in the previous week’s Muddy Points as well. Please follow this link for my work through of the example. And here is the PDF with my work.\nSub-question: why don’t we just multiply the probability of A and B to get the intersection? This is a specific property of probability when A and B are independent. Only when A and B are independent can we conclude that \\(P(A \\cap B) = P(A)P(B)\\)."
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability_muddy_points.html#partition-of-events",
    "href": "lessons_old/01_Probability/01_Probability_muddy_points.html#partition-of-events",
    "title": "Muddy Points",
    "section": "3. Partition of events",
    "text": "3. Partition of events\nWe’ve been working with event partitions throughout Chapter 2, but we have not formally identified them. Partitions are advantageous to define for two reasons:\n\nThe partitions may be easier to calculate. We can then use the partitions to reconstruct other probabilities that may be more difficult to calculate\nPartitions have nice properties as a consequence of being disjoint. For example, the probability of the union of partitions is the sum of the probabilities across each partition: \\[P\\bigg(\\bigcup_{i=1}^n A_i\\bigg) = P(A_1)P(A_2)P(A_3) \\cdot \\cdot \\cdot P(A_n)\\]"
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs_key_info.html",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 videos should be in!\n\nSome presentations today\n\nNeed to grade HW 4 solutions and HW 5 assignment STILL\n\nHappy to be flexible on the HW 5 solutions deadline\n\nAnything else?"
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs_key_info.html#announcements",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 videos should be in!\n\nSome presentations today\n\nNeed to grade HW 4 solutions and HW 5 assignment STILL\n\nHappy to be flexible on the HW 5 solutions deadline\n\nAnything else?"
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs_key_info.html#key-dates",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 6 due\nSunday: HW 5 solutions due\n\nFLEXIBLE"
  },
  {
    "objectID": "lessons_old/04_Conditional_Probability/04_Conditional_Probability.html",
    "href": "lessons_old/04_Conditional_Probability/04_Conditional_Probability.html",
    "title": "Chapter 4: Conditional Probability",
    "section": "",
    "text": "Use set process to calculate probability of event of interest\nCalculate the probability of an event occurring, given that another event occurred.\nDefine keys facts for conditional probabilities using notation."
  },
  {
    "objectID": "lessons_old/04_Conditional_Probability/04_Conditional_Probability.html#learning-objectives",
    "href": "lessons_old/04_Conditional_Probability/04_Conditional_Probability.html#learning-objectives",
    "title": "Chapter 4: Conditional Probability",
    "section": "",
    "text": "Use set process to calculate probability of event of interest\nCalculate the probability of an event occurring, given that another event occurred.\nDefine keys facts for conditional probabilities using notation."
  },
  {
    "objectID": "lessons_old/04_Conditional_Probability/04_Conditional_Probability.html#where-are-we",
    "href": "lessons_old/04_Conditional_Probability/04_Conditional_Probability.html#where-are-we",
    "title": "Chapter 4: Conditional Probability",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons_old/04_Conditional_Probability/04_Conditional_Probability.html#general-process-for-probability-word-problems",
    "href": "lessons_old/04_Conditional_Probability/04_Conditional_Probability.html#general-process-for-probability-word-problems",
    "title": "Chapter 4: Conditional Probability",
    "section": "General Process for Probability Word Problems",
    "text": "General Process for Probability Word Problems\n\nClearly define your events of interest\nTranslate question to probability using defined events OR Venn Diagram\nAsk yourself:\n\nAre we sampling with or without replacement?\nDoes order matter?\n\nUse axioms, properties, partitions, facts, etc. to define the end probability calculation into smaller parts\n\nIf probabilities are given to you, Venn Diagrams may help you parse out the events and probability calculations\nIf you need to find probabilities with counting, pictures or diagrams might help here\n\nWrite out a concluding statement that gives the probability context\n(For own check) Make sure the calculated probability follows the axioms. Is is between 0 and 1?"
  },
  {
    "objectID": "lessons_old/04_Conditional_Probability/04_Conditional_Probability.html#lets-revisit-our-deck-of-cards",
    "href": "lessons_old/04_Conditional_Probability/04_Conditional_Probability.html#lets-revisit-our-deck-of-cards",
    "title": "Chapter 4: Conditional Probability",
    "section": "Let’s revisit our deck of cards",
    "text": "Let’s revisit our deck of cards\n\n\n\n\nExample 1\n\n\nSuppose we randomly draw 2 cards from a standard deck of cards. What is the probability that we draw a spade then a heart?\n\n\nLet\n\nLet \\(A =\\) event \\(1^{st}\\) card is spades\nLet \\(B =\\) event \\(2^{nd}\\) card is heart"
  },
  {
    "objectID": "lessons_old/04_Conditional_Probability/04_Conditional_Probability.html#conditional-probability-facts-12",
    "href": "lessons_old/04_Conditional_Probability/04_Conditional_Probability.html#conditional-probability-facts-12",
    "title": "Chapter 4: Conditional Probability",
    "section": "Conditional Probability facts (1/2)",
    "text": "Conditional Probability facts (1/2)\n\n\n\n\nFact 1: General Multiplication Rule\n\n\n\\[\\mathbb{P}(A\\cap B)=\\mathbb{P}(A)\\cdot\\mathbb{P}(B|A)\\]\n\n\n\n\n\nFact 2: Conditional Probability Definition\n\n\n\\[\\mathbb{P}(A|B)=\\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)}\\]"
  },
  {
    "objectID": "lessons_old/04_Conditional_Probability/04_Conditional_Probability.html#conditional-probability-facts-22",
    "href": "lessons_old/04_Conditional_Probability/04_Conditional_Probability.html#conditional-probability-facts-22",
    "title": "Chapter 4: Conditional Probability",
    "section": "Conditional Probability facts (2/2)",
    "text": "Conditional Probability facts (2/2)\n\n\n\n\nFact 3\n\n\nIf \\(A\\) and \\(B\\) are independent events (\\(A \\unicode{x2AEB}B\\)), then \\[\\mathbb{P}(A|B) = \\mathbb{P}(A)\\]\n\n\n\n\n\nFact 4\n\n\n\\(\\mathbb{P}(A|B)\\) is a probability, meaning that it satisfies the probability axioms. In particular, \\[\\mathbb{P}(A|B) + \\mathbb{P}(A^C|B) = 1\\]"
  },
  {
    "objectID": "lessons_old/04_Conditional_Probability/04_Conditional_Probability.html#monty-hall-problem",
    "href": "lessons_old/04_Conditional_Probability/04_Conditional_Probability.html#monty-hall-problem",
    "title": "Chapter 4: Conditional Probability",
    "section": "Monty Hall Problem",
    "text": "Monty Hall Problem\nSurvivor Season 42\nWith the Wiki page on it!"
  },
  {
    "objectID": "lessons_old/04_Conditional_Probability/04_Conditional_Probability.html#conditional-probability-with-two-dice",
    "href": "lessons_old/04_Conditional_Probability/04_Conditional_Probability.html#conditional-probability-with-two-dice",
    "title": "Chapter 4: Conditional Probability",
    "section": "Conditional probability with two dice",
    "text": "Conditional probability with two dice\n\n\n\n\nExample 2\n\n\nTwo dice (red and blue) are rolled. If the dice do not show the same face, what is the probability that one of the dice is a 1?"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs_muddy_points.html",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "1. In-class example of the Poisson distribution\n\nlibrary(tidyverse)\n\nx &lt;- 0:250\n# n = c(6,14,30,60)\np = c(0.1, 0.5)\n\ngeom = expand.grid(x = x, p = p) %&gt;%\n  mutate(y = dgeom(x, prob = p))\n\nggplot(geom %&gt;% filter(y &gt; 1e-5), \n       aes(x, y, color=factor(p))) +\n  geom_point(size=1) +\n  geom_segment(aes(x=x, xend=x, y=0, yend=y, color=factor(p)), lwd=0.8, alpha=0.5) +\n  facet_grid(rows = vars(p), scales=\"free_x\", space=\"free_x\") +\n  theme(legend.position = \"none\",\n        axis.title = element_text(size = 14),    # Axis title size\n        axis.text = element_text(size = 12),     # Axis text size\n        strip.text = element_text(size = 13)) +  # Facet label size\n  labs(x = \"Number of trials\", y = \"Probability\")"
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "",
    "text": "Distinguish between discrete and continuous random variables.\nCalculate probabilities for continuous random variables.\nCalculate and graph a density (i.e., probability density function, PDF).\nCalculate and graph a CDF (i.e., a cumulative distribution function)"
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#learning-objectives",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#learning-objectives",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "",
    "text": "Distinguish between discrete and continuous random variables.\nCalculate probabilities for continuous random variables.\nCalculate and graph a density (i.e., probability density function, PDF).\nCalculate and graph a CDF (i.e., a cumulative distribution function)"
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#discrete-vs.-continuous-rvs",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#discrete-vs.-continuous-rvs",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Discrete vs. Continuous RVs",
    "text": "Discrete vs. Continuous RVs\n\n\n\nFor a discrete RV, the set of possible values is either finite or can be put into a countably infinite list.\n \nContinuous RVs take on values from continuous intervals, or unions of continuous intervals\n\n\n\n\n\nFigure from Introduction to Probability TB (pg. 301)"
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#how-to-define-probabilities-for-continuous-rvs",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#how-to-define-probabilities-for-continuous-rvs",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "How to define probabilities for continuous RVs?",
    "text": "How to define probabilities for continuous RVs?\n\n\nDiscrete RV \\(X\\):\n\nlibrary(ggplot2)\ndata = data.frame(x = seq(0, 10, 1), y = seq(0, 0.5, 0.05))\nggplot(data, aes(x = x, y = y)) +\n  labs(x = \"x\", y = \"Probability\") +\n  theme_minimal() +\n  theme(text = element_text(size=28))\n\n\n\n\n\n\n\n\n\npmf: \\(p_X(x) = P(X=x)\\)\n\n\nContinuous RV \\(X\\):\n\nlibrary(ggplot2)\ndata = data.frame(x = seq(0, 10, 1), y = seq(0, 1, 0.1))\nggplot(data, aes(x = x, y = y)) +\n  labs(x = \"x\", y = \"Density\") +\n  theme_minimal() +\n  theme(text = element_text(size=28))\n\n\n\n\n\n\n\n\n\ndensity: \\(f_X(x)\\)\nprobability: \\(P(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\)"
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#what-is-a-probability-density-function",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#what-is-a-probability-density-function",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "What is a probability density function?",
    "text": "What is a probability density function?\n\n\nProbability density function\n\n\nThe probability distribution, or probability density function (pdf), of a continuous random variable \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\),\n\\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\]\n\n\nRemarks:\n\nNote that \\(f_X(x) \\neq \\mathbb{P}(X=x)\\)!!!\nIn order for \\(f_X(x)\\) to be a pdf, it needs to satisfy the properties\n\n\\(f_X(x) \\geq 0\\) for all \\(x\\)\n\\(\\int_{-\\infty}^{\\infty} f_X(x)dx=1\\)"
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-15",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-15",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (1/5)",
    "text": "Let’s demonstrate the PDF with an example (1/5)\n\n\n\n\nExample 1.1\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind the value of \\(a\\) so that \\(f_X(x)\\) is a pdf."
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-25",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-25",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (2/5)",
    "text": "Let’s demonstrate the PDF with an example (2/5)\n\n\n\n\nExample 1.2\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(2.7 \\leq X \\leq 2.9)\\)."
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-35",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-35",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (3/5)",
    "text": "Let’s demonstrate the PDF with an example (3/5)\n\n\n\n\nExample 1.3\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(2.7 &lt; X \\leq 2.9)\\)."
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-45",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-45",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (4/5)",
    "text": "Let’s demonstrate the PDF with an example (4/5)\n\n\n\n\nExample 1.4\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(X = 2.9)\\)."
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-55",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-pdf-with-an-example-55",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (5/5)",
    "text": "Let’s demonstrate the PDF with an example (5/5)\n\n\n\n\nExample 1.5\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(X \\leq 2.8)\\)."
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#what-is-a-cumulative-distribution-function",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#what-is-a-cumulative-distribution-function",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "What is a cumulative distribution function?",
    "text": "What is a cumulative distribution function?\n\n\nCumulative distribution function\n\n\nThe cumulative distribution function (cdf) of a continuous random variable \\(X\\), is the function \\(F_X(x)\\), such that for all real values of \\(x\\), \\[F_X(x)= \\mathbb{P}(X \\leq x) = \\int_{-\\infty}^x f_X(s)ds\\]\n\n\nRemarks: In general, \\(F_X(x)\\) is increasing and\n\n\\(\\lim_{x\\rightarrow -\\infty} F_X(x)= 0\\)\n\\(\\lim_{x\\rightarrow \\infty} F_X(x)= 1\\)\n\\(P(X &gt; a) = 1 - P(X \\leq a) = 1 - F_X(a)\\)\n\\(P(a \\leq X \\leq b) = F_X(b) - F_X(a)\\)"
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-cdf-with-an-example",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-demonstrate-the-cdf-with-an-example",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the CDF with an example",
    "text": "Let’s demonstrate the CDF with an example\n\n\n\n\nExample 2\n\n\nLet \\(f_X(x)= 2\\), for \\(2.5 \\leq x \\leq 3\\). Find \\(F_X(x)\\)."
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#derivatives-of-the-cdf",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#derivatives-of-the-cdf",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Derivatives of the CDF",
    "text": "Derivatives of the CDF\n\n\nTheorem 1\n\n\nIf \\(X\\) is a continuous random variable with pdf \\(f_X(x)\\) and cdf \\(F_X(x)\\), then for all real values of \\(x\\) at which \\(F'_X(x)\\) exists, \\[\\frac{d}{dx} F_X(x)= F'_X(x) = f_X(x)\\]"
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#finding-the-pdf-from-a-cdf",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#finding-the-pdf-from-a-cdf",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Finding the PDF from a CDF",
    "text": "Finding the PDF from a CDF\n\n\n\n\nExample 3\n\n\nLet \\(X\\) be a RV with cdf \\[F_X(x)= \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x &lt; 2.5 \\\\\n            2x-5 & \\quad 2.5 \\leq x \\leq 3 \\\\\n            1 & \\quad x &gt; 3\n        \\end{array}\n    \\right.\\] Find the pdf \\(f_X(x)\\)."
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-17",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-17",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (1/7)",
    "text": "Let’s go through another example (1/7)\n\n\n\n\nExample 4\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nShow \\(f_X(x)\\) is a pdf.\nFind \\(\\mathbb{P}(1 \\leq X \\leq 3)\\).\nFind \\(F_X(x)\\).\nGiven \\(F_X(x)\\), find \\(f_X(x)\\).\nFind \\(\\mathbb{P}(X \\geq 1 | X \\leq 3)\\).\nFind the median of the distribution of \\(X\\)."
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-27",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-27",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (2/7)",
    "text": "Let’s go through another example (2/7)\n\n\n\n\nExample 4.1\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nShow \\(f_X(x)\\) is a pdf."
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-37",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-37",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (3/7)",
    "text": "Let’s go through another example (3/7)\n\n\n\n\n\n\nDo this problem at home for extra practice.\n\n\n\n\n\n\n\nExample 4.2\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nFind \\(\\mathbb{P}(1 \\leq X \\leq 3)\\)."
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-47",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-47",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (4/7)",
    "text": "Let’s go through another example (4/7)\n\n\n\n\nExample 4.3\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nFind \\(F_X(x)\\)."
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-57",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-57",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (5/7)",
    "text": "Let’s go through another example (5/7)\n\n\n\n\n\n\nDo this problem at home for extra practice.\n\n\n\n\n\n\n\nExample 4.4\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nGiven \\(F_X(x)\\), find \\(f_X(x)\\)."
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-67",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-67",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (6/7)",
    "text": "Let’s go through another example (6/7)\n\n\n\n\nExample 4.5\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nFind \\(\\mathbb{P}(X \\geq 1 | X \\leq 3)\\)."
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-77",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv.html#lets-go-through-another-example-77",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s go through another example (7/7)",
    "text": "Let’s go through another example (7/7)\n\n\n\n\nExample 4.6\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nFind the median of the distribution of \\(X\\)."
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv_key_info.html",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Graded: HW 4 assignment and HW 3 solutions\nCalendly is up!!"
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv_key_info.html#announcements",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Graded: HW 4 assignment and HW 3 solutions\nCalendly is up!!"
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv_key_info.html#key-dates",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 5 due\nSunday: HW 4 solutions due\nWeek of 11/11\n\nMake a meeting with me\n11/12: recordings due if you are making that\nNow on Sakai"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "",
    "text": "Find derivatives of continuous functions with one variable\nFind antiderivatives and integrals of functions with one variable"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#learning-objectives",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#learning-objectives",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "",
    "text": "Find derivatives of continuous functions with one variable\nFind antiderivatives and integrals of functions with one variable"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#where-are-we",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#where-are-we",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.1\n\n\n\\(f(x) = 2\\)\n\n\n\n\nDerivative of a constant\n\n\n\\[\\dfrac{d}{dx} c = 0\\]"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-1",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-1",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.2\n\n\n\\(f(x) = 2x\\)"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-2",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-2",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.3\n\n\n\\(f(x) = 2x+2\\)"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-3",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-3",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.4\n\n\n\\(f(x) = x^2\\)\n\n\n\n\nDerivative of \\(x\\) to a constant\n\n\n\\[\\dfrac{d}{dx} x^n = nx^{n-1}\\]"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-4",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-4",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.5\n\n\n\\(f(x) = 3\\sqrt{x}+\\frac2x+5\\)"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-5",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-5",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.6\n\n\n\\(f(x) = e^x\\)\n\n\n\n\nDerivative of exponential function\n\n\n\\(\\dfrac{d}{dx} e^x = e^x\\)"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-6",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-6",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.7\n\n\n\\(f(x) = \\ln(x)\\)\n\n\n\n\nDerivative of logarithm\n\n\n\\(\\dfrac{d}{dx} ln(x) = \\dfrac{1}{x}\\)"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-7",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-7",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.8\n\n\n\\(f(x) = x^2 e^x\\)\n\n\n\n\nProduct Rule\n\n\n\\(\\dfrac{d}{dx} f(x)g(x) = f'(x)g(x) + f(x)g'(x)\\)"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-8",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-8",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.9\n\n\n\\(f(x) = \\dfrac{x^5}{2x+7}\\)\n\n\n\n\nQuotient Rule\n\n\n\\(\\dfrac{d}{dx} \\dfrac{f(x)}{g(x)} = \\dfrac{g(x)f'(x) - f(x)g'(x)}{\\big(g(x)\\big)^2}\\)"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-9",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-9",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.10\n\n\n\\(f(x) = e^{-2x+7}\\)\n\n\n\n\nChain Rule\n\n\n\\(\\dfrac{d}{dx} f\\big(g(x)\\big)= f'\\big(g(x)\\big)g'(x)\\)"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-10",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-derivative-of-the-following-function-10",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.11\n\n\n\\(f(x) = \\ln(x^2)\\)"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.1\n\n\n\\(f(x) = 2\\)"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-1",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-1",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.2\n\n\n\\(f(x) = x\\)\n\n\n\n\nIntegration of x to a constant\n\n\n\\(\\displaystyle\\int x^n dx = \\dfrac{x^{n+1}}{n+1} + c\\)"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-2",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-2",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.3\n\n\n\\(f(x) = \\frac1x\\)"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-3",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-3",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.4\n\n\n\\(f(x) = x^{3/2}\\)"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-4",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-4",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.5\n\n\n\\(f(x) = e^x\\)"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-5",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-5",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.6\n\n\n\\(f(x) = e^{-x}\\)"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-6",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#find-the-antiderivative-of-the-following-function-6",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.7\n\n\n\\(f(x) = e^{-2x}\\)"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.1\n\n\n\\(\\displaystyle\\int_0^1 (2x+x^5)dx\\)"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-1",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-1",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.2\n\n\n\\(\\displaystyle\\int_2^3 e^{-x}dx\\)\n\n\n\n\nU-substitution\n\n\n\\(\\displaystyle\\int f\\big(g(x)\\big) g'(x) dx = \\displaystyle\\int f(u) dx\\)"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-2",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-2",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.3\n\n\n\\(\\displaystyle\\int_2^3 x e^{x^2}dx\\)"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-3",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-3",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.4\n\n\n\\(\\displaystyle\\int_0^{\\infty} x e^{-x}dx\\)\n\n\n\n\nIntegrating by Parts\n\n\n\\(\\displaystyle\\int f(x) g'(x) dx = f(x)g(x) -\\)\n\\(\\displaystyle\\int f'(x) g(x) dx\\)\nOR\n\\(\\displaystyle\\int_a^b u dv = uv\\bigg|^b_a - \\displaystyle\\int_a^b vdu\\)"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-4",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-4",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.5\n\n\n\\(\\displaystyle\\int_1^2 x^2 \\ln(x)dx\\)"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-5",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-5",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.6\n\n\n\\(\\displaystyle\\int_1^2 \\ln(x)dx\\)"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-6",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review.html#solve-the-following-integral-6",
    "title": "Pre Chapter 24: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.7\n\n\n\\(\\displaystyle\\int_1^2 x^2 e^{x}dx\\)"
  },
  {
    "objectID": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html",
    "href": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "",
    "text": "Calculate probabilities for discrete random variables\nCalculate and graph a probability mass function (pmf)\nCalculate and graph a cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#learning-objectives",
    "href": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#learning-objectives",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "",
    "text": "Calculate probabilities for discrete random variables\nCalculate and graph a probability mass function (pmf)\nCalculate and graph a cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#where-are-we",
    "href": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#where-are-we",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#what-is-a-probability-mass-function",
    "href": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#what-is-a-probability-mass-function",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "What is a probability mass function?",
    "text": "What is a probability mass function?\n\n\nDefinition: probability distribution or probability mass function (pmf)\n\n\nThe probability distribution or probability mass function (pmf) of a discrete r.v. \\(X\\) is defined for every number \\(x\\) by \\[p_X(x) = \\mathbb{P}(X=x) = \\mathbb{P}(\\mathrm{all }\\ \\omega\\in S:X(\\omega) = x)\\]"
  },
  {
    "objectID": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#lets-demonstrate-this-definition-with-our-coin-toss",
    "href": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#lets-demonstrate-this-definition-with-our-coin-toss",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Let’s demonstrate this definition with our coin toss",
    "text": "Let’s demonstrate this definition with our coin toss\n\n\n\n\nExample 1\n\n\nSuppose we toss 3 coins with probability of tails \\(p\\). If \\(X\\) is the random variable counting the number of tails, what are the probabilities of each value of \\(X\\)?"
  },
  {
    "objectID": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#remarks-on-the-pmf",
    "href": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#remarks-on-the-pmf",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Remarks on the pmf",
    "text": "Remarks on the pmf\n\n\nProperties of pmf\n\n\nA pmf \\(p_X(x)\\) must satisfy the following properties:\n\n\\(0 \\leq p_X(x) \\leq 1\\) for all \\(x\\).\n\\(\\sum \\limits_{\\{all\\ x\\}}p_X(x)=1\\).\n\n\n\n\nSome distributions depend on parameters\n\nEach value of a parameter gives a different pmf\nIn previous example, the number of coins tossed was a parameter\n\nWe tossed 3 coins\nIf we tossed 4 coins, we’d get a different pmf!\n\nThe collection of all pmf’s for different values of the parameters is called a family of pmf’s"
  },
  {
    "objectID": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#binomial-family-of-rvs",
    "href": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#binomial-family-of-rvs",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Binomial family of RVs",
    "text": "Binomial family of RVs\n\n\n\n\nExample 2\n\n\nSuppose you toss \\(n\\) coins, each with probability of tails \\(p\\). If \\(X\\) is the number of tails, what is the pmf of \\(X\\)?"
  },
  {
    "objectID": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#bernoulli-family-of-rvs",
    "href": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#bernoulli-family-of-rvs",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Bernoulli family of RVs",
    "text": "Bernoulli family of RVs\n\n\n\n\nExample 3\n\n\nSuppose you toss 1 coin, with probability of tails \\(p\\). If \\(X\\) is the number of tails, what is the pmf of \\(X\\)?"
  },
  {
    "objectID": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#household-size-15",
    "href": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#household-size-15",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (1/5)",
    "text": "Household size (1/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nWhat is the sample space for household sizes?\nDefine the random variable for household sizes.\nDo the values in the table create a pmf? Why or why not?\nMake a plot of the pmf.\nWrite the cdf as a function.\nGraph the cdf of household sizes in 2019."
  },
  {
    "objectID": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#household-size-25",
    "href": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#household-size-25",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (2/5)",
    "text": "Household size (2/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nWhat is the sample space for household sizes?\nDefine the random variable for household sizes."
  },
  {
    "objectID": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#household-size-35",
    "href": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#household-size-35",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (3/5)",
    "text": "Household size (3/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nDo the values in the table create a pmf? Why or why not?\nMake a plot of the pmf"
  },
  {
    "objectID": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#what-is-a-cumulative-distribution-function",
    "href": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#what-is-a-cumulative-distribution-function",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "What is a cumulative distribution function?",
    "text": "What is a cumulative distribution function?\n\n\nDefinition: cumulative distribution function (CDF)\n\n\nThe cumulative distribution function (cdf) of a discrete r.v. \\(X\\) with pmf \\(p_X(x)\\), is defined for every value \\(x\\) by \\[F_X(x) = \\mathbb{P}(X \\leq x) = \\sum \\limits_{\\{all\\ y:\\ y\\leq x\\}}p_X(y)\\]"
  },
  {
    "objectID": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#household-size-45",
    "href": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#household-size-45",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (4/5)",
    "text": "Household size (4/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nWrite the cdf as a function."
  },
  {
    "objectID": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#household-size-55",
    "href": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#household-size-55",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Household size (5/5)",
    "text": "Household size (5/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nGraph the cdf of household sizes in 2019."
  },
  {
    "objectID": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#properties-of-discrete-cdfs",
    "href": "lessons_old/08_pmfs_and_cdfs/08_pmfs_and_cdfs.html#properties-of-discrete-cdfs",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "Properties of discrete CDFs",
    "text": "Properties of discrete CDFs\n\n\\(F(x)\\) is increasing or flat (never decreasing)\n\\(\\min\\limits_x F(x) = 0\\)\n\\(\\max\\limits_xF(x)=1\\)\nCDF is a step function"
  },
  {
    "objectID": "lessons_old/12_Variance/12_Variance_muddy_points.html",
    "href": "lessons_old/12_Variance/12_Variance_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy Points from Fall 2023:\n\n1. Proof of variance formula\nHere is the variance formula that we worked through on slide 9 of Chapter 12’s notes.\n\n\n\n\n\n\nLemma 6: “Computation formula” for variance\n\n\n\nThe variance of a r.v. \\(X\\), can be computed as \\[\\begin{align}\\sigma_X^2 & =Var(X) \\\\ & = \\mathbb{E}[X^2]-\\mu_X^2 \\\\ & = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2\\end{align}\\]\n\n\nI stepped through this quite quickly and made some implicit steps. So let’s revisit it with explicit steps!\n       \n\n\n2. What progression are we following in the course??\nSomeone asked if this is our progression: RV is function \\(\\to\\) Expected value is function to describe mean of RV \\(\\to\\) Use functions within expected value to set up variance\nBasically, yes! The random variable is a function of a random process. The RV inherits that randomness.\nFrom there, we’ve been working towards calculating the probability of a realized value ($x$) of the RV. The probability can be different for different realized values (as it links back to the random process).\nWe also want to construct ways to describe our random variables. We may want to figure out what to expect from our random variable (which translates to the mean value of the RV). Since our RV is rooted in a random process, we may want to get an idea of how spread out our realized values are. We use our expected value (mean) as an anchor in our spread. Variance is one way to measure this spread."
  },
  {
    "objectID": "lessons_old/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html",
    "href": "lessons_old/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Homework 7 presentations due soon!\n\nI will check your HW 7 solutions ASAP!\n\nDepending on how far we get today and Wednesday, I might cancel the 12/9 class\nAnything else?"
  },
  {
    "objectID": "lessons_old/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#announcements",
    "href": "lessons_old/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Homework 7 presentations due soon!\n\nI will check your HW 7 solutions ASAP!\n\nDepending on how far we get today and Wednesday, I might cancel the 12/9 class\nAnything else?"
  },
  {
    "objectID": "lessons_old/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#key-dates",
    "href": "lessons_old/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 8 assignment due\nSunday: HW 7 presentations due at 11pm"
  },
  {
    "objectID": "lessons_old/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html",
    "href": "lessons_old/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "",
    "text": "Calculate probability of a sample mean using a Normally distributed population"
  },
  {
    "objectID": "lessons_old/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#learning-objectives",
    "href": "lessons_old/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#learning-objectives",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "",
    "text": "Calculate probability of a sample mean using a Normally distributed population"
  },
  {
    "objectID": "lessons_old/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#sum-of-normal-rvs",
    "href": "lessons_old/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#sum-of-normal-rvs",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "Sum of Normal RVs",
    "text": "Sum of Normal RVs\n\n\nTheorem 1\n\n\nLet \\(X\\sim N(\\mu, \\sigma^2)\\), and let \\(Y=aX+b\\), where \\(a\\) and \\(b\\) are constants. Then \\[Y \\sim N(a\\mu+b, a^2\\sigma^2)\\]\n\n\n\n\nTheorem 2\n\n\nLet \\(X_i \\sim N(\\mu_i, \\sigma_i^2)\\) be independent normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\sim N\\Bigg(\\sum_{i=1}^n \\mu_i , \\sum_{i=1}^n \\sigma^2_i\\Bigg)\\]"
  },
  {
    "objectID": "lessons_old/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#special-cases",
    "href": "lessons_old/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#special-cases",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "Special Cases",
    "text": "Special Cases\n\nLet \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\sim N\\big(n\\mu, n \\sigma^2\\big)\\]\nLet \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\bar{X}=\\frac{\\sum_{i=1}^n X_i}{n} \\sim N\\big(\\mu, \\sigma^2 / n\\big)\\]\nLet \\(X\\sim N(\\mu_X,\\sigma_X^2)\\), and \\(Y\\sim N(\\mu_Y,\\sigma_Y^2)\\). Then \\[X-Y \\sim N\\big(\\mu_X - \\mu_Y, \\sigma^2_X + \\sigma^2_Y \\big)\\]"
  },
  {
    "objectID": "lessons_old/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#detecting-and-solving-sums-of-normal-rvs-from-a-word-problem",
    "href": "lessons_old/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#detecting-and-solving-sums-of-normal-rvs-from-a-word-problem",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "Detecting and solving sums of Normal RVs from a word problem",
    "text": "Detecting and solving sums of Normal RVs from a word problem\n\n\n\n\nExample 1\n\n\nGlaucoma is an eye disease that is manifested by high intraocular pressure (IOP). The distribution of IOP in the general population is approximately normal with mean 16 mmHg and standard deviation 3 mmHg.\n\nSuppose a patient has 40 IOP readings. What is the probability that their average reading is greater than 20.32 mmHg, assuming their eyes are healthy?\nRepeat the previous question for a patient with 10 IOP readings."
  },
  {
    "objectID": "lessons_old/12_Variance/12_Variance_key_info.html",
    "href": "lessons_old/12_Variance/12_Variance_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 4 assignment due last night!\nHW 3 solutions also due\nTime to grade later today: HW 3 solutions or HW 4 assignment?"
  },
  {
    "objectID": "lessons_old/12_Variance/12_Variance_key_info.html#announcements",
    "href": "lessons_old/12_Variance/12_Variance_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 4 assignment due last night!\nHW 3 solutions also due\nTime to grade later today: HW 3 solutions or HW 4 assignment?"
  },
  {
    "objectID": "lessons_old/12_Variance/12_Variance_key_info.html#key-dates",
    "href": "lessons_old/12_Variance/12_Variance_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates"
  },
  {
    "objectID": "lessons_old/12_Variance/12_Variance.html",
    "href": "lessons_old/12_Variance/12_Variance.html",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "",
    "text": "Calculate the variance and standard deviation of discrete random variables\nCalculate the variance of sums of discrete random variables\nCalculate the variance of functions of discrete random variables"
  },
  {
    "objectID": "lessons_old/12_Variance/12_Variance.html#learning-objectives",
    "href": "lessons_old/12_Variance/12_Variance.html#learning-objectives",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "",
    "text": "Calculate the variance and standard deviation of discrete random variables\nCalculate the variance of sums of discrete random variables\nCalculate the variance of functions of discrete random variables"
  },
  {
    "objectID": "lessons_old/12_Variance/12_Variance.html#where-are-we",
    "href": "lessons_old/12_Variance/12_Variance.html#where-are-we",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons_old/12_Variance/12_Variance.html#lets-start-building-the-variance-through-expected-values-of-functions",
    "href": "lessons_old/12_Variance/12_Variance.html#lets-start-building-the-variance-through-expected-values-of-functions",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Let’s start building the variance through expected values of functions",
    "text": "Let’s start building the variance through expected values of functions\n\n\n\n\nExample 1\n\n\nLet \\(g\\) be a function and let \\(g(x) = ax+b\\), for real-valued constants \\(a\\) and \\(b\\). What is \\(\\mathbb{E}[g(X)]\\)?"
  },
  {
    "objectID": "lessons_old/12_Variance/12_Variance.html#what-is-the-expected-value-of-a-function",
    "href": "lessons_old/12_Variance/12_Variance.html#what-is-the-expected-value-of-a-function",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "What is the expected value of a function?",
    "text": "What is the expected value of a function?\n\n\nDefinition: Expected value of function of RV\n\n\nFor any function \\(g\\) and discrete r.v. \\(X\\), the expected value of \\(g(X)\\) is \\[\\mathbb{E}[g(X)] = \\sum_{\\{all\\ x\\}}\\ g(x) p_X(x).\\]"
  },
  {
    "objectID": "lessons_old/12_Variance/12_Variance.html#lets-revisit-the-card-example-12",
    "href": "lessons_old/12_Variance/12_Variance.html#lets-revisit-the-card-example-12",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Let’s revisit the card example (1/2)",
    "text": "Let’s revisit the card example (1/2)\n\n\n\n\nExample 2\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw.\n\nFind \\(\\mathbb{E}[X^2]\\).\n\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "lessons_old/12_Variance/12_Variance.html#lets-revisit-the-card-example-22",
    "href": "lessons_old/12_Variance/12_Variance.html#lets-revisit-the-card-example-22",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Let’s revisit the card example (2/2)",
    "text": "Let’s revisit the card example (2/2)\n\n\n\n\nExample 2\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw.\n\nFind \\(\\mathbb{E}\\big[\\big(X-\\frac{1}{2}\\big)^2\\big]\\).\n\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "lessons_old/12_Variance/12_Variance.html#variance-of-a-rv",
    "href": "lessons_old/12_Variance/12_Variance.html#variance-of-a-rv",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Variance of a RV",
    "text": "Variance of a RV\n\n\nDefinition: Variance of RV\n\n\nThe variance of a r.v. \\(X\\), with (finite) expected value \\(\\mu_X=\\mathbb{E}[X]\\) is \\[\\sigma_X^2=Var(X)=\\mathbb{E}[(X-\\mu_X)^2] = \\mathbb{E}[(X-\\mathbb{E}[X])^2]\\]\n\n\n\n\nDefinition: Standard deviation of RV\n\n\nThe standard deviation of a r.v. \\(X\\) is \\[\\sigma_X = SD(X) = \\sqrt{\\sigma_X^2}=\\sqrt{Var(X)}.\\]"
  },
  {
    "objectID": "lessons_old/12_Variance/12_Variance.html#questions",
    "href": "lessons_old/12_Variance/12_Variance.html#questions",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Questions",
    "text": "Questions\nQuestions: Why do we square the difference in the variance definition? \\((X-\\mu_X)^2\\)\n\nWhy not define the measure of spread as \\(\\mathbb{E}[X-\\mu_X] = \\mathbb{E}[X-\\mathbb{E}[X]]\\)?\nWhy not use \\(\\mathbb{E}[|X-\\mu_X|]\\)?"
  },
  {
    "objectID": "lessons_old/12_Variance/12_Variance.html#lets-calculate-the-variance-and-prove-it",
    "href": "lessons_old/12_Variance/12_Variance.html#lets-calculate-the-variance-and-prove-it",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Let’s calculate the variance and prove it!",
    "text": "Let’s calculate the variance and prove it!\n\n\n\n\nLemma 6: “Computation formula” for Variance\n\n\nThe variance of a r.v. \\(X\\), can be computed as \\[\\begin{align}\n\\sigma_X^2 & =Var(X) \\\\ & = \\mathbb{E}[X^2]-\\mu_X^2 \\\\ & = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2\n\\end{align}\\]"
  },
  {
    "objectID": "lessons_old/12_Variance/12_Variance.html#variance-of-a-function-with-a-single-rv",
    "href": "lessons_old/12_Variance/12_Variance.html#variance-of-a-function-with-a-single-rv",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Variance of a function with a single RV",
    "text": "Variance of a function with a single RV\n\n\nLemma 7\n\n\nFor a r.v. \\(X\\) and constants \\(a\\) and \\(b\\), \\[Var(aX+b) = a^2Var(X).\\]\n\n\nProof will be exercise in homework. It’s fun! In a mathy kinda way."
  },
  {
    "objectID": "lessons_old/12_Variance/12_Variance.html#important-results-for-independent-rvs",
    "href": "lessons_old/12_Variance/12_Variance.html#important-results-for-independent-rvs",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Important results for independent RVs",
    "text": "Important results for independent RVs\n\n\nTheorem 8\n\n\nFor independent r.v.’s \\(X\\) and \\(Y\\), and functions \\(g\\) and \\(h\\), \\[\\mathbb{E}[g(X)h(Y)] = \\mathbb{E}[g(X)]\\mathbb{E}[h(Y)].\\]\n\n\n\n\nCorollary 1\n\n\nFor independent r.v.’s \\(X\\) and \\(Y\\), \\[\\mathbb{E}[XY] = \\mathbb{E}[X]\\mathbb{E}[Y].\\]"
  },
  {
    "objectID": "lessons_old/12_Variance/12_Variance.html#variance-of-sum-of-independent-discrete-rvs",
    "href": "lessons_old/12_Variance/12_Variance.html#variance-of-sum-of-independent-discrete-rvs",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Variance of sum of independent discrete RVs",
    "text": "Variance of sum of independent discrete RVs\n\n\nTheorem 9: Variance of sum of independent discrete r.v.’s\n\n\nFor independent discrete r.v.’s \\(X_i\\) and constants \\(a_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n a_iX_i\\Bigg) = \\sum_{i=1}^n a_i^2Var(X_i).\\]\n\n\nSimpler version:\n\\[Var(a_1 X + a_2 Y) = Var(a_1X) + Var(a_2 Y) = a_1^2 Var(X) + a_2^2 Var(Y)\\]"
  },
  {
    "objectID": "lessons_old/12_Variance/12_Variance.html#corollaries",
    "href": "lessons_old/12_Variance/12_Variance.html#corollaries",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Corollaries",
    "text": "Corollaries\n\n\nCorollary 2\n\n\nFor independent discrete r.v.’s \\(X_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n X_i\\Bigg) = \\sum_{i=1}^n Var(X_i).\\]\n\n\n\n\nCorollary 3\n\n\nFor independent identically distributed (i.i.d.) discrete r.v.’s \\(X_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n X_i\\Bigg) = n Var(X_1).\\]"
  },
  {
    "objectID": "lessons_old/12_Variance/12_Variance.html#lets-look-at-a-ghost-problem-with-replacement",
    "href": "lessons_old/12_Variance/12_Variance.html#lets-look-at-a-ghost-problem-with-replacement",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Let’s look at a ghost problem with replacement",
    "text": "Let’s look at a ghost problem with replacement\n\n\n\n\nExample 3.2\n\n\nThe ghost is trick-or-treating at a different house now. In this case it is known that the bag of candy has 10 chocolates, 20 lollipops, and 30 laffy taffies. The ghost grabs a handful of five pieces of candy. What is the variance for the number of chocolates the ghost takes? Let’s solve this for the cases with replacement.\n\n\n\n\nRecall probability with replacement:\n\\[\np_X(x) = {n \\choose k}p^k(1-p)^{n-k}\n\\]"
  },
  {
    "objectID": "lessons_old/12_Variance/12_Variance.html#back-to-our-hotel-example-from-chapter-11",
    "href": "lessons_old/12_Variance/12_Variance.html#back-to-our-hotel-example-from-chapter-11",
    "title": "Chapter 12: Variance of Discrete RVs",
    "section": "Back to our hotel example from Chapter 11",
    "text": "Back to our hotel example from Chapter 11\n\n\n\n\nExample 4\n\n\nA tour group is planning a visit to the city of Minneapolis and needs to book 30 hotel rooms. The average price of a room is $200 with standard deviation $10. In addition, there is a 10% tourism tax for each room. What is the standard deviation of the cost for the 30 hotel rooms? Assume rooms are independent.\n\n\nProblem to do at home if we don’t have enough time."
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review_key_info.html",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 4 assignment due last night!\nHW 3 solutions also due\nTime to grade later today: HW 3 solutions or HW 4 assignment?\nTomorrow I will be sending out a Calendly invite for next week\n\nTo make an appointment with me to present your HW 3 solutions\nIt will be posted around 11:45am/12pm\nThere are limited spots just based on my availability"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review_key_info.html#announcements",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 4 assignment due last night!\nHW 3 solutions also due\nTime to grade later today: HW 3 solutions or HW 4 assignment?\nTomorrow I will be sending out a Calendly invite for next week\n\nTo make an appointment with me to present your HW 3 solutions\nIt will be posted around 11:45am/12pm\nThere are limited spots just based on my availability"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review_key_info.html#key-dates",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 5 due\nSunday: HW 4 solutions due\nWeek of 11/11\n\nMake a meeting with me\n11/12: recordings due if you are making that"
  },
  {
    "objectID": "lessons_old/24_00_Calculus_review/24_00_Calculus_review_muddy_points.html",
    "href": "lessons_old/24_00_Calculus_review/24_00_Calculus_review_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n1. Why we are allowed to “split” the operator d/dx into two pieces as if it were a fraction when it’s an operator\nHere is a pretty helpful StackExchange post talking about this!\n\n\n2. How to know what to use as \\(u\\) and \\(dv\\) for integration by parts\nI have two approaches to identifying \\(u\\) and \\(dv\\):\n\nTry to find a \\(u\\) that will eventually differentiate into a constant. This usually works unless you’re left with a \\(dv\\) that is hard to integrate.\n\nFor example, \\(u=x^6\\). the first derivative, \\(u'=6x^5\\), which may lead us to do another integration by parts, but eventually, at the 6th derivative, we get 720. This means, in our integration by parts, we eventually get an integral that only has \\(x\\) in the function once.\n\nIn this example, \\(x^6\\) would result in many integration by parts. I feel like we don’t typically see that many in our work.\n\nIn Example 3.5 in Calculus Review, setting \\(u=x^2\\) is a bad idea because we don’t really know how to integrate \\(dv=ln(x)\\) into \\(v\\).\n\nTry to find a \\(u\\) where \\(du\\) is the reciprocal of \\(v\\) or \\(du\\) cancels with \\(v\\).\n\nLook again at Example 3.5 in the notes! Hint: What is the derivative of \\(ln(x)\\)? And what does \\(\\dfrac{1}{x}x^3\\) equal?\n\n\n\n\n3. Looking for more practice in calculus?\nI just stumbled upon this website! Just a bunch of calculus practice problems! Might be some help."
  },
  {
    "objectID": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv_muddy_points.html",
    "href": "lessons_old/24_01_Continuous_rv/24_01_Continuous_rv_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n1. Why we are allowed to “split” the operator d/dx into two pieces as if it were a fraction when it’s an operator\nHere is a pretty helpful StackExchange post talking about this!\n\n\n2. How to know what to use as \\(u\\) and \\(dv\\) for integration by parts\nI have two approaches to identifying \\(u\\) and \\(dv\\):\n\nTry to find a \\(u\\) that will eventually differentiate into a constant. This usually works unless you’re left with a \\(dv\\) that is hard to integrate.\n\nFor example, \\(u=x^6\\). the first derivative, \\(u'=6x^5\\), which may lead us to do another integration by parts, but eventually, at the 6th derivative, we get 720. This means, in our integration by parts, we eventually get an integral that only has \\(x\\) in the function once.\n\nIn this example, \\(x^6\\) would result in many integration by parts. I feel like we don’t typically see that many in our work.\n\nIn Example 3.5 in Calculus Review, setting \\(u=x^2\\) is a bad idea because we don’t really know how to integrate \\(dv=ln(x)\\) into \\(v\\).\n\nTry to find a \\(u\\) where \\(du\\) is the reciprocal of \\(v\\) or \\(du\\) cancels with \\(v\\).\n\nLook again at Example 3.5 in the notes! Hint: What is the derivative of \\(ln(x)\\)? And what does \\(\\dfrac{1}{x}x^3\\) equal?\n\n\n\n\n3. Looking for more practice in calculus?\nI just stumbled upon this website! Just a bunch of calculus practice problems! Might be some help."
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs_key_info.html",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 01 assignments are graded!\n\nSolutions and videos are posted!"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs_key_info.html#announcements",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 01 assignments are graded!\n\nSolutions and videos are posted!"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs_key_info.html#key-dates",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 02 Assignment due this Thursday at 11pm\nNo HW 01 Solutions"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "",
    "text": "Distinguish between Bernoulli, Binomial, Geometric, Hypergeometric, Discrete Uniform, Negative Binomial, and Poisson distributions when reading a story.\nIdentify the variable and the parameters in a story, and state what the variable and parameters mean.\nUse the formulas for the pmf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#learning-objectives",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#learning-objectives",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "",
    "text": "Distinguish between Bernoulli, Binomial, Geometric, Hypergeometric, Discrete Uniform, Negative Binomial, and Poisson distributions when reading a story.\nIdentify the variable and the parameters in a story, and state what the variable and parameters mean.\nUse the formulas for the pmf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#where-are-we",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#where-are-we",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-bernoulli-rvs",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-bernoulli-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Bernoulli RVs",
    "text": "Properties of Bernoulli RVs\n\nScenario: One trial, with outcome success or failure\nShorthand: \\(X \\sim \\text{Bernoulli}(p)\\)\n\n\\[\nX = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\quad \\\\\n            0 & \\quad \\mathrm{with\\ probability}\\ 1-p \\quad\n        \\end{array}\n    \\right.\n\\]\n\\[\np_X(x) = P(X=x) = p^x(1-p)^{1-x} \\text{ for } x=0,1\n\\]\n\\[\\text{E}(X) = p\\]\n\\[\\text{Var}(X) = pq = p(1-p)\\]"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bernoulli-example-1",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bernoulli-example-1",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bernoulli Example 1",
    "text": "Bernoulli Example 1\n\n\n\n\nExample 1\n\n\n\nWe roll a fair 6-sided die.\nWe get $1 if we roll a 5, and nothing otherwise.\nLet \\(X\\) be how much money we get.\nFind the mean and variance of \\(X\\)."
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-binomial-rvs",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-binomial-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Binomial RVs",
    "text": "Properties of Binomial RVs\n\nScenario: There are \\(n\\) independent trials, each resulting in a success or failure, with constant probability, \\(p\\), in each trial. We are counting the number of successes (or failures).\nShorthand: \\(X \\sim \\text{Binomial}(n, p)\\)\n\n\\[\nX = \\text{Number of successes of } n \\text{ independent trials}\n\\]\n\\[\np_X(x) = P(X=x) = {n \\choose x}p^x(1-p)^{n-x} \\text{ for } x=0,1,2,  ..., n\n\\]\n\\[\\text{E}(X) = np\\] \\[\\text{Var}(X) = npq = np(1-p)\\]"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#our-beloved-fair-sided-die",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#our-beloved-fair-sided-die",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Our beloved fair-sided die",
    "text": "Our beloved fair-sided die\n\n\n\n\nExample 2\n\n\n\nSuppose we roll a fair 6-sided die 50 times.\nWe get $1 every time we roll a 5, and nothing otherwise.\nLet \\(X\\) be how much money we get on the 50 rolls.\nFind the mean and variance of \\(X\\)."
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#geometric-rvs",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#geometric-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Geometric RVs",
    "text": "Geometric RVs\n\nScenario: There are repeated independent trials, each resulting in a success or failure, with constant probability of success for each trial. We are counting the number of trials until the first success.\nShorthand: \\(X \\sim \\text{Geo}(p)\\) or \\(X \\sim \\text{Geometric}(p)\\) or \\(X \\sim \\text{G}(p)\\)\n\n\n\n\n\n\n\n\n\\(X =\\) Number of trials needed for first success (count \\(x\\) includes the success)\n\\(X =\\) Number of failures before first success (count \\(x\\) does not include the success)\n\n\n\n\n\\(p _\nX( x ) = P(X=x) = (1-p)^{x-1}p\\)\nfor \\(x=1,2, 3,...\\)\n\\[F_\nX(x ) = P(X\\leq x) = 1-(1-p)^x\\]\nfor \\(x=1,2, 3,...\\)\n\\(p _X (x)= P(X=x) = (1-p)^{x}p\\)\nfor \\(x=0, 1,2,...\\)\n\\[F_X ( x\n)\n= P(X\\leq x) = 1-(1-p)^{x+1}\\]\nfor \\(x=0, 1,2,...\\)\n\n\n\\(E(X)=\\dfrac{1}{p}\\)\n\\(Var(X)= \\dfrac{1-p}{p^2}\\)\n\\(E(X)=\\dfrac{1-p}{p}\\)\n\\(Var(X) = \\dfrac{1-p}{p^2}\\)"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-14",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-14",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (1/4)",
    "text": "Bullseye (1/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the pmf for the number of throws needed to hit the bullseye?\nWhat are the mean and variance for the number of throws needed to hit the bullseye?\nFind the probability that our first bullseye:\n\nis on one of the first fifty tries\nis after the \\(50^{th}\\) try, given that it did not happen on the first 20 tries"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-24",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-24",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (2/4)",
    "text": "Bullseye (2/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the pmf for the number of throws needed to hit the bullseye?"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-34",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-34",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (3/4)",
    "text": "Bullseye (3/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat are the mean and variance for the number of throws needed to hit the bullseye?"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-44",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#bullseye-44",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (4/4)",
    "text": "Bullseye (4/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nFind the probability that our first bullseye:\n\nis on one of the first fifty tries\nis after the \\(50^{th}\\) try, given that it did not happen on the first 20 tries"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#memoryless-property-for-geometric-rvs",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#memoryless-property-for-geometric-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Memoryless property for Geometric RVs",
    "text": "Memoryless property for Geometric RVs\nIf we know \\(X\\) is greater than some number (aka given \\(X &gt;j\\)), then the probability of \\(X &gt; k+j\\) is just the probability that \\(X&gt;k\\).\n \n\\(P(X &gt; k+j |X &gt; j) = P(X &gt; k)\\) \\[ P(X &gt; k+j |X &gt; j) = \\dfrac{P(X&gt;k+j \\text{ and } X&gt;j)}{P(X&gt;j)} = \\dfrac{P(X&gt;k+j)}{P(X&gt;j)} = \\dfrac{(1-p)^{k+j}}{(1-p)^{j}} = (1-p)^{k} \\]"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-negative-binomial-rvs",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-negative-binomial-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Negative Binomial RVs",
    "text": "Properties of Negative Binomial RVs\n\nScenario: There are repeated independent trials, each resulting in a success or failure, with constant probability of success for each trial. We are counting the number of trials until the \\(r^{th}\\) success.\nShorthand: \\(X \\sim \\text{NegBin}(p, r)\\) or \\(X \\sim \\text{NB}(p, r)\\)\nNegative binomial is sum of \\(r\\) geometric distributions\n\n\\[\nX = \\text{Number of independent trials until } r^{th} \\text{ success}\n\\]\n\\[ p_X(x) = P(X=x) = {x-1 \\choose r-1}(1-p)^{x-r}p^r \\text{ for } x = r, r+1, r+2, ...\\]\n\\[ E(X) = \\dfrac{r}{p}\\]\n\\[Var(X) = \\dfrac{rq}{p^2} = \\dfrac{r(1-p)}{p^2}\\]"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#hitting-more-than-1-bullseye",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#hitting-more-than-1-bullseye",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Hitting more than 1 bullseye",
    "text": "Hitting more than 1 bullseye\n\n\n\n\nExample 1\n\n\nConsider again the bullseye example, where we throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the expected value and variance of the number of throws needed to hit 5 bullseyes?"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#hitting-more-than-1-bullseye-1",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#hitting-more-than-1-bullseye-1",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Hitting more than 1 bullseye",
    "text": "Hitting more than 1 bullseye\n\n\n\n\nExample 1\n\n\nConsider again the bullseye example, where we throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the probability that the \\(5^{th}\\) bullseye is on the \\(20^{th}\\) throw?"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-poisson-rvs",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#properties-of-poisson-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Poisson RVs",
    "text": "Properties of Poisson RVs\n\nScenario: We are counting the number of successes in a fixed time period, which has a constant rate of successes\nShorthand: \\(X \\sim \\text{Poisson}(\\lambda)\\) or \\(X \\sim \\text{Pois}(\\lambda)\\)\n\n\\[\nX = \\text{Number of successes in a given period}\n\\]\n\\[ p_X(x) = P(X=x) = \\dfrac{e^{-\\lambda}\\lambda^x}{x!} \\text{ for } x = 0, 1, 2,3, ...\\]\n\\[ \\text{E}(X) = \\lambda\\]\n\\[\\text{Var}(X) = \\lambda\\]"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#distinguishing-between-binomial-and-poisson-rvs",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#distinguishing-between-binomial-and-poisson-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Distinguishing between Binomial and Poisson RVs",
    "text": "Distinguishing between Binomial and Poisson RVs\n\nRecall that if \\(X\\sim \\text{Binomial}(n,p)\\), then\n\n\\(X\\) models the number of successes …\nin \\(n\\) independent (Bernoulli) trials …\nthat each have the same probability of success \\(p\\).\n\nPoisson r.v.’s are similar,\n\nexcept that instead of having \\(n\\) discrete independent trials,\nthere is a fixed time period (or space) during which the successes happen"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#examples-of-poisson-rvs",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#examples-of-poisson-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Examples of Poisson RVs",
    "text": "Examples of Poisson RVs\n\nNumber of visitors to an emergency room in an hour during a weekend night\nNumber of study participants enrolled in a study per week\nNumber of pedestrians walking through a square mile\nAny more?"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#emergency-room-visitors",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#emergency-room-visitors",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Emergency Room Visitors",
    "text": "Emergency Room Visitors\n\n\n\n\nExample 1\n\n\nSuppose an emergency room has an average of 50 visitors per day. Find the following probabilities.\n\nProbability of 30 visitors in a day.\nProbability of 8 visitors in an hour.\nProbability of at least 8 visitors in an hour."
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#combining-independent-poisson-distributions",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#combining-independent-poisson-distributions",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Combining independent Poisson distributions",
    "text": "Combining independent Poisson distributions\n\n\nTheorem 1\n\n\nIf \\(X\\sim Pois(\\lambda_1)\\) and \\(Y\\sim Pois(\\lambda_2)\\) are independent of each other, then \\(Z=X+Y\\sim Pois(\\lambda_1 + \\lambda_2)\\)."
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#two-emergency-rooms",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#two-emergency-rooms",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Two emergency rooms",
    "text": "Two emergency rooms\n\n\n\n\nExample 2\n\n\nSuppose emergency room 1 has an average of 50 visitors per day, and emergency room 2 has an average of 70 visitors per day, independently of each other. What is the probability distribution to model of the total number of visitors to both?"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#poisson-approximation-of-the-binomial",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#poisson-approximation-of-the-binomial",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Poisson Approximation of the Binomial",
    "text": "Poisson Approximation of the Binomial\nBoth Poisson and Binomial r.v.’s are counting the number of successes\n\nIf for a Binomial r.v.\n\nthe number of trials \\(n\\) is very large, and\nthe probability of success \\(p\\) is close to 0 or 1,\n\nThen the Poisson distribution can be used to approximate Binomial probabilities\n\nand we use \\(\\lambda = np\\)\n\nRule of thumb: We can use the Poisson approximation when \\(\\dfrac{1}{10} \\leq np(1-p) \\leq 10\\)"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#medical-lab-errors",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#medical-lab-errors",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Medical lab errors",
    "text": "Medical lab errors\n\n\n\n\nExample 3\n\n\nSuppose that in the long run, errors in a medical testing lab are made 0.1% of the time. Find the probability that fewer than 4 mistakes are made in the next 2,000 tests.\n\nFind the probability using the Binomial distribution.\nApproximate the probability in part (1) using the Poisson distribution.\n\n\n\n\nTo do for extra practice - will also see a similar problem in BSTA 511"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#hypergeometric-rvs",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#hypergeometric-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Hypergeometric RVs",
    "text": "Hypergeometric RVs\n\nScenario: There are a fixed number of successes and failures (which are known in advance), from which we make \\(n\\) draws without replacement. We are counting the number of successes from the \\(n\\) trials.\n\nThere is a finite population of \\(N\\) items\nEach item in the population is either a success or a failure, and there are \\(M\\) successes total.\nWe randomly select (sample) \\(n\\) items from the population without replacement\n\nShorthand: \\(X \\sim \\text{Hypergeo}(M, N, n)\\)\n\n\n\n\\[\nX = \\text{Number of successes in } n \\text{ draws}\n\\]\n\\[\np_X(x) = P(X=x) = \\dfrac{{M \\choose x}{N-M \\choose n-x}}{{N \\choose n}}\n\\] \\[\\text{ for } x \\text{ integer-valued } \\\\ \\max(0, n-(N-M)) \\leq x \\leq \\min(n, M)\\]\n\n\\[\\text{E}(X) =\\dfrac{nM}{N}\\]\n\\[\\text{Var}(X) = n \\dfrac{M}{N} \\bigg(1- \\dfrac{M}{N} \\bigg)\\bigg(\\dfrac{N-n}{N-1} \\bigg)\\]"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#wolf-population",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#wolf-population",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Wolf population",
    "text": "Wolf population\n\n\n\n\nExample 4\n\n\nA wildlife biologist is using mark-recapture to research a wolf population. Suppose a specific study region is known to have 24 wolves, of which 11 have already been tagged. If 5 wolves are randomly captured, what is the probability that 3 of them have already been tagged?"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#binomial-approximation-of-the-hypergeometric-rv",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#binomial-approximation-of-the-hypergeometric-rv",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Binomial approximation of the hypergeometric RV",
    "text": "Binomial approximation of the hypergeometric RV\nSuppose a hypergeometric RV \\(X\\) has the following properties:\n\nthe population size \\(N\\) is really big,\nthe number of successes \\(M\\) in the population is relatively large,\n\n\\(\\frac{M}{N}\\) shouldn’t be close to 0 or 1\n\nand the number of items \\(n\\) selected is small\nRule of thumb: \\(\\dfrac{n}{N}&lt;0.05\\) or \\(N&gt;20n\\)\n\nThen, in this case, making \\(n\\) draws from the population doesn’t change the probability of success much, and the hypergeometric RV. can be approximated by a binomial RV"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#wolf-population-revisited",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#wolf-population-revisited",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Wolf population revisited",
    "text": "Wolf population revisited\n\n\n\n\nExample 5\n\n\nSuppose a specific study region is known to have 2400 wolves, of which 1100 have already been tagged.\n\nIf 50 wolves are randomly captured, what is the probability that 20 of them have already been tagged?\nApproximate the probability in part (1) using the binomial distribution."
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#discrete-uniform-rvs",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#discrete-uniform-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Discrete Uniform RVs",
    "text": "Discrete Uniform RVs\n\nScenario: There are \\(N\\) possible outcomes, which are all equally likely.\nShorthand: \\(X \\sim \\text{Uniform}(N)\\)\n\n\\[\nX = \\text{Outcome of interest, with } x=1, 2, ..., N\n\\]\n\\[\np_X(x) = P(X=x) = \\dfrac{1}{N} \\text{ for } x=1, 2, 3, ..., N\n\\]\n\\[\\text{E}(X) =\\dfrac{N+1}{2}\\]\n\\[\\text{Var}(X) = \\dfrac{N^2 -1}{12}\\]"
  },
  {
    "objectID": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#what-discrete-uniform-rvs-have-we-seen-already",
    "href": "lessons_old/14_20_Discrete_RVs/14_20_Discrete_RVs.html#what-discrete-uniform-rvs-have-we-seen-already",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "What discrete uniform RVs have we seen already?",
    "text": "What discrete uniform RVs have we seen already?\n\n\n\n\nExample 6\n\n\nExamples of discrete uniform RVs"
  },
  {
    "objectID": "lessons_old/04_Conditional_Probability/04_Conditional_Probability_key_info.html",
    "href": "lessons_old/04_Conditional_Probability/04_Conditional_Probability_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "For office hours, we decided to do appointments!\n\nHere’s my Calendly: https://calendly.com/nickywakim/15min\nI teach on Mondays and Wednesdays so I am keeping most of my meetings to Tuesdays and Thursdays\nFor my EPI class, I have scheduled office hours on Mondays 4-5pm in VPT 627\n\nI will give priority to EPI students, but you can drop by for those as well\n\n\nI think all the dates in the schedule were correct except for next week"
  },
  {
    "objectID": "lessons_old/04_Conditional_Probability/04_Conditional_Probability_key_info.html#announcements",
    "href": "lessons_old/04_Conditional_Probability/04_Conditional_Probability_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "For office hours, we decided to do appointments!\n\nHere’s my Calendly: https://calendly.com/nickywakim/15min\nI teach on Mondays and Wednesdays so I am keeping most of my meetings to Tuesdays and Thursdays\nFor my EPI class, I have scheduled office hours on Mondays 4-5pm in VPT 627\n\nI will give priority to EPI students, but you can drop by for those as well\n\n\nI think all the dates in the schedule were correct except for next week"
  },
  {
    "objectID": "lessons_old/04_Conditional_Probability/04_Conditional_Probability_key_info.html#key-dates",
    "href": "lessons_old/04_Conditional_Probability/04_Conditional_Probability_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 1 Assignment due this Thursday at 11pm"
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "",
    "text": "Distinguish between Uniform, Exponential, Gamma, and Normal distributions when reading a story.\nIdentify the variable and the parameters in a story, and state what the variable and parameters mean.\nUse the formulas for the pdf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#properties-of-continuous-uniform-rvs",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#properties-of-continuous-uniform-rvs",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Properties of continuous uniform RVs",
    "text": "Properties of continuous uniform RVs\n\nScenario: Events are equally likely to happen anywhere or anytime in an interval of values\nShorthand: \\(X \\sim \\text{U}[a,b]\\)\n\n\\[\nf_X(x) = \\dfrac{1}{b-a}, \\text{ for }a \\leq x \\leq b\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;a \\quad \\\\\n            \\dfrac{x-a}{b-a} & \\quad a \\leq x \\leq b\\quad \\\\\n            1 & \\quad x&gt;b \\quad\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{a+b}{2} \\text{, } \\text{ Var}(X) = \\dfrac{(b-a)^2}{12}\\]"
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#identifying-continuous-uniform-rv-from-word-problems",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#identifying-continuous-uniform-rv-from-word-problems",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Identifying continuous uniform RV from word problems",
    "text": "Identifying continuous uniform RV from word problems\n\nLook for some indication that all events are equally likely\n\nCould also say “uniformly distributed”\n\nLook for an interval\n\nTime example: Costumer in your store will approach the cash register in next 30 minutes. Approaching the register throughout the 30 minutes is equally likely.\nLength example: You have a 12 inch string that you need to cut. You are equally likely to cut anywhere on the string.\n\nDifferent than the discrete uniform\n\nDiscrete usually includes a countable number of events that are equally likely\nContinuous is not countable\n\nExact time and length can be measured with infinite decimal places"
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re looking at equally likely arrival times between 10 am and 11 am.\n\nIf we want to know the probability that someone arrives at 10:30am or earlier:\n\npunif(q = 30, min = 0, max = 60)\n\n[1] 0.5\n\n\nIf we want to know the time, say \\(t\\), where the probability of arriving at \\(t\\) or earlier is 0.35:\n\nqunif(p = 0.35, min = 0, max = 60)\n\n[1] 21\n\n\nIf we want to know the probability that someone arrives between 10:14 and 10:16 am:\n\npunif(q = 16, min = 0, max = 60) - punif(q = 14, min = 0, max = 60)\n\n[1] 0.03333333\n\n\nIf we want to sample 20 arrival times from the distribution:\n\nrunif(n = 20, min = 0, max = 60)\n\n [1] 32.344076 30.257801 33.239564 41.171104 51.175109 56.237454 52.591784\n [8]  6.168688 47.204869 21.843940 14.237919  3.566863 26.432725 45.246377\n[15] 21.791561 54.575130 40.956728 41.026087 20.026951 16.720593"
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#bird-on-a-wire-tb-31.5",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#bird-on-a-wire-tb-31.5",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Bird on a wire (TB 31.5)",
    "text": "Bird on a wire (TB 31.5)\n\n\n\n\nExample 1\n\n\nA bird lands at a location that is Uniformly distributed along an electrical wire of length 150 feet. The wire is stretched tightly between two poles. What is the probability that the bird is 20 feet or less from one or the other of the poles?"
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#properties-of-exponential-rvs",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#properties-of-exponential-rvs",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Properties of exponential RVs",
    "text": "Properties of exponential RVs\n\nScenario: Modeling the time until the next (first) event\nContinuous analog to the geometric distribution!\nShorthand: \\(X \\sim \\text{Exp}(\\lambda)\\)\n\n\\[\nf_X(x) = \\lambda e^{-\\lambda x}\\text{ for } x&gt;0, \\lambda&gt;0\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;0 \\quad \\\\\n            1 - e^{-\\lambda x} & \\quad x\\geq0 \\\\\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{1}{\\lambda}\\] \\[\\text{Var}(X) = \\dfrac{1}{\\lambda^2}\\]"
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#memoryless-property",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#memoryless-property",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Memoryless Property",
    "text": "Memoryless Property\n   \nIf \\(b&gt;0\\),\n\\[P(X &gt; a +b | X&gt; a) = P(X &gt; b)\\]\n     \n\nThis can be interpreted as:\n\nIf you have waited \\(a\\) seconds (or any other measure of time) without a success\nThen the probability that you have to wait \\(b\\) more seconds is the same as as the probability of waiting \\(b\\) seconds initially."
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#identifying-exponential-rv-from-word-problems",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#identifying-exponential-rv-from-word-problems",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Identifying exponential RV from word problems",
    "text": "Identifying exponential RV from word problems\n\nLook for time between events/successes\nLook for a rate of the events over time period\nHow does it differ from the geometric distribution?\n\nGeometric is number of trials until first success\nExponential is time until first success\n\nRelation to the Poisson distribution?\n\nWhen the time between arrivals is exponential, the number of arrivals in a fixed time interval is Poisson with the mean \\(\\lambda\\)"
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-1",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-1",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re sitting at the bus stop, measuring the time until our bus arrives. We know the bus comes every 10 minutes on average.\n\nIf we want to know the probability that the bus arrives in the next 5 minutes:\n\npexp(q = 5, rate = 1/10)\n\n[1] 0.3934693\n\n\nIf we want to know the time, say \\(t\\), where the probability of the bus arriving at \\(t\\) or earlier is 0.35:\n\nqexp(p = 0.35, rate = 1/10)\n\n[1] 4.307829\n\n\nIf we want to know the probability that the bus arrives between 3 and 5 minutes:\n\npexp(q = 5, rate = 1/10) - pexp(q = 3, rate = 1/10)\n\n[1] 0.1342876\n\n\nIf we want to sample 20 bus arrival times from the distribution:\n\nrexp(n = 20, rate = 1/10)\n\n [1]  6.1428488  5.7702809  4.7216306  0.1803120  8.0881904  6.6174270\n [7]  0.6382305 11.0979408 11.8187740 28.4106592  1.0032984  0.7278661\n[13]  6.0539431  3.8940467  4.8817649  8.8015558 25.1247100  2.9737880\n[19] 12.5418032 27.4686140"
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#transformation-of-independent-exponential-rvs",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#transformation-of-independent-exponential-rvs",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Transformation of independent exponential RVs",
    "text": "Transformation of independent exponential RVs\n\n\nRevisit after joint notes:\n\n\nExample 1\n\n\nLet \\(X_i \\sim \\textrm{Exp}(\\lambda_i)\\) be independent RVs, for \\(i=1 \\ldots n\\). Find the pdf for the first of the arrival times."
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#properties-of-gamma-rvs",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#properties-of-gamma-rvs",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Properties of gamma RVs",
    "text": "Properties of gamma RVs\n\nScenario: Modeling the time until the \\(r^{th}\\) event.\nContinuous analog to the Negative Binomial distribution\nShorthand: \\(X \\sim \\text{Gamma}(r, \\lambda)\\)\n\n\\[\nf_X(x) = \\dfrac{\\lambda^r}{\\Gamma(r)}x^{r-1} e^{-\\lambda x}\\text{ for } x&gt;0, \\lambda&gt;0, \\Gamma(r) = (r-1)!\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;0 \\quad \\\\\n            1 - e^{-\\lambda x}\\displaystyle\\sum_{j=0}^{r-1}\\dfrac{(\\lambda x)^j}{j!}  & \\quad x\\geq0 \\\\\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{r}{\\lambda}\\text{, }\\text{ Var}(X) = \\dfrac{r}{\\lambda^2}\\]\nCommon to see \\(\\alpha = r\\) and \\(\\beta = \\lambda\\)"
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#identifying-gamma-rv-from-word-problems",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#identifying-gamma-rv-from-word-problems",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Identifying gamma RV from word problems",
    "text": "Identifying gamma RV from word problems\n\nGamma distribution with \\(r=1\\) is same as exponential\n\nJust like Negative Binomial with \\(r=1\\) is same as the geometric distribution\n\nSimilar to exponential\n\nLook for time between or until events/successes\n\nBUT now we are measuring time until more than 1 success\n\nLook for a rate of the events over time period"
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-2",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-2",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re sitting at the bus stop, measuring the time until 4 buses arrive. We know the bus comes every 10 minutes on average.\n\nIf we want to know the probability that the 4 buses arrive in the next 50 minutes:\n\n\n\n\npgamma(q = 50, rate = 1/10, shape = 4)\n\n[1] 0.7349741\n\n\n\n\npgamma(q = 50, scale = 10, shape = 4)\n\n[1] 0.7349741\n\n\n\n\n\nIf we want to know the time, say \\(t\\), where the probability of the 4 buses arriving at \\(t\\) or earlier is 0.35:\n\nqgamma(p = 0.35, rate = 1/10, shape = 4)\n\n[1] 29.87645\n\n\nIf we want to know the probability that the 4 buses arrives between 30 and 50 minutes:\n\npgamma(q = 50, scale = 10, shape = 4) - pgamma(q = 30, scale = 10, shape = 4)\n\n[1] 0.382206\n\n\nIf we want to sample 20 arrival times for the 4 buses:\n\nrgamma(n = 20, scale = 10, shape = 4)\n\n [1]  54.747551  55.676098  50.641989  48.628563   7.398563  26.790619\n [7]  32.145748  29.368795  32.729944  35.771609  43.808196  43.929835\n[13]  51.420173  56.847993  40.482057  12.111137  42.879689 111.300746\n[19]  37.062525  52.664171"
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#remarks",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#remarks",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Remarks",
    "text": "Remarks\n\nThe parameter \\(r\\) in a Gamma(\\(r\\),\\(\\lambda\\)) distribution does NOT need to be a positive integer\n\n\\(r\\) is usually a positive integer\n\nWhen \\(r\\) is a positive integer, the distribution is sometimes called an Erlang(\\(r\\),\\(\\lambda\\)) distribution\n \n \nWhen \\(r\\) is any positive real number, we have a general gamma distribution that is usually instead parameterized by \\(\\alpha&gt;0\\) and \\(\\beta&gt;0\\), where:\n\n\\(\\alpha = \\text{shape parameter}\\) : same as \\(k\\), the total number of events we must witness\n\nIn R code example: 4 buses to wait for\n\n\\(\\beta = \\text{scale parameter}\\) : same as \\(\\lambda\\), the rate parameter\n\nIn R code example: 1 bus per 10 minutes (1/10)"
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#sending-money-orders",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#sending-money-orders",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Sending money orders",
    "text": "Sending money orders\n\n\n\n\nExample 1\n\n\nOn average, someone sends a money order once per 15 minutes. What is the probability someone sends 10 money orders in less than 3 hours?"
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#additional-resource",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#additional-resource",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Additional Resource",
    "text": "Additional Resource\n\nAnother helpful site with R code: https://rpubs.com/mpfoley73/459051"
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#properties-of-normal-rvs",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#properties-of-normal-rvs",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Properties of Normal RVs",
    "text": "Properties of Normal RVs\n\nNo scenario description here because the Normal distribution is so universal\n\nCentral Limit Theorem (next class) makes it applicable to many types of events\n\nShorthand: \\(X \\sim \\text{Normal}(\\mu, \\sigma^2)\\)\n\n\\[\nf_X(x) = \\dfrac{1}{\\sqrt{2\\pi \\sigma^2}}e^{-(x-\\mu)^2/(2\\sigma^2)} \\text{, for} -inf &lt; x &lt; inf\n\\]\n\\[\\text{E}(X) = \\mu \\] \\[\\text{Var}(X) = \\sigma^2\\]"
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-3",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-3",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re measuring the high temperature today. The average high temperature on this day across many, many years is 50 degrees with a standard deviation of 4 degrees.\n\nIf we want to know the probability that the high temperature is below 45 degrees:\n\npnorm(q = 45, mean = 50, sd = 4)\n\n[1] 0.1056498\n\n\nIf we want to know the temoerature, say \\(t\\), where the probability of that the temperature is at \\(t\\) or lower is 0.35:\n\nqnorm(p = 0.35, mean = 50, sd = 4)\n\n[1] 48.45872\n\n\nIf we want to know the probability that the temperature is between 45 and 50 degrees:\n\npnorm(q = 50, mean = 50, sd = 4) - pnorm(q = 45, mean = 50, sd = 4)\n\n[1] 0.3943502\n\n\nIf we want to sample 20 days’ temperature (over the years) from the distribution:\n\nrnorm(n = 20, mean = 50, sd = 4)\n\n [1] 44.20980 48.10194 51.66071 36.64423 47.60898 56.83969 52.72222 43.48835\n [9] 46.22541 51.48154 50.45066 45.36346 58.27313 51.57238 47.62438 54.47735\n[17] 49.82309 52.20275 44.29908 51.06931"
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#movie-night-while-studying",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#movie-night-while-studying",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Movie night while studying",
    "text": "Movie night while studying\n\n\n\n\nExample 1\n\n\nChildren’s movies run an average of 98 minutes with a standard deviation of 10 minutes. You check out a random movie from the library to entertain your kids so you can study for your test. Assume that your kids will be occupied for the entire length of the movie.\n\nWhat is the probability that your kids will be occupied for at least the 2 hours you would like to study?\nWhat is range for the bottom quartile (lowest 25%) of time they will be occupied?"
  },
  {
    "objectID": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#standard-normal-distribution",
    "href": "lessons_old/31_35_Cont_RVs/31_35_Cont_RVs.html#standard-normal-distribution",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Standard Normal Distribution",
    "text": "Standard Normal Distribution\n\\[ Z \\sim \\text{Normal}(\\mu = 0, \\sigma^2 = 1)\\]\n\nUsed to be more helpful when computing was not as advanced\n\nUse tables of the standard normal\nYou can convert any normal distribution to a standard normal through transformation\n\n\\(Z = \\dfrac{X - \\mu_X}{\\sigma_X}\\)\n\nComes from \\(X = \\sigma_X Z + \\mu_X\\)\nSince \\(\\sigma_X\\) and \\(\\mu_X\\) are constants, then \\(E(X) = \\mu_X\\) and \\(SD(X) = \\sigma_X SD(Z) = \\sigma_X\\)"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability.html",
    "href": "lessons_old/01_Probability/01_Probability.html",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "",
    "text": "probability and randomness"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability.html#what-is-probability-12",
    "href": "lessons_old/01_Probability/01_Probability.html#what-is-probability-12",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "What is probability? (1/2)",
    "text": "What is probability? (1/2)\n\nWe hear the word “probability” pretty often\n\nCommon in news reports, advertisements, sports, medicine, etc.\n\n\n\nResearchers say the probability of living past 110 is on the rise\nCNBC, 2021\n\n\nWe may hear “probability” or similar words like “chance,” “likelihood,” or “odds”\n\n\nScientists fine-tune odds of asteroid Bennu hitting Earth through 2300 with NASA probe’s help\nSpace.com, 2021"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability.html#before-we-take-one-more-step",
    "href": "lessons_old/01_Probability/01_Probability.html#before-we-take-one-more-step",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Before we take one more step",
    "text": "Before we take one more step\n\nThe following few slides use some undefined words to define new words that in turn define other words\nIt’s confusing!\nWe’re going off assumption that we all have some understanding of probability, so stop me if you are confused!"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability.html#probability-and-randomness",
    "href": "lessons_old/01_Probability/01_Probability.html#probability-and-randomness",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Probability and randomness",
    "text": "Probability and randomness\n\nProbability requires randomness\nSomething is random if there are many potential outcomes, but there is uncertainty which outcome will occur\n\n \n\nOutcomes can be “equally likely,” meaning each outcome has the same probability of happening\n\nBut random does NOT necessarily mean equally likely\n\nWe often use physical randomness to demonstrate equally likely outcomes\n\nThink: flipping coins, rolling a dice, drawing cards\n\n\n \n\nThe occurrence of outcomes can be uncertain, but there is an underlying distribution of the probability of outcomes\n\nThere is a distribution of outcomes over large number of (hypothetical repetitions)"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability.html#a-single-coin-flip-then-100-coin-flips",
    "href": "lessons_old/01_Probability/01_Probability.html#a-single-coin-flip-then-100-coin-flips",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "A single coin flip then 100 coin flips",
    "text": "A single coin flip then 100 coin flips\nSeeing Theory, Chapter 1: Basic Probability, Chance Events"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability.html#how-do-we-simulate-this-in-r",
    "href": "lessons_old/01_Probability/01_Probability.html#how-do-we-simulate-this-in-r",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "How do we simulate this in R?",
    "text": "How do we simulate this in R?\n\nWe know that heads and tails are equally likely for a single flip\n\n\nset.seed(13)\ncoin = c(\"heads\", \"tails\")\nsample(coin, 1)\n\n[1] \"tails\"\n\n\n\nWhen we only flip the coin once, we only only get one outcome (heads or tails)\n\nWe cannot see any distribution of the probability of outcomes"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability.html#what-if-i-sample-10-coin-flips",
    "href": "lessons_old/01_Probability/01_Probability.html#what-if-i-sample-10-coin-flips",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "What if I sample 10 coin flips?",
    "text": "What if I sample 10 coin flips?\n\nHow many tails do we get? Are we getting closer to a distribution of heads and tails that we expect?\n\n\n\n\nResults and running proportion of H for 10 flips of a fair coin.\n\n\nFlip\nResult\nRunning count of H\nRunning proportion of H\n\n\n\n\n1\nH\n1\n1.000\n\n\n2\nT\n1\n0.500\n\n\n3\nH\n2\n0.667\n\n\n4\nT\n2\n0.500\n\n\n5\nH\n3\n0.600\n\n\n6\nT\n3\n0.500\n\n\n7\nT\n3\n0.429\n\n\n8\nT\n3\n0.375\n\n\n9\nT\n3\n0.333\n\n\n10\nT\n3\n0.300"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability.html#what-if-i-sample-100-coin-flips",
    "href": "lessons_old/01_Probability/01_Probability.html#what-if-i-sample-100-coin-flips",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "What if I sample 100 coin flips?",
    "text": "What if I sample 100 coin flips?"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability.html#can-we-simulate-more",
    "href": "lessons_old/01_Probability/01_Probability.html#can-we-simulate-more",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Can we simulate more??",
    "text": "Can we simulate more??\n\nI can start to count the number of tails in the flips\n\n\nsum( sample(coin, 100, replace = T) == \"heads\" )\n\n[1] 42\n\n\n\nAnd I can see the proportion of tails in the flips\n\n\nsum( sample(coin, 100, replace = T) == \"heads\" ) / 100\n\n[1] 0.42\n\n\n\nI can do this with more flips\n\n\nsum( sample(coin, 1000, replace = T) == \"heads\" ) / 1000\n\n[1] 0.531\n\nsum( sample(coin, 10000, replace = T) == \"heads\" ) / 10000\n\n[1] 0.4956\n\nsum( sample(coin, 100000, replace = T) == \"heads\" ) / 100000\n\n[1] 0.50033"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability.html#whats-the-point",
    "href": "lessons_old/01_Probability/01_Probability.html#whats-the-point",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "What’s the point?",
    "text": "What’s the point?\n\nWe know the probability of a heads is 0.5!\nWhy do we need to simulate 100s or 1000s of coin flips?\nWith enough repetitions, we can use simulations to approximate the probability of an event\nSimulations involve artificial recreation of a random phenomenon"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability.html#why-are-simulations-important-bigger-picture",
    "href": "lessons_old/01_Probability/01_Probability.html#why-are-simulations-important-bigger-picture",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Why are simulations important? (bigger picture)",
    "text": "Why are simulations important? (bigger picture)\n\nIn the previous example, coding a simulation seemed more educational than necessary\nWe can often calculate probabilities mathematically, but we will eventually get to complex calculations\n\nSimulations can help us (or be necessary) to solve a problem when calculations are complex\n\nSimulations are a great way to check your work!\nSimulation based reasoning is helpful in statistics\n\nYou’ll see this in confidence intervals in Biostatistics courses\n\nSimulations allow you to change assumptions easily and see how they affect your results\nIt is often how statisticians “run” experiments on their methods of hypotheses"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability.html#outcomes-events-sample-spaces",
    "href": "lessons_old/01_Probability/01_Probability.html#outcomes-events-sample-spaces",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Outcomes, events, sample spaces",
    "text": "Outcomes, events, sample spaces\n\n\nDefinition: Outcome\n\n\nThe possible results in a random phenomenon.\n\n\n\n\nDefinition: Sample Space\n\n\nThe sample space \\(S\\) is the set of all outcomes\n\n\n\n\nDefinition: Event\n\n\nAn event is a collection of some outcomes. An event can include multiple outcomes or no outcomes (a subset of the sample space).\n\n\nWhen thinking about events, think about outcomes that you might be asking the probability of. For example, what is the probability that you get a heads or a tails in one flip? (Answer: 1)"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability.html#coin-toss-example-1-coin-13",
    "href": "lessons_old/01_Probability/01_Probability.html#coin-toss-example-1-coin-13",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Coin Toss Example: 1 coin (1/3)",
    "text": "Coin Toss Example: 1 coin (1/3)\n\n\n\n\nSingle coin toss\n\n\nSuppose you toss one coin.\n\nWhat are the possible outcomes?\n \nWhat is the sample space?\n \nWhat are the possible events?"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability.html#coin-toss-example-1-coin-23",
    "href": "lessons_old/01_Probability/01_Probability.html#coin-toss-example-1-coin-23",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Coin Toss Example: 1 coin (2/3)",
    "text": "Coin Toss Example: 1 coin (2/3)\nSuppose you toss one coin.\n\nWhat are the possible outcomes?\n\nHeads (\\(H\\))\nTails (\\(T\\))\n\n\n \n\n\nNote\n\n\nWhen something happens at random, such as a coin toss, there are several possible outcomes, and exactly one of the outcomes will occur."
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability.html#coin-toss-example-1-coin-33",
    "href": "lessons_old/01_Probability/01_Probability.html#coin-toss-example-1-coin-33",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Coin Toss Example: 1 coin (3/3)",
    "text": "Coin Toss Example: 1 coin (3/3)\n\n\n\nWhat is the sample space?\n\n\\(S =\\)\n\n\n \n \n\nWhat are the possible events?\n\n\n\n\n\n\n \n\n\n\n\nNote #1\n\n\nWe use curly brackets (\\(\\{\\}\\)) to denote a set (collecting a list of outcomes or values)\n\n\n\n\nNote #2\n\n\nThe total number of possible events is \\[2^{|S|}\\] where \\(|S|\\) is the total number of outcomes in the sample space. Also, possible events are not necessarily something that can actually occur (i.e. getting a heads and a tails on a single coin flip)"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability.html#coin-toss-example-2-coins",
    "href": "lessons_old/01_Probability/01_Probability.html#coin-toss-example-2-coins",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Coin Toss Example: 2 coins",
    "text": "Coin Toss Example: 2 coins\nSuppose you toss two coins.\n\nWhat is the sample space? Assume the coins are distinguishable\n\n\\(S =\\)\n\n\n \n\nWhat are some possible events?\n\n\\(A =\\) exactly one \\(H =\\)\n\\(B =\\) at least one \\(H =\\)"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability.html#more-info-on-events-and-sample-spaces",
    "href": "lessons_old/01_Probability/01_Probability.html#more-info-on-events-and-sample-spaces",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "More info on events and sample spaces",
    "text": "More info on events and sample spaces\n\nWe usually use capital letters from the beginning of the alphabet to denote events. However, other letters might be chosen to be more descriptive.\n\nExamples: \\(A, B, C, A_1, A_2\\)\n\nWe can also define a new event as a combination of other events\n\nExamples: \\(A \\cup B\\) (union), \\(A \\cap B\\) (intersection), \\(A^C\\) (complement)\n\n\n \n\nWe use the notation \\(|S|\\) to denote the size of the sample space.\n\n \n\nThe total number of possible events is \\(2^{|S|}\\), which is the total number of possible subsets of \\(S\\).\n\n \n\nThe empty set, denoted by \\(\\emptyset\\), is the set containing no outcomes."
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability.html#example-keep-sampling-until",
    "href": "lessons_old/01_Probability/01_Probability.html#example-keep-sampling-until",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Example: Keep sampling until…",
    "text": "Example: Keep sampling until…\nSuppose you keep sampling people until you have someone with high blood pressure (BP)\n \nWhat is the sample space?\n\nLet \\(H =\\) denote someone with high BP.\nLet \\(H^C =\\) denote someone with not high blood pressure, such as low or regular BP.\n\n \n\nThen, \\(S =\\)"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability.html#lets-define-probability-with-events-and-spaces",
    "href": "lessons_old/01_Probability/01_Probability.html#lets-define-probability-with-events-and-spaces",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "Let’s define probability with events and spaces",
    "text": "Let’s define probability with events and spaces\nIf \\(S\\) is a finite sample space, with equally likely outcomes, then\n\\[\\mathbb{P}(A) = \\frac{|A|}{|S|}\\]\nIn human speak:\n\nFor equally likely outcomes, the probability that a certain event occurs is: the number of outcomes within the event of interest (\\(|A|\\)) divided by the total number of possible outcomes (\\(|S|\\))\n\n\\[\\mathbb{P}(A) = \\frac{\\text{total number of outcomes in event A}}{\\text{total number of outcomes in sample space}}\\]\n\nThus, it is important to be able to count the outcomes within an event"
  },
  {
    "objectID": "lessons_old/01_Probability/01_Probability.html#a-probability-is-a-function",
    "href": "lessons_old/01_Probability/01_Probability.html#a-probability-is-a-function",
    "title": "Lesson 1: Introduction to Probability and Simulation",
    "section": "A probability is a function…",
    "text": "A probability is a function…\n\n\\(\\mathbb{P}(A)\\) is a function with\n\nInput: event \\(A\\) from the sample space \\(S\\), (\\(A \\subseteq S\\))\n\n\\(A \\subseteq S\\) means “A contained within S” or “A is a subset of S”\n\nOutput: a number between 0 and 1 (inclusive)\n\n\n \n\nThe probability function maps an event (input) to value between 0 and 1 (output)\n\nWhen we speak of the probability function, we often call the values between 0 and 1 “probabilities”\n\nExample: “The probability of drawing a heart is 0.25” for \\(P(\\text{heart}) = 0.25\\)\n\n\n\n \n\nThe probability function needs to follow some specific rules (called axioms)!"
  },
  {
    "objectID": "lessons_old/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html",
    "href": "lessons_old/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "",
    "text": "Calculate the mean (expected value) of sums of discrete random variables"
  },
  {
    "objectID": "lessons_old/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#learning-objectives",
    "href": "lessons_old/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#learning-objectives",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "",
    "text": "Calculate the mean (expected value) of sums of discrete random variables"
  },
  {
    "objectID": "lessons_old/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#where-are-we",
    "href": "lessons_old/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#where-are-we",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons_old/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#revisiting-our-two-card-draw",
    "href": "lessons_old/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#revisiting-our-two-card-draw",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Revisiting our two card draw",
    "text": "Revisiting our two card draw\n\n\n\n\nExample 1\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw. Find \\(\\mathbb{E}[X]\\).\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "lessons_old/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#what-if-we-draw-a-lot-of-cards",
    "href": "lessons_old/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#what-if-we-draw-a-lot-of-cards",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "What if we draw A LOT of cards?",
    "text": "What if we draw A LOT of cards?\n\n\n\n\nExample 2\n\n\nWhat is the expected number of hearts in Example 1 if you draw 200 cards?\n\n\n\n\nRecall Binomial RV with \\(n=200\\):\n\\[p_X(x) = {200 \\choose x}p^x(1-p)^{200-x}\\] \\[\\text{  for } x = 0, 1, 2, ..., 200\\]"
  },
  {
    "objectID": "lessons_old/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#sum-of-discrete-rvs",
    "href": "lessons_old/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#sum-of-discrete-rvs",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Sum of discrete RVs",
    "text": "Sum of discrete RVs\n\n\nTheorem 11.1: Sum of discrete RVs\n\n\nFor discrete r.v.’s \\(X_i\\) and constants \\(a_i\\), \\(i=1,2,\\dots, n\\), \\[\\mathbb{E}\\Bigg[\\sum_{i=1}^n a_iX_i\\Bigg] = \\sum_{i=1}^n a_i\\mathbb{E}[X_i] .\\] Remark: The theorem holds for infinitely r.v.’s \\(X_i\\) as well.\n\n\n\nFor two RVs, \\(X\\) and \\(Y\\):\n\nWe can say \\(E[X+Y] = E[X] + E[Y]\\)\n… and constant numbers \\(a\\) and \\(b\\), we can also say \\(E[aX+bY] = aE[X] + bE[Y]\\)\nWe can also also say \\(E[X-Y] = E[X] - E[Y]\\), since \\(b=-1\\)"
  },
  {
    "objectID": "lessons_old/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#corollaries-from-thm-11.1",
    "href": "lessons_old/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#corollaries-from-thm-11.1",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Corollaries from Thm 11.1",
    "text": "Corollaries from Thm 11.1\n\n\n\n\nCorollary 11.1.1\n\n\nFor a discrete r.v. \\(X\\), and constants \\(a\\) and \\(b\\), \\[\\mathbb{E}[aX+b] = a\\mathbb{E}[X] + b.\\]\n\n\n\n\n\nCorollary 11.1.2\n\n\nIf \\(X_i\\), \\(i=1,2,\\dots, n\\), are identically distributed r.v.’s, then \\[\\mathbb{E}\\bigg[\\sum_{i=1}^n X_i\\bigg] = n\\mathbb{E}[X_1] .\\]"
  },
  {
    "objectID": "lessons_old/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#cost-of-hotel-rooms",
    "href": "lessons_old/11_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#cost-of-hotel-rooms",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Cost of hotel rooms",
    "text": "Cost of hotel rooms\n\n\n\n\nExample 4\n\n\nA tour group is planning a visit to the city of Minneapolis and needs to book 30 hotel rooms. The average price of a room is $200. In addition, there is a 10% tourism tax for each room. What is the expected cost for the 30 hotel rooms?"
  },
  {
    "objectID": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html",
    "href": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "",
    "text": "Learn the definition of a moment-generating function.\nFind the moment-generating function of a binomial random variable.\nUse a moment-generating function to find the mean and variance of a random variable."
  },
  {
    "objectID": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#learning-objectives",
    "href": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#learning-objectives",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "",
    "text": "Learn the definition of a moment-generating function.\nFind the moment-generating function of a binomial random variable.\nUse a moment-generating function to find the mean and variance of a random variable."
  },
  {
    "objectID": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#where-are-we",
    "href": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#where-are-we",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#what-are-moments",
    "href": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#what-are-moments",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "What are moments?",
    "text": "What are moments?\n\n\nDefinition 1\n\n\nThe \\(j^{th}\\) moment of a r.v. \\(X\\) is \\(\\mathbb{E}[X^j]\\)\n\n\n\n\nExample 1\n\n\n\\(1^{st}-4^{th}\\) moments"
  },
  {
    "objectID": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#what-is-a-moment-generating-function-mgf",
    "href": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#what-is-a-moment-generating-function-mgf",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "What is a moment generating function (mgf)??",
    "text": "What is a moment generating function (mgf)??\n\n\nDefinition 3\n\n\nIf \\(X\\) is a r.v., then the moment generating function (mgf) associated with \\(X\\) is: \\[M_X(t)= \\mathbb{E}[e^{tX}]\\]\n\n\nRemarks\n\n\n\nFor a discrete r.v., the mgf of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\sum_{all \\ x}e^{tx}p_X(x)\\]\nFor a continuous r.v., the mgf of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\int_{-\\infty}^{\\infty}e^{tx}f_X(x)dx\\]\n\n\n\nThe mgf \\(M_X(t)\\) is a function of \\(t\\), not of \\(X\\), and it might not be defined (i.e. finite) for all values of \\(t\\). We just need it to be defined for \\(t=0\\)."
  },
  {
    "objectID": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#example",
    "href": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#example",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Example",
    "text": "Example\n\n\n\n\nExample 4\n\n\nWhat is \\(M_X(t)\\) for \\(t=0\\)?"
  },
  {
    "objectID": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#theorem",
    "href": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#theorem",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Theorem",
    "text": "Theorem\n\n\nTheorem 5\n\n\nThe moment generating function uniquely specifies a probability distribution.\n\n\n\n\nTheorem 6\n\n\n\\[\\mathbb{E}[X^r] = M_X^{(r)}(0)\\]\n\\((r)\\) in this equation is the \\(r\\)th derivative with respect to \\(t\\)\n\n\n\nWhen \\(r=1\\), we are taking the first derivative\nWhen \\(r=4\\), we are taking the fourth derivative"
  },
  {
    "objectID": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-a-probability-distribution",
    "href": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-a-probability-distribution",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Using the mgf to uniquely describe a probability distribution",
    "text": "Using the mgf to uniquely describe a probability distribution\n\n\n\n\nExample 7\n\n\nLet \\(X \\sim Poisson(\\lambda)\\)\n\nFind the mgf of \\(X\\)\nFind \\(\\mathbb{E}[X]\\)\nFind \\(Var(X)\\)"
  },
  {
    "objectID": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#theorem-1",
    "href": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#theorem-1",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Theorem",
    "text": "Theorem\nRemark: Finding the mean and variance is sometimes easier with the following trick\n\n\nTheorem 8\n\n\nLet \\(R_X(t) = \\ln[M_X(t)]\\). Then,\n\\[\\mu = \\mathbb{E}[X] = R_X'(0) \\text{, and}\\] \\[\\sigma^2 = Var(X) = R_X''(0)\\]\n\n\n\nProof."
  },
  {
    "objectID": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-r_xt-to-uniquely-describe-a-probability-distribution",
    "href": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-r_xt-to-uniquely-describe-a-probability-distribution",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Using \\(R_X(t)\\) to uniquely describe a probability distribution",
    "text": "Using \\(R_X(t)\\) to uniquely describe a probability distribution\n\n\n\n\nExample 9\n\n\nLet \\(X \\sim Poisson(\\lambda)\\).\n\nFind \\(\\mathbb{E}[X]\\) using \\(R_X(t)\\)\nFind \\(Var(X)\\) using \\(R_X(t)\\)"
  },
  {
    "objectID": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-the-standard-normal-distribution",
    "href": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-the-standard-normal-distribution",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Using the mgf to uniquely describe the standard normal distribution",
    "text": "Using the mgf to uniquely describe the standard normal distribution\n\n\n\n\nExample 10\n\n\nLet \\(Z\\) be a standard normal random variable, i.e. \\(Z \\sim N(0,1)\\).\n\nFind the mgf of \\(Z\\)\nFind \\(\\mathbb{E}[Z]\\)\nFind \\(Var(Z)\\)"
  },
  {
    "objectID": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#mgfs-of-sums-of-independent-rvs",
    "href": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#mgfs-of-sums-of-independent-rvs",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Mgf’s of sums of independent RV’s",
    "text": "Mgf’s of sums of independent RV’s\n\n\nTheorem 9\n\n\nIf \\(X\\) and \\(Y\\) are independent RV’s with respective mgf’s \\(M_X(t)\\) and \\(M_Y(t)\\), then\n\\[M_{X+Y}(t) = E[e^{t(X+Y)}] = E[e^{tX} e^{tY}] = E[e^{tX}]E[e^{tY}]=M_{X}(t)M_{Y}(t)\\]"
  },
  {
    "objectID": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#main-takeaways",
    "href": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#main-takeaways",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Main takeaways",
    "text": "Main takeaways\n\nMgf’s are a purely mathematically definition\n\nWe can’t really relate it to our real world analysis\n\nThey are helpful mathematically because they are unique to a probability distribution\n\nWe can find the unique mgf from for a probability distribution\nAnd we can find a distribution from an mgf\n\nMgf’s can sometimes make it easier to find the mean and variance of an RV\nMgf’s are most helpful when we are finding a joint distribution that is a sum or transformation of two RV’s\n\nMake the calculation easier!\n\nMgf’s are often used to prove certain distribution are sums of other ones!"
  },
  {
    "objectID": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#more-resources",
    "href": "lessons_old/43_01_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#more-resources",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "More resources",
    "text": "More resources\n\nhttps://online.stat.psu.edu/stat414/book/export/html/676\nhttps://www.youtube.com/watch/ez_vq23xWrQ\nhttps://www.youtube.com/watch/2p9J9ChTeFI\nhttps://www.youtube.com/watch/A5bWU8xcQkE\nhttps://www.youtube.com/watch/QeUrTGFTFm4\nhttps://www.youtube.com/watch/HhrkwyyRtgI"
  },
  {
    "objectID": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html",
    "href": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "",
    "text": "Calculate conditional probability of an event using Bayes’ Theorem\nUtilize additional probability rules in probability calculations, specifically the Higher Order Multiplication Rule and the Law of Total Probabilities"
  },
  {
    "objectID": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#learning-objectives",
    "href": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#learning-objectives",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "",
    "text": "Calculate conditional probability of an event using Bayes’ Theorem\nUtilize additional probability rules in probability calculations, specifically the Higher Order Multiplication Rule and the Law of Total Probabilities"
  },
  {
    "objectID": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#where-are-we",
    "href": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#where-are-we",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#introduction",
    "href": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#introduction",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Introduction",
    "text": "Introduction\n\nSo we learned about conditional probabilities\n\nWe learned how the occurrence of event A affects event B (B conditional on A)\n\nCan we figure out information on how the occurrence of event B affects event A?\nWe can use the conditional probability (\\(\\mathbb{P}(A|B)\\)) to get information on the flipped conditional probability (\\(\\mathbb{P}(B|A)\\))"
  },
  {
    "objectID": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#bayes-rule-for-two-events",
    "href": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#bayes-rule-for-two-events",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Bayes’ Rule for two events",
    "text": "Bayes’ Rule for two events\n\n\n\n\nTheorem: Bayes’ Rule (for two events)\n\n\nFor any two events \\(A\\) and \\(B\\) with nonzero probabilties,\n\\[\\mathbb{P}(A| B) =\n\\frac{\\mathbb{P}(A) \\cdot \\mathbb{P}(B|A)}\n{\\mathbb{P}(B)}\\]"
  },
  {
    "objectID": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-higher-order-multiplication-rule",
    "href": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-higher-order-multiplication-rule",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with Higher Order Multiplication Rule",
    "text": "Calculating probability with Higher Order Multiplication Rule\n\n\n\n\nExample 1\n\n\nSuppose we draw 5 cards from a standard shuffled deck of 52 cards. What is the probability of a flush, that is all the cards are of the same suit (including straight flushes)?\n\n\n\n\n\nHigher Order Multiplication Rule\n\n\n\\[\\mathbb{P}(A_1\\cap A_2 \\cap  \\ldots \\cap A_n)=\\mathbb{P}(A_1)\\cdot\\mathbb{P}(A_2|A_1) \\cdot \\\\\n\\mathbb{P}(A_3|A_1A_2)\\ldots \\cdot\\mathbb{P}(A_n|A_1A_2\\ldots A_{n-1})\\]"
  },
  {
    "objectID": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-law-of-total-probability",
    "href": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-law-of-total-probability",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with Law of Total Probability",
    "text": "Calculating probability with Law of Total Probability\n\n\n\n\nExample 2\n\n\nSuppose 1% of people assigned female at birth (AFAB) and 5% of people assigned male at birth (AMAB) are color-blind. Assume person born is equally likely AFAB or AMAB (not including intersex). What is the probability that a person chosen at random is color-blind?\n\n\n\n\n\nLaw of Total Probability for 2 Events\n\n\nFor events \\(A\\) and \\(B\\),\n\\[%\\left(\n\\begin{array}{ccl}\n\\mathbb{P}(B)&=&\\mathbb{P}(B \\cap A) + \\mathbb{P}(B \\cap A^C)\\\\\n           &=& \\mathbb{P}(B|A) \\cdot \\mathbb{P}(A)+ \\mathbb{P}(B | A^C)\\cdot \\mathbb{P}(A^C)\n\\end{array}\n%\\right)\\]"
  },
  {
    "objectID": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#general-law-of-total-proability",
    "href": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#general-law-of-total-proability",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "General Law of Total Proability",
    "text": "General Law of Total Proability\n\n\nLaw of Total Probability (general)\n\n\nIf \\(\\{A_i\\}_{i=1}^{n} = \\{A_1, A_2, \\ldots, A_n\\}\\) form a partition of the sample space, then for event \\(B\\),\n\\[%\\left(\n\\begin{array}{ccl}\n\\mathbb{P}(B)&=& \\sum_{i=1}^{n} \\mathbb{P}(B \\cap A_i)\\\\\n           &=& \\sum_{i=1}^{n} \\mathbb{P}(B|A_i) \\cdot \\mathbb{P}(A_i)\n\\end{array}\n%\\right)\\]"
  },
  {
    "objectID": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability",
    "href": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with generalized Law of Total Probability",
    "text": "Calculating probability with generalized Law of Total Probability"
  },
  {
    "objectID": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability-1",
    "href": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability-1",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with generalized Law of Total Probability",
    "text": "Calculating probability with generalized Law of Total Probability\n\n\n\n\nExample 3\n\n\nIndividuals are diagnosed with a particular type of cancer that can take on three different disease forms,* \\(D_1\\), \\(D_2\\), and \\(D_3\\). It is known that amongst people diagnosed with this particular type of cancer,\n\n20% of people will eventually be diagnosed with form \\(D_1\\),\n30% with form \\(D_2\\), and\n50% with form \\(D_3\\).\n\nThe probability of requiring chemotherapy (\\(C\\)) differs among the three forms of disease:\n\n80% with \\(D_1\\),\n30% with \\(D_2\\), and\n10% with \\(D_3\\).\n\nBased solely on the preliminary test of being diagnosed with the cancer, what is the probability of requiring chemotherapy (the event C)?\n\n\n\nSkipping in class! Let me know if you would like me to post solutions to this if you work through it!"
  },
  {
    "objectID": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#lets-revisit-the-color-blind-example",
    "href": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#lets-revisit-the-color-blind-example",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Let’s revisit the color-blind example",
    "text": "Let’s revisit the color-blind example\n\n\n\n\nExample 4\n\n\nRecall the color-blind example (Example 2), where\n\na person is AMAB with probability 0.5,\nAMAB people are color-blind with probability 0.05, and\nall people are color-blind with probability 0.03.\n\nAssuming people are AMAB or AFAB, find the probability that a color-blind person is AMAB."
  },
  {
    "objectID": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#calculate-probability-with-both-rules",
    "href": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#calculate-probability-with-both-rules",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculate probability with both rules",
    "text": "Calculate probability with both rules\n\n\n\n\nExample 5\n\n\nSuppose\n\n1% of people who are AFAB aged 40-50 years have breast cancer,\nan AFAB person with breast cancer has a 90% chance of a positive test from a mammogram, and\nan AFAB person has a 10% chance of a false-positive result from a mammogram.\n\nWhat is the probability that an AFAB person has breast cancer given that they just had a positive test?"
  },
  {
    "objectID": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#bayes-rule",
    "href": "lessons_old/05_Bayes_Theorem/05_Bayes_Theorem.html#bayes-rule",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Bayes’ Rule",
    "text": "Bayes’ Rule\n\n\nTheorem: Bayes’ Rule\n\n\nIf \\(\\{A_i\\}_{i=1}^{n}\\) form a partition of the sample space \\(S\\), with \\(\\mathbb{P}(A_i)&gt;0\\) for \\(i=1\\ldots n\\) and \\(\\mathbb{P}(B)&gt;0\\), then\n\\[\\mathbb{P}(A_j | B) =\n\\frac{\\mathbb{P}(B|A_j) \\cdot \\mathbb{P}(A_j)}\n{\\sum_{i=1}^{n} \\mathbb{P}(B|A_i) \\cdot \\mathbb{P}(A_i)}\\]"
  },
  {
    "objectID": "lessons_old/00_Intro/00_Intro_key_info.html",
    "href": "lessons_old/00_Intro/00_Intro_key_info.html",
    "title": "Key Info and Announcements",
    "section": "",
    "text": "Welcome! Here is where I will put announcements for class!\nHomework 0 is due THIS THURSDAY at 11pm!"
  },
  {
    "objectID": "lessons_old/00_Intro/00_Intro_key_info.html#announcements",
    "href": "lessons_old/00_Intro/00_Intro_key_info.html#announcements",
    "title": "Key Info and Announcements",
    "section": "",
    "text": "Welcome! Here is where I will put announcements for class!\nHomework 0 is due THIS THURSDAY at 11pm!"
  },
  {
    "objectID": "lessons_old/09_Joint_distributions/09_Joint_distributions.html",
    "href": "lessons_old/09_Joint_distributions/09_Joint_distributions.html",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "",
    "text": "Calculate probabilities for a pair of discrete random variables\nCalculate a joint, marginal, and conditional probability mass function (pmf)\nCalculate a joint, marginal, and conditional cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#learning-objectives",
    "href": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#learning-objectives",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "",
    "text": "Calculate probabilities for a pair of discrete random variables\nCalculate a joint, marginal, and conditional probability mass function (pmf)\nCalculate a joint, marginal, and conditional cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#where-are-we",
    "href": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#where-are-we",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#what-is-a-joint-pmf",
    "href": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#what-is-a-joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is a joint pmf?",
    "text": "What is a joint pmf?\n\n\nDefinition: joint pmf\n\n\nThe joint pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[p_{X,Y}(x,y) = \\mathbb{P}(X=x\\ and\\ Y=y) = \\mathbb{P}(X=x, Y=y)\\]"
  },
  {
    "objectID": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#this-chapters-main-example",
    "href": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#this-chapters-main-example",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "This chapter’s main example",
    "text": "This chapter’s main example\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?"
  },
  {
    "objectID": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#joint-pmf",
    "href": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Joint pmf",
    "text": "Joint pmf\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)"
  },
  {
    "objectID": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#marginal-pmfs",
    "href": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#marginal-pmfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Marginal pmf’s",
    "text": "Marginal pmf’s\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)"
  },
  {
    "objectID": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#remarks-on-the-joint-pmf",
    "href": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#remarks-on-the-joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the joint pmf",
    "text": "Remarks on the joint pmf\nSome properties of joint pmf’s:\n\nA joint pmf \\(p_{X,Y}(x,y)\\) must satisfy the following properties:\n\n\\(p_{X,Y}(x,y)\\geq 0\\) for all \\(x, y\\).\n\\(\\sum \\limits_{\\{all\\ x\\}} \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)=1\\).\n\nMarginal pmf’s:\n\n\\(p_X(x) = \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)\\)\n\\(p_Y(y) = \\sum \\limits_{\\{all\\ x\\}} p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#what-is-a-joint-cdf",
    "href": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#what-is-a-joint-cdf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is a joint CDF?",
    "text": "What is a joint CDF?\n\n\nDefinition: joint CDF\n\n\nThe joint CDF of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[F_{X,Y}(x,y) = \\mathbb{P}(X \\leq x\\ and\\ Y \\leq y) = \\mathbb{P}(X \\leq x, Y \\leq y)\\]"
  },
  {
    "objectID": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#joint-cdfs",
    "href": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#joint-cdfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Joint CDFs",
    "text": "Joint CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#marginal-cdfs",
    "href": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#marginal-cdfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Marginal CDFs",
    "text": "Marginal CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)"
  },
  {
    "objectID": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#remarks-on-the-joint-and-marginal-cdf",
    "href": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#remarks-on-the-joint-and-marginal-cdf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the joint and marginal CDF",
    "text": "Remarks on the joint and marginal CDF\n\n\\(F_X(x)\\): right most columns of the CDf table (where the \\(Y\\) values are largest)\n\\(F_Y(y)\\): bottom row of the table (where X values are largest)\n\\(F_X(x)=\\lim\\limits_{y\\rightarrow\\infty}F_{X, Y}(x,y)\\)\n\\(F_Y(y)=\\lim\\limits_{x\\rightarrow\\infty}F_{X, Y}(x,y)\\)"
  },
  {
    "objectID": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#independence-and-conditioning",
    "href": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#independence-and-conditioning",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Independence and Conditioning",
    "text": "Independence and Conditioning\nRecall that for events \\(A\\) and \\(B\\),\n\n\\(\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}\\)\n\\(A\\) and \\(B\\) are independent if and only if\n\n\\(\\mathbb{P}(A|B) = \\mathbb{P}(A)\\)\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A)\\cdot\\mathbb{P}(B)\\)\n\n\nIndependence and conditioning are defined similarly for r.v.’s, since \\[p_X(x) = \\mathbb{P}(X=x)\\ \\mathrm{and}\\ \\ p_{X,Y}(x,y) = \\mathbb{P}(X = x ,Y = y).\\]"
  },
  {
    "objectID": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#what-is-the-conditional-pmf",
    "href": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#what-is-the-conditional-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is the conditional pmf?",
    "text": "What is the conditional pmf?\n\n\nDefinition: conditional pmf\n\n\nThe conditional pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is defined as \\[p_{X|Y}(x|y) = \\mathbb{P}(X = x |Y = y) = \\frac{\\mathbb{P}(X = x\\ and\\ Y = y)}{\\mathbb{P}(Y = y)}\n=\\frac{p_{X,Y}(x,y) }{p_{Y}(y) }\\] if \\(p_{Y}(y) &gt; 0\\)."
  },
  {
    "objectID": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#remarks-on-the-conditional-pmf",
    "href": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#remarks-on-the-conditional-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the conditional pmf",
    "text": "Remarks on the conditional pmf\nThe following properties follow from the conditional pmf definition:\n\nIf \\(X \\perp Y\\) (independent)\n\n\\(p_{X|Y}(x|y) = p_X(x)\\) for all \\(x\\) and \\(y\\)\n\\(p_{X,Y}(x,y) = p_X(x)p_Y(y)\\) for all \\(x\\) and \\(y\\)\nWhich also implies (\\(\\Rightarrow\\)): \\(F_{X,Y}(x,y) = F_X(x)F_Y(y)\\) for all \\(x\\) and \\(y\\)\n\nIf \\(X_1, X_2, …, X_n\\) are independent\n\n\\[p_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1=x_1, X_2=x_2, …, X_n=x_n)=\\prod\\limits_{i=1}^np_{X_i}(x_i)\\]\n\\[F_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1\\leq x_1, X_2\\leq x_2, …, X_n\\leq x_n)=\\prod\\limits_{i=1}^nP(X_i \\leq x_i) = \\prod\\limits_{i=1}^nF_{X_i}(x_i)\\]"
  },
  {
    "objectID": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#conditional-pmfs",
    "href": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#conditional-pmfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Conditional pmf’s",
    "text": "Conditional pmf’s\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?\n\n\n\n\n\nRemark:\n\nTo show that \\(X\\) and \\(Y\\) are not independent, we just need to find one counter example\nHowever, to show that they are independent, we need to verify this for all possible pairs of \\(x\\) and \\(y\\)"
  },
  {
    "objectID": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#hypothetical-4-sided-die",
    "href": "lessons_old/09_Joint_distributions/09_Joint_distributions.html#hypothetical-4-sided-die",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Hypothetical 4-sided die",
    "text": "Hypothetical 4-sided die\n\n\nExample 3\n\n\n\nSuppose you have a 4-sided die, and you roll the 4-sided die until the first 4 appears.\nLet \\(X\\) be the number of rolls required until (and including) the first 4.\nAfter the first 4, you keep rolling it again until you roll a 3.\nLet \\(Y\\) be the number of rolls, after the first 4, required until (and including) the 3.\n\n\nFind \\(p_{X,Y}(x,y)\\).\nUsing \\(p_{X,Y}(x,y)\\), find \\(p_{Y}(y)\\).\nFind \\(p_{X}(x)\\).\nAre \\(X\\) and \\(Y\\) are independent? Why or why not?\nFind \\(F_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "lessons_old/28_Expected_Values/28_Expected_Values_key_info.html",
    "href": "lessons_old/28_Expected_Values/28_Expected_Values_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Wow! Week 7…\nHW 3 video/presentation\n\nTomorrow! 11/12 at 11pm: recordings due if you are making that\nCalendly is up!! Please see me original announcement\n\nNeed to grade HW 4 solutions and HW 5 assignment\nAnything else?"
  },
  {
    "objectID": "lessons_old/28_Expected_Values/28_Expected_Values_key_info.html#announcements",
    "href": "lessons_old/28_Expected_Values/28_Expected_Values_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Wow! Week 7…\nHW 3 video/presentation\n\nTomorrow! 11/12 at 11pm: recordings due if you are making that\nCalendly is up!! Please see me original announcement\n\nNeed to grade HW 4 solutions and HW 5 assignment\nAnything else?"
  },
  {
    "objectID": "lessons_old/28_Expected_Values/28_Expected_Values_key_info.html#key-dates",
    "href": "lessons_old/28_Expected_Values/28_Expected_Values_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 6 due\nSunday: HW 5 solutions due"
  },
  {
    "objectID": "lessons_old/10_Expected_Values/10_Expected_Values.html",
    "href": "lessons_old/10_Expected_Values/10_Expected_Values.html",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "",
    "text": "Calculate the mean (expected value) of discrete random variables"
  },
  {
    "objectID": "lessons_old/10_Expected_Values/10_Expected_Values.html#learning-objectives",
    "href": "lessons_old/10_Expected_Values/10_Expected_Values.html#learning-objectives",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "",
    "text": "Calculate the mean (expected value) of discrete random variables"
  },
  {
    "objectID": "lessons_old/10_Expected_Values/10_Expected_Values.html#where-are-we",
    "href": "lessons_old/10_Expected_Values/10_Expected_Values.html#where-are-we",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons_old/10_Expected_Values/10_Expected_Values.html#our-good-and-fair-friend-the-6-sided-die",
    "href": "lessons_old/10_Expected_Values/10_Expected_Values.html#our-good-and-fair-friend-the-6-sided-die",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Our good and fair friend, the 6-sided die",
    "text": "Our good and fair friend, the 6-sided die\n\n\n\n\nExample 1\n\n\nSuppose you roll a fair 6-sided die. What value do you expect to get?"
  },
  {
    "objectID": "lessons_old/10_Expected_Values/10_Expected_Values.html#what-is-an-expected-value",
    "href": "lessons_old/10_Expected_Values/10_Expected_Values.html#what-is-an-expected-value",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "What is an expected value?",
    "text": "What is an expected value?\n\n\nDefinition: Expected value\n\n\nThe expected value of a discrete r.v. \\(X\\) that takes on values \\(x_1, x_2, \\ldots, x_n\\) is \\[\\mathbb{E}[X] = \\sum_{i=1}^n x_ip_X(x_i).\\]\n\n\n\nExpected values are not necessarily an actual outcome\n\nIn previous example, we cannot roll a 3.5\nIt could be that our expected value is not in the sample space (\\(E(X) \\notin S\\))\n\nDefinition holds when \\(X\\) takes on countably infinitely many values:\n\n\\[\\mathbb{E}[X] = \\sum_{i=1}^\\infty x_ip_X(x_i)\\]"
  },
  {
    "objectID": "lessons_old/10_Expected_Values/10_Expected_Values.html#our-good-and-not-so-fair-friend-the-6-sided-die",
    "href": "lessons_old/10_Expected_Values/10_Expected_Values.html#our-good-and-not-so-fair-friend-the-6-sided-die",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Our good and not-so-fair friend, the 6-sided die",
    "text": "Our good and not-so-fair friend, the 6-sided die\n\n\n\n\nExample 2\n\n\nSuppose the die is 6-sided, but not fair. And the probabilities of each side is distributed as:\n\n\n\n\\(x\\)\n\\(p_X(x)\\)\n\n\n\n\n1\n0.10\n\n\n2\n0.05\n\n\n3\n0.02\n\n\n4\n0.30\n\n\n5\n0.50\n\n\n6\n0.03\n\n\n\nWhat value do you expect to get on a roll?"
  },
  {
    "objectID": "lessons_old/10_Expected_Values/10_Expected_Values.html#expected-value-of-a-bernoulli-distribution",
    "href": "lessons_old/10_Expected_Values/10_Expected_Values.html#expected-value-of-a-bernoulli-distribution",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Expected value of a Bernoulli distribution",
    "text": "Expected value of a Bernoulli distribution\n\n\n\n\nExample 3\n\n\nSuppose \\[X = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\quad\\mathrm{(success)}\\\\\n            0 & \\quad \\mathrm{with\\ probability}\\ 1-p \\quad\\mathrm{(failure)}\n        \\end{array}\n    \\right.\\] Find the expected value of \\(X\\)."
  },
  {
    "objectID": "lessons_old/10_Expected_Values/10_Expected_Values.html#lets-slightly-change-our-random-variable",
    "href": "lessons_old/10_Expected_Values/10_Expected_Values.html#lets-slightly-change-our-random-variable",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Let’s slightly change our random variable",
    "text": "Let’s slightly change our random variable\n\n\n\n\nExample 5\n\n\nSuppose \\[X = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\\\\n            -1 & \\quad \\mathrm{with\\ probability}\\ 1-p\n        \\end{array}\n    \\right.\\] Find the expected value of \\(X\\)."
  },
  {
    "objectID": "lessons_old/10_Expected_Values/10_Expected_Values.html#bullseye",
    "href": "lessons_old/10_Expected_Values/10_Expected_Values.html#bullseye",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Bullseye! 🎯",
    "text": "Bullseye! 🎯\n\n\n\n\nExample 5\n\n\nSuppose I throw darts at a dartboard until I hit the bullseye, and that my probability of hitting the bullseye is \\(p\\). Suppose further that all of my throws are independent, and that the probability of a bullseye never changes, no matter how many times I throw a dart. How many times should I expect to have to throw the dart until I hit the bullseye?"
  },
  {
    "objectID": "lessons_old/10_Expected_Values/10_Expected_Values.html#ghost",
    "href": "lessons_old/10_Expected_Values/10_Expected_Values.html#ghost",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Ghost! 👻",
    "text": "Ghost! 👻\n\n\n\n\nExample 6\n\n\nA ghost is trick-or-treating. It comes to a house where it is known that there are 30 candies in the bag and only one is a watermelon Jolly Rancher, which is the ghost’s favorite. The ghost takes pieces of candy without replacement until it gets the watermelon Jolly Rancher. How many pieces of candy do we expect the ghost to take?\n\n\nCan we model this with a distribution?"
  },
  {
    "objectID": "lessons_old/10_Expected_Values/10_Expected_Values.html#some-remarks-on-last-two-examples",
    "href": "lessons_old/10_Expected_Values/10_Expected_Values.html#some-remarks-on-last-two-examples",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Some remarks on last two examples",
    "text": "Some remarks on last two examples\nBoth examples are repeated random processes. They are fundamentally different though:\n\nThe bullseye example is “with replacement” since the probability of success remains constant.\nThe ghost trick-or-treating example is without replacement, and thus the probability of success changes with each trial."
  },
  {
    "objectID": "lessons_old/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html",
    "href": "lessons_old/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "",
    "text": "Calculate probability of a sample mean using a population mean and variance with unknown distribution\nUse the Central Limit Theorem to construct the Normal approximation of the Binomial and Poisson distributions"
  },
  {
    "objectID": "lessons_old/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#learning-objectives",
    "href": "lessons_old/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#learning-objectives",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "",
    "text": "Calculate probability of a sample mean using a population mean and variance with unknown distribution\nUse the Central Limit Theorem to construct the Normal approximation of the Binomial and Poisson distributions"
  },
  {
    "objectID": "lessons_old/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#the-central-limit-theorem",
    "href": "lessons_old/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#the-central-limit-theorem",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\n\n\nTheorem 1: Central Limit Theorem (CLT)\n\n\nLet \\(X_i\\) be iid rv’s with common mean \\(\\mu\\) and variance \\(\\sigma^2\\), for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\rightarrow \\text{N}(n\\mu, n\\sigma^2)\\]"
  },
  {
    "objectID": "lessons_old/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#extension-of-the-clt",
    "href": "lessons_old/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#extension-of-the-clt",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "Extension of the CLT",
    "text": "Extension of the CLT\n\n\nCorollary 1\n\n\nLet \\(X_i\\) be iid rv’s with common mean \\(\\mu\\) and variance \\(\\sigma^2\\), for \\(i=1,2,\\ldots,n\\). Then \\[\\overline{X}=\\frac{\\sum_{i=1}^n X_i}{n}  \\rightarrow \\text{N}\\Bigg(\\mu, \\dfrac{\\sigma^2}{n}\\Bigg)\\]"
  },
  {
    "objectID": "lessons_old/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#example-of-corollary-in-use",
    "href": "lessons_old/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#example-of-corollary-in-use",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "Example of Corollary in use",
    "text": "Example of Corollary in use\n\n\n\n\nExample 1\n\n\nAccording to a large US study, the mean resting heart rate of adult women is about 74 beats per minutes (bpm), with standard deviation 13 bpm (NHANES 2003-2004).\n\nFind the probability that the average resting heart rate for a random sample of 36 adult women is more than 3 bpm away from the mean.\nRepeat the previous question for a single adult woman."
  },
  {
    "objectID": "lessons_old/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#example-of-clt-for-exponential-distribution",
    "href": "lessons_old/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#example-of-clt-for-exponential-distribution",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "Example of CLT for exponential distribution",
    "text": "Example of CLT for exponential distribution\n\n\n\n\nExample 2\n\n\nLet \\(X_i \\sim Exp(\\lambda)\\) be iid RVs for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\rightarrow\\]"
  },
  {
    "objectID": "lessons_old/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#clt-for-discrete-rvs",
    "href": "lessons_old/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#clt-for-discrete-rvs",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "CLT for Discrete RVs",
    "text": "CLT for Discrete RVs\n\n\n\nBinomial rv’s: Let \\(X \\sim Bin(n,p)\\)\n\n\\(X = \\displaystyle\\sum_{i=1}^n X_i\\), where \\(X_i\\) are iid \\(\\text{Bernoulli}(p)\\)\nRule of thumb: \\(np\\geq10\\) and \\(n(1-p)\\geq 10\\) to use Normal approximation\n\n\n\n\n\n\nPoisson rv’s: Let \\(X \\sim Poisson(\\lambda)\\)\n\n\\(X = \\displaystyle\\sum_{i=1}^n X_i\\), where \\(X_i\\) are iid \\(\\text{Poiss}(1)\\)\nRecall from Chapter 18 that if \\(X_i \\sim Poiss(\\lambda_i)\\) and \\(X_i\\) independent, then \\(\\sum_{i=1}^n X_i \\sim Poiss(\\sum_{i=1}^n \\lambda_i)\\)\nRule of thumb: \\(\\lambda \\geq10\\) to use Normal approximation"
  },
  {
    "objectID": "lessons_old/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#at-home-example",
    "href": "lessons_old/37_Central_Limit_Theorem/37_Central_Limit_Theorem.html#at-home-example",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "At home example",
    "text": "At home example\n\n\nExample 3\n\n\nSuppose that the probability of developing a specific type of breast cancer in women aged 40-49 is 0.001. Assume the occurrences of cancer are independent. Suppose you have data from a random sample of 20,000 women aged 40-49.\n\nHow many of the 20,000 women would you expect to develop this type of breast cancer, and what is the standard deviation?\nFind the exact probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to find the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to approximate the following probabilities, where \\(X\\) is the number of women that will develop this type of breast cancer.\n\n\\(\\mathbb{P}(15 \\leq X \\leq 22)\\)\n\\(\\mathbb{P}(X &gt; 20)\\)\n\\(\\mathbb{P}(X &lt; 20)\\)\n\nFind the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer - not using the CLT!\nUse the CLT to approximate the approximate probability in the previous question!"
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities_key_info.html",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 6 assignment today!\n\nFeel free to turn in solutions later than 11/24 since I took so long to grade\n\nI made quite a few changes to the homeworks\n\nHW 10 is gone\nHW 9 is optional\nInstead of a HW assignment due over late November break\n\nHW 8 will include material from Week 8 and 9 and be due 12/5\n\n\nI have quite a bit of grading to catch up on!\nRealizing I never gave you mid-quarter feedback forms…\n\nLet’s chat about this and our assessment breakdown in the coming weeks\n\nAnything else?"
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities_key_info.html#announcements",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 6 assignment today!\n\nFeel free to turn in solutions later than 11/24 since I took so long to grade\n\nI made quite a few changes to the homeworks\n\nHW 10 is gone\nHW 9 is optional\nInstead of a HW assignment due over late November break\n\nHW 8 will include material from Week 8 and 9 and be due 12/5\n\n\nI have quite a bit of grading to catch up on!\nRealizing I never gave you mid-quarter feedback forms…\n\nLet’s chat about this and our assessment breakdown in the coming weeks\n\nAnything else?"
  },
  {
    "objectID": "lessons_old/25_Joint_densities/25_Joint_densities_key_info.html#key-dates",
    "href": "lessons_old/25_Joint_densities/25_Joint_densities_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 7 due\nSunday: HW 6 solutions due"
  },
  {
    "objectID": "lessons_old/26_Independent_rvs/26_Independent_rvs_muddy_points.html",
    "href": "lessons_old/26_Independent_rvs/26_Independent_rvs_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n2. Joint vs marginal vs conditional: How are we calculating the probability?\nIf we start at a joint probability \\(f_{X,Y}(x,y)\\)…. we can look at a few probabilities:\n\nJoint probability: \\(P(a \\leq X \\leq b, c \\leq Y \\leq d)\\)\n\\[P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=c}^{y=d} f_{X,Y}(x,y) dydx\\]\nMarginal probability: \\(P(a \\leq X \\leq b)\\)\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b} f_{X}(x) dx\\]\nOR\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=-\\inf}^{y=\\inf} f_{X,Y}(x,y) dydx\\]\nConditional probability: \\(P(a \\leq X \\leq b | Y = c)\\)\n\\[P(a \\leq X \\leq b | Y=c) = \\displaystyle\\int_{x=a}^{x=b} f_{X|Y}(x|y=c) dx\\]\nYou cannot calculate \\(P(a \\leq X \\leq b | Y = c)\\) by \\(\\dfrac{P(a \\leq X \\leq b, Y=c)}{P(Y = c)}\\) because \\(P(Y = c)\\) is 0. Instead, we need to find \\(f_{X|Y}(x|y=c)\\) by \\(\\dfrac{f_{X,Y}(x,y=c)}{f_{Y}(y=c)}\\) and THEN integrate over X.\n\n\n\n4. Here’s a 3D plot of one of our joint pdf’s\n\\[\nf_{X,Y}(x,y) = 5e^{-x-3y} \\text{ for } 0 \\leq y \\leq x/2\n\\]\n\nlibrary(plotly)\n\nx = seq(0, 5, 0.1)\ny = seq(0, max(x)/2, 0.1/2)\nfn = expand.grid(x=x,y=y)\nfn$z = ifelse(fn$y&lt;fn$x/2, 5*exp( (-1)*fn$x - 3*fn$y), NA)\n\nz = matrix(fn$z, ncol = 51, nrow = 51, byrow = T)\n\nfig &lt;- plot_ly(x = x, y=y, z=z) %&gt;% add_surface()\n\nfig"
  },
  {
    "objectID": "lessons_old/26_Independent_rvs/26_Independent_rvs_key_info.html",
    "href": "lessons_old/26_Independent_rvs/26_Independent_rvs_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 presentations are graded! You did great!\nHW 7 assignment: I’ll grade tonight!\nAnything else?"
  },
  {
    "objectID": "lessons_old/26_Independent_rvs/26_Independent_rvs_key_info.html#announcements",
    "href": "lessons_old/26_Independent_rvs/26_Independent_rvs_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 presentations are graded! You did great!\nHW 7 assignment: I’ll grade tonight!\nAnything else?"
  },
  {
    "objectID": "lessons_old/26_Independent_rvs/26_Independent_rvs_key_info.html#key-dates",
    "href": "lessons_old/26_Independent_rvs/26_Independent_rvs_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: NONE due\nSunday: HW 7 solutions due (feel free to take an additional 3 days)"
  },
  {
    "objectID": "lessons_old/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance_muddy_points.html",
    "href": "lessons_old/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n2. How do we set the bounds on a double integral?\nWhen the domain of the RVs are not dependent on each other, then we use the bounds as is. In example 2 of Chapter 26 notes, we have the joint pdf \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for\\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\). If we wanted to calculate something like \\(E(X)\\), then we could use the bounds as they are. Below is the domain for \\(x\\) and \\(y\\):\n\n\n\n\n\nHere is the integral for the expected value where we integrate over the whole domain of \\(x\\) and \\(y\\):\n\\[ E(X) = \\displaystyle\\int_0^1 \\displaystyle\\int_0^1 x (18 x^2 y^5 )dy dx \\]If we want to find the probability \\(P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75)\\), then we can look at the specific values of the probability:\n\n\n\n\n\nNote the blue lines above indicate how we integrate over \\(y\\) first from 0.5 to 0.75 and the green lines indicate how integrate over \\(x\\) first from 0.25 to 0.5. It seems like we’ve integrated over an area that isn’t within our specified probability. However, the integrated area is ONLY the overlap of the \\(x\\) and \\(y\\) bounds for the probability.\n\\[P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.25}^{0.5} \\displaystyle\\int_{0.5}^{0.75} 18 x^2 y^5 dy dx\\]\nLet’s use the same pdf, but now the domain of the two RVs is dependent on one another. We have the joint pdf \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for\\(0 \\leq x \\leq y\\leq1\\)\nIf we wanted to calculate something like \\(E(X)\\), then we need to account for fact that \\(x\\) must be less than of equal to \\(y\\). We can look back at the domain for this:\n\n\n\n\n\nNote the blue lines above still indicate how we integrate over \\(y\\) first from \\(x\\) to 1, and the green lines indicate how integrate over \\(x\\) first from 0 to 1. Once again, it seems like we’ve integrated over an area that isn’t within the domain. However, the integrated area is ONLY the overlap of the \\(x\\) and \\(y\\) bounds. Thus, once we’ve restricted \\(y\\) to the area between \\(x\\) and 1, we no longer need to restrict \\(x\\) to the are of 0 to \\(y\\).\n\\[ E(X) = \\displaystyle\\int_0^1 \\displaystyle\\int_x^1 x (18 x^2 y^5 )dy dx \\] If we want to find the probability \\(P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75)\\), then we should look back at our domain. For now, we are focusing on the orange area:\n\n\n\n\n\nBecause the orange area is totally within our domain, we can leave our integral our bounds as the exact values we specified:\n\\[P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.25}^{0.5} \\displaystyle\\int_{0.5}^{0.75} 18 x^2 y^5 dy dx\\]\nHowever, if we want the probability \\(P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75)\\), we would focus on the pink area above. We would limit one of our integrals to the \\(y=x\\) equation:\n\\[P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.5}^{0.75} \\displaystyle\\int_{x}^{0.75} 18 x^2 y^5 dy dx\\]\nOR\n\\[P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.5}^{0.75} \\displaystyle\\int_{0.5}^{y} 18 x^2 y^5 dx dy\\]\nThe key to these probabilities is that the bounds with the other variable is on the inside integral! Otherwise we end up with a answer that includes a RV."
  },
  {
    "objectID": "lessons_old/22_Counting_Intro/22_Counting_Intro.html",
    "href": "lessons_old/22_Counting_Intro/22_Counting_Intro.html",
    "title": "Chapter 22: Introduction to Counting",
    "section": "",
    "text": "Define permutations and combinations\nCharacterize difference between sampling with and without replacement\nCharacterize difference between sampling when order matters and when order does not matter\nCalculate the probability of sampling any combination of the following: with or without replacement and order does or does not matter"
  },
  {
    "objectID": "lessons_old/22_Counting_Intro/22_Counting_Intro.html#learning-objectives",
    "href": "lessons_old/22_Counting_Intro/22_Counting_Intro.html#learning-objectives",
    "title": "Chapter 22: Introduction to Counting",
    "section": "",
    "text": "Define permutations and combinations\nCharacterize difference between sampling with and without replacement\nCharacterize difference between sampling when order matters and when order does not matter\nCalculate the probability of sampling any combination of the following: with or without replacement and order does or does not matter"
  },
  {
    "objectID": "lessons_old/22_Counting_Intro/22_Counting_Intro.html#where-are-we",
    "href": "lessons_old/22_Counting_Intro/22_Counting_Intro.html#where-are-we",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons_old/22_Counting_Intro/22_Counting_Intro.html#basic-counting-examples-13",
    "href": "lessons_old/22_Counting_Intro/22_Counting_Intro.html#basic-counting-examples-13",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Basic Counting Examples (1/3)",
    "text": "Basic Counting Examples (1/3)\n\n\nExample 1\n\n\nSuppose we have 10 (distinguishable) subjects for study.\n\nHow many possible ways are there to order them?\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?\n\nHow many ways to order them without replacement and only need 6?\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?"
  },
  {
    "objectID": "lessons_old/22_Counting_Intro/22_Counting_Intro.html#basic-counting-examples-23",
    "href": "lessons_old/22_Counting_Intro/22_Counting_Intro.html#basic-counting-examples-23",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Basic Counting Examples (2/3)",
    "text": "Basic Counting Examples (2/3)\nSuppose we have 10 (distinguishable) subjects for study.\n\n\n\n\nExample 1.1\n\n\nHow many possible ways are there to order them?\n\n\n \n\n\nExample 1.2\n\n\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?"
  },
  {
    "objectID": "lessons_old/22_Counting_Intro/22_Counting_Intro.html#basic-counting-examples-33",
    "href": "lessons_old/22_Counting_Intro/22_Counting_Intro.html#basic-counting-examples-33",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Basic Counting Examples (3/3)",
    "text": "Basic Counting Examples (3/3)\nSuppose we have 10 (distinguishable) subjects for study.\n\n\n\n\nExample 1.3\n\n\nHow many ways to order them without replacement and only need 6?\n\n\n \n\n\nExample 1.4\n\n\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?"
  },
  {
    "objectID": "lessons_old/22_Counting_Intro/22_Counting_Intro.html#permutations-and-combinations-1",
    "href": "lessons_old/22_Counting_Intro/22_Counting_Intro.html#permutations-and-combinations-1",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Permutations and Combinations",
    "text": "Permutations and Combinations\n\n\nDefinition: Permutations\n\n\nPermutations are the number of ways to arrange in order \\(r\\) distinct objects when there are \\(n\\) total.\n\\[nPr = \\frac{n!}{(n-r)!}\\]\n\n\n\n\nDefinition: Combinations\n\n\nCombinations are the number of ways to choose (order doesn’t matter) \\(r\\) objects from \\(n\\) without replacement.\n\\[nCr = \\textrm{\"n choose r\"} = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "lessons_old/22_Counting_Intro/22_Counting_Intro.html#some-combinations-properties",
    "href": "lessons_old/22_Counting_Intro/22_Counting_Intro.html#some-combinations-properties",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Some combinations properties",
    "text": "Some combinations properties\n\n\n\n\n\n\n\nProperty\nProof\n\n\n\n\n\\[\\binom{n}{r} = \\binom{n}{n-r}\\]\n\\(\\binom{n}{r} = \\dfrac{n!}{r!(n-r)!}\\) and \\(\\binom{n}{n-r} = \\dfrac{n!}{(n-r)!(n-(n-r))!} = \\dfrac{n!}{(n-r)!r!}\\)\n\n\n\\[\\binom{n}{1} = n\\]\n\\[\\binom{n}{1} = \\dfrac{n!}{1!(n-1)!}=\\dfrac{n\\cdot(n-1)\\cdot(n-2)\\cdots1}{1! \\cdot (n-1)\\cdot(n-2)\\cdots1} = \\dfrac{n\\cdot(n-1)!}{1\\cdot (n-1)!} = \\dfrac{n}{1}=n\\]\n\n\n\\[\\binom{n}{0} = 1\\]\n\\[\\binom{n}{0} = \\dfrac{n!}{0!(n-0)!}=\\dfrac{n!}{1\\cdot n!} = 1\\]"
  },
  {
    "objectID": "lessons_old/22_Counting_Intro/22_Counting_Intro.html#table-of-different-cases",
    "href": "lessons_old/22_Counting_Intro/22_Counting_Intro.html#table-of-different-cases",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Table of different cases",
    "text": "Table of different cases\nSee table on pg. 277 of textbook\n\n\\(n\\) = total number of objects\n\\(r\\) = number objects needed\n\n\n\n\n\n\n\n\n\nwith replacement\nwithout replacement\n\n\n\n\norder matters\n\\[n^r\\]\n\\[n\\text{P}r = \\frac{n!}{(n-r)!}\\]\n\n\norder doesn’t matter\n\\[ \\binom{n+r-1}{r}\\]\n\\[n\\text{C}r = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "lessons_old/22_Counting_Intro/22_Counting_Intro.html#enumerating-events-and-sample-space",
    "href": "lessons_old/22_Counting_Intro/22_Counting_Intro.html#enumerating-events-and-sample-space",
    "title": "Chapter 22: Introduction to Counting",
    "section": "Enumerating Events and Sample Space",
    "text": "Enumerating Events and Sample Space\n\nRecall, \\(P(A) = \\dfrac{|A|}{|S|}\\)\n\nWithin combinatorics, we can use the previous equations to help enumerate the event and sample space\nBut \\(A\\) might be a combination of enumerations\n\n\n \n\nFor example in the following example drawing 2 spades when order does not matter, we actually need to enumerate the other cards that are NOT spades. So the event is choosing 2 spades out of 13 AND choosing 0 other cards of 39 cards (13 hearts + 13 clubs + 13 diamonds).\nThus the probability is actually:\n\n\\[ P(\\text{two spades}) = \\dfrac{{13 \\choose 2}{39 \\choose 0}}{{52 \\choose 2}} \\]\n\nNote that \\(13 + 39 = 52\\) and \\(2+ 0 = 2\\). So the numerator’s \\(n\\)’s add up to the denominator’s \\(n\\) and the numerator’s \\(r\\)’s add up to the denominator’s \\(r\\)’s"
  },
  {
    "objectID": "lessons_old/22_Counting_Intro/22_Counting_Intro.html#more-examples-order-matters-vs.-not-12",
    "href": "lessons_old/22_Counting_Intro/22_Counting_Intro.html#more-examples-order-matters-vs.-not-12",
    "title": "Chapter 22: Introduction to Counting",
    "section": "More examples: order matters vs. not (1/2)",
    "text": "More examples: order matters vs. not (1/2)\n\n\n\n\nExample 2\n\n\nSuppose we draw 2 cards from a standard deck without replacement. What is the probability that both are spades when\n\norder matters?\norder doesn’t matter?"
  },
  {
    "objectID": "lessons_old/07_Random_Variables/07_Random_Variables.html",
    "href": "lessons_old/07_Random_Variables/07_Random_Variables.html",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "",
    "text": "Map the sample space to the set of real numbers using a discrete and continuous random variable\nDistinguish between discrete and continuous random variables from a written description"
  },
  {
    "objectID": "lessons_old/07_Random_Variables/07_Random_Variables.html#learning-objectives",
    "href": "lessons_old/07_Random_Variables/07_Random_Variables.html#learning-objectives",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "",
    "text": "Map the sample space to the set of real numbers using a discrete and continuous random variable\nDistinguish between discrete and continuous random variables from a written description"
  },
  {
    "objectID": "lessons_old/07_Random_Variables/07_Random_Variables.html#where-are-we",
    "href": "lessons_old/07_Random_Variables/07_Random_Variables.html#where-are-we",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons_old/07_Random_Variables/07_Random_Variables.html#what-is-a-random-variable",
    "href": "lessons_old/07_Random_Variables/07_Random_Variables.html#what-is-a-random-variable",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "What is a random variable?",
    "text": "What is a random variable?\n\n\nDefinition: Random Variable\n\n\nFor a given sample space \\(S\\), a random variable (r.v.) is a function whose domain is \\(S\\) and whose range is the set of real numbers \\(\\mathbb{R}\\). A random variable assigns a real number to each outcome in the sample space."
  },
  {
    "objectID": "lessons_old/07_Random_Variables/07_Random_Variables.html#lets-demonstrate-this-definition-with-our-coin-toss",
    "href": "lessons_old/07_Random_Variables/07_Random_Variables.html#lets-demonstrate-this-definition-with-our-coin-toss",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Let’s demonstrate this definition with our coin toss",
    "text": "Let’s demonstrate this definition with our coin toss\n\n\n\n\nExample 1\n\n\nSuppose we toss 3 fair coins.\n\nWhat is the sample space?\nWhat are the probabilities for each of the elements in the sample space?\nWhat are the probabilities that you get 0, 1, 2, or 3 tails?"
  },
  {
    "objectID": "lessons_old/07_Random_Variables/07_Random_Variables.html#lets-stretch-our-definition-of-random-variables",
    "href": "lessons_old/07_Random_Variables/07_Random_Variables.html#lets-stretch-our-definition-of-random-variables",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Let’s stretch our definition of random variables",
    "text": "Let’s stretch our definition of random variables\n\n\n\n\nExample 2\n\n\nWhat are some other random variables we could consider in Example 1?"
  },
  {
    "objectID": "lessons_old/07_Random_Variables/07_Random_Variables.html#some-remarks-on-random-variables",
    "href": "lessons_old/07_Random_Variables/07_Random_Variables.html#some-remarks-on-random-variables",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Some remarks on random variables",
    "text": "Some remarks on random variables\n\nA random variable’s value is completely determined by the outcome \\(\\omega\\), where \\(\\omega \\in S\\)\n\nWhat is random is the outcome \\(\\omega\\)\n\nA random variable is a function from the sample space (with outcomes \\(\\omega\\)) to the set of real numbers\n\nWe typically write \\(X\\) instead of \\(X(\\omega)\\), where \\(X\\) is our random variable\n\nFor example, if we roll three dice, there are \\(6^3 = 216\\) possible outcomes (which is \\(\\omega\\))\n\nWe can define a random variable as the sum of the of the three dice\nIf our outcome is the set of numbers the dice landed on ( \\(\\omega=(a,b,c)\\) ), then \\[ X(\\omega) = X = a + b + c \\]"
  },
  {
    "objectID": "lessons_old/07_Random_Variables/07_Random_Variables.html#lets-look-at-a-continuous-r.v.",
    "href": "lessons_old/07_Random_Variables/07_Random_Variables.html#lets-look-at-a-continuous-r.v.",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Let’s look at a continuous R.V.",
    "text": "Let’s look at a continuous R.V.\n\n\n\n\nExample 3\n\n\nLet \\(X =\\) how many hours you slept last night.\n\nWhat is the sample space \\(S\\)?\nWhat is the range of possible values for \\(X\\)?\nWhat is \\(X(\\omega)\\)?"
  },
  {
    "objectID": "lessons_old/07_Random_Variables/07_Random_Variables.html#discrete-vs.-continuous-r.v.s",
    "href": "lessons_old/07_Random_Variables/07_Random_Variables.html#discrete-vs.-continuous-r.v.s",
    "title": "Chapter 7: Discrete vs. Continuous Random Variables",
    "section": "Discrete vs. Continuous r.v.’s",
    "text": "Discrete vs. Continuous r.v.’s\n\nFor a discrete r.v., the set of possible values is either finite or can be put into a countably infinite list\n\nYou could theoretically list the specific possible outcomes that the variable can take\nIf you sum the rolls of three dice, you must get a whole number. For example, you can’t get any number between 3 and 4.\n\n\n   \n\nContinuous r.v.’s take on values from continuous intervals, or unions of continuous intervals\n\nVariable takes on a range of values, but there are infinitely possible values within the range\nIf you keep track of the time you sleep, you can sleep for 8 hours or 7.9 hours or 7.99 hours or 7.999 hours …"
  },
  {
    "objectID": "lessons_old/02_Lang_prob/02_Lang_prob.html",
    "href": "lessons_old/02_Lang_prob/02_Lang_prob.html",
    "title": "Lesson 2: Language of Probability",
    "section": "",
    "text": "building important definitions so that we have a mutual understanding of the language of probability\n\nDefine basic terms related to events such as events, outcomes, and sample space.\nUse proper set notation for events\nCharacterize possible outcomes, when something random occurs\nDescribe events into which outcomes can be grouped\nDefine important terms and rules within set theory such as unions, intersections, complements, mutually exclusive, and De Morgan’s Laws"
  },
  {
    "objectID": "lessons_old/02_Lang_prob/02_Lang_prob.html#learning-objectives",
    "href": "lessons_old/02_Lang_prob/02_Lang_prob.html#learning-objectives",
    "title": "Lesson 2: Language of Probability",
    "section": "",
    "text": "building important definitions so that we have a mutual understanding of the language of probability\n\nDefine basic terms related to events such as events, outcomes, and sample space.\nUse proper set notation for events\nCharacterize possible outcomes, when something random occurs\nDescribe events into which outcomes can be grouped\nDefine important terms and rules within set theory such as unions, intersections, complements, mutually exclusive, and De Morgan’s Laws"
  },
  {
    "objectID": "lessons_old/02_Lang_prob/02_Lang_prob.html#where-are-we",
    "href": "lessons_old/02_Lang_prob/02_Lang_prob.html#where-are-we",
    "title": "Lesson 2: Language of Probability",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons_old/02_Lang_prob/02_Lang_prob.html#set-theory-12",
    "href": "lessons_old/02_Lang_prob/02_Lang_prob.html#set-theory-12",
    "title": "Lesson 2: Language of Probability",
    "section": "Set Theory (1/2)",
    "text": "Set Theory (1/2)\n\n\n \n\n\nDefinition: Union\n\n\nThe union of events \\(A\\) and \\(B\\), denoted by \\(A \\cup B\\), contains all outcomes that are in \\(A\\) or \\(B\\) or both\n\n\n\n\nDefinition: Intersection\n\n\nThe intersection of events \\(A\\) and \\(B\\), denoted by \\(A \\cap B\\), contains all outcomes that are both in \\(A\\) and \\(B\\).\n\n\n\nVenn diagrams"
  },
  {
    "objectID": "lessons_old/02_Lang_prob/02_Lang_prob.html#set-theory-22",
    "href": "lessons_old/02_Lang_prob/02_Lang_prob.html#set-theory-22",
    "title": "Lesson 2: Language of Probability",
    "section": "Set Theory (2/2)",
    "text": "Set Theory (2/2)\n\n\n \n\n\nDefinition: Complement\n\n\nThe complement of event \\(A\\), denoted by \\(A^C\\) or \\(A'\\), contains all outcomes in the sample space \\(S\\) that are not in \\(A\\) .\n\n\n\n\nDefinition: Mutually Exclusive\n\n\nEvents \\(A\\) and \\(B\\) are mutually exclusive, or disjoint, if they have no outcomes in common. In this case \\(A \\cap B = \\emptyset\\), where \\(\\emptyset\\) is the empty set.\n\n\n\nVenn diagrams"
  },
  {
    "objectID": "lessons_old/02_Lang_prob/02_Lang_prob.html#probability-axioms-1",
    "href": "lessons_old/02_Lang_prob/02_Lang_prob.html#probability-axioms-1",
    "title": "Lesson 2: Language of Probability",
    "section": "Probability Axioms",
    "text": "Probability Axioms\n\n\n\n\nAxiom 1\n\n\nFor every event \\(A\\), \\(0\\leq\\mathbb{P}(A)\\leq 1\\). Probability is between 0 and 1.\n\n\n\n\nAxiom 2\n\n\nFor the sample space \\(S\\), \\(\\mathbb{P}(S)=1\\).\n\n\n\n\nAxiom 3\n\n\nIf \\(A_1, A_2, A_3, \\ldots\\), is a collection of disjoint events, then \\[\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i).\\] The probability of at least one \\(A_i\\) is the sum of the individual probabilities of each."
  },
  {
    "objectID": "lessons_old/02_Lang_prob/02_Lang_prob.html#some-probability-properties-1",
    "href": "lessons_old/02_Lang_prob/02_Lang_prob.html#some-probability-properties-1",
    "title": "Lesson 2: Language of Probability",
    "section": "Some probability properties",
    "text": "Some probability properties\nUsing the Axioms, we can prove all other probability properties! Events A, B, and C are not necessarily disjoint!\n\n\n\n\nProposition 1\n\n\nFor any event \\(A\\), \\(\\mathbb{P}(A)= 1 - \\mathbb{P}(A^C)\\)\n\n\n\n\nProposition 2\n\n\n\\(\\mathbb{P}(\\emptyset)=0\\)\n\n\n\n\nProposition 3\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\n\n\n\n\n\nProposition 4\n\n\n\\[\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\] where \\(A\\) and \\(B\\) are not necessarily disjoint\n\n\n\n\nProposition 5\n\n\n\\(\\begin{aligned} \\mathbb{P}(A \\cup B & \\cup C) = \\mathbb{P}(A) + \\mathbb{P}(B) + \\\\ & \\mathbb{P}(C) - \\mathbb{P}(A \\cap B) - \\mathbb{P}(A \\cap C) - \\\\ & \\mathbb{P}(B \\cap C) + \\mathbb{P}(A \\cap B \\cap C) \\end{aligned}\\)"
  },
  {
    "objectID": "lessons_old/02_Lang_prob/02_Lang_prob.html#proposition-1-proof",
    "href": "lessons_old/02_Lang_prob/02_Lang_prob.html#proposition-1-proof",
    "title": "Lesson 2: Language of Probability",
    "section": "Proposition 1 Proof",
    "text": "Proposition 1 Proof\n\n\n\n\nProposition 1\n\n\nFor any event \\(A\\), \\(\\mathbb{P}(A)= 1 - \\mathbb{P}(A^C)\\)\n\n\n\n\n\nUse Axioms!\n\n\nA1: \\(0\\leq\\mathbb{P}(A)\\leq 1\\)\nA2: \\(\\mathbb{P}(S)=1\\)\nA3: For disjoint \\(A_i\\),\n\\(\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i)\\)"
  },
  {
    "objectID": "lessons_old/02_Lang_prob/02_Lang_prob.html#proposition-2-proof",
    "href": "lessons_old/02_Lang_prob/02_Lang_prob.html#proposition-2-proof",
    "title": "Lesson 2: Language of Probability",
    "section": "Proposition 2 Proof",
    "text": "Proposition 2 Proof\n\n\n\n\nProposition 2\n\n\n\\(\\mathbb{P}(\\emptyset)=0\\)\n\n\n\n\n\nUse Axioms!\n\n\nA1: \\(0\\leq\\mathbb{P}(A)\\leq 1\\)\nA2: \\(\\mathbb{P}(S)=1\\)\nA3: For disjoint \\(A_i\\),\n\\(\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i)\\)"
  },
  {
    "objectID": "lessons_old/02_Lang_prob/02_Lang_prob.html#proposition-3-proof",
    "href": "lessons_old/02_Lang_prob/02_Lang_prob.html#proposition-3-proof",
    "title": "Lesson 2: Language of Probability",
    "section": "Proposition 3 Proof",
    "text": "Proposition 3 Proof\n\n\n\n\nProposition 3\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\n\n\n\n\n\nUse Axioms!\n\n\nA1: \\(0\\leq\\mathbb{P}(A)\\leq 1\\)\nA2: \\(\\mathbb{P}(S)=1\\)\nA3: For disjoint \\(A_i\\),\n\\(\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i)\\)"
  },
  {
    "objectID": "lessons_old/02_Lang_prob/02_Lang_prob.html#proposition-4-visual-proof",
    "href": "lessons_old/02_Lang_prob/02_Lang_prob.html#proposition-4-visual-proof",
    "title": "Lesson 2: Language of Probability",
    "section": "Proposition 4 Visual Proof",
    "text": "Proposition 4 Visual Proof\n\n\nProposition 4\n\n\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)"
  },
  {
    "objectID": "lessons_old/02_Lang_prob/02_Lang_prob.html#proposition-5-visual-proof",
    "href": "lessons_old/02_Lang_prob/02_Lang_prob.html#proposition-5-visual-proof",
    "title": "Lesson 2: Language of Probability",
    "section": "Proposition 5 Visual Proof",
    "text": "Proposition 5 Visual Proof\n\n\nProposition 5\n\n\n\\(\\mathbb{P}(A \\cup B \\cup C) = \\mathbb{P}(A) + \\mathbb{P}(B) + \\mathbb{P}(C) - \\mathbb{P}(A \\cap B) - \\mathbb{P}(A \\cap C) - \\mathbb{P}(B \\cap C) + \\mathbb{P}(A \\cap B \\cap C)\\)"
  },
  {
    "objectID": "lessons_old/02_Lang_prob/02_Lang_prob.html#some-final-remarks-on-these-proposition",
    "href": "lessons_old/02_Lang_prob/02_Lang_prob.html#some-final-remarks-on-these-proposition",
    "title": "Lesson 2: Language of Probability",
    "section": "Some final remarks on these proposition",
    "text": "Some final remarks on these proposition\n\nNotice how we spliced events into multiple disjoint events\n\nIt is often easier to work with disjoint events\n\n\n \n\nIf we want to calculate the probability for one event, we may need to get creative with how we manipulate other events and the sample space\n\nHelps us use any incomplete information we have"
  },
  {
    "objectID": "lessons_old/02_Lang_prob/02_Lang_prob.html#de-morgans-laws",
    "href": "lessons_old/02_Lang_prob/02_Lang_prob.html#de-morgans-laws",
    "title": "Lesson 2: Language of Probability",
    "section": "De Morgan’s Laws",
    "text": "De Morgan’s Laws\n\n\nTheorem: De Morgan’s 1st Law\n\n\nFor a collection of events (sets) \\(A_1, A_2, A_3, \\ldots\\)\n\\[\\bigcap\\limits_{i=1}^{n}A_i^C = \\Big(\\bigcup\\limits_{i=1}^{n}A_i\\Big)^C\\]\n\n\n“all not A = \\((\\)at least one event A\\()^C\\)” or “intersection of the complements is the complement of the union”\n\n\nTheorem: De Morgan’s 2nd Law\n\n\nFor a collection of events (sets) \\(A_1, A_2, A_3, \\ldots\\)\n\\[\\bigcup\\limits_{i=1}^{n}A_i^C = \\Big(\\bigcap\\limits_{i=1}^{n}A_i\\Big)^C\\]\n\n\n“at least one event not A = \\((\\)all A\\()^C\\)” or “union of complements is complement of the intersection”"
  },
  {
    "objectID": "lessons_old/02_Lang_prob/02_Lang_prob.html#bp-example-variation-13",
    "href": "lessons_old/02_Lang_prob/02_Lang_prob.html#bp-example-variation-13",
    "title": "Lesson 2: Language of Probability",
    "section": "BP example variation (1/3)",
    "text": "BP example variation (1/3)\n\nSuppose you have \\(n\\) subjects in a study.\nLet \\(H_i\\) be the event that person \\(i\\) has high BP, for \\(i=1\\ldots n\\).\n\n \nUse set theory notation to denote the following events:\n\nEvent subject \\(i\\) does not have high BP\nEvent all \\(n\\) subjects have high BP\nEvent at least one subject has high BP\nEvent all of them do not have high BP\nEvent at least one subject does not have high BP"
  },
  {
    "objectID": "lessons_old/02_Lang_prob/02_Lang_prob.html#bp-example-variation-23",
    "href": "lessons_old/02_Lang_prob/02_Lang_prob.html#bp-example-variation-23",
    "title": "Lesson 2: Language of Probability",
    "section": "BP example variation (2/3)",
    "text": "BP example variation (2/3)\n\nSuppose you have \\(n\\) subjects in a study.\nLet \\(H_i\\) be the event that person \\(i\\) has high BP, for \\(i=1\\ldots n\\).\n\nUse set theory notation to denote the following events:\n\nEvent subject \\(i\\) does not have high BP\n \nEvent all \\(n\\) subjects have high BP\n \n \nEvent at least one subject has high BP"
  },
  {
    "objectID": "lessons_old/02_Lang_prob/02_Lang_prob.html#bp-example-variation-33",
    "href": "lessons_old/02_Lang_prob/02_Lang_prob.html#bp-example-variation-33",
    "title": "Lesson 2: Language of Probability",
    "section": "BP example variation (3/3)",
    "text": "BP example variation (3/3)\n\nEvent all of them do not have high BP\n \n \n \nEvent at least one subject does not have high BP"
  },
  {
    "objectID": "lessons_old/02_Lang_prob/02_Lang_prob.html#remarks-on-de-morgans-laws",
    "href": "lessons_old/02_Lang_prob/02_Lang_prob.html#remarks-on-de-morgans-laws",
    "title": "Lesson 2: Language of Probability",
    "section": "Remarks on De Morgan’s Laws",
    "text": "Remarks on De Morgan’s Laws\n\nThese laws also hold for infinite collections of events.\n \nDraw Venn diagrams to convince yourself that these are true!\n \nThese laws are very useful when calculating probabilities.\n\nThis is because calculating the probability of the intersection of events is often much easier than the union of events.\nThis is not obvious right now, but we will see in the coming chapters why."
  },
  {
    "objectID": "lessons_old/02_Lang_prob/02_Lang_prob.html#partitions-1",
    "href": "lessons_old/02_Lang_prob/02_Lang_prob.html#partitions-1",
    "title": "Lesson 2: Language of Probability",
    "section": "Partitions",
    "text": "Partitions\n\n\n\n\nDefinition: Partition\n\n\nA set of events \\(\\{A_i\\}_{i=1}^{n}\\) create a partition of \\(A\\), if\n\nthe \\(A_i\\)’s are disjoint (mutually exclusive) and\n\\(\\bigcup \\limits_{i=1}^n A_i = A\\)\n\n\n\n\n\nExample 2\n\n\n\nIf \\(A \\subset B\\), then \\(\\{A, B \\cap A^C\\}\\) is a partition of \\(B\\).\nIf \\(S = \\bigcup \\limits_{i=1}^n A_i\\), and the \\(A_i\\)’s are disjoint, then the \\(A_i\\)’s are a partition of the sample space.\n\n\n\n\n\n\n\nCreating partitions is sometimes used to help calculate probabilities, since by Axiom 3 we can add the probabilities of disjoint events."
  },
  {
    "objectID": "lessons_old/02_Lang_prob/02_Lang_prob.html#weekly-medications",
    "href": "lessons_old/02_Lang_prob/02_Lang_prob.html#weekly-medications",
    "title": "Lesson 2: Language of Probability",
    "section": "Weekly medications",
    "text": "Weekly medications\n\n\n\n\nExample 3\n\n\nIf a subject has an\n\n80% chance of taking their medication this week,\n70% chance of taking their medication next week, and\n10% chance of not taking their medication either week,\n\nthen find the probability of them taking their medication exactly one of the two weeks.\n\n\n\nHint: Draw a Venn diagram labelling each of the parts to find the probability."
  },
  {
    "objectID": "lessons_old/03_Independent_Events/03_Independent_Events_muddy_points.html",
    "href": "lessons_old/03_Independent_Events/03_Independent_Events_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "1. How do I know if two events are independent?\nMy main piece of advice for independence is to rely on the math to show it, not logic! Don’t go into a problem thinking “Logically, these two events are independent.” If the problem does not say “Assume independence,” then we need to show it mathematically.\nSame goes with the definition of independence. When we say “knowing the outcome of one provides no information about the outcome of the other,” we once again need to show this mathematically, not just using logic. We translate the previous statement to \\[P(A) = P(A|B)\\] And we need to show this mathematically!\n\n\n2. Disjoint vs. Independent Events\nHere is a pretty good video breaking down disjoint (mutually exclusive) events and independent events. It includes examples as well."
  },
  {
    "objectID": "lessons_old/Continuous_distributions.html",
    "href": "lessons_old/Continuous_distributions.html",
    "title": "Continuous Random Variables",
    "section": "",
    "text": "Scenario: Events are equally likely to happen anywhere or anytime in an interval of values\nShorthand: \\(X \\sim \\text{U}[a,b]\\)\n\n\\[\nf_X(x) = \\dfrac{1}{b-a}, \\text{ for }a \\leq x \\leq b\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;a \\quad \\\\\n            \\dfrac{x-a}{b-a} & \\quad a \\leq x \\leq b\\quad \\\\\n            1 & \\quad x&gt;b \\quad\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{a+b}{2} \\text{, } \\text{ Var}(X) = \\dfrac{(b-a)^2}{12}\\]"
  },
  {
    "objectID": "lessons_old/Continuous_distributions.html#properties-of-continuous-uniform-rvs",
    "href": "lessons_old/Continuous_distributions.html#properties-of-continuous-uniform-rvs",
    "title": "Continuous Random Variables",
    "section": "",
    "text": "Scenario: Events are equally likely to happen anywhere or anytime in an interval of values\nShorthand: \\(X \\sim \\text{U}[a,b]\\)\n\n\\[\nf_X(x) = \\dfrac{1}{b-a}, \\text{ for }a \\leq x \\leq b\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;a \\quad \\\\\n            \\dfrac{x-a}{b-a} & \\quad a \\leq x \\leq b\\quad \\\\\n            1 & \\quad x&gt;b \\quad\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{a+b}{2} \\text{, } \\text{ Var}(X) = \\dfrac{(b-a)^2}{12}\\]"
  },
  {
    "objectID": "lessons_old/Continuous_distributions.html#properties-of-exponential-rvs",
    "href": "lessons_old/Continuous_distributions.html#properties-of-exponential-rvs",
    "title": "Continuous Random Variables",
    "section": "Properties of exponential RVs",
    "text": "Properties of exponential RVs\n\nScenario: Modeling the time until the next (first) event\nContinuous analog to the geometric distribution!\nShorthand: \\(X \\sim \\text{Exp}(\\lambda)\\)\n\n\\[\nf_X(x) = \\lambda e^{-\\lambda x}\\text{ for } x&gt;0, \\lambda&gt;0\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;0 \\quad \\\\\n            1 - e^{-\\lambda x} & \\quad x\\geq0 \\\\\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{1}{\\lambda}\\] \\[\\text{Var}(X) = \\dfrac{1}{\\lambda^2}\\]"
  },
  {
    "objectID": "lessons_old/Continuous_distributions.html#properties-of-gamma-rvs",
    "href": "lessons_old/Continuous_distributions.html#properties-of-gamma-rvs",
    "title": "Continuous Random Variables",
    "section": "Properties of gamma RVs",
    "text": "Properties of gamma RVs\n\nScenario: Modeling the time until the \\(r^{th}\\) event.\nContinuous analog to the Negative Binomial distribution\nShorthand: \\(X \\sim \\text{Gamma}(r, \\lambda)\\)\n\n\\[\nf_X(x) = \\dfrac{\\lambda^r}{\\Gamma(r)}x^{r-1} e^{-\\lambda x}\\text{ for } x&gt;0, \\lambda&gt;0, \\Gamma(r) = (r-1)!\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;0 \\quad \\\\\n            1 - e^{-\\lambda x}\\displaystyle\\sum_{j=0}^{r-1}\\dfrac{(\\lambda x)^j}{j!}  & \\quad x\\geq0 \\\\\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{r}{\\lambda}\\text{, }\\text{ Var}(X) = \\dfrac{r}{\\lambda^2}\\]\nCommon to see \\(\\alpha = r\\) and \\(\\beta = \\lambda\\)"
  },
  {
    "objectID": "lessons_old/Continuous_distributions.html#properties-of-normal-rvs",
    "href": "lessons_old/Continuous_distributions.html#properties-of-normal-rvs",
    "title": "Continuous Random Variables",
    "section": "Properties of Normal RVs",
    "text": "Properties of Normal RVs\n\nNo scenario description here because the Normal distribution is so universal\n\nCentral Limit Theorem (next class) makes it applicable to many types of events\n\nShorthand: \\(X \\sim \\text{Normal}(\\mu, \\sigma^2)\\)\n\n\\[\nf_X(x) = \\dfrac{1}{\\sqrt{2\\pi \\sigma^2}}e^{-(x-\\mu)^2/(2\\sigma^2)} \\text{, for} -inf &lt; x &lt; inf\n\\]\n\\[\\text{E}(X) = \\mu \\] \\[\\text{Var}(X) = \\sigma^2\\]"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Conditional_Probability_key_info.html",
    "href": "lessons/04_Rules_of_prob/04_Conditional_Probability_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "For office hours, we decided to do appointments!\n\nHere’s my Calendly: https://calendly.com/nickywakim/15min\nI teach on Mondays and Wednesdays so I am keeping most of my meetings to Tuesdays and Thursdays\nFor my EPI class, I have scheduled office hours on Mondays 4-5pm in VPT 627\n\nI will give priority to EPI students, but you can drop by for those as well\n\n\nI think all the dates in the schedule were correct except for next week"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Conditional_Probability_key_info.html#announcements",
    "href": "lessons/04_Rules_of_prob/04_Conditional_Probability_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "For office hours, we decided to do appointments!\n\nHere’s my Calendly: https://calendly.com/nickywakim/15min\nI teach on Mondays and Wednesdays so I am keeping most of my meetings to Tuesdays and Thursdays\nFor my EPI class, I have scheduled office hours on Mondays 4-5pm in VPT 627\n\nI will give priority to EPI students, but you can drop by for those as well\n\n\nI think all the dates in the schedule were correct except for next week"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Conditional_Probability_key_info.html#key-dates",
    "href": "lessons/04_Rules_of_prob/04_Conditional_Probability_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 1 Assignment due this Thursday at 11pm"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html",
    "href": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "",
    "text": "Calculate conditional probability of an event using Bayes’ Theorem\nUtilize additional probability rules in probability calculations, specifically the Higher Order Multiplication Rule and the Law of Total Probabilities"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#learning-objectives",
    "href": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#learning-objectives",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "",
    "text": "Calculate conditional probability of an event using Bayes’ Theorem\nUtilize additional probability rules in probability calculations, specifically the Higher Order Multiplication Rule and the Law of Total Probabilities"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#where-are-we",
    "href": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#where-are-we",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#introduction",
    "href": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#introduction",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Introduction",
    "text": "Introduction\n\nSo we learned about conditional probabilities\n\nWe learned how the occurrence of event A affects event B (B conditional on A)\n\nCan we figure out information on how the occurrence of event B affects event A?\nWe can use the conditional probability (\\(\\mathbb{P}(A|B)\\)) to get information on the flipped conditional probability (\\(\\mathbb{P}(B|A)\\))"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#bayes-rule-for-two-events",
    "href": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#bayes-rule-for-two-events",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Bayes’ Rule for two events",
    "text": "Bayes’ Rule for two events\n\n\n\n\nTheorem: Bayes’ Rule (for two events)\n\n\nFor any two events \\(A\\) and \\(B\\) with nonzero probabilties,\n\\[\\mathbb{P}(A| B) =\n\\frac{\\mathbb{P}(A) \\cdot \\mathbb{P}(B|A)}\n{\\mathbb{P}(B)}\\]"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#calculating-probability-with-higher-order-multiplication-rule",
    "href": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#calculating-probability-with-higher-order-multiplication-rule",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with Higher Order Multiplication Rule",
    "text": "Calculating probability with Higher Order Multiplication Rule\n\n\n\n\nExample 1\n\n\nSuppose we draw 5 cards from a standard shuffled deck of 52 cards. What is the probability of a flush, that is all the cards are of the same suit (including straight flushes)?\n\n\n\n\n\nHigher Order Multiplication Rule\n\n\n\\[\\mathbb{P}(A_1\\cap A_2 \\cap  \\ldots \\cap A_n)=\\mathbb{P}(A_1)\\cdot\\mathbb{P}(A_2|A_1) \\cdot \\\\\n\\mathbb{P}(A_3|A_1A_2)\\ldots \\cdot\\mathbb{P}(A_n|A_1A_2\\ldots A_{n-1})\\]"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#calculating-probability-with-law-of-total-probability",
    "href": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#calculating-probability-with-law-of-total-probability",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with Law of Total Probability",
    "text": "Calculating probability with Law of Total Probability\n\n\n\n\nExample 2\n\n\nSuppose 1% of people assigned female at birth (AFAB) and 5% of people assigned male at birth (AMAB) are color-blind. Assume person born is equally likely AFAB or AMAB (not including intersex). What is the probability that a person chosen at random is color-blind?\n\n\n\n\n\nLaw of Total Probability for 2 Events\n\n\nFor events \\(A\\) and \\(B\\),\n\\[%\\left(\n\\begin{array}{ccl}\n\\mathbb{P}(B)&=&\\mathbb{P}(B \\cap A) + \\mathbb{P}(B \\cap A^C)\\\\\n           &=& \\mathbb{P}(B|A) \\cdot \\mathbb{P}(A)+ \\mathbb{P}(B | A^C)\\cdot \\mathbb{P}(A^C)\n\\end{array}\n%\\right)\\]"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#general-law-of-total-proability",
    "href": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#general-law-of-total-proability",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "General Law of Total Proability",
    "text": "General Law of Total Proability\n\n\nLaw of Total Probability (general)\n\n\nIf \\(\\{A_i\\}_{i=1}^{n} = \\{A_1, A_2, \\ldots, A_n\\}\\) form a partition of the sample space, then for event \\(B\\),\n\\[%\\left(\n\\begin{array}{ccl}\n\\mathbb{P}(B)&=& \\sum_{i=1}^{n} \\mathbb{P}(B \\cap A_i)\\\\\n           &=& \\sum_{i=1}^{n} \\mathbb{P}(B|A_i) \\cdot \\mathbb{P}(A_i)\n\\end{array}\n%\\right)\\]"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability",
    "href": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with generalized Law of Total Probability",
    "text": "Calculating probability with generalized Law of Total Probability"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability-1",
    "href": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#calculating-probability-with-generalized-law-of-total-probability-1",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculating probability with generalized Law of Total Probability",
    "text": "Calculating probability with generalized Law of Total Probability\n\n\n\n\nExample 3\n\n\nIndividuals are diagnosed with a particular type of cancer that can take on three different disease forms,* \\(D_1\\), \\(D_2\\), and \\(D_3\\). It is known that amongst people diagnosed with this particular type of cancer,\n\n20% of people will eventually be diagnosed with form \\(D_1\\),\n30% with form \\(D_2\\), and\n50% with form \\(D_3\\).\n\nThe probability of requiring chemotherapy (\\(C\\)) differs among the three forms of disease:\n\n80% with \\(D_1\\),\n30% with \\(D_2\\), and\n10% with \\(D_3\\).\n\nBased solely on the preliminary test of being diagnosed with the cancer, what is the probability of requiring chemotherapy (the event C)?\n\n\n\nSkipping in class! Let me know if you would like me to post solutions to this if you work through it!"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#lets-revisit-the-color-blind-example",
    "href": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#lets-revisit-the-color-blind-example",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Let’s revisit the color-blind example",
    "text": "Let’s revisit the color-blind example\n\n\n\n\nExample 4\n\n\nRecall the color-blind example (Example 2), where\n\na person is AMAB with probability 0.5,\nAMAB people are color-blind with probability 0.05, and\nall people are color-blind with probability 0.03.\n\nAssuming people are AMAB or AFAB, find the probability that a color-blind person is AMAB."
  },
  {
    "objectID": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#calculate-probability-with-both-rules",
    "href": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#calculate-probability-with-both-rules",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Calculate probability with both rules",
    "text": "Calculate probability with both rules\n\n\n\n\nExample 5\n\n\nSuppose\n\n1% of people who are AFAB aged 40-50 years have breast cancer,\nan AFAB person with breast cancer has a 90% chance of a positive test from a mammogram, and\nan AFAB person has a 10% chance of a false-positive result from a mammogram.\n\nWhat is the probability that an AFAB person has breast cancer given that they just had a positive test?"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#bayes-rule",
    "href": "lessons/04_Rules_of_prob/05_Bayes_Theorem.html#bayes-rule",
    "title": "Chapter 5: Bayes’ Theorem",
    "section": "Bayes’ Rule",
    "text": "Bayes’ Rule\n\n\nTheorem: Bayes’ Rule\n\n\nIf \\(\\{A_i\\}_{i=1}^{n}\\) form a partition of the sample space \\(S\\), with \\(\\mathbb{P}(A_i)&gt;0\\) for \\(i=1\\ldots n\\) and \\(\\mathbb{P}(B)&gt;0\\), then\n\\[\\mathbb{P}(A_j | B) =\n\\frac{\\mathbb{P}(B|A_j) \\cdot \\mathbb{P}(A_j)}\n{\\sum_{i=1}^{n} \\mathbb{P}(B|A_i) \\cdot \\mathbb{P}(A_i)}\\]"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/03_Independent_Events_muddy_points.html",
    "href": "lessons/04_Rules_of_prob/03_Independent_Events_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "1. How do I know if two events are independent?\nMy main piece of advice for independence is to rely on the math to show it, not logic! Don’t go into a problem thinking “Logically, these two events are independent.” If the problem does not say “Assume independence,” then we need to show it mathematically.\nSame goes with the definition of independence. When we say “knowing the outcome of one provides no information about the outcome of the other,” we once again need to show this mathematically, not just using logic. We translate the previous statement to \\[P(A) = P(A|B)\\] And we need to show this mathematically!\n\n\n2. Disjoint vs. Independent Events\nHere is a pretty good video breaking down disjoint (mutually exclusive) events and independent events. It includes examples as well."
  },
  {
    "objectID": "lessons/13_Expected_Values/28_Expected_Values/28_Expected_Values.html",
    "href": "lessons/13_Expected_Values/28_Expected_Values/28_Expected_Values.html",
    "title": "Chapter 28: Expected Values of Continuous Random Variables",
    "section": "",
    "text": "Calculate the mean (expected value) of a continuous RV"
  },
  {
    "objectID": "lessons/13_Expected_Values/28_Expected_Values/28_Expected_Values.html#learning-objectives",
    "href": "lessons/13_Expected_Values/28_Expected_Values/28_Expected_Values.html#learning-objectives",
    "title": "Chapter 28: Expected Values of Continuous Random Variables",
    "section": "",
    "text": "Calculate the mean (expected value) of a continuous RV"
  },
  {
    "objectID": "lessons/13_Expected_Values/28_Expected_Values/28_Expected_Values.html#expected-value-of-a-function-of-a-continuous-rv",
    "href": "lessons/13_Expected_Values/28_Expected_Values/28_Expected_Values.html#expected-value-of-a-function-of-a-continuous-rv",
    "title": "Chapter 28: Expected Values of Continuous Random Variables",
    "section": "Expected value of a function of a continuous RV",
    "text": "Expected value of a function of a continuous RV\n\n\nHow do we calculate expected values of discrete RVs?\n       \nFor discrete RVs: weight average \\[\\mathbb{E}[X] = \\sum_{i=1}^n x_ip_X(x_i).\\]\n\n\n\nHow do we calculate expected values of continuous RVs?\n       \nFor continuous RVs:"
  },
  {
    "objectID": "lessons/13_Expected_Values/28_Expected_Values/28_Expected_Values.html#expected-value-of-the-uniform-distribution",
    "href": "lessons/13_Expected_Values/28_Expected_Values/28_Expected_Values.html#expected-value-of-the-uniform-distribution",
    "title": "Chapter 28: Expected Values of Continuous Random Variables",
    "section": "Expected Value of the Uniform Distribution",
    "text": "Expected Value of the Uniform Distribution\n\n\n\n\nExample 1\n\n\nLet \\(f_X(x)= \\frac{1}{b-a}\\), for \\(a \\leq x \\leq b\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons/13_Expected_Values/28_Expected_Values/28_Expected_Values.html#expected-value-of-the-exponential-distribution",
    "href": "lessons/13_Expected_Values/28_Expected_Values/28_Expected_Values.html#expected-value-of-the-exponential-distribution",
    "title": "Chapter 28: Expected Values of Continuous Random Variables",
    "section": "Expected Value of the Exponential Distribution",
    "text": "Expected Value of the Exponential Distribution\n\n\n\n\nExample 2\n\n\nLet \\(f_X(x)= \\lambda e^{-\\lambda x}\\), for \\(x &gt; 0\\) and \\(\\lambda&gt; 0\\). Find \\(\\mathbb{E}[X]\\).\n\n\n\n\nIntegrating by Parts\n\n\n\\(\\displaystyle\\int_a^b u dv = uv\\bigg|^b_a - \\displaystyle\\int_a^b vdu\\)"
  },
  {
    "objectID": "lessons/13_Expected_Values/10_Expected_Values.html",
    "href": "lessons/13_Expected_Values/10_Expected_Values.html",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "",
    "text": "Calculate the mean (expected value) of discrete random variables"
  },
  {
    "objectID": "lessons/13_Expected_Values/10_Expected_Values.html#learning-objectives",
    "href": "lessons/13_Expected_Values/10_Expected_Values.html#learning-objectives",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "",
    "text": "Calculate the mean (expected value) of discrete random variables"
  },
  {
    "objectID": "lessons/13_Expected_Values/10_Expected_Values.html#where-are-we",
    "href": "lessons/13_Expected_Values/10_Expected_Values.html#where-are-we",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/13_Expected_Values/10_Expected_Values.html#our-good-and-fair-friend-the-6-sided-die",
    "href": "lessons/13_Expected_Values/10_Expected_Values.html#our-good-and-fair-friend-the-6-sided-die",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Our good and fair friend, the 6-sided die",
    "text": "Our good and fair friend, the 6-sided die\n\n\n\n\nExample 1\n\n\nSuppose you roll a fair 6-sided die. What value do you expect to get?"
  },
  {
    "objectID": "lessons/13_Expected_Values/10_Expected_Values.html#what-is-an-expected-value",
    "href": "lessons/13_Expected_Values/10_Expected_Values.html#what-is-an-expected-value",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "What is an expected value?",
    "text": "What is an expected value?\n\n\nDefinition: Expected value\n\n\nThe expected value of a discrete r.v. \\(X\\) that takes on values \\(x_1, x_2, \\ldots, x_n\\) is \\[\\mathbb{E}[X] = \\sum_{i=1}^n x_ip_X(x_i).\\]\n\n\n\nExpected values are not necessarily an actual outcome\n\nIn previous example, we cannot roll a 3.5\nIt could be that our expected value is not in the sample space (\\(E(X) \\notin S\\))\n\nDefinition holds when \\(X\\) takes on countably infinitely many values:\n\n\\[\\mathbb{E}[X] = \\sum_{i=1}^\\infty x_ip_X(x_i)\\]"
  },
  {
    "objectID": "lessons/13_Expected_Values/10_Expected_Values.html#our-good-and-not-so-fair-friend-the-6-sided-die",
    "href": "lessons/13_Expected_Values/10_Expected_Values.html#our-good-and-not-so-fair-friend-the-6-sided-die",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Our good and not-so-fair friend, the 6-sided die",
    "text": "Our good and not-so-fair friend, the 6-sided die\n\n\n\n\nExample 2\n\n\nSuppose the die is 6-sided, but not fair. And the probabilities of each side is distributed as:\n\n\n\n\\(x\\)\n\\(p_X(x)\\)\n\n\n\n\n1\n0.10\n\n\n2\n0.05\n\n\n3\n0.02\n\n\n4\n0.30\n\n\n5\n0.50\n\n\n6\n0.03\n\n\n\nWhat value do you expect to get on a roll?"
  },
  {
    "objectID": "lessons/13_Expected_Values/10_Expected_Values.html#expected-value-of-a-bernoulli-distribution",
    "href": "lessons/13_Expected_Values/10_Expected_Values.html#expected-value-of-a-bernoulli-distribution",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Expected value of a Bernoulli distribution",
    "text": "Expected value of a Bernoulli distribution\n\n\n\n\nExample 3\n\n\nSuppose \\[X = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\quad\\mathrm{(success)}\\\\\n            0 & \\quad \\mathrm{with\\ probability}\\ 1-p \\quad\\mathrm{(failure)}\n        \\end{array}\n    \\right.\\] Find the expected value of \\(X\\)."
  },
  {
    "objectID": "lessons/13_Expected_Values/10_Expected_Values.html#lets-slightly-change-our-random-variable",
    "href": "lessons/13_Expected_Values/10_Expected_Values.html#lets-slightly-change-our-random-variable",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Let’s slightly change our random variable",
    "text": "Let’s slightly change our random variable\n\n\n\n\nExample 5\n\n\nSuppose \\[X = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\\\\n            -1 & \\quad \\mathrm{with\\ probability}\\ 1-p\n        \\end{array}\n    \\right.\\] Find the expected value of \\(X\\)."
  },
  {
    "objectID": "lessons/13_Expected_Values/10_Expected_Values.html#bullseye",
    "href": "lessons/13_Expected_Values/10_Expected_Values.html#bullseye",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Bullseye! 🎯",
    "text": "Bullseye! 🎯\n\n\n\n\nExample 5\n\n\nSuppose I throw darts at a dartboard until I hit the bullseye, and that my probability of hitting the bullseye is \\(p\\). Suppose further that all of my throws are independent, and that the probability of a bullseye never changes, no matter how many times I throw a dart. How many times should I expect to have to throw the dart until I hit the bullseye?"
  },
  {
    "objectID": "lessons/13_Expected_Values/10_Expected_Values.html#ghost",
    "href": "lessons/13_Expected_Values/10_Expected_Values.html#ghost",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Ghost! 👻",
    "text": "Ghost! 👻\n\n\n\n\nExample 6\n\n\nA ghost is trick-or-treating. It comes to a house where it is known that there are 30 candies in the bag and only one is a watermelon Jolly Rancher, which is the ghost’s favorite. The ghost takes pieces of candy without replacement until it gets the watermelon Jolly Rancher. How many pieces of candy do we expect the ghost to take?\n\n\nCan we model this with a distribution?"
  },
  {
    "objectID": "lessons/13_Expected_Values/10_Expected_Values.html#some-remarks-on-last-two-examples",
    "href": "lessons/13_Expected_Values/10_Expected_Values.html#some-remarks-on-last-two-examples",
    "title": "Chapter 10: Expected Values of Discrete RVs",
    "section": "Some remarks on last two examples",
    "text": "Some remarks on last two examples\nBoth examples are repeated random processes. They are fundamentally different though:\n\nThe bullseye example is “with replacement” since the probability of success remains constant.\nThe ghost trick-or-treating example is without replacement, and thus the probability of success changes with each trial."
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/27_Conditional_distributions.html",
    "href": "lessons/12_Independence_Conditioning/27_Conditional_distributions.html",
    "title": "Chapter 27: Conditional Distributions",
    "section": "",
    "text": "Calculate the conditional probability density from a joint pdf"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/27_Conditional_distributions.html#learning-objectives",
    "href": "lessons/12_Independence_Conditioning/27_Conditional_distributions.html#learning-objectives",
    "title": "Chapter 27: Conditional Distributions",
    "section": "",
    "text": "Calculate the conditional probability density from a joint pdf"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/27_Conditional_distributions.html#conditional-probabilities-weve-seen-before",
    "href": "lessons/12_Independence_Conditioning/27_Conditional_distributions.html#conditional-probabilities-weve-seen-before",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Conditional probabilities we’ve seen before",
    "text": "Conditional probabilities we’ve seen before\n\n\nWhat do we know about conditional probabilities for events and discrete RVs?    \nFor events:\n\\[P(A | B) = \\dfrac{P(A \\cap B)}{P(B)}\\]    \nFor discrete RVs: \\[p_{X|Y}(x|y) = P(X=x|Y=y) = \\dfrac{p_{X,Y}(x,y)}{p_Y(y)}\\]\n\n\n\nWhat does it mean for conditional densities of continuous RVs?\nFor continuous RVs:"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-first-try",
    "href": "lessons/12_Independence_Conditioning/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-first-try",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf: first try!",
    "text": "Example starting from a joint pdf: first try!\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(2&lt;X&lt;10|Y=4)\\)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/27_Conditional_distributions.html#what-is-a-conditional-density",
    "href": "lessons/12_Independence_Conditioning/27_Conditional_distributions.html#what-is-a-conditional-density",
    "title": "Chapter 27: Conditional Distributions",
    "section": "What is a conditional density?",
    "text": "What is a conditional density?\n\n\n\n\nDefinition: Conditional density\n\n\nThe conditional density of a r.v. \\(X\\) given \\(Y=y\\), is \\[f_{X|Y}(x|y)= \\frac{f_{X,Y}(x,y)}{f_Y(y)},\\] for \\(f_Y(y)&gt; 0\\)\n\n\n\n\n\nRemarks\n\nIt follows from the definition for the conditional density \\(f_{X|Y}(x|y)\\), that \\[f_{X,Y}(x,y)= f_{X|Y}(x|y)f_Y(y).\\]\n\n     \n\nFor a fixed value of \\(Y=y\\), the conditional density \\(f_{X|Y}(x|y)\\) is an actual pdf, meaning\n\n\\(f_{X|Y}(x|y)\\geq 0\\) for all \\(x\\) and \\(y\\), and\n\\(\\displaystyle\\int_{-\\infty}^{\\infty} f_{X|Y}(x|y)dx =1\\)."
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try-12",
    "href": "lessons/12_Independence_Conditioning/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try-12",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf: second try! (1/2)",
    "text": "Example starting from a joint pdf: second try! (1/2)\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(2&lt;X&lt;10|Y=4)\\)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try-22",
    "href": "lessons/12_Independence_Conditioning/27_Conditional_distributions.html#example-starting-from-a-joint-pdf-second-try-22",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf: second try! (2/2)",
    "text": "Example starting from a joint pdf: second try! (2/2)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/27_Conditional_distributions.html#example-starting-from-a-joint-pdf",
    "href": "lessons/12_Independence_Conditioning/27_Conditional_distributions.html#example-starting-from-a-joint-pdf",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Example starting from a joint pdf",
    "text": "Example starting from a joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(X&gt;20 |Y=5)\\)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/27_Conditional_distributions.html#finding-probability-with-conditional-domain-and-pdf",
    "href": "lessons/12_Independence_Conditioning/27_Conditional_distributions.html#finding-probability-with-conditional-domain-and-pdf",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Finding probability with conditional domain and pdf",
    "text": "Finding probability with conditional domain and pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 2\n\n\nRandomly choose a point \\(X\\) from the interval \\([0,1]\\), and given \\(X=x\\), randomly choose a point \\(Y\\) from \\([0,x]\\). Find \\(\\mathbb{P}(0 &lt; Y &lt; \\frac14)\\)."
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/27_Conditional_distributions.html#independence-and-conditional-distributions",
    "href": "lessons/12_Independence_Conditioning/27_Conditional_distributions.html#independence-and-conditional-distributions",
    "title": "Chapter 27: Conditional Distributions",
    "section": "Independence and conditional distributions",
    "text": "Independence and conditional distributions\n    Question What is \\(f_{X|Y}(x|y)\\) if \\(X\\) and \\(Y\\) are independent?\n\\[f_{X|Y}(x|y) = \\dfrac{f_{X,Y}(x,y)}{f_y(y)} = \\dfrac{f_{X}(x)f_y(y)}{f_y(y)} = f_{X}(x)\\]\n       \n\nIf \\(f_{X|Y}(x|y)\\) does not depend on \\(y\\) (including the bounds/domain), then \\(X\\) and \\(Y\\) are independent."
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "",
    "text": "Show that a joint pdf consists of two independent, continuous RVs.\nCombine two independent RVs into one joint pdf or CDF.\n\n\n\n\n\nWhat do we know about independence for events and discrete RVs?\nFor events: If \\(A \\perp B\\)\n\\[P(A \\cap B) = P(A)P(B)\\] \\[P(A|B) = P(A)\\]\nFor discrete RVs: If \\(X \\perp Y\\) \\[p_{X,Y}(x,y) = p_{X}(x)p_{Y}(y)\\] \\[F_{X,Y}(x,y) = F_{X}(x)F_{Y}(y)\\] \\[p_{X|Y}(x|y) = p_{X}(x)\\] \\[p_{Y|X}(y|x) = p_{Y}(y)\\]\n\n\n\nWhat does it mean for continuous r.v.’s to be independent?\nFor continuous RVs: If \\(X \\perp Y\\)\n\n\n\n\n\n\n\n\n\nExample 1.1\n\n\nLet \\(X\\) and \\(Y\\) be independent r.v.’s with \\(f_X(x)= \\frac12\\), for \\(0 \\leq x \\leq 2\\) and \\(f_Y(y)= 3y^2\\), for \\(0 \\leq y \\leq 1\\).\n\nFind \\(f_{X,Y}(x,y)\\).\n\n\n\n\n\n\n\n\n\n\n\n\nExample 1.2\n\n\nLet \\(X\\) and \\(Y\\) be independent r.v.’s with \\(f_X(x)= \\frac12\\), for \\(0 \\leq x \\leq 2\\) and \\(f_Y(y)= 3y^2\\), for \\(0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\).\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for \\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\).\n\nAre \\(X\\) and \\(Y\\) independent?\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for \\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(F_{X,Y}(x,y)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 3\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Are \\(X\\) and \\(Y\\) independent?\n\n\n\n\n\n\n\n\nIf \\(f_{X,Y}(x,y)= g(x)h(y)\\), where \\(g(x)\\) and \\(h(y)\\) are pdf’s, then \\(X\\) and \\(Y\\) are independent.\n\nThe domain of the joint pdf needs to be independent as well!!\n\n\n       \n\nIf \\(F_{X,Y}(x,y)= G(x)H(y)\\), where \\(G(x)\\) and \\(H(y)\\) are cdf’s, then \\(X\\) and \\(Y\\) are independent.\n\nThe domain of the joint CDF needs to be independent as well!!"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#learning-objectives",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#learning-objectives",
    "title": "Chapter 26: Independent Continuous RVs",
    "section": "",
    "text": "Show that a joint pdf consists of two independent, continuous RVs.\nCombine two independent RVs into one joint pdf or CDF."
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#how-do-we-represent-independent-continuous-rvs-in-a-joint-pdf",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#how-do-we-represent-independent-continuous-rvs-in-a-joint-pdf",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "How do we represent independent continuous RVs in a joint pdf?",
    "text": "How do we represent independent continuous RVs in a joint pdf?\nWhat do we know about independence for events?\nFor events: If \\(A \\perp B\\)\n\\[P(A \\cap B) = P(A)P(B)\\] \\[P(A|B) = P(A)\\]\n\n\n\n\nFor discrete RVs: If \\(X \\perp Y\\)\n\n\n\\[p_{X,Y}(x,y) = p_{X}(x)p_{Y}(y)\\] \\[F_{X,Y}(x,y) = F_{X}(x)F_{Y}(y)\\] \\[p_{X|Y}(x|y) = p_{X}(x)\\] \\[p_{Y|X}(y|x) = p_{Y}(y)\\]\n\n\n\n\n\n\n\nFor continuous RVs: If \\(X \\perp Y\\)\n\n\n\\[f_{X,Y}(x,y) = f_{X}(x)f_{Y}(y)\\] \\[F_{X,Y}(x,y) = F_{X}(x)F_{Y}(y)\\] \\[f_{X|Y}(x|y) = f_{X}(x)\\] \\[f_{Y|X}(y|x) = f_{Y}(y)\\]"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "Constructing a joint pdf from two independent, continuous RVs",
    "text": "Constructing a joint pdf from two independent, continuous RVs\n\n\n\n\nExample 1.1\n\n\nLet \\(X\\) and \\(Y\\) be independent r.v.’s with \\(f_X(x)= \\frac12\\), for \\(0 \\leq x \\leq 2\\) and \\(f_Y(y)= 3y^2\\), for \\(0 \\leq y \\leq 1\\).\n\nFind \\(f_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs-1",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs-1",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "Constructing a joint pdf from two independent, continuous RVs",
    "text": "Constructing a joint pdf from two independent, continuous RVs\n\n\n\n\nExample 1.2\n\n\nLet \\(X\\) and \\(Y\\) be independent r.v.’s with \\(f_X(x)= \\frac12\\), for \\(0 \\leq x \\leq 2\\) and \\(f_Y(y)= 3y^2\\), for \\(0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)."
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#showing-independence-from-joint-pdf",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#showing-independence-from-joint-pdf",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "Showing independence from joint pdf",
    "text": "Showing independence from joint pdf\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for \\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\).\n\nAre \\(X\\) and \\(Y\\) independent?"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#finding-cdf-from-two-independent-rvs",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#finding-cdf-from-two-independent-rvs",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "Finding CDF from two independent RVs",
    "text": "Finding CDF from two independent RVs\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for \\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(F_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#showing-independence-from-joint-pdf-1",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#showing-independence-from-joint-pdf-1",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "Showing independence from joint pdf",
    "text": "Showing independence from joint pdf\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 3\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Are \\(X\\) and \\(Y\\) independent?"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#final-statement-on-independence",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#final-statement-on-independence",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "Final statement on independence",
    "text": "Final statement on independence\n\nIf \\(f_{X,Y}(x,y)= g(x)h(y)\\), where \\(g(x)\\) and \\(h(y)\\) are pdf’s, then \\(X\\) and \\(Y\\) are independent.\n\nThe domain of the joint pdf needs to be independent as well!!\n\n\n       \n\nIf \\(F_{X,Y}(x,y)= G(x)H(y)\\), where \\(G(x)\\) and \\(H(y)\\) are cdf’s, then \\(X\\) and \\(Y\\) are independent.\n\nThe domain of the joint CDF needs to be independent as well!!\n\n\n       \n\nMake sure that:\n\n\\(X\\) domain does NOT depend on \\(Y\\)\n\\(Y\\) domain does NOT depend on \\(X\\)"
  },
  {
    "objectID": "lessons/15_Variance/12_Variance_key_info.html",
    "href": "lessons/15_Variance/12_Variance_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 4 assignment due last night!\nHW 3 solutions also due\nTime to grade later today: HW 3 solutions or HW 4 assignment?"
  },
  {
    "objectID": "lessons/15_Variance/12_Variance_key_info.html#announcements",
    "href": "lessons/15_Variance/12_Variance_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 4 assignment due last night!\nHW 3 solutions also due\nTime to grade later today: HW 3 solutions or HW 4 assignment?"
  },
  {
    "objectID": "lessons/15_Variance/12_Variance_key_info.html#key-dates",
    "href": "lessons/15_Variance/12_Variance_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates"
  },
  {
    "objectID": "lessons/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html",
    "href": "lessons/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "",
    "text": "Calculate expected value of functions of RVs\nCalculate variance of RVs"
  },
  {
    "objectID": "lessons/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#learning-objectives",
    "href": "lessons/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#learning-objectives",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "",
    "text": "Calculate expected value of functions of RVs\nCalculate variance of RVs"
  },
  {
    "objectID": "lessons/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#expected-value-of-a-function-of-a-continuous-rv",
    "href": "lessons/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#expected-value-of-a-function-of-a-continuous-rv",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Expected value of a function of a continuous RV",
    "text": "Expected value of a function of a continuous RV\n\n\nHow do we calculate the expected value of a function of a discrete RV or joint RVs?\n   \nFor discrete RVs:\n\\[\\mathbb{E}[g(X)] = \\sum_{\\{all\\ x\\}}\\ g(x) p_X(x).\\] \\[\\mathbb{E}[g(X, Y)] = \\sum_{\\{all\\ x\\}}\\sum_{\\{all\\ y\\}}\\ g(x,y) p_{X,Y}(x,y).\\]\n\n\n\nHow do we calculate the expected value of a function of a continuous RV or joint RVs?\n   \nFor continuous RVs:"
  },
  {
    "objectID": "lessons/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#important-properties-of-expected-values-of-functions-of-continuous-rvs",
    "href": "lessons/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#important-properties-of-expected-values-of-functions-of-continuous-rvs",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Important properties of expected values of functions of continuous RVs",
    "text": "Important properties of expected values of functions of continuous RVs\n\n\n\n\nFunction of RV with two constants\n\n\n\\(\\mathbb{E}[aX+b] =a\\mathbb{E}[X]+b\\)\n\n\n\n\nFunction of two RVs added\n\n\n\\(\\mathbb{E}[X+Y] =\\mathbb{E}[X]+\\mathbb{E}[Y]\\)\n\n\n\n\nExpected value of sum of independent RVs pt 1\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are continuous RVs and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\[\\mathbb{E}\\Bigg[\\sum_{i=1}^{n} a_i X_i\\Bigg] = \\sum_{i=1}^{n}a_i\\mathbb{E}[X_i]\\]\n\n\n\n\n\nExpected value of multiplication of function of independent RVs\n\n\nIf \\(X\\) and \\(Y\\) are independent continuous RVs, and \\(g\\) and \\(h\\) are functions, then \\[\\mathbb{E}[g(X)h(Y)] =\\mathbb{E}[g(X)]\\mathbb{E}[h(Y)]\\]\n\n\n\n\nExpected value of multiplication of independent RVs\n\n\nIf \\(X\\) and \\(Y\\) are independent continuous RVs, then \\[\\mathbb{E}[XY] = \\mathbb{E}[X] \\mathbb{E}[Y] \\]"
  },
  {
    "objectID": "lessons/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-continuous-rvs",
    "href": "lessons/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-continuous-rvs",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Variance of continuous RVs",
    "text": "Variance of continuous RVs\n\n\nHow do we calculate the variance of a discrete RV?\n   \nFor discrete RVs:\n\\[\n\\begin{align}\nVar(X) & =\n\\mathbb{E}[(X-\\mu_X)^2] \\\\ & = \\mathbb{E}[(X-\\mathbb{E}[X])^2] \\\\ &= \\mathbb{E}[X^2]-(\\mathbb{E}[X])^2 \\\\ & = \\sum_{\\{all\\ x\\}}(x-\\mu_x)^2 p_{X}(x)\n\\end{align}\n\\]\n\n\n\nHow do we calculate the variance of a continuous RV?\n    \nFor continuous RVs:"
  },
  {
    "objectID": "lessons/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-an-uniform-distribution",
    "href": "lessons/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-an-uniform-distribution",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Variance of an Uniform distribution",
    "text": "Variance of an Uniform distribution\n\n\n\n\nExample 2\n\n\nLet \\(f_X(x)= \\frac{1}{b-a}\\), for \\(a \\leq x \\leq b\\). Find \\(Var[X]\\)."
  },
  {
    "objectID": "lessons/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-exponential-distribution",
    "href": "lessons/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#variance-of-exponential-distribution",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Variance of exponential distribution",
    "text": "Variance of exponential distribution\n\n\nIn the homework:\n\n\nExample 3\n\n\nLet \\(f_X(x)= \\lambda e^{-\\lambda x}\\), for \\(x &gt; 0\\) and \\(\\lambda&gt; 0\\). Find \\(Var[X]\\)."
  },
  {
    "objectID": "lessons/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#important-properties-of-variances-of-continuous-rvs",
    "href": "lessons/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#important-properties-of-variances-of-continuous-rvs",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Important properties of variances of continuous RVs",
    "text": "Important properties of variances of continuous RVs\n\n\n\n\nFunction of RV with two constants\n\n\n\\[Var[aX+b] = a^2Var[X]\\]\n\n\n\n\n\nVariance of sum of independent RVs pt 1\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous RVs and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\[Var\\Bigg(\\sum_{i=1}^{n} a_i X_i\\Bigg) =\\sum_{i=1}^{n} a^2_i Var(X_i)\\]\n\n\n\n\nVariance of sum of independent RVs pt 2\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous RVs, then \\[Var\\Bigg(\\sum_{i=1}^{n} X_i\\Bigg) = \\sum_{i=1}^{n} Var(X_i)\\]"
  },
  {
    "objectID": "lessons/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#find-the-mean-and-sd-from-word-problem",
    "href": "lessons/15_Variance/29_Variance_and_Sums_of_rv/29_Variance_and_Sums_of_rv.html#find-the-mean-and-sd-from-word-problem",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Find the mean and sd from word problem",
    "text": "Find the mean and sd from word problem\n\n\n\n\nExample 4\n\n\nA machine manufactures cubes with a side length that varies uniformly from 1 to 2 inches. Assume the sides of the base and height are equal. The cost to make a cube is 10 ¢ per cubic inch, and 5 ¢ cents for the general cost per cube. Find the mean and standard deviation of the cost to make 10 cubes."
  },
  {
    "objectID": "lessons/20_Moment_Generating_Functions/43_Moment_Generating_Functions_Part2.html",
    "href": "lessons/20_Moment_Generating_Functions/43_Moment_Generating_Functions_Part2.html",
    "title": "Chapter 43: Moment Generating Functions Part 2",
    "section": "",
    "text": "Chapter 43: Moment Generating Functions Part 2\nRecap: What is an mgf?\n\nExample 1.   Let \\(X\\) be a random variable with mgf \\[M_X(t)= \\frac{1}{5}e^t + \\frac{3}{10}e^{2t} + \\frac{1}{2}e^{3t}.\\] Find the pmf or pdf of \\(X\\).\n\n\nExample 2.   Let \\(X\\) be a normal random variable with mean \\(\\mu\\) and variance \\(\\sigma^2\\), i.e. \\(X \\sim N(\\mu,\\sigma^2)\\).\n\nFind the mgf of \\(X\\).\nFind \\(\\mathbb{E}[X]\\).\nFind \\(Var(X)\\).\n\n\n\n\nTheorem 3.   Let \\(X\\) have mgf \\(M_X(t)\\), and let \\(Y=aX+b\\), where \\(a\\) and \\(b\\) are constants. Then \\[M_Y(t)=\\]\n\n\nProof. Proof. ◻\n\nQuestion: Do linear transformations always preserve the distribution type?\nI.e., if \\(X\\) has a certain probability distribution, does \\(aX+b\\) always have the same distribution type?\n\n\nExample 4.   Let \\(X \\sim U[0,1]\\), and \\(Y = 2X+3\\). Is \\(Y\\) also a uniform rv? If so, what are its parameters?\n\n\nExample 5.   Let \\(X \\sim Exp(\\lambda=5)\\), and \\(Y = 2X+3\\). Is \\(Y\\) also an exponential rv? If so, what is its parameter?\n\nMgf’s of Sums of Independent rv’s\n\n\nTheorem 6.   Let \\(X_1, X_2, \\ldots, X_n\\) be independent rv’s with respective mgf’s \\(M_{X_i}(t)\\), for \\(i=1,2,\\ldots,n\\). Let \\(Y=\\sum_{i=1}^n a_iX_i\\), where \\(a_i\\) are constants. Then \\[M_Y(t)= %\\Pi_{i=1}^n M_{X_i}(a_it).\\]\n\n\nProof. Proof. ◻\n\n\n\nExample 7.   Let \\(X_i \\sim N(\\mu_i, \\sigma_i^2)\\) be independent normal rv’s. What is the distribution of  \\(Y=\\sum_{i=1}^n X_i\\)?\n\n\n\nExample 8.   Let \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). What is the distribution of  \\(\\bar{X}=\\frac{\\sum_{i=1}^n X_i}{n}\\)?\n\n\nExample 9.   Let \\(Z\\) be a standard normal random variable, i.e. \\(Z \\sim N(0,1)\\). Show that \\(Z^2 \\sim \\chi_1^2\\), i.e. is a chi-squared rv with 1 degree of freedom."
  },
  {
    "objectID": "lessons/08_pmfs/08_pmfs.html",
    "href": "lessons/08_pmfs/08_pmfs.html",
    "title": "Chapter 8: Probability Mass Functions (pmf’s) and Cumulative Distribution Functions (cdf’s)",
    "section": "",
    "text": "Calculate probabilities for discrete random variables\nCalculate and graph a probability mass function (pmf)\nCalculate and graph a cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons/08_pmfs/08_pmfs.html#learning-objectives",
    "href": "lessons/08_pmfs/08_pmfs.html#learning-objectives",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate probabilities for discrete random variables\nCalculate and graph a probability mass function (pmf)\nCalculate and graph a cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons/08_pmfs/08_pmfs.html#where-are-we",
    "href": "lessons/08_pmfs/08_pmfs.html#where-are-we",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/08_pmfs/08_pmfs.html#what-is-a-probability-mass-function",
    "href": "lessons/08_pmfs/08_pmfs.html#what-is-a-probability-mass-function",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "What is a probability mass function?",
    "text": "What is a probability mass function?\n\n\nDefinition: probability distribution or probability mass function (pmf)\n\n\nThe probability distribution or probability mass function (pmf) of a discrete r.v. \\(X\\) is defined for every number \\(x\\) by \\[p_X(x) = \\mathbb{P}(X=x) = \\mathbb{P}(\\mathrm{all }\\ \\omega\\in S:X(\\omega) = x)\\]"
  },
  {
    "objectID": "lessons/08_pmfs/08_pmfs.html#lets-demonstrate-this-definition-with-our-coin-toss",
    "href": "lessons/08_pmfs/08_pmfs.html#lets-demonstrate-this-definition-with-our-coin-toss",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Let’s demonstrate this definition with our coin toss",
    "text": "Let’s demonstrate this definition with our coin toss\n\n\n\n\nExample 1\n\n\nSuppose we toss 3 coins with probability of tails \\(p\\). If \\(X\\) is the random variable counting the number of tails, what are the probabilities of each value of \\(X\\)?"
  },
  {
    "objectID": "lessons/08_pmfs/08_pmfs.html#remarks-on-the-pmf",
    "href": "lessons/08_pmfs/08_pmfs.html#remarks-on-the-pmf",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Remarks on the pmf",
    "text": "Remarks on the pmf\n\n\nProperties of pmf\n\n\nA pmf \\(p_X(x)\\) must satisfy the following properties:\n\n\\(0 \\leq p_X(x) \\leq 1\\) for all \\(x\\).\n\\(\\sum \\limits_{\\{all\\ x\\}}p_X(x)=1\\).\n\n\n\n\nSome distributions depend on parameters\n\nEach value of a parameter gives a different pmf\nIn previous example, the number of coins tossed was a parameter\n\nWe tossed 3 coins\nIf we tossed 4 coins, we’d get a different pmf!\n\nThe collection of all pmf’s for different values of the parameters is called a family of pmf’s"
  },
  {
    "objectID": "lessons/08_pmfs/08_pmfs.html#binomial-family-of-rvs",
    "href": "lessons/08_pmfs/08_pmfs.html#binomial-family-of-rvs",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Binomial family of RVs",
    "text": "Binomial family of RVs\n\n\n\n\nExample 2\n\n\nSuppose you toss \\(n\\) coins, each with probability of tails \\(p\\). If \\(X\\) is the number of tails, what is the pmf of \\(X\\)?"
  },
  {
    "objectID": "lessons/08_pmfs/08_pmfs.html#bernoulli-family-of-rvs",
    "href": "lessons/08_pmfs/08_pmfs.html#bernoulli-family-of-rvs",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Bernoulli family of RVs",
    "text": "Bernoulli family of RVs\n\n\n\n\nExample 3\n\n\nSuppose you toss 1 coin, with probability of tails \\(p\\). If \\(X\\) is the number of tails, what is the pmf of \\(X\\)?"
  },
  {
    "objectID": "lessons/08_pmfs/08_pmfs.html#household-size-15",
    "href": "lessons/08_pmfs/08_pmfs.html#household-size-15",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Household size (1/5)",
    "text": "Household size (1/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nWhat is the sample space for household sizes?\nDefine the random variable for household sizes.\nDo the values in the table create a pmf? Why or why not?\nMake a plot of the pmf.\nWrite the cdf as a function.\nGraph the cdf of household sizes in 2019."
  },
  {
    "objectID": "lessons/08_pmfs/08_pmfs.html#household-size-25",
    "href": "lessons/08_pmfs/08_pmfs.html#household-size-25",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Household size (2/5)",
    "text": "Household size (2/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nWhat is the sample space for household sizes?\nDefine the random variable for household sizes."
  },
  {
    "objectID": "lessons/08_pmfs/08_pmfs.html#household-size-35",
    "href": "lessons/08_pmfs/08_pmfs.html#household-size-35",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Household size (3/5)",
    "text": "Household size (3/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nDo the values in the table create a pmf? Why or why not?\nMake a plot of the pmf"
  },
  {
    "objectID": "lessons/08_pmfs/08_pmfs.html#what-is-a-cumulative-distribution-function",
    "href": "lessons/08_pmfs/08_pmfs.html#what-is-a-cumulative-distribution-function",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "What is a cumulative distribution function?",
    "text": "What is a cumulative distribution function?\n\n\nDefinition: cumulative distribution function (CDF)\n\n\nThe cumulative distribution function (cdf) of a discrete r.v. \\(X\\) with pmf \\(p_X(x)\\), is defined for every value \\(x\\) by \\[F_X(x) = \\mathbb{P}(X \\leq x) = \\sum \\limits_{\\{all\\ y:\\ y\\leq x\\}}p_X(y)\\]"
  },
  {
    "objectID": "lessons/08_pmfs/08_pmfs.html#household-size-45",
    "href": "lessons/08_pmfs/08_pmfs.html#household-size-45",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Household size (4/5)",
    "text": "Household size (4/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nWrite the cdf as a function."
  },
  {
    "objectID": "lessons/08_pmfs/08_pmfs.html#household-size-55",
    "href": "lessons/08_pmfs/08_pmfs.html#household-size-55",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Household size (5/5)",
    "text": "Household size (5/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nGraph the cdf of household sizes in 2019."
  },
  {
    "objectID": "lessons/08_pmfs/08_pmfs.html#properties-of-discrete-cdfs",
    "href": "lessons/08_pmfs/08_pmfs.html#properties-of-discrete-cdfs",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Properties of discrete CDFs",
    "text": "Properties of discrete CDFs\n\n\\(F(x)\\) is increasing or flat (never decreasing)\n\\(\\min\\limits_x F(x) = 0\\)\n\\(\\max\\limits_xF(x)=1\\)\nCDF is a step function"
  },
  {
    "objectID": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html",
    "href": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "",
    "text": "Learn the definition of a moment-generating function.\nFind the moment-generating function of a binomial random variable.\nUse a moment-generating function to find the mean and variance of a random variable."
  },
  {
    "objectID": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#learning-objectives",
    "href": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#learning-objectives",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "",
    "text": "Learn the definition of a moment-generating function.\nFind the moment-generating function of a binomial random variable.\nUse a moment-generating function to find the mean and variance of a random variable."
  },
  {
    "objectID": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#where-are-we",
    "href": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#where-are-we",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#what-are-moments",
    "href": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#what-are-moments",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "What are moments?",
    "text": "What are moments?\n\n\nDefinition 1\n\n\nThe \\(j^{th}\\) moment of a r.v. \\(X\\) is \\(\\mathbb{E}[X^j]\\)\n\n\n\n\nExample 1\n\n\n\\(1^{st}-4^{th}\\) moments"
  },
  {
    "objectID": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#what-is-a-moment-generating-function-mgf",
    "href": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#what-is-a-moment-generating-function-mgf",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "What is a moment generating function (mgf)??",
    "text": "What is a moment generating function (mgf)??\n\n\nDefinition 3\n\n\nIf \\(X\\) is a r.v., then the moment generating function (mgf) associated with \\(X\\) is: \\[M_X(t)= \\mathbb{E}[e^{tX}]\\]\n\n\nRemarks\n\n\n\nFor a discrete r.v., the mgf of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\sum_{all \\ x}e^{tx}p_X(x)\\]\nFor a continuous r.v., the mgf of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\int_{-\\infty}^{\\infty}e^{tx}f_X(x)dx\\]\n\n\n\nThe mgf \\(M_X(t)\\) is a function of \\(t\\), not of \\(X\\), and it might not be defined (i.e. finite) for all values of \\(t\\). We just need it to be defined for \\(t=0\\)."
  },
  {
    "objectID": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#example",
    "href": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#example",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Example",
    "text": "Example\n\n\n\n\nExample 4\n\n\nWhat is \\(M_X(t)\\) for \\(t=0\\)?"
  },
  {
    "objectID": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#theorem",
    "href": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#theorem",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Theorem",
    "text": "Theorem\n\n\nTheorem 5\n\n\nThe moment generating function uniquely specifies a probability distribution.\n\n\n\n\nTheorem 6\n\n\n\\[\\mathbb{E}[X^r] = M_X^{(r)}(0)\\]\n\\((r)\\) in this equation is the \\(r\\)th derivative with respect to \\(t\\)\n\n\n\nWhen \\(r=1\\), we are taking the first derivative\nWhen \\(r=4\\), we are taking the fourth derivative"
  },
  {
    "objectID": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-a-probability-distribution",
    "href": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-a-probability-distribution",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Using the mgf to uniquely describe a probability distribution",
    "text": "Using the mgf to uniquely describe a probability distribution\n\n\n\n\nExample 7\n\n\nLet \\(X \\sim Poisson(\\lambda)\\)\n\nFind the mgf of \\(X\\)\nFind \\(\\mathbb{E}[X]\\)\nFind \\(Var(X)\\)"
  },
  {
    "objectID": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#theorem-1",
    "href": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#theorem-1",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Theorem",
    "text": "Theorem\nRemark: Finding the mean and variance is sometimes easier with the following trick\n\n\nTheorem 8\n\n\nLet \\(R_X(t) = \\ln[M_X(t)]\\). Then,\n\\[\\mu = \\mathbb{E}[X] = R_X'(0) \\text{, and}\\] \\[\\sigma^2 = Var(X) = R_X''(0)\\]\n\n\n\nProof."
  },
  {
    "objectID": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-r_xt-to-uniquely-describe-a-probability-distribution",
    "href": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-r_xt-to-uniquely-describe-a-probability-distribution",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Using \\(R_X(t)\\) to uniquely describe a probability distribution",
    "text": "Using \\(R_X(t)\\) to uniquely describe a probability distribution\n\n\n\n\nExample 9\n\n\nLet \\(X \\sim Poisson(\\lambda)\\).\n\nFind \\(\\mathbb{E}[X]\\) using \\(R_X(t)\\)\nFind \\(Var(X)\\) using \\(R_X(t)\\)"
  },
  {
    "objectID": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-the-standard-normal-distribution",
    "href": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-the-standard-normal-distribution",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Using the mgf to uniquely describe the standard normal distribution",
    "text": "Using the mgf to uniquely describe the standard normal distribution\n\n\n\n\nExample 10\n\n\nLet \\(Z\\) be a standard normal random variable, i.e. \\(Z \\sim N(0,1)\\).\n\nFind the mgf of \\(Z\\)\nFind \\(\\mathbb{E}[Z]\\)\nFind \\(Var(Z)\\)"
  },
  {
    "objectID": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#mgfs-of-sums-of-independent-rvs",
    "href": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#mgfs-of-sums-of-independent-rvs",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Mgf’s of sums of independent RV’s",
    "text": "Mgf’s of sums of independent RV’s\n\n\nTheorem 9\n\n\nIf \\(X\\) and \\(Y\\) are independent RV’s with respective mgf’s \\(M_X(t)\\) and \\(M_Y(t)\\), then\n\\[M_{X+Y}(t) = E[e^{t(X+Y)}] = E[e^{tX} e^{tY}] = E[e^{tX}]E[e^{tY}]=M_{X}(t)M_{Y}(t)\\]"
  },
  {
    "objectID": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#main-takeaways",
    "href": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#main-takeaways",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Main takeaways",
    "text": "Main takeaways\n\nMgf’s are a purely mathematically definition\n\nWe can’t really relate it to our real world analysis\n\nThey are helpful mathematically because they are unique to a probability distribution\n\nWe can find the unique mgf from for a probability distribution\nAnd we can find a distribution from an mgf\n\nMgf’s can sometimes make it easier to find the mean and variance of an RV\nMgf’s are most helpful when we are finding a joint distribution that is a sum or transformation of two RV’s\n\nMake the calculation easier!\n\nMgf’s are often used to prove certain distribution are sums of other ones!"
  },
  {
    "objectID": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#more-resources",
    "href": "lessons/19_Moment_Generating_Functions/43_01_Moment_Generating_Functions.html#more-resources",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "More resources",
    "text": "More resources\n\nhttps://online.stat.psu.edu/stat414/book/export/html/676\nhttps://www.youtube.com/watch/ez_vq23xWrQ\nhttps://www.youtube.com/watch/2p9J9ChTeFI\nhttps://www.youtube.com/watch/A5bWU8xcQkE\nhttps://www.youtube.com/watch/QeUrTGFTFm4\nhttps://www.youtube.com/watch/HhrkwyyRtgI"
  },
  {
    "objectID": "lessons/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html",
    "href": "lessons/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Homework 7 presentations due soon!\n\nI will check your HW 7 solutions ASAP!\n\nDepending on how far we get today and Wednesday, I might cancel the 12/9 class\nAnything else?"
  },
  {
    "objectID": "lessons/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#announcements",
    "href": "lessons/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Homework 7 presentations due soon!\n\nI will check your HW 7 solutions ASAP!\n\nDepending on how far we get today and Wednesday, I might cancel the 12/9 class\nAnything else?"
  },
  {
    "objectID": "lessons/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#key-dates",
    "href": "lessons/14_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 8 assignment due\nSunday: HW 7 presentations due at 11pm"
  },
  {
    "objectID": "lessons/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html",
    "href": "lessons/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "",
    "text": "Calculate the mean (expected value) of a joint distribution of continuous RV"
  },
  {
    "objectID": "lessons/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#learning-objectives",
    "href": "lessons/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#learning-objectives",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "",
    "text": "Calculate the mean (expected value) of a joint distribution of continuous RV"
  },
  {
    "objectID": "lessons/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#remark-on-expected-value-of-one-rv-from-joint-pdf",
    "href": "lessons/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#remark-on-expected-value-of-one-rv-from-joint-pdf",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "Remark on expected value of one RV from joint pdf",
    "text": "Remark on expected value of one RV from joint pdf\nIf you are given \\(f_{X,Y}(x,y)\\) and want to calculate \\(\\mathbb{E}[X]\\), you have two options:\n\nFind \\(f_X(x)\\) and use it to calculate \\(\\mathbb{E}[X]\\).\nOr, calculate \\(\\mathbb{E}[X]\\) using the joint density: \\[\\mathbb{E}[X] = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}x f_{X,Y}(x,y)dydx.\\]"
  },
  {
    "objectID": "lessons/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-1-expected-value-from-a-joint-distribution",
    "href": "lessons/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-1-expected-value-from-a-joint-distribution",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "Option 1: Expected value from a joint distribution",
    "text": "Option 1: Expected value from a joint distribution\n\n\n\n\nExample 3\n\n\nLet \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-2-expected-value-from-a-joint-distribution",
    "href": "lessons/14_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-2-expected-value-from-a-joint-distribution",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "Option 2: Expected value from a joint distribution",
    "text": "Option 2: Expected value from a joint distribution\n\n\n\n\nExample 1\n\n\nLet \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html",
    "title": "Chapter 25: Joint densities",
    "section": "",
    "text": "Solve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#learning-objectives",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#learning-objectives",
    "title": "Chapter 25: Joint densities",
    "section": "",
    "text": "Solve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-13",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-13",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (1/3)",
    "text": "Double Integrals Mini Lesson (1/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 1\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} xy dydx\\)"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-23",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-23",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (2/3)",
    "text": "Double Integrals Mini Lesson (2/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 2\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} (x+y) dydx\\)"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-33",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-33",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (3/3)",
    "text": "Double Integrals Mini Lesson (3/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 3\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} e^{x+y} dydx\\)"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "title": "Chapter 25: Joint densities",
    "section": "How to define the joint pdf for continuous RVs?",
    "text": "How to define the joint pdf for continuous RVs?\n\n\nFor a single continuous RV \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\), \\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\]\n\nFor two continuous RVs (\\(X\\) and \\(Y\\)), we can define the joint pdf, \\(f_{X,Y}(x,y)\\), such that for all real values \\(a,b, c, d\\) with \\(a \\leq b\\) and \\(c \\leq d\\), \\[\\mathbb{P}(a \\leq X \\leq b, c \\leq Y \\leq d) = \\int_a^b \\int_c^d f_{X,Y}(x,y)dydx\\]"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#important-properties-of-the-joint-pdf",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#important-properties-of-the-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Important properties of the joint pdf",
    "text": "Important properties of the joint pdf\n\nNote that \\(f_{X,Y}(x,y)\\neq \\mathbb{P}(X=x, Y=y)\\)!!!\nIn order for \\(f_{X,Y}(x,y)\\) to be a pdf, it needs to satisfy the properties\n\n\\(f_{X,Y}(x,y)\\geq 0\\) for all \\(x,y\\)\n\\(\\displaystyle\\int_{-\\infty}^{\\infty}\\displaystyle\\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dxdy=1\\)"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "title": "Chapter 25: Joint densities",
    "section": "What is the joint cumulative distribution function?",
    "text": "What is the joint cumulative distribution function?\n\n\nDefinition: Joint cumulative distribution function (Joint CDF)\n\n\nThe joint cumulative distribution function (cdf) of continuous random variables \\(X\\) and \\(Y\\), is the function \\(F_{X,Y}(x,y)\\), such that for all real values of \\(x\\) and \\(y\\), \\[F_{X,Y}(x,y)= \\mathbb{P}(X \\leq x, Y \\leq y) = \\int_{-\\infty}^x\\int_{-\\infty}^y f_{X,Y}(s,t)dtds\\]\n\n\nRemarks:\n\nThe definition above for \\(F_{X,Y}(x,y)\\) is a function of \\(x\\) and \\(y\\).\nThe joint cdf at the point \\((a,b)\\), is \\[F_{X,Y}(a,b) = \\mathbb{P}(X \\leq a, Y \\leq b) = \\int_{-\\infty}^a\\int_{-\\infty}^b f_{X,Y}(s,t)dtds\\]"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#what-are-the-marginal-pdfs",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#what-are-the-marginal-pdfs",
    "title": "Chapter 25: Joint densities",
    "section": "What are the marginal pdf’s?",
    "text": "What are the marginal pdf’s?\n\n\nDefinition: Marginal pdf’s\n\n\nSuppose \\(X\\) and \\(Y\\) are continuous r.v.’s, with joint pdf \\(f_{X,Y}(x,y)\\). Then the marginal probability density functions are \\[\\begin{aligned}\nf_X(x)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dy\\\\\nf_Y(y)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dx\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#common-steps-for-solving-problems",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#common-steps-for-solving-problems",
    "title": "Chapter 25: Joint densities",
    "section": "Common steps for solving problems",
    "text": "Common steps for solving problems\n\nSet up the domain of the pdf with a picture\nTranslate to needed integrands\n\nFor probability: shade in the area of interest, then translate\nFor expected value: translate domain\n\nSet up integral: \\(dxdy\\) or \\(dydx\\)?\nSolve integral!"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#example-of-joint-pdf",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#example-of-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)."
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#example-of-joint-pdf-1",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#example-of-joint-pdf-1",
    "title": "Chapter 25: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "title": "Chapter 25: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(\\mathbb{P}(Y &lt; 3)\\)."
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.1\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nFind \\(\\mathbb{P}(|X-Y| &lt; 2)\\)"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "title": "Chapter 25: Joint densities",
    "section": "Finding the pdf of a transformation",
    "text": "Finding the pdf of a transformation\n\nLet \\(M\\) be a transformation of \\(X\\) and \\(Y\\)\nWhen we have a transformation of \\(X\\) and \\(Y\\), \\(M\\), we need to follow a specific process to find the pdf of \\(M\\)\n\nWe follow this process:\n\nStart with the joint pdf for \\(X\\) and \\(Y\\)\n\naka \\(f_{X,Y}(x, y)\\)\n\nTranslate the domain of \\(X\\) and \\(Y\\) to \\(M\\)\nFind the CDF of \\(M\\)\n\naka \\(F_M(m)\\) or \\(P(M \\leq m)\\)\n\nTake the derivative of the CDF of \\(M\\) to find the pdf of \\(M\\)\n\naka \\(f_M(m) = \\dfrac{d}{dm}F_M(m)\\)"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more-1",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more-1",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.2\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(M = \\max(X,Y)\\). Find the pdf for \\(M\\), that is \\(f_M(m)\\)."
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more-2",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more-2",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 3.3\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(Z = \\min(X,Y)\\). Find the pdf for \\(Z\\), that is \\(f_Z(z)\\)."
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-further",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-further",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even further!",
    "text": "Let’s complicate this even further!\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 4\n\n\nLet \\(X\\) and \\(Y\\) have joint density \\(f_{X,Y}(x,y)= \\frac85(x+y)\\) in the region \\(0 &lt; x &lt; 1,\\ \\frac12 &lt; y &lt;1\\). Find the pdf of the r.v. \\(Z\\), where \\(Z=XY\\)."
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities_key_info.html",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 6 assignment today!\n\nFeel free to turn in solutions later than 11/24 since I took so long to grade\n\nI made quite a few changes to the homeworks\n\nHW 10 is gone\nHW 9 is optional\nInstead of a HW assignment due over late November break\n\nHW 8 will include material from Week 8 and 9 and be due 12/5\n\n\nI have quite a bit of grading to catch up on!\nRealizing I never gave you mid-quarter feedback forms…\n\nLet’s chat about this and our assessment breakdown in the coming weeks\n\nAnything else?"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities_key_info.html#announcements",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 6 assignment today!\n\nFeel free to turn in solutions later than 11/24 since I took so long to grade\n\nI made quite a few changes to the homeworks\n\nHW 10 is gone\nHW 9 is optional\nInstead of a HW assignment due over late November break\n\nHW 8 will include material from Week 8 and 9 and be due 12/5\n\n\nI have quite a bit of grading to catch up on!\nRealizing I never gave you mid-quarter feedback forms…\n\nLet’s chat about this and our assessment breakdown in the coming weeks\n\nAnything else?"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/25_Joint_densities_key_info.html#key-dates",
    "href": "lessons/11_Transformations_Joint_distributions/25_Joint_densities_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 7 due\nSunday: HW 6 solutions due"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/11_Transformations.html",
    "href": "lessons/11_Transformations_Joint_distributions/11_Transformations.html",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "",
    "text": "Calculate probabilities for a pair of discrete random variables\nCalculate a joint, marginal, and conditional probability mass function (pmf)\nCalculate a joint, marginal, and conditional cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#learning-objectives",
    "href": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#learning-objectives",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "",
    "text": "Calculate probabilities for a pair of discrete random variables\nCalculate a joint, marginal, and conditional probability mass function (pmf)\nCalculate a joint, marginal, and conditional cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#where-are-we",
    "href": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#where-are-we",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#what-is-a-joint-pmf",
    "href": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#what-is-a-joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is a joint pmf?",
    "text": "What is a joint pmf?\n\n\nDefinition: joint pmf\n\n\nThe joint pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[p_{X,Y}(x,y) = \\mathbb{P}(X=x\\ and\\ Y=y) = \\mathbb{P}(X=x, Y=y)\\]"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#this-chapters-main-example",
    "href": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#this-chapters-main-example",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "This chapter’s main example",
    "text": "This chapter’s main example\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#joint-pmf",
    "href": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Joint pmf",
    "text": "Joint pmf\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#marginal-pmfs",
    "href": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#marginal-pmfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Marginal pmf’s",
    "text": "Marginal pmf’s\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#remarks-on-the-joint-pmf",
    "href": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#remarks-on-the-joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the joint pmf",
    "text": "Remarks on the joint pmf\nSome properties of joint pmf’s:\n\nA joint pmf \\(p_{X,Y}(x,y)\\) must satisfy the following properties:\n\n\\(p_{X,Y}(x,y)\\geq 0\\) for all \\(x, y\\).\n\\(\\sum \\limits_{\\{all\\ x\\}} \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)=1\\).\n\nMarginal pmf’s:\n\n\\(p_X(x) = \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)\\)\n\\(p_Y(y) = \\sum \\limits_{\\{all\\ x\\}} p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#what-is-a-joint-cdf",
    "href": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#what-is-a-joint-cdf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is a joint CDF?",
    "text": "What is a joint CDF?\n\n\nDefinition: joint CDF\n\n\nThe joint CDF of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[F_{X,Y}(x,y) = \\mathbb{P}(X \\leq x\\ and\\ Y \\leq y) = \\mathbb{P}(X \\leq x, Y \\leq y)\\]"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#joint-cdfs",
    "href": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#joint-cdfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Joint CDFs",
    "text": "Joint CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#marginal-cdfs",
    "href": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#marginal-cdfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Marginal CDFs",
    "text": "Marginal CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#remarks-on-the-joint-and-marginal-cdf",
    "href": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#remarks-on-the-joint-and-marginal-cdf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the joint and marginal CDF",
    "text": "Remarks on the joint and marginal CDF\n\n\\(F_X(x)\\): right most columns of the CDf table (where the \\(Y\\) values are largest)\n\\(F_Y(y)\\): bottom row of the table (where X values are largest)\n\\(F_X(x)=\\lim\\limits_{y\\rightarrow\\infty}F_{X, Y}(x,y)\\)\n\\(F_Y(y)=\\lim\\limits_{x\\rightarrow\\infty}F_{X, Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#independence-and-conditioning",
    "href": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#independence-and-conditioning",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Independence and Conditioning",
    "text": "Independence and Conditioning\nRecall that for events \\(A\\) and \\(B\\),\n\n\\(\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}\\)\n\\(A\\) and \\(B\\) are independent if and only if\n\n\\(\\mathbb{P}(A|B) = \\mathbb{P}(A)\\)\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A)\\cdot\\mathbb{P}(B)\\)\n\n\nIndependence and conditioning are defined similarly for r.v.’s, since \\[p_X(x) = \\mathbb{P}(X=x)\\ \\mathrm{and}\\ \\ p_{X,Y}(x,y) = \\mathbb{P}(X = x ,Y = y).\\]"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#what-is-the-conditional-pmf",
    "href": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#what-is-the-conditional-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is the conditional pmf?",
    "text": "What is the conditional pmf?\n\n\nDefinition: conditional pmf\n\n\nThe conditional pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is defined as \\[p_{X|Y}(x|y) = \\mathbb{P}(X = x |Y = y) = \\frac{\\mathbb{P}(X = x\\ and\\ Y = y)}{\\mathbb{P}(Y = y)}\n=\\frac{p_{X,Y}(x,y) }{p_{Y}(y) }\\] if \\(p_{Y}(y) &gt; 0\\)."
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#remarks-on-the-conditional-pmf",
    "href": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#remarks-on-the-conditional-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the conditional pmf",
    "text": "Remarks on the conditional pmf\nThe following properties follow from the conditional pmf definition:\n\nIf \\(X \\perp Y\\) (independent)\n\n\\(p_{X|Y}(x|y) = p_X(x)\\) for all \\(x\\) and \\(y\\)\n\\(p_{X,Y}(x,y) = p_X(x)p_Y(y)\\) for all \\(x\\) and \\(y\\)\nWhich also implies (\\(\\Rightarrow\\)): \\(F_{X,Y}(x,y) = F_X(x)F_Y(y)\\) for all \\(x\\) and \\(y\\)\n\nIf \\(X_1, X_2, …, X_n\\) are independent\n\n\\[p_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1=x_1, X_2=x_2, …, X_n=x_n)=\\prod\\limits_{i=1}^np_{X_i}(x_i)\\]\n\\[F_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1\\leq x_1, X_2\\leq x_2, …, X_n\\leq x_n)=\\prod\\limits_{i=1}^nP(X_i \\leq x_i) = \\prod\\limits_{i=1}^nF_{X_i}(x_i)\\]"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#conditional-pmfs",
    "href": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#conditional-pmfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Conditional pmf’s",
    "text": "Conditional pmf’s\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?\n\n\n\n\n\nRemark:\n\nTo show that \\(X\\) and \\(Y\\) are not independent, we just need to find one counter example\nHowever, to show that they are independent, we need to verify this for all possible pairs of \\(x\\) and \\(y\\)"
  },
  {
    "objectID": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#hypothetical-4-sided-die",
    "href": "lessons/11_Transformations_Joint_distributions/11_Transformations.html#hypothetical-4-sided-die",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Hypothetical 4-sided die",
    "text": "Hypothetical 4-sided die\n\n\nExample 3\n\n\n\nSuppose you have a 4-sided die, and you roll the 4-sided die until the first 4 appears.\nLet \\(X\\) be the number of rolls required until (and including) the first 4.\nAfter the first 4, you keep rolling it again until you roll a 3.\nLet \\(Y\\) be the number of rolls, after the first 4, required until (and including) the 3.\n\n\nFind \\(p_{X,Y}(x,y)\\).\nUsing \\(p_{X,Y}(x,y)\\), find \\(p_{Y}(y)\\).\nFind \\(p_{X}(x)\\).\nAre \\(X\\) and \\(Y\\) are independent? Why or why not?\nFind \\(F_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs.html",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs.html",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "",
    "text": "Distinguish between Uniform, Exponential, Gamma, and Normal distributions when reading a story.\nIdentify the variable and the parameters in a story, and state what the variable and parameters mean.\nUse the formulas for the pdf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#properties-of-continuous-uniform-rvs",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#properties-of-continuous-uniform-rvs",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Properties of continuous uniform RVs",
    "text": "Properties of continuous uniform RVs\n\nScenario: Events are equally likely to happen anywhere or anytime in an interval of values\nShorthand: \\(X \\sim \\text{U}[a,b]\\)\n\n\\[\nf_X(x) = \\dfrac{1}{b-a}, \\text{ for }a \\leq x \\leq b\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;a \\quad \\\\\n            \\dfrac{x-a}{b-a} & \\quad a \\leq x \\leq b\\quad \\\\\n            1 & \\quad x&gt;b \\quad\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{a+b}{2} \\text{, } \\text{ Var}(X) = \\dfrac{(b-a)^2}{12}\\]"
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#identifying-continuous-uniform-rv-from-word-problems",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#identifying-continuous-uniform-rv-from-word-problems",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Identifying continuous uniform RV from word problems",
    "text": "Identifying continuous uniform RV from word problems\n\nLook for some indication that all events are equally likely\n\nCould also say “uniformly distributed”\n\nLook for an interval\n\nTime example: Costumer in your store will approach the cash register in next 30 minutes. Approaching the register throughout the 30 minutes is equally likely.\nLength example: You have a 12 inch string that you need to cut. You are equally likely to cut anywhere on the string.\n\nDifferent than the discrete uniform\n\nDiscrete usually includes a countable number of events that are equally likely\nContinuous is not countable\n\nExact time and length can be measured with infinite decimal places"
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re looking at equally likely arrival times between 10 am and 11 am.\n\nIf we want to know the probability that someone arrives at 10:30am or earlier:\n\npunif(q = 30, min = 0, max = 60)\n\n[1] 0.5\n\n\nIf we want to know the time, say \\(t\\), where the probability of arriving at \\(t\\) or earlier is 0.35:\n\nqunif(p = 0.35, min = 0, max = 60)\n\n[1] 21\n\n\nIf we want to know the probability that someone arrives between 10:14 and 10:16 am:\n\npunif(q = 16, min = 0, max = 60) - punif(q = 14, min = 0, max = 60)\n\n[1] 0.03333333\n\n\nIf we want to sample 20 arrival times from the distribution:\n\nrunif(n = 20, min = 0, max = 60)\n\n [1] 21.8627405 57.2897017 31.6735503 26.6098003 45.8747441 56.3086312\n [7] 59.6817038 19.0348337 57.7767097 43.6806288  4.6916006 18.4769707\n[13] 29.2724909 38.4348042  2.0001106 45.7411314  0.4687437 19.3275406\n[19] 43.3832917 45.0107990"
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#bird-on-a-wire-tb-31.5",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#bird-on-a-wire-tb-31.5",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Bird on a wire (TB 31.5)",
    "text": "Bird on a wire (TB 31.5)\n\n\n\n\nExample 1\n\n\nA bird lands at a location that is Uniformly distributed along an electrical wire of length 150 feet. The wire is stretched tightly between two poles. What is the probability that the bird is 20 feet or less from one or the other of the poles?"
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#properties-of-exponential-rvs",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#properties-of-exponential-rvs",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Properties of exponential RVs",
    "text": "Properties of exponential RVs\n\nScenario: Modeling the time until the next (first) event\nContinuous analog to the geometric distribution!\nShorthand: \\(X \\sim \\text{Exp}(\\lambda)\\)\n\n\\[\nf_X(x) = \\lambda e^{-\\lambda x}\\text{ for } x&gt;0, \\lambda&gt;0\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;0 \\quad \\\\\n            1 - e^{-\\lambda x} & \\quad x\\geq0 \\\\\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{1}{\\lambda}\\] \\[\\text{Var}(X) = \\dfrac{1}{\\lambda^2}\\]"
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#memoryless-property",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#memoryless-property",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Memoryless Property",
    "text": "Memoryless Property\n   \nIf \\(b&gt;0\\),\n\\[P(X &gt; a +b | X&gt; a) = P(X &gt; b)\\]\n     \n\nThis can be interpreted as:\n\nIf you have waited \\(a\\) seconds (or any other measure of time) without a success\nThen the probability that you have to wait \\(b\\) more seconds is the same as as the probability of waiting \\(b\\) seconds initially."
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#identifying-exponential-rv-from-word-problems",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#identifying-exponential-rv-from-word-problems",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Identifying exponential RV from word problems",
    "text": "Identifying exponential RV from word problems\n\nLook for time between events/successes\nLook for a rate of the events over time period\nHow does it differ from the geometric distribution?\n\nGeometric is number of trials until first success\nExponential is time until first success\n\nRelation to the Poisson distribution?\n\nWhen the time between arrivals is exponential, the number of arrivals in a fixed time interval is Poisson with the mean \\(\\lambda\\)"
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-1",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-1",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re sitting at the bus stop, measuring the time until our bus arrives. We know the bus comes every 10 minutes on average.\n\nIf we want to know the probability that the bus arrives in the next 5 minutes:\n\npexp(q = 5, rate = 1/10)\n\n[1] 0.3934693\n\n\nIf we want to know the time, say \\(t\\), where the probability of the bus arriving at \\(t\\) or earlier is 0.35:\n\nqexp(p = 0.35, rate = 1/10)\n\n[1] 4.307829\n\n\nIf we want to know the probability that the bus arrives between 3 and 5 minutes:\n\npexp(q = 5, rate = 1/10) - pexp(q = 3, rate = 1/10)\n\n[1] 0.1342876\n\n\nIf we want to sample 20 bus arrival times from the distribution:\n\nrexp(n = 20, rate = 1/10)\n\n [1]  5.7140965  0.4696854  9.2960640 15.8516573 10.4100672 15.3441678\n [7] 16.4104659 26.6630887  2.3370310  5.8140909  1.0284010  3.3812394\n[13]  4.4863757  3.4561201 24.1388756 11.0591577 15.1184989 41.9239819\n[19]  5.8815765  7.2625976"
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#transformation-of-independent-exponential-rvs",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#transformation-of-independent-exponential-rvs",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Transformation of independent exponential RVs",
    "text": "Transformation of independent exponential RVs\n\n\nRevisit after joint notes:\n\n\nExample 1\n\n\nLet \\(X_i \\sim \\textrm{Exp}(\\lambda_i)\\) be independent RVs, for \\(i=1 \\ldots n\\). Find the pdf for the first of the arrival times."
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#properties-of-gamma-rvs",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#properties-of-gamma-rvs",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Properties of gamma RVs",
    "text": "Properties of gamma RVs\n\nScenario: Modeling the time until the \\(r^{th}\\) event.\nContinuous analog to the Negative Binomial distribution\nShorthand: \\(X \\sim \\text{Gamma}(r, \\lambda)\\)\n\n\\[\nf_X(x) = \\dfrac{\\lambda^r}{\\Gamma(r)}x^{r-1} e^{-\\lambda x}\\text{ for } x&gt;0, \\lambda&gt;0, \\Gamma(r) = (r-1)!\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;0 \\quad \\\\\n            1 - e^{-\\lambda x}\\displaystyle\\sum_{j=0}^{r-1}\\dfrac{(\\lambda x)^j}{j!}  & \\quad x\\geq0 \\\\\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{r}{\\lambda}\\text{, }\\text{ Var}(X) = \\dfrac{r}{\\lambda^2}\\]\nCommon to see \\(\\alpha = r\\) and \\(\\beta = \\lambda\\)"
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#identifying-gamma-rv-from-word-problems",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#identifying-gamma-rv-from-word-problems",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Identifying gamma RV from word problems",
    "text": "Identifying gamma RV from word problems\n\nGamma distribution with \\(r=1\\) is same as exponential\n\nJust like Negative Binomial with \\(r=1\\) is same as the geometric distribution\n\nSimilar to exponential\n\nLook for time between or until events/successes\n\nBUT now we are measuring time until more than 1 success\n\nLook for a rate of the events over time period"
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-2",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-2",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re sitting at the bus stop, measuring the time until 4 buses arrive. We know the bus comes every 10 minutes on average.\n\nIf we want to know the probability that the 4 buses arrive in the next 50 minutes:\n\n\n\n\npgamma(q = 50, rate = 1/10, shape = 4)\n\n[1] 0.7349741\n\n\n\n\npgamma(q = 50, scale = 10, shape = 4)\n\n[1] 0.7349741\n\n\n\n\n\nIf we want to know the time, say \\(t\\), where the probability of the 4 buses arriving at \\(t\\) or earlier is 0.35:\n\nqgamma(p = 0.35, rate = 1/10, shape = 4)\n\n[1] 29.87645\n\n\nIf we want to know the probability that the 4 buses arrives between 30 and 50 minutes:\n\npgamma(q = 50, scale = 10, shape = 4) - pgamma(q = 30, scale = 10, shape = 4)\n\n[1] 0.382206\n\n\nIf we want to sample 20 arrival times for the 4 buses:\n\nrgamma(n = 20, scale = 10, shape = 4)\n\n [1] 22.148259 31.270159  8.886592 32.781764 44.199073 53.001578 47.060746\n [8] 26.987028 66.458139 44.875758 36.873618 20.998544 34.363207 17.750104\n[15] 35.960139 46.075365 38.744752 27.478616 57.602600 40.093104"
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#remarks",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#remarks",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Remarks",
    "text": "Remarks\n\nThe parameter \\(r\\) in a Gamma(\\(r\\),\\(\\lambda\\)) distribution does NOT need to be a positive integer\n\n\\(r\\) is usually a positive integer\n\nWhen \\(r\\) is a positive integer, the distribution is sometimes called an Erlang(\\(r\\),\\(\\lambda\\)) distribution\n \n \nWhen \\(r\\) is any positive real number, we have a general gamma distribution that is usually instead parameterized by \\(\\alpha&gt;0\\) and \\(\\beta&gt;0\\), where:\n\n\\(\\alpha = \\text{shape parameter}\\) : same as \\(k\\), the total number of events we must witness\n\nIn R code example: 4 buses to wait for\n\n\\(\\beta = \\text{scale parameter}\\) : same as \\(\\lambda\\), the rate parameter\n\nIn R code example: 1 bus per 10 minutes (1/10)"
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#sending-money-orders",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#sending-money-orders",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Sending money orders",
    "text": "Sending money orders\n\n\n\n\nExample 1\n\n\nOn average, someone sends a money order once per 15 minutes. What is the probability someone sends 10 money orders in less than 3 hours?"
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#additional-resource",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#additional-resource",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Additional Resource",
    "text": "Additional Resource\n\nAnother helpful site with R code: https://rpubs.com/mpfoley73/459051"
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#properties-of-normal-rvs",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#properties-of-normal-rvs",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Properties of Normal RVs",
    "text": "Properties of Normal RVs\n\nNo scenario description here because the Normal distribution is so universal\n\nCentral Limit Theorem (next class) makes it applicable to many types of events\n\nShorthand: \\(X \\sim \\text{Normal}(\\mu, \\sigma^2)\\)\n\n\\[\nf_X(x) = \\dfrac{1}{\\sqrt{2\\pi \\sigma^2}}e^{-(x-\\mu)^2/(2\\sigma^2)} \\text{, for} -inf &lt; x &lt; inf\n\\]\n\\[\\text{E}(X) = \\mu \\] \\[\\text{Var}(X) = \\sigma^2\\]"
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-3",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#helpful-r-code-3",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re measuring the high temperature today. The average high temperature on this day across many, many years is 50 degrees with a standard deviation of 4 degrees.\n\nIf we want to know the probability that the high temperature is below 45 degrees:\n\npnorm(q = 45, mean = 50, sd = 4)\n\n[1] 0.1056498\n\n\nIf we want to know the temoerature, say \\(t\\), where the probability of that the temperature is at \\(t\\) or lower is 0.35:\n\nqnorm(p = 0.35, mean = 50, sd = 4)\n\n[1] 48.45872\n\n\nIf we want to know the probability that the temperature is between 45 and 50 degrees:\n\npnorm(q = 50, mean = 50, sd = 4) - pnorm(q = 45, mean = 50, sd = 4)\n\n[1] 0.3943502\n\n\nIf we want to sample 20 days’ temperature (over the years) from the distribution:\n\nrnorm(n = 20, mean = 50, sd = 4)\n\n [1] 52.20024 53.46404 48.22772 43.98347 55.44691 51.36376 53.71397 49.17262\n [9] 52.51266 50.24188 53.35812 56.10262 48.61211 41.34544 49.34543 52.59708\n[17] 50.79741 54.90462 38.88627 54.33463"
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#movie-night-while-studying",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#movie-night-while-studying",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Movie night while studying",
    "text": "Movie night while studying\n\n\n\n\nExample 1\n\n\nChildren’s movies run an average of 98 minutes with a standard deviation of 10 minutes. You check out a random movie from the library to entertain your kids so you can study for your test. Assume that your kids will be occupied for the entire length of the movie.\n\nWhat is the probability that your kids will be occupied for at least the 2 hours you would like to study?\nWhat is range for the bottom quartile (lowest 25%) of time they will be occupied?"
  },
  {
    "objectID": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#standard-normal-distribution",
    "href": "lessons/17_Cont_RVs/31_35_Cont_RVs.html#standard-normal-distribution",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "Standard Normal Distribution",
    "text": "Standard Normal Distribution\n\\[ Z \\sim \\text{Normal}(\\mu = 0, \\sigma^2 = 1)\\]\n\nUsed to be more helpful when computing was not as advanced\n\nUse tables of the standard normal\nYou can convert any normal distribution to a standard normal through transformation\n\n\\(Z = \\dfrac{X - \\mu_X}{\\sigma_X}\\)\n\nComes from \\(X = \\sigma_X Z + \\mu_X\\)\nSince \\(\\sigma_X\\) and \\(\\mu_X\\) are constants, then \\(E(X) = \\mu_X\\) and \\(SD(X) = \\sigma_X SD(Z) = \\sigma_X\\)"
  },
  {
    "objectID": "lessons/16_Discrete_RVs/14_20_Discrete_RVs_muddy_points.html",
    "href": "lessons/16_Discrete_RVs/14_20_Discrete_RVs_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "1. In-class example of the Poisson distribution\n\nlibrary(tidyverse)\n\nx &lt;- 0:250\n# n = c(6,14,30,60)\np = c(0.1, 0.5)\n\ngeom = expand.grid(x = x, p = p) %&gt;%\n  mutate(y = dgeom(x, prob = p))\n\nggplot(geom %&gt;% filter(y &gt; 1e-5), \n       aes(x, y, color=factor(p))) +\n  geom_point(size=1) +\n  geom_segment(aes(x=x, xend=x, y=0, yend=y, color=factor(p)), lwd=0.8, alpha=0.5) +\n  facet_grid(rows = vars(p), scales=\"free_x\", space=\"free_x\") +\n  theme(legend.position = \"none\",\n        axis.title = element_text(size = 14),    # Axis title size\n        axis.text = element_text(size = 12),     # Axis text size\n        strip.text = element_text(size = 13)) +  # Facet label size\n  labs(x = \"Number of trials\", y = \"Probability\")"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review_key_info.html",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 4 assignment due last night!\nHW 3 solutions also due\nTime to grade later today: HW 3 solutions or HW 4 assignment?\nTomorrow I will be sending out a Calendly invite for next week\n\nTo make an appointment with me to present your HW 3 solutions\nIt will be posted around 11:45am/12pm\nThere are limited spots just based on my availability"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review_key_info.html#announcements",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 4 assignment due last night!\nHW 3 solutions also due\nTime to grade later today: HW 3 solutions or HW 4 assignment?\nTomorrow I will be sending out a Calendly invite for next week\n\nTo make an appointment with me to present your HW 3 solutions\nIt will be posted around 11:45am/12pm\nThere are limited spots just based on my availability"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review_key_info.html#key-dates",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 5 due\nSunday: HW 4 solutions due\nWeek of 11/11\n\nMake a meeting with me\n11/12: recordings due if you are making that"
  },
  {
    "objectID": "lessons/06_Calculus_review/24_00_Calculus_review_muddy_points.html",
    "href": "lessons/06_Calculus_review/24_00_Calculus_review_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n1. Why we are allowed to “split” the operator d/dx into two pieces as if it were a fraction when it’s an operator\nHere is a pretty helpful StackExchange post talking about this!\n\n\n2. How to know what to use as \\(u\\) and \\(dv\\) for integration by parts\nI have two approaches to identifying \\(u\\) and \\(dv\\):\n\nTry to find a \\(u\\) that will eventually differentiate into a constant. This usually works unless you’re left with a \\(dv\\) that is hard to integrate.\n\nFor example, \\(u=x^6\\). the first derivative, \\(u'=6x^5\\), which may lead us to do another integration by parts, but eventually, at the 6th derivative, we get 720. This means, in our integration by parts, we eventually get an integral that only has \\(x\\) in the function once.\n\nIn this example, \\(x^6\\) would result in many integration by parts. I feel like we don’t typically see that many in our work.\n\nIn Example 3.5 in Calculus Review, setting \\(u=x^2\\) is a bad idea because we don’t really know how to integrate \\(dv=ln(x)\\) into \\(v\\).\n\nTry to find a \\(u\\) where \\(du\\) is the reciprocal of \\(v\\) or \\(du\\) cancels with \\(v\\).\n\nLook again at Example 3.5 in the notes! Hint: What is the derivative of \\(ln(x)\\)? And what does \\(\\dfrac{1}{x}x^3\\) equal?\n\n\n\n\n3. Looking for more practice in calculus?\nI just stumbled upon this website! Just a bunch of calculus practice problems! Might be some help."
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html",
    "href": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html",
    "title": "Chapter 22: Introduction to Counting",
    "section": "",
    "text": "Define permutations and combinations\nCharacterize difference between sampling with and without replacement\nCharacterize difference between sampling when order matters and when order does not matter\nCalculate the probability of sampling any combination of the following: with or without replacement and order does or does not matter"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html#learning-objectives",
    "href": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html#learning-objectives",
    "title": "Lesson 5: Equally Likely Outcomes",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDefine permutations and combinations\nCharacterize difference between sampling with and without replacement\nCharacterize difference between sampling when order matters and when order does not matter\nCalculate the probability of sampling any combination of the following: with or without replacement and order does or does not matter"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html#where-are-we",
    "href": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html#where-are-we",
    "title": "Lesson 5: Equally Likely Outcomes",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html#basic-counting-examples-13",
    "href": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html#basic-counting-examples-13",
    "title": "Lesson 5: Equally Likely Outcomes",
    "section": "Basic Counting Examples (1/3)",
    "text": "Basic Counting Examples (1/3)\n\n\nExample 1\n\n\nSuppose we have 10 (distinguishable) subjects for study.\n\nHow many possible ways are there to order them?\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?\n\nHow many ways to order them without replacement and only need 6?\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html#basic-counting-examples-23",
    "href": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html#basic-counting-examples-23",
    "title": "Lesson 5: Equally Likely Outcomes",
    "section": "Basic Counting Examples (2/3)",
    "text": "Basic Counting Examples (2/3)\nSuppose we have 10 (distinguishable) subjects for study.\n\n\n\n\nExample 1.1\n\n\nHow many possible ways are there to order them?\n\n\n \n\n\nExample 1.2\n\n\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html#basic-counting-examples-33",
    "href": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html#basic-counting-examples-33",
    "title": "Lesson 5: Equally Likely Outcomes",
    "section": "Basic Counting Examples (3/3)",
    "text": "Basic Counting Examples (3/3)\nSuppose we have 10 (distinguishable) subjects for study.\n\n\n\n\nExample 1.3\n\n\nHow many ways to order them without replacement and only need 6?\n\n\n \n\n\nExample 1.4\n\n\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html#permutations-and-combinations-1",
    "href": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html#permutations-and-combinations-1",
    "title": "Lesson 5: Equally Likely Outcomes",
    "section": "Permutations and Combinations",
    "text": "Permutations and Combinations\n\n\nDefinition: Permutations\n\n\nPermutations are the number of ways to arrange in order \\(r\\) distinct objects when there are \\(n\\) total.\n\\[nPr = \\frac{n!}{(n-r)!}\\]\n\n\n\n\nDefinition: Combinations\n\n\nCombinations are the number of ways to choose (order doesn’t matter) \\(r\\) objects from \\(n\\) without replacement.\n\\[nCr = \\textrm{\"n choose r\"} = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html#some-combinations-properties",
    "href": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html#some-combinations-properties",
    "title": "Lesson 5: Equally Likely Outcomes",
    "section": "Some combinations properties",
    "text": "Some combinations properties\n\n\n\n\n\n\n\nProperty\nProof\n\n\n\n\n\\[\\binom{n}{r} = \\binom{n}{n-r}\\]\n\\(\\binom{n}{r} = \\dfrac{n!}{r!(n-r)!}\\) and \\(\\binom{n}{n-r} = \\dfrac{n!}{(n-r)!(n-(n-r))!} = \\dfrac{n!}{(n-r)!r!}\\)\n\n\n\\[\\binom{n}{1} = n\\]\n\\[\\binom{n}{1} = \\dfrac{n!}{1!(n-1)!}=\\dfrac{n\\cdot(n-1)\\cdot(n-2)\\cdots1}{1! \\cdot (n-1)\\cdot(n-2)\\cdots1} = \\dfrac{n\\cdot(n-1)!}{1\\cdot (n-1)!} = \\dfrac{n}{1}=n\\]\n\n\n\\[\\binom{n}{0} = 1\\]\n\\[\\binom{n}{0} = \\dfrac{n!}{0!(n-0)!}=\\dfrac{n!}{1\\cdot n!} = 1\\]"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html#table-of-different-cases",
    "href": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html#table-of-different-cases",
    "title": "Lesson 5: Equally Likely Outcomes",
    "section": "Table of different cases",
    "text": "Table of different cases\nSee table on pg. 277 of textbook\n\n\\(n\\) = total number of objects\n\\(r\\) = number objects needed\n\n\n\n\n\n\n\n\n\nwith replacement\nwithout replacement\n\n\n\n\norder matters\n\\[n^r\\]\n\\[n\\text{P}r = \\frac{n!}{(n-r)!}\\]\n\n\norder doesn’t matter\n\\[ \\binom{n+r-1}{r}\\]\n\\[n\\text{C}r = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html#enumerating-events-and-sample-space",
    "href": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html#enumerating-events-and-sample-space",
    "title": "Lesson 5: Equally Likely Outcomes",
    "section": "Enumerating Events and Sample Space",
    "text": "Enumerating Events and Sample Space\n\nRecall, \\(P(A) = \\dfrac{|A|}{|S|}\\)\n\nWithin combinatorics, we can use the previous equations to help enumerate the event and sample space\nBut \\(A\\) might be a combination of enumerations\n\n\n \n\nFor example in the following example drawing 2 spades when order does not matter, we actually need to enumerate the other cards that are NOT spades. So the event is choosing 2 spades out of 13 AND choosing 0 other cards of 39 cards (13 hearts + 13 clubs + 13 diamonds).\nThus the probability is actually:\n\n\\[ P(\\text{two spades}) = \\dfrac{{13 \\choose 2}{39 \\choose 0}}{{52 \\choose 2}} \\]\n\nNote that \\(13 + 39 = 52\\) and \\(2+ 0 = 2\\). So the numerator’s \\(n\\)’s add up to the denominator’s \\(n\\) and the numerator’s \\(r\\)’s add up to the denominator’s \\(r\\)’s"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html#more-examples-order-matters-vs.-not-12",
    "href": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html#more-examples-order-matters-vs.-not-12",
    "title": "Lesson 5: Equally Likely Outcomes",
    "section": "More examples: order matters vs. not (1/2)",
    "text": "More examples: order matters vs. not (1/2)\n\n\n\n\nExample 2\n\n\nSuppose we draw 2 cards from a standard deck without replacement. What is the probability that both are spades when\n\norder matters?\norder doesn’t matter?"
  },
  {
    "objectID": "lessons/09_pdfs/24_01_Continuous_rv_key_info.html",
    "href": "lessons/09_pdfs/24_01_Continuous_rv_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Graded: HW 4 assignment and HW 3 solutions\nCalendly is up!!"
  },
  {
    "objectID": "lessons/09_pdfs/24_01_Continuous_rv_key_info.html#announcements",
    "href": "lessons/09_pdfs/24_01_Continuous_rv_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Graded: HW 4 assignment and HW 3 solutions\nCalendly is up!!"
  },
  {
    "objectID": "lessons/09_pdfs/24_01_Continuous_rv_key_info.html#key-dates",
    "href": "lessons/09_pdfs/24_01_Continuous_rv_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 5 due\nSunday: HW 4 solutions due\nWeek of 11/11\n\nMake a meeting with me\n11/12: recordings due if you are making that\nNow on Sakai"
  },
  {
    "objectID": "lessons/16_Variance/16_Variance.html#learning-objectives",
    "href": "lessons/16_Variance/16_Variance.html#learning-objectives",
    "title": "Lesson 16: Variance",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate the variance and standard deviation of discrete random variables\nCalculate the variance of sums of discrete random variables\nCalculate the variance of functions of discrete random variables"
  },
  {
    "objectID": "lessons/16_Variance/16_Variance.html#where-are-we",
    "href": "lessons/16_Variance/16_Variance.html#where-are-we",
    "title": "Lesson 16: Variance",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/16_Variance/16_Variance.html#lets-start-building-the-variance-through-expected-values-of-functions",
    "href": "lessons/16_Variance/16_Variance.html#lets-start-building-the-variance-through-expected-values-of-functions",
    "title": "Lesson 16: Variance",
    "section": "Let’s start building the variance through expected values of functions",
    "text": "Let’s start building the variance through expected values of functions\n\n\n\n\nExample 1\n\n\nLet \\(g\\) be a function and let \\(g(x) = ax+b\\), for real-valued constants \\(a\\) and \\(b\\). What is \\(\\mathbb{E}[g(X)]\\)?"
  },
  {
    "objectID": "lessons/16_Variance/16_Variance.html#what-is-the-expected-value-of-a-function",
    "href": "lessons/16_Variance/16_Variance.html#what-is-the-expected-value-of-a-function",
    "title": "Lesson 16: Variance",
    "section": "What is the expected value of a function?",
    "text": "What is the expected value of a function?\n\n\nDefinition: Expected value of function of RV\n\n\nFor any function \\(g\\) and discrete r.v. \\(X\\), the expected value of \\(g(X)\\) is \\[\\mathbb{E}[g(X)] = \\sum_{\\{all\\ x\\}}\\ g(x) p_X(x).\\]"
  },
  {
    "objectID": "lessons/16_Variance/16_Variance.html#lets-revisit-the-card-example-12",
    "href": "lessons/16_Variance/16_Variance.html#lets-revisit-the-card-example-12",
    "title": "Lesson 16: Variance",
    "section": "Let’s revisit the card example (1/2)",
    "text": "Let’s revisit the card example (1/2)\n\n\n\n\nExample 2\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw.\n\nFind \\(\\mathbb{E}[X^2]\\).\n\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "lessons/16_Variance/16_Variance.html#lets-revisit-the-card-example-22",
    "href": "lessons/16_Variance/16_Variance.html#lets-revisit-the-card-example-22",
    "title": "Lesson 16: Variance",
    "section": "Let’s revisit the card example (2/2)",
    "text": "Let’s revisit the card example (2/2)\n\n\n\n\nExample 2\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw.\n\nFind \\(\\mathbb{E}\\big[\\big(X-\\frac{1}{2}\\big)^2\\big]\\).\n\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "lessons/16_Variance/16_Variance.html#variance-of-a-rv",
    "href": "lessons/16_Variance/16_Variance.html#variance-of-a-rv",
    "title": "Lesson 16: Variance",
    "section": "Variance of a RV",
    "text": "Variance of a RV\n\n\nDefinition: Variance of RV\n\n\nThe variance of a r.v. \\(X\\), with (finite) expected value \\(\\mu_X=\\mathbb{E}[X]\\) is \\[\\sigma_X^2=Var(X)=\\mathbb{E}[(X-\\mu_X)^2] = \\mathbb{E}[(X-\\mathbb{E}[X])^2]\\]\n\n\n\n\nDefinition: Standard deviation of RV\n\n\nThe standard deviation of a r.v. \\(X\\) is \\[\\sigma_X = SD(X) = \\sqrt{\\sigma_X^2}=\\sqrt{Var(X)}.\\]"
  },
  {
    "objectID": "lessons/16_Variance/16_Variance.html#lets-calculate-the-variance-and-prove-it",
    "href": "lessons/16_Variance/16_Variance.html#lets-calculate-the-variance-and-prove-it",
    "title": "Lesson 16: Variance",
    "section": "Let’s calculate the variance and prove it!",
    "text": "Let’s calculate the variance and prove it!\n\n\n\n\nLemma 6: “Computation formula” for Variance\n\n\nThe variance of a r.v. \\(X\\), can be computed as \\[\\begin{align}\n\\sigma_X^2 & =Var(X) \\\\ & = \\mathbb{E}[X^2]-\\mu_X^2 \\\\ & = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2\n\\end{align}\\]"
  },
  {
    "objectID": "lessons/16_Variance/16_Variance.html#variance-of-a-function-with-a-single-rv",
    "href": "lessons/16_Variance/16_Variance.html#variance-of-a-function-with-a-single-rv",
    "title": "Lesson 16: Variance",
    "section": "Variance of a function with a single RV",
    "text": "Variance of a function with a single RV\n\n\nLemma 7\n\n\nFor a r.v. \\(X\\) and constants \\(a\\) and \\(b\\), \\[Var(aX+b) = a^2Var(X).\\]\n\n\nProof will be exercise in homework. It’s fun! In a mathy kinda way."
  },
  {
    "objectID": "lessons/16_Variance/16_Variance.html#important-results-for-independent-rvs",
    "href": "lessons/16_Variance/16_Variance.html#important-results-for-independent-rvs",
    "title": "Lesson 16: Variance",
    "section": "Important results for independent RVs",
    "text": "Important results for independent RVs\n\n\nTheorem 8\n\n\nFor independent r.v.’s \\(X\\) and \\(Y\\), and functions \\(g\\) and \\(h\\), \\[\\mathbb{E}[g(X)h(Y)] = \\mathbb{E}[g(X)]\\mathbb{E}[h(Y)].\\]\n\n\n\n\nCorollary 1\n\n\nFor independent r.v.’s \\(X\\) and \\(Y\\), \\[\\mathbb{E}[XY] = \\mathbb{E}[X]\\mathbb{E}[Y].\\]"
  },
  {
    "objectID": "lessons/16_Variance/16_Variance.html#variance-of-sum-of-independent-discrete-rvs",
    "href": "lessons/16_Variance/16_Variance.html#variance-of-sum-of-independent-discrete-rvs",
    "title": "Lesson 16: Variance",
    "section": "Variance of sum of independent discrete RVs",
    "text": "Variance of sum of independent discrete RVs\n\n\nTheorem 9: Variance of sum of independent discrete r.v.’s\n\n\nFor independent discrete r.v.’s \\(X_i\\) and constants \\(a_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n a_iX_i\\Bigg) = \\sum_{i=1}^n a_i^2Var(X_i).\\]\n\n\nSimpler version:\n\\[Var(a_1 X + a_2 Y) = Var(a_1X) + Var(a_2 Y) = a_1^2 Var(X) + a_2^2 Var(Y)\\]"
  },
  {
    "objectID": "lessons/16_Variance/16_Variance.html#corollaries",
    "href": "lessons/16_Variance/16_Variance.html#corollaries",
    "title": "Lesson 16: Variance",
    "section": "Corollaries",
    "text": "Corollaries\n\n\nCorollary 2\n\n\nFor independent discrete r.v.’s \\(X_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n X_i\\Bigg) = \\sum_{i=1}^n Var(X_i).\\]\n\n\n\n\nCorollary 3\n\n\nFor independent identically distributed (i.i.d.) discrete r.v.’s \\(X_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n X_i\\Bigg) = n Var(X_1).\\]"
  },
  {
    "objectID": "lessons/16_Variance/16_Variance.html#lets-look-at-a-ghost-problem-with-replacement",
    "href": "lessons/16_Variance/16_Variance.html#lets-look-at-a-ghost-problem-with-replacement",
    "title": "Lesson 16: Variance",
    "section": "Let’s look at a ghost problem with replacement",
    "text": "Let’s look at a ghost problem with replacement\n\n\n\n\nExample 3.2\n\n\nThe ghost is trick-or-treating at a different house now. In this case it is known that the bag of candy has 10 chocolates, 20 lollipops, and 30 laffy taffies. The ghost grabs a handful of five pieces of candy. What is the variance for the number of chocolates the ghost takes? Let’s solve this for the cases with replacement.\n\n\n\n\nRecall probability with replacement:\n\\[\np_X(x) = {n \\choose k}p^k(1-p)^{n-k}\n\\]"
  },
  {
    "objectID": "lessons/16_Variance/16_Variance.html#back-to-our-hotel-example-from-chapter-11",
    "href": "lessons/16_Variance/16_Variance.html#back-to-our-hotel-example-from-chapter-11",
    "title": "Lesson 16: Variance",
    "section": "Back to our hotel example from Chapter 11",
    "text": "Back to our hotel example from Chapter 11\n\n\n\n\nExample 4\n\n\nA tour group is planning a visit to the city of Minneapolis and needs to book 30 hotel rooms. The average price of a room is $200 with standard deviation $10. In addition, there is a 10% tourism tax for each room. What is the standard deviation of the cost for the 30 hotel rooms? Assume rooms are independent.\n\n\nProblem to do at home if we don’t have enough time."
  },
  {
    "objectID": "lessons/16_Variance/16_Variance.html#learning-objectives-1",
    "href": "lessons/16_Variance/16_Variance.html#learning-objectives-1",
    "title": "Lesson 16: Variance",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate expected value of functions of RVs\nCalculate variance of RVs"
  },
  {
    "objectID": "lessons/16_Variance/16_Variance.html#expected-value-of-a-function-of-a-continuous-rv",
    "href": "lessons/16_Variance/16_Variance.html#expected-value-of-a-function-of-a-continuous-rv",
    "title": "Lesson 16: Variance",
    "section": "Expected value of a function of a continuous RV",
    "text": "Expected value of a function of a continuous RV\n\n\nHow do we calculate the expected value of a function of a discrete RV or joint RVs?\n   \nFor discrete RVs:\n\\[\\mathbb{E}[g(X)] = \\sum_{\\{all\\ x\\}}\\ g(x) p_X(x).\\] \\[\\mathbb{E}[g(X, Y)] = \\sum_{\\{all\\ x\\}}\\sum_{\\{all\\ y\\}}\\ g(x,y) p_{X,Y}(x,y).\\]\n\n\n\nHow do we calculate the expected value of a function of a continuous RV or joint RVs?\n   \nFor continuous RVs:"
  },
  {
    "objectID": "lessons/16_Variance/16_Variance.html#important-properties-of-expected-values-of-functions-of-continuous-rvs",
    "href": "lessons/16_Variance/16_Variance.html#important-properties-of-expected-values-of-functions-of-continuous-rvs",
    "title": "Lesson 16: Variance",
    "section": "Important properties of expected values of functions of continuous RVs",
    "text": "Important properties of expected values of functions of continuous RVs\n\n\n\n\nFunction of RV with two constants\n\n\n\\(\\mathbb{E}[aX+b] =a\\mathbb{E}[X]+b\\)\n\n\n\n\nFunction of two RVs added\n\n\n\\(\\mathbb{E}[X+Y] =\\mathbb{E}[X]+\\mathbb{E}[Y]\\)\n\n\n\n\nExpected value of sum of independent RVs pt 1\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are continuous RVs and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\[\\mathbb{E}\\Bigg[\\sum_{i=1}^{n} a_i X_i\\Bigg] = \\sum_{i=1}^{n}a_i\\mathbb{E}[X_i]\\]\n\n\n\n\n\nExpected value of multiplication of function of independent RVs\n\n\nIf \\(X\\) and \\(Y\\) are independent continuous RVs, and \\(g\\) and \\(h\\) are functions, then \\[\\mathbb{E}[g(X)h(Y)] =\\mathbb{E}[g(X)]\\mathbb{E}[h(Y)]\\]\n\n\n\n\nExpected value of multiplication of independent RVs\n\n\nIf \\(X\\) and \\(Y\\) are independent continuous RVs, then \\[\\mathbb{E}[XY] = \\mathbb{E}[X] \\mathbb{E}[Y] \\]"
  },
  {
    "objectID": "lessons/16_Variance/16_Variance.html#variance-of-continuous-rvs",
    "href": "lessons/16_Variance/16_Variance.html#variance-of-continuous-rvs",
    "title": "Lesson 16: Variance",
    "section": "Variance of continuous RVs",
    "text": "Variance of continuous RVs\n\n\nHow do we calculate the variance of a discrete RV?\n   \nFor discrete RVs:\n\\[\n\\begin{align}\nVar(X) & =\n\\mathbb{E}[(X-\\mu_X)^2] \\\\ & = \\mathbb{E}[(X-\\mathbb{E}[X])^2] \\\\ &= \\mathbb{E}[X^2]-(\\mathbb{E}[X])^2 \\\\ & = \\sum_{\\{all\\ x\\}}(x-\\mu_x)^2 p_{X}(x)\n\\end{align}\n\\]\n\n\n\nHow do we calculate the variance of a continuous RV?\n    \nFor continuous RVs:"
  },
  {
    "objectID": "lessons/16_Variance/16_Variance.html#variance-of-an-uniform-distribution",
    "href": "lessons/16_Variance/16_Variance.html#variance-of-an-uniform-distribution",
    "title": "Lesson 16: Variance",
    "section": "Variance of an Uniform distribution",
    "text": "Variance of an Uniform distribution\n\n\n\n\nExample 2\n\n\nLet \\(f_X(x)= \\frac{1}{b-a}\\), for \\(a \\leq x \\leq b\\). Find \\(Var[X]\\)."
  },
  {
    "objectID": "lessons/16_Variance/16_Variance.html#variance-of-exponential-distribution",
    "href": "lessons/16_Variance/16_Variance.html#variance-of-exponential-distribution",
    "title": "Lesson 16: Variance",
    "section": "Variance of exponential distribution",
    "text": "Variance of exponential distribution\n\n\nIn the homework:\n\n\nExample 3\n\n\nLet \\(f_X(x)= \\lambda e^{-\\lambda x}\\), for \\(x &gt; 0\\) and \\(\\lambda&gt; 0\\). Find \\(Var[X]\\)."
  },
  {
    "objectID": "lessons/16_Variance/16_Variance.html#important-properties-of-variances-of-continuous-rvs",
    "href": "lessons/16_Variance/16_Variance.html#important-properties-of-variances-of-continuous-rvs",
    "title": "Lesson 16: Variance",
    "section": "Important properties of variances of continuous RVs",
    "text": "Important properties of variances of continuous RVs\n\n\n\n\nFunction of RV with two constants\n\n\n\\[Var[aX+b] = a^2Var[X]\\]\n\n\n\n\n\nVariance of sum of independent RVs pt 1\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous RVs and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\[Var\\Bigg(\\sum_{i=1}^{n} a_i X_i\\Bigg) =\\sum_{i=1}^{n} a^2_i Var(X_i)\\]\n\n\n\n\nVariance of sum of independent RVs pt 2\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous RVs, then \\[Var\\Bigg(\\sum_{i=1}^{n} X_i\\Bigg) = \\sum_{i=1}^{n} Var(X_i)\\]"
  },
  {
    "objectID": "lessons/16_Variance/16_Variance.html#find-the-mean-and-sd-from-word-problem",
    "href": "lessons/16_Variance/16_Variance.html#find-the-mean-and-sd-from-word-problem",
    "title": "Lesson 16: Variance",
    "section": "Find the mean and sd from word problem",
    "text": "Find the mean and sd from word problem\n\n\n\n\nExample 4\n\n\nA machine manufactures cubes with a side length that varies uniformly from 1 to 2 inches. Assume the sides of the base and height are equal. The cost to make a cube is 10 ¢ per cubic inch, and 5 ¢ cents for the general cost per cube. Find the mean and standard deviation of the cost to make 10 cubes."
  },
  {
    "objectID": "lessons/14_Expected_Values/14_Expected_Values.html#learning-objectives",
    "href": "lessons/14_Expected_Values/14_Expected_Values.html#learning-objectives",
    "title": "Lesson 14: Expected Values",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate the mean (expected value) of discrete random variables"
  },
  {
    "objectID": "lessons/14_Expected_Values/14_Expected_Values.html#where-are-we",
    "href": "lessons/14_Expected_Values/14_Expected_Values.html#where-are-we",
    "title": "Lesson 14: Expected Values",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/14_Expected_Values/14_Expected_Values.html#our-good-and-fair-friend-the-6-sided-die",
    "href": "lessons/14_Expected_Values/14_Expected_Values.html#our-good-and-fair-friend-the-6-sided-die",
    "title": "Lesson 14: Expected Values",
    "section": "Our good and fair friend, the 6-sided die",
    "text": "Our good and fair friend, the 6-sided die\n\n\n\n\nExample 1\n\n\nSuppose you roll a fair 6-sided die. What value do you expect to get?"
  },
  {
    "objectID": "lessons/14_Expected_Values/14_Expected_Values.html#what-is-an-expected-value",
    "href": "lessons/14_Expected_Values/14_Expected_Values.html#what-is-an-expected-value",
    "title": "Lesson 14: Expected Values",
    "section": "What is an expected value?",
    "text": "What is an expected value?\n\n\nDefinition: Expected value\n\n\nThe expected value of a discrete r.v. \\(X\\) that takes on values \\(x_1, x_2, \\ldots, x_n\\) is \\[\\mathbb{E}[X] = \\sum_{i=1}^n x_ip_X(x_i).\\]\n\n\n\nExpected values are not necessarily an actual outcome\n\nIn previous example, we cannot roll a 3.5\nIt could be that our expected value is not in the sample space (\\(E(X) \\notin S\\))\n\nDefinition holds when \\(X\\) takes on countably infinitely many values:\n\n\\[\\mathbb{E}[X] = \\sum_{i=1}^\\infty x_ip_X(x_i)\\]"
  },
  {
    "objectID": "lessons/14_Expected_Values/14_Expected_Values.html#our-good-and-not-so-fair-friend-the-6-sided-die",
    "href": "lessons/14_Expected_Values/14_Expected_Values.html#our-good-and-not-so-fair-friend-the-6-sided-die",
    "title": "Lesson 14: Expected Values",
    "section": "Our good and not-so-fair friend, the 6-sided die",
    "text": "Our good and not-so-fair friend, the 6-sided die\n\n\n\n\nExample 2\n\n\nSuppose the die is 6-sided, but not fair. And the probabilities of each side is distributed as:\n\n\n\n\\(x\\)\n\\(p_X(x)\\)\n\n\n\n\n1\n0.10\n\n\n2\n0.05\n\n\n3\n0.02\n\n\n4\n0.30\n\n\n5\n0.50\n\n\n6\n0.03\n\n\n\nWhat value do you expect to get on a roll?"
  },
  {
    "objectID": "lessons/14_Expected_Values/14_Expected_Values.html#expected-value-of-a-bernoulli-distribution",
    "href": "lessons/14_Expected_Values/14_Expected_Values.html#expected-value-of-a-bernoulli-distribution",
    "title": "Lesson 14: Expected Values",
    "section": "Expected value of a Bernoulli distribution",
    "text": "Expected value of a Bernoulli distribution\n\n\n\n\nExample 3\n\n\nSuppose \\[X = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\quad\\mathrm{(success)}\\\\\n            0 & \\quad \\mathrm{with\\ probability}\\ 1-p \\quad\\mathrm{(failure)}\n        \\end{array}\n    \\right.\\] Find the expected value of \\(X\\)."
  },
  {
    "objectID": "lessons/14_Expected_Values/14_Expected_Values.html#lets-slightly-change-our-random-variable",
    "href": "lessons/14_Expected_Values/14_Expected_Values.html#lets-slightly-change-our-random-variable",
    "title": "Lesson 14: Expected Values",
    "section": "Let’s slightly change our random variable",
    "text": "Let’s slightly change our random variable\n\n\n\n\nExample 5\n\n\nSuppose \\[X = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\\\\n            -1 & \\quad \\mathrm{with\\ probability}\\ 1-p\n        \\end{array}\n    \\right.\\] Find the expected value of \\(X\\)."
  },
  {
    "objectID": "lessons/14_Expected_Values/14_Expected_Values.html#ghost",
    "href": "lessons/14_Expected_Values/14_Expected_Values.html#ghost",
    "title": "Lesson 14: Expected Values",
    "section": "Ghost! 👻",
    "text": "Ghost! 👻\n\n\n\n\nExample 6\n\n\nA ghost is trick-or-treating. It comes to a house where it is known that there are 30 candies in the bag and only one is a watermelon Jolly Rancher, which is the ghost’s favorite. The ghost takes pieces of candy without replacement until it gets the watermelon Jolly Rancher. How many pieces of candy do we expect the ghost to take?\n\n\nCan we model this with a distribution?"
  },
  {
    "objectID": "lessons/14_Expected_Values/14_Expected_Values.html#expected-value-of-a-function-of-a-continuous-rv",
    "href": "lessons/14_Expected_Values/14_Expected_Values.html#expected-value-of-a-function-of-a-continuous-rv",
    "title": "Lesson 14: Expected Values",
    "section": "Expected value of a function of a continuous RV",
    "text": "Expected value of a function of a continuous RV\n\n\nHow do we calculate expected values of discrete RVs?\n       \nFor discrete RVs: weight average \\[\\mathbb{E}[X] = \\sum_{i=1}^n x_ip_X(x_i).\\]\n\n\n\nHow do we calculate expected values of continuous RVs?\n       \nFor continuous RVs:"
  },
  {
    "objectID": "lessons/14_Expected_Values/14_Expected_Values.html#expected-value-of-the-uniform-distribution",
    "href": "lessons/14_Expected_Values/14_Expected_Values.html#expected-value-of-the-uniform-distribution",
    "title": "Lesson 14: Expected Values",
    "section": "Expected Value of the Uniform Distribution",
    "text": "Expected Value of the Uniform Distribution\n\n\n\n\nExample 1\n\n\nLet \\(f_X(x)= \\frac{1}{b-a}\\), for \\(a \\leq x \\leq b\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons/14_Expected_Values/14_Expected_Values.html#expected-value-of-the-exponential-distribution",
    "href": "lessons/14_Expected_Values/14_Expected_Values.html#expected-value-of-the-exponential-distribution",
    "title": "Lesson 14: Expected Values",
    "section": "Expected Value of the Exponential Distribution",
    "text": "Expected Value of the Exponential Distribution\n\n\n\n\nExample 2\n\n\nLet \\(f_X(x)= \\lambda e^{-\\lambda x}\\), for \\(x &gt; 0\\) and \\(\\lambda&gt; 0\\). Find \\(\\mathbb{E}[X]\\).\n\n\n\n\nIntegrating by Parts\n\n\n\\(\\displaystyle\\int_a^b u dv = uv\\bigg|^b_a - \\displaystyle\\int_a^b vdu\\)"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#how-do-we-represent-independent-continuous-rvs-in-a-joint-pdf",
    "href": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#how-do-we-represent-independent-continuous-rvs-in-a-joint-pdf",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "How do we represent independent continuous RVs in a joint pdf?",
    "text": "How do we represent independent continuous RVs in a joint pdf?\n\n\nWhat do we know about independence for events and discrete RVs?\nFor events: If \\(A \\perp B\\)\n\\[P(A \\cap B) = P(A)P(B)\\] \\[P(A|B) = P(A)\\]\nFor discrete RVs: If \\(X \\perp Y\\) \\[p_{X,Y}(x,y) = p_{X}(x)p_{Y}(y)\\] \\[F_{X,Y}(x,y) = F_{X}(x)F_{Y}(y)\\] \\[p_{X|Y}(x|y) = p_{X}(x)\\] \\[p_{Y|X}(y|x) = p_{Y}(y)\\]\n\n\n\nWhat does it mean for continuous r.v.’s to be independent?\nFor continuous RVs: If \\(X \\perp Y\\)"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs",
    "href": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "Constructing a joint pdf from two independent, continuous RVs",
    "text": "Constructing a joint pdf from two independent, continuous RVs\n\n\n\n\nExample 1.1\n\n\nLet \\(X\\) and \\(Y\\) be independent r.v.’s with \\(f_X(x)= \\frac12\\), for \\(0 \\leq x \\leq 2\\) and \\(f_Y(y)= 3y^2\\), for \\(0 \\leq y \\leq 1\\).\n\nFind \\(f_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs-1",
    "href": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs-1",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "Constructing a joint pdf from two independent, continuous RVs",
    "text": "Constructing a joint pdf from two independent, continuous RVs\n\n\n\n\nExample 1.2\n\n\nLet \\(X\\) and \\(Y\\) be independent r.v.’s with \\(f_X(x)= \\frac12\\), for \\(0 \\leq x \\leq 2\\) and \\(f_Y(y)= 3y^2\\), for \\(0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)."
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#showing-independence-from-joint-pdf",
    "href": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#showing-independence-from-joint-pdf",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "Showing independence from joint pdf",
    "text": "Showing independence from joint pdf\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for \\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\).\n\nAre \\(X\\) and \\(Y\\) independent?"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#finding-cdf-from-two-independent-rvs",
    "href": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#finding-cdf-from-two-independent-rvs",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "Finding CDF from two independent RVs",
    "text": "Finding CDF from two independent RVs\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for \\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(F_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#showing-independence-from-joint-pdf-1",
    "href": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#showing-independence-from-joint-pdf-1",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "Showing independence from joint pdf",
    "text": "Showing independence from joint pdf\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 3\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Are \\(X\\) and \\(Y\\) independent?"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#final-statement-on-independence",
    "href": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#final-statement-on-independence",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "Final statement on independence",
    "text": "Final statement on independence\n\nIf \\(f_{X,Y}(x,y)= g(x)h(y)\\), where \\(g(x)\\) and \\(h(y)\\) are pdf’s, then \\(X\\) and \\(Y\\) are independent.\n\nThe domain of the joint pdf needs to be independent as well!!\n\n\n       \n\nIf \\(F_{X,Y}(x,y)= G(x)H(y)\\), where \\(G(x)\\) and \\(H(y)\\) are cdf’s, then \\(X\\) and \\(Y\\) are independent.\n\nThe domain of the joint CDF needs to be independent as well!!"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#conditional-probabilities-weve-seen-before",
    "href": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#conditional-probabilities-weve-seen-before",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "Conditional probabilities we’ve seen before",
    "text": "Conditional probabilities we’ve seen before\n\n\nWhat do we know about conditional probabilities for events and discrete RVs?    \nFor events:\n\\[P(A | B) = \\dfrac{P(A \\cap B)}{P(B)}\\]    \nFor discrete RVs: \\[p_{X|Y}(x|y) = P(X=x|Y=y) = \\dfrac{p_{X,Y}(x,y)}{p_Y(y)}\\]\n\n\n\nWhat does it mean for conditional densities of continuous RVs?\nFor continuous RVs:"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#example-starting-from-a-joint-pdf-first-try",
    "href": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#example-starting-from-a-joint-pdf-first-try",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "Example starting from a joint pdf: first try!",
    "text": "Example starting from a joint pdf: first try!\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(2&lt;X&lt;10|Y=4)\\)"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#what-is-a-conditional-density",
    "href": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#what-is-a-conditional-density",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "What is a conditional density?",
    "text": "What is a conditional density?\n\n\n\n\nDefinition: Conditional density\n\n\nThe conditional density of a r.v. \\(X\\) given \\(Y=y\\), is \\[f_{X|Y}(x|y)= \\frac{f_{X,Y}(x,y)}{f_Y(y)},\\] for \\(f_Y(y)&gt; 0\\)\n\n\n\n\n\nRemarks\n\nIt follows from the definition for the conditional density \\(f_{X|Y}(x|y)\\), that \\[f_{X,Y}(x,y)= f_{X|Y}(x|y)f_Y(y).\\]\n\n     \n\nFor a fixed value of \\(Y=y\\), the conditional density \\(f_{X|Y}(x|y)\\) is an actual pdf, meaning\n\n\\(f_{X|Y}(x|y)\\geq 0\\) for all \\(x\\) and \\(y\\), and\n\\(\\displaystyle\\int_{-\\infty}^{\\infty} f_{X|Y}(x|y)dx =1\\)."
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#example-starting-from-a-joint-pdf-second-try-12",
    "href": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#example-starting-from-a-joint-pdf-second-try-12",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "Example starting from a joint pdf: second try! (1/2)",
    "text": "Example starting from a joint pdf: second try! (1/2)\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(2&lt;X&lt;10|Y=4)\\)"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#example-starting-from-a-joint-pdf-second-try-22",
    "href": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#example-starting-from-a-joint-pdf-second-try-22",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "Example starting from a joint pdf: second try! (2/2)",
    "text": "Example starting from a joint pdf: second try! (2/2)"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#example-starting-from-a-joint-pdf",
    "href": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#example-starting-from-a-joint-pdf",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "Example starting from a joint pdf",
    "text": "Example starting from a joint pdf\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(X&gt;20 |Y=5)\\)"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#finding-probability-with-conditional-domain-and-pdf",
    "href": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#finding-probability-with-conditional-domain-and-pdf",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "Finding probability with conditional domain and pdf",
    "text": "Finding probability with conditional domain and pdf\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 2\n\n\nRandomly choose a point \\(X\\) from the interval \\([0,1]\\), and given \\(X=x\\), randomly choose a point \\(Y\\) from \\([0,x]\\). Find \\(\\mathbb{P}(0 &lt; Y &lt; \\frac14)\\)."
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#independence-and-conditional-distributions",
    "href": "lessons/13_Independence_Conditioning/12_Independence_conditioning.html#independence-and-conditional-distributions",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "Independence and conditional distributions",
    "text": "Independence and conditional distributions\n    Question What is \\(f_{X|Y}(x|y)\\) if \\(X\\) and \\(Y\\) are independent?\n\\[f_{X|Y}(x|y) = \\dfrac{f_{X,Y}(x,y)}{f_y(y)} = \\dfrac{f_{X}(x)f_y(y)}{f_y(y)} = f_{X}(x)\\]\n       \n\nIf \\(f_{X|Y}(x|y)\\) does not depend on \\(y\\) (including the bounds/domain), then \\(X\\) and \\(Y\\) are independent."
  },
  {
    "objectID": "lessons/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance_muddy_points.html",
    "href": "lessons/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n2. How do we set the bounds on a double integral?\nWhen the domain of the RVs are not dependent on each other, then we use the bounds as is. In example 2 of Chapter 26 notes, we have the joint pdf \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for\\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\). If we wanted to calculate something like \\(E(X)\\), then we could use the bounds as they are. Below is the domain for \\(x\\) and \\(y\\):\n\n\n\n\n\nHere is the integral for the expected value where we integrate over the whole domain of \\(x\\) and \\(y\\):\n\\[ E(X) = \\displaystyle\\int_0^1 \\displaystyle\\int_0^1 x (18 x^2 y^5 )dy dx \\]If we want to find the probability \\(P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75)\\), then we can look at the specific values of the probability:\n\n\n\n\n\nNote the blue lines above indicate how we integrate over \\(y\\) first from 0.5 to 0.75 and the green lines indicate how integrate over \\(x\\) first from 0.25 to 0.5. It seems like we’ve integrated over an area that isn’t within our specified probability. However, the integrated area is ONLY the overlap of the \\(x\\) and \\(y\\) bounds for the probability.\n\\[P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.25}^{0.5} \\displaystyle\\int_{0.5}^{0.75} 18 x^2 y^5 dy dx\\]\nLet’s use the same pdf, but now the domain of the two RVs is dependent on one another. We have the joint pdf \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for\\(0 \\leq x \\leq y\\leq1\\)\nIf we wanted to calculate something like \\(E(X)\\), then we need to account for fact that \\(x\\) must be less than of equal to \\(y\\). We can look back at the domain for this:\n\n\n\n\n\nNote the blue lines above still indicate how we integrate over \\(y\\) first from \\(x\\) to 1, and the green lines indicate how integrate over \\(x\\) first from 0 to 1. Once again, it seems like we’ve integrated over an area that isn’t within the domain. However, the integrated area is ONLY the overlap of the \\(x\\) and \\(y\\) bounds. Thus, once we’ve restricted \\(y\\) to the area between \\(x\\) and 1, we no longer need to restrict \\(x\\) to the are of 0 to \\(y\\).\n\\[ E(X) = \\displaystyle\\int_0^1 \\displaystyle\\int_x^1 x (18 x^2 y^5 )dy dx \\] If we want to find the probability \\(P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75)\\), then we should look back at our domain. For now, we are focusing on the orange area:\n\n\n\n\n\nBecause the orange area is totally within our domain, we can leave our integral our bounds as the exact values we specified:\n\\[P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.25}^{0.5} \\displaystyle\\int_{0.5}^{0.75} 18 x^2 y^5 dy dx\\]\nHowever, if we want the probability \\(P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75)\\), we would focus on the pink area above. We would limit one of our integrals to the \\(y=x\\) equation:\n\\[P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.5}^{0.75} \\displaystyle\\int_{x}^{0.75} 18 x^2 y^5 dy dx\\]\nOR\n\\[P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.5}^{0.75} \\displaystyle\\int_{0.5}^{y} 18 x^2 y^5 dx dy\\]\nThe key to these probabilities is that the bounds with the other variable is on the inside integral! Otherwise we end up with a answer that includes a RV."
  },
  {
    "objectID": "lessons/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html",
    "href": "lessons/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "",
    "text": "Calculate the mean (expected value) of sums of discrete random variables"
  },
  {
    "objectID": "lessons/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#learning-objectives",
    "href": "lessons/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#learning-objectives",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "",
    "text": "Calculate the mean (expected value) of sums of discrete random variables"
  },
  {
    "objectID": "lessons/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#where-are-we",
    "href": "lessons/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#where-are-we",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#revisiting-our-two-card-draw",
    "href": "lessons/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#revisiting-our-two-card-draw",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Revisiting our two card draw",
    "text": "Revisiting our two card draw\n\n\n\n\nExample 1\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw. Find \\(\\mathbb{E}[X]\\).\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "lessons/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#what-if-we-draw-a-lot-of-cards",
    "href": "lessons/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#what-if-we-draw-a-lot-of-cards",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "What if we draw A LOT of cards?",
    "text": "What if we draw A LOT of cards?\n\n\n\n\nExample 2\n\n\nWhat is the expected number of hearts in Example 1 if you draw 200 cards?\n\n\n\n\nRecall Binomial RV with \\(n=200\\):\n\\[p_X(x) = {200 \\choose x}p^x(1-p)^{200-x}\\] \\[\\text{  for } x = 0, 1, 2, ..., 200\\]"
  },
  {
    "objectID": "lessons/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#sum-of-discrete-rvs",
    "href": "lessons/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#sum-of-discrete-rvs",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Sum of discrete RVs",
    "text": "Sum of discrete RVs\n\n\nTheorem 11.1: Sum of discrete RVs\n\n\nFor discrete r.v.’s \\(X_i\\) and constants \\(a_i\\), \\(i=1,2,\\dots, n\\), \\[\\mathbb{E}\\Bigg[\\sum_{i=1}^n a_iX_i\\Bigg] = \\sum_{i=1}^n a_i\\mathbb{E}[X_i] .\\] Remark: The theorem holds for infinitely r.v.’s \\(X_i\\) as well.\n\n\n\nFor two RVs, \\(X\\) and \\(Y\\):\n\nWe can say \\(E[X+Y] = E[X] + E[Y]\\)\n… and constant numbers \\(a\\) and \\(b\\), we can also say \\(E[aX+bY] = aE[X] + bE[Y]\\)\nWe can also also say \\(E[X-Y] = E[X] - E[Y]\\), since \\(b=-1\\)"
  },
  {
    "objectID": "lessons/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#corollaries-from-thm-11.1",
    "href": "lessons/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#corollaries-from-thm-11.1",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Corollaries from Thm 11.1",
    "text": "Corollaries from Thm 11.1\n\n\n\n\nCorollary 11.1.1\n\n\nFor a discrete r.v. \\(X\\), and constants \\(a\\) and \\(b\\), \\[\\mathbb{E}[aX+b] = a\\mathbb{E}[X] + b.\\]\n\n\n\n\n\nCorollary 11.1.2\n\n\nIf \\(X_i\\), \\(i=1,2,\\dots, n\\), are identically distributed r.v.’s, then \\[\\mathbb{E}\\bigg[\\sum_{i=1}^n X_i\\bigg] = n\\mathbb{E}[X_1] .\\]"
  },
  {
    "objectID": "lessons/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#cost-of-hotel-rooms",
    "href": "lessons/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#cost-of-hotel-rooms",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Cost of hotel rooms",
    "text": "Cost of hotel rooms\n\n\n\n\nExample 4\n\n\nA tour group is planning a visit to the city of Minneapolis and needs to book 30 hotel rooms. The average price of a room is $200. In addition, there is a 10% tourism tax for each room. What is the expected cost for the 30 hotel rooms?"
  },
  {
    "objectID": "lessons/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html",
    "href": "lessons/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "",
    "text": "Calculate probability of a sample mean using a Normally distributed population"
  },
  {
    "objectID": "lessons/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#learning-objectives",
    "href": "lessons/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#learning-objectives",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "",
    "text": "Calculate probability of a sample mean using a Normally distributed population"
  },
  {
    "objectID": "lessons/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#sum-of-normal-rvs",
    "href": "lessons/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#sum-of-normal-rvs",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "Sum of Normal RVs",
    "text": "Sum of Normal RVs\n\n\nTheorem 1\n\n\nLet \\(X\\sim N(\\mu, \\sigma^2)\\), and let \\(Y=aX+b\\), where \\(a\\) and \\(b\\) are constants. Then \\[Y \\sim N(a\\mu+b, a^2\\sigma^2)\\]\n\n\n\n\nTheorem 2\n\n\nLet \\(X_i \\sim N(\\mu_i, \\sigma_i^2)\\) be independent normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\sim N\\Bigg(\\sum_{i=1}^n \\mu_i , \\sum_{i=1}^n \\sigma^2_i\\Bigg)\\]"
  },
  {
    "objectID": "lessons/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#special-cases",
    "href": "lessons/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#special-cases",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "Special Cases",
    "text": "Special Cases\n\nLet \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\sim N\\big(n\\mu, n \\sigma^2\\big)\\]\nLet \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\bar{X}=\\frac{\\sum_{i=1}^n X_i}{n} \\sim N\\big(\\mu, \\sigma^2 / n\\big)\\]\nLet \\(X\\sim N(\\mu_X,\\sigma_X^2)\\), and \\(Y\\sim N(\\mu_Y,\\sigma_Y^2)\\). Then \\[X-Y \\sim N\\big(\\mu_X - \\mu_Y, \\sigma^2_X + \\sigma^2_Y \\big)\\]"
  },
  {
    "objectID": "lessons/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#detecting-and-solving-sums-of-normal-rvs-from-a-word-problem",
    "href": "lessons/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#detecting-and-solving-sums-of-normal-rvs-from-a-word-problem",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "Detecting and solving sums of Normal RVs from a word problem",
    "text": "Detecting and solving sums of Normal RVs from a word problem\n\n\n\n\nExample 1\n\n\nGlaucoma is an eye disease that is manifested by high intraocular pressure (IOP). The distribution of IOP in the general population is approximately normal with mean 16 mmHg and standard deviation 3 mmHg.\n\nSuppose a patient has 40 IOP readings. What is the probability that their average reading is greater than 20.32 mmHg, assuming their eyes are healthy?\nRepeat the previous question for a patient with 10 IOP readings."
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs_key_info.html",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 01 assignments are graded!\n\nSolutions and videos are posted!"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs_key_info.html#announcements",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 01 assignments are graded!\n\nSolutions and videos are posted!"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs_key_info.html#key-dates",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 02 Assignment due this Thursday at 11pm\nNo HW 01 Solutions"
  },
  {
    "objectID": "lessons/19_Central_Limit_Theorem/19_Central_Limit_Theorem.html",
    "href": "lessons/19_Central_Limit_Theorem/19_Central_Limit_Theorem.html",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "",
    "text": "Calculate probability of a sample mean using a population mean and variance with unknown distribution\nUse the Central Limit Theorem to construct the Normal approximation of the Binomial and Poisson distributions"
  },
  {
    "objectID": "lessons/19_Central_Limit_Theorem/19_Central_Limit_Theorem.html#learning-objectives",
    "href": "lessons/19_Central_Limit_Theorem/19_Central_Limit_Theorem.html#learning-objectives",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "",
    "text": "Calculate probability of a sample mean using a population mean and variance with unknown distribution\nUse the Central Limit Theorem to construct the Normal approximation of the Binomial and Poisson distributions"
  },
  {
    "objectID": "lessons/19_Central_Limit_Theorem/19_Central_Limit_Theorem.html#the-central-limit-theorem",
    "href": "lessons/19_Central_Limit_Theorem/19_Central_Limit_Theorem.html#the-central-limit-theorem",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\n\n\nTheorem 1: Central Limit Theorem (CLT)\n\n\nLet \\(X_i\\) be iid rv’s with common mean \\(\\mu\\) and variance \\(\\sigma^2\\), for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\rightarrow \\text{N}(n\\mu, n\\sigma^2)\\]"
  },
  {
    "objectID": "lessons/19_Central_Limit_Theorem/19_Central_Limit_Theorem.html#extension-of-the-clt",
    "href": "lessons/19_Central_Limit_Theorem/19_Central_Limit_Theorem.html#extension-of-the-clt",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "Extension of the CLT",
    "text": "Extension of the CLT\n\n\nCorollary 1\n\n\nLet \\(X_i\\) be iid rv’s with common mean \\(\\mu\\) and variance \\(\\sigma^2\\), for \\(i=1,2,\\ldots,n\\). Then \\[\\overline{X}=\\frac{\\sum_{i=1}^n X_i}{n}  \\rightarrow \\text{N}\\Bigg(\\mu, \\dfrac{\\sigma^2}{n}\\Bigg)\\]"
  },
  {
    "objectID": "lessons/19_Central_Limit_Theorem/19_Central_Limit_Theorem.html#example-of-corollary-in-use",
    "href": "lessons/19_Central_Limit_Theorem/19_Central_Limit_Theorem.html#example-of-corollary-in-use",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "Example of Corollary in use",
    "text": "Example of Corollary in use\n\n\n\n\nExample 1\n\n\nAccording to a large US study, the mean resting heart rate of adult women is about 74 beats per minutes (bpm), with standard deviation 13 bpm (NHANES 2003-2004).\n\nFind the probability that the average resting heart rate for a random sample of 36 adult women is more than 3 bpm away from the mean.\nRepeat the previous question for a single adult woman."
  },
  {
    "objectID": "lessons/19_Central_Limit_Theorem/19_Central_Limit_Theorem.html#example-of-clt-for-exponential-distribution",
    "href": "lessons/19_Central_Limit_Theorem/19_Central_Limit_Theorem.html#example-of-clt-for-exponential-distribution",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "Example of CLT for exponential distribution",
    "text": "Example of CLT for exponential distribution\n\n\n\n\nExample 2\n\n\nLet \\(X_i \\sim Exp(\\lambda)\\) be iid RVs for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\rightarrow\\]"
  },
  {
    "objectID": "lessons/19_Central_Limit_Theorem/19_Central_Limit_Theorem.html#clt-for-discrete-rvs",
    "href": "lessons/19_Central_Limit_Theorem/19_Central_Limit_Theorem.html#clt-for-discrete-rvs",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "CLT for Discrete RVs",
    "text": "CLT for Discrete RVs\n\n\n\nBinomial rv’s: Let \\(X \\sim Bin(n,p)\\)\n\n\\(X = \\displaystyle\\sum_{i=1}^n X_i\\), where \\(X_i\\) are iid \\(\\text{Bernoulli}(p)\\)\nRule of thumb: \\(np\\geq10\\) and \\(n(1-p)\\geq 10\\) to use Normal approximation\n\n\n\n\n\n\nPoisson rv’s: Let \\(X \\sim Poisson(\\lambda)\\)\n\n\\(X = \\displaystyle\\sum_{i=1}^n X_i\\), where \\(X_i\\) are iid \\(\\text{Poiss}(1)\\)\nRecall from Chapter 18 that if \\(X_i \\sim Poiss(\\lambda_i)\\) and \\(X_i\\) independent, then \\(\\sum_{i=1}^n X_i \\sim Poiss(\\sum_{i=1}^n \\lambda_i)\\)\nRule of thumb: \\(\\lambda \\geq10\\) to use Normal approximation"
  },
  {
    "objectID": "lessons/19_Central_Limit_Theorem/19_Central_Limit_Theorem.html#at-home-example",
    "href": "lessons/19_Central_Limit_Theorem/19_Central_Limit_Theorem.html#at-home-example",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "At home example",
    "text": "At home example\n\n\nExample 3\n\n\nSuppose that the probability of developing a specific type of breast cancer in women aged 40-49 is 0.001. Assume the occurrences of cancer are independent. Suppose you have data from a random sample of 20,000 women aged 40-49.\n\nHow many of the 20,000 women would you expect to develop this type of breast cancer, and what is the standard deviation?\nFind the exact probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to find the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to approximate the following probabilities, where \\(X\\) is the number of women that will develop this type of breast cancer.\n\n\\(\\mathbb{P}(15 \\leq X \\leq 22)\\)\n\\(\\mathbb{P}(X &gt; 20)\\)\n\\(\\mathbb{P}(X &lt; 20)\\)\n\nFind the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer - not using the CLT!\nUse the CLT to approximate the approximate probability in the previous question!"
  },
  {
    "objectID": "lessons/16_Variance/16_Variance_key_info.html",
    "href": "lessons/16_Variance/16_Variance_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 4 assignment due last night!\nHW 3 solutions also due\nTime to grade later today: HW 3 solutions or HW 4 assignment?"
  },
  {
    "objectID": "lessons/16_Variance/16_Variance_key_info.html#announcements",
    "href": "lessons/16_Variance/16_Variance_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 4 assignment due last night!\nHW 3 solutions also due\nTime to grade later today: HW 3 solutions or HW 4 assignment?"
  },
  {
    "objectID": "lessons/16_Variance/16_Variance_key_info.html#key-dates",
    "href": "lessons/16_Variance/16_Variance_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/13_Independence_conditioning_muddy_points.html",
    "href": "lessons/13_Independence_Conditioning/13_Independence_conditioning_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n2. Joint vs marginal vs conditional: How are we calculating the probability?\nIf we start at a joint probability \\(f_{X,Y}(x,y)\\)…. we can look at a few probabilities:\n\nJoint probability: \\(P(a \\leq X \\leq b, c \\leq Y \\leq d)\\)\n\\[P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=c}^{y=d} f_{X,Y}(x,y) dydx\\]\nMarginal probability: \\(P(a \\leq X \\leq b)\\)\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b} f_{X}(x) dx\\]\nOR\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=-\\inf}^{y=\\inf} f_{X,Y}(x,y) dydx\\]\nConditional probability: \\(P(a \\leq X \\leq b | Y = c)\\)\n\\[P(a \\leq X \\leq b | Y=c) = \\displaystyle\\int_{x=a}^{x=b} f_{X|Y}(x|y=c) dx\\]\nYou cannot calculate \\(P(a \\leq X \\leq b | Y = c)\\) by \\(\\dfrac{P(a \\leq X \\leq b, Y=c)}{P(Y = c)}\\) because \\(P(Y = c)\\) is 0. Instead, we need to find \\(f_{X|Y}(x|y=c)\\) by \\(\\dfrac{f_{X,Y}(x,y=c)}{f_{Y}(y=c)}\\) and THEN integrate over X.\n\n\n\n4. Here’s a 3D plot of one of our joint pdf’s\n\\[\nf_{X,Y}(x,y) = 5e^{-x-3y} \\text{ for } 0 \\leq y \\leq x/2\n\\]\n\nlibrary(plotly)\n\nx = seq(0, 5, 0.1)\ny = seq(0, max(x)/2, 0.1/2)\nfn = expand.grid(x=x,y=y)\nfn$z = ifelse(fn$y&lt;fn$x/2, 5*exp( (-1)*fn$x - 3*fn$y), NA)\n\nz = matrix(fn$z, ncol = 51, nrow = 51, byrow = T)\n\nfig &lt;- plot_ly(x = x, y=y, z=z) %&gt;% add_surface()\n\nfig"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/13_Independence_conditioning_key_info.html",
    "href": "lessons/13_Independence_Conditioning/13_Independence_conditioning_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 presentations are graded! You did great!\nHW 7 assignment: I’ll grade tonight!\nAnything else?"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/13_Independence_conditioning_key_info.html#announcements",
    "href": "lessons/13_Independence_Conditioning/13_Independence_conditioning_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 presentations are graded! You did great!\nHW 7 assignment: I’ll grade tonight!\nAnything else?"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/13_Independence_conditioning_key_info.html#key-dates",
    "href": "lessons/13_Independence_Conditioning/13_Independence_conditioning_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: NONE due\nSunday: HW 7 solutions due (feel free to take an additional 3 days)"
  },
  {
    "objectID": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html",
    "href": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "",
    "text": "Learn the definition of a moment-generating function.\nFind the moment-generating function of a binomial random variable.\nUse a moment-generating function to find the mean and variance of a random variable."
  },
  {
    "objectID": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#learning-objectives",
    "href": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#learning-objectives",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "",
    "text": "Learn the definition of a moment-generating function.\nFind the moment-generating function of a binomial random variable.\nUse a moment-generating function to find the mean and variance of a random variable."
  },
  {
    "objectID": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#where-are-we",
    "href": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#where-are-we",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#what-are-moments",
    "href": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#what-are-moments",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "What are moments?",
    "text": "What are moments?\n\n\nDefinition 1\n\n\nThe \\(j^{th}\\) moment of a r.v. \\(X\\) is \\(\\mathbb{E}[X^j]\\)\n\n\n\n\nExample 1\n\n\n\\(1^{st}-4^{th}\\) moments"
  },
  {
    "objectID": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#what-is-a-moment-generating-function-mgf",
    "href": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#what-is-a-moment-generating-function-mgf",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "What is a moment generating function (mgf)??",
    "text": "What is a moment generating function (mgf)??\n\n\nDefinition 3\n\n\nIf \\(X\\) is a r.v., then the moment generating function (mgf) associated with \\(X\\) is: \\[M_X(t)= \\mathbb{E}[e^{tX}]\\]\n\n\nRemarks\n\n\n\nFor a discrete r.v., the mgf of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\sum_{all \\ x}e^{tx}p_X(x)\\]\nFor a continuous r.v., the mgf of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\int_{-\\infty}^{\\infty}e^{tx}f_X(x)dx\\]\n\n\n\nThe mgf \\(M_X(t)\\) is a function of \\(t\\), not of \\(X\\), and it might not be defined (i.e. finite) for all values of \\(t\\). We just need it to be defined for \\(t=0\\)."
  },
  {
    "objectID": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#example",
    "href": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#example",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Example",
    "text": "Example\n\n\n\n\nExample 4\n\n\nWhat is \\(M_X(t)\\) for \\(t=0\\)?"
  },
  {
    "objectID": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#theorem",
    "href": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#theorem",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Theorem",
    "text": "Theorem\n\n\nTheorem 5\n\n\nThe moment generating function uniquely specifies a probability distribution.\n\n\n\n\nTheorem 6\n\n\n\\[\\mathbb{E}[X^r] = M_X^{(r)}(0)\\]\n\\((r)\\) in this equation is the \\(r\\)th derivative with respect to \\(t\\)\n\n\n\nWhen \\(r=1\\), we are taking the first derivative\nWhen \\(r=4\\), we are taking the fourth derivative"
  },
  {
    "objectID": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-a-probability-distribution",
    "href": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-a-probability-distribution",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Using the mgf to uniquely describe a probability distribution",
    "text": "Using the mgf to uniquely describe a probability distribution\n\n\n\n\nExample 7\n\n\nLet \\(X \\sim Poisson(\\lambda)\\)\n\nFind the mgf of \\(X\\)\nFind \\(\\mathbb{E}[X]\\)\nFind \\(Var(X)\\)"
  },
  {
    "objectID": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#theorem-1",
    "href": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#theorem-1",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Theorem",
    "text": "Theorem\nRemark: Finding the mean and variance is sometimes easier with the following trick\n\n\nTheorem 8\n\n\nLet \\(R_X(t) = \\ln[M_X(t)]\\). Then,\n\\[\\mu = \\mathbb{E}[X] = R_X'(0) \\text{, and}\\] \\[\\sigma^2 = Var(X) = R_X''(0)\\]\n\n\n\nProof."
  },
  {
    "objectID": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#using-r_xt-to-uniquely-describe-a-probability-distribution",
    "href": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#using-r_xt-to-uniquely-describe-a-probability-distribution",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Using \\(R_X(t)\\) to uniquely describe a probability distribution",
    "text": "Using \\(R_X(t)\\) to uniquely describe a probability distribution\n\n\n\n\nExample 9\n\n\nLet \\(X \\sim Poisson(\\lambda)\\).\n\nFind \\(\\mathbb{E}[X]\\) using \\(R_X(t)\\)\nFind \\(Var(X)\\) using \\(R_X(t)\\)"
  },
  {
    "objectID": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-the-standard-normal-distribution",
    "href": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-the-standard-normal-distribution",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Using the mgf to uniquely describe the standard normal distribution",
    "text": "Using the mgf to uniquely describe the standard normal distribution\n\n\n\n\nExample 10\n\n\nLet \\(Z\\) be a standard normal random variable, i.e. \\(Z \\sim N(0,1)\\).\n\nFind the mgf of \\(Z\\)\nFind \\(\\mathbb{E}[Z]\\)\nFind \\(Var(Z)\\)"
  },
  {
    "objectID": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#mgfs-of-sums-of-independent-rvs",
    "href": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#mgfs-of-sums-of-independent-rvs",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Mgf’s of sums of independent RV’s",
    "text": "Mgf’s of sums of independent RV’s\n\n\nTheorem 9\n\n\nIf \\(X\\) and \\(Y\\) are independent RV’s with respective mgf’s \\(M_X(t)\\) and \\(M_Y(t)\\), then\n\\[M_{X+Y}(t) = E[e^{t(X+Y)}] = E[e^{tX} e^{tY}] = E[e^{tX}]E[e^{tY}]=M_{X}(t)M_{Y}(t)\\]"
  },
  {
    "objectID": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#main-takeaways",
    "href": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#main-takeaways",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Main takeaways",
    "text": "Main takeaways\n\nMgf’s are a purely mathematically definition\n\nWe can’t really relate it to our real world analysis\n\nThey are helpful mathematically because they are unique to a probability distribution\n\nWe can find the unique mgf from for a probability distribution\nAnd we can find a distribution from an mgf\n\nMgf’s can sometimes make it easier to find the mean and variance of an RV\nMgf’s are most helpful when we are finding a joint distribution that is a sum or transformation of two RV’s\n\nMake the calculation easier!\n\nMgf’s are often used to prove certain distribution are sums of other ones!"
  },
  {
    "objectID": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#more-resources",
    "href": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions.html#more-resources",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "More resources",
    "text": "More resources\n\nhttps://online.stat.psu.edu/stat414/book/export/html/676\nhttps://www.youtube.com/watch/ez_vq23xWrQ\nhttps://www.youtube.com/watch/2p9J9ChTeFI\nhttps://www.youtube.com/watch/A5bWU8xcQkE\nhttps://www.youtube.com/watch/QeUrTGFTFm4\nhttps://www.youtube.com/watch/HhrkwyyRtgI"
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities_muddy_points.html",
    "href": "lessons/12_Joint_distributions/25_Joint_densities_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n1. How do pdf, CDF, and probability interact with each other?\nLet’s say we have a pdf, \\(f_X(x) = \\dfrac{1}{9}x^2\\) for \\(0 \\leq x \\leq 3\\). This is just a function. The pdf is not used on its own to report any probability. We must integrate over the pdf to find a probability.\n\nlibrary(\"ggplot2\")\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3)\n\n\n\n\n\n\n\n\nThe total area under the pdf is 1. This makes our pdf valid.\n\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 3),\n                geom = \"area\", \n                aes(fill = \"red\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 1\", color = \"black\")\n\n\n\n\n\n\n\n\nIf we only look at a proportion of the area under the pdf, then we start constructing our probabilities. For example, we can look at probability that we have a value between 0 and 1.5.\n\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 1.5),\n                geom = \"area\", \n                aes(fill = \"blue\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 0.125\", color = \"black\")\n\n\n\n\n\n\n\n\nInstead of calculating the EXACT probability for each value between 0 and 3, we can find the CDF of the pdf.\nThe CDF is: \\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;3 \\quad \\\\\n            \\dfrac{1}{27}x^3 & \\quad 0 \\leq x \\leq 3\\quad \\\\\n            1 & \\quad x&gt;3 \\quad\n        \\end{array}\n    \\right.\n\\]\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nWhen \\(x=1.5\\), we can calculate the probability using the CDF. Remember that \\(F_X(x) = P(X \\leq x)\\). So we can say \\(P(X \\leq 1.5) = F_X(1.5) = \\dfrac{1}{27}(1.5)^3\\), which equals 0.125.\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\") +\n  geom_point(aes(x=1.5, y=.125), colour=\"blue\", size=3) +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"CDF = 0.125\", color = \"black\")\n\nWarning in geom_point(aes(x = 1.5, y = 0.125), colour = \"blue\", size = 3): All aesthetics have length 1, but the data has 2 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\nWe can also calculate the probability with an integral: \\(P(X \\leq 1.5) = \\displaystyle\\int_0^{1.5} \\dfrac{1}{9}x^2 dx\\).\nWe can also find the probability that X is between two numbers. \\(P(1\\leq X \\leq 1.5) = F_X(1.5) - F_X(1)\\) or \\(P(1\\leq X \\leq 1.5) = \\displaystyle\\int_1^{1.5} \\dfrac{1}{9}x^2 dx\\).\n\n\n2. Joint vs marginal vs conditional: How are we calculating the probability?\nIf we start at a joint probability \\(f_{X,Y}(x,y)\\)…. we can look at a few probabilities:\n\nJoint probability: \\(P(a \\leq X \\leq b, c \\leq Y \\leq d)\\)\n\\[P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=c}^{y=d} f_{X,Y}(x,y) dydx\\]\nMarginal probability: \\(P(a \\leq X \\leq b)\\)\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b} f_{X}(x) dx\\]\nOR\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=-\\inf}^{y=\\inf} f_{X,Y}(x,y) dydx\\]\nConditional probability: \\(P(a \\leq X \\leq b | Y = c)\\)\n\\[P(a \\leq X \\leq b | Y=c) = \\displaystyle\\int_{x=a}^{x=b} f_{X|Y}(x|y=c) dx\\]\nYou cannot calculate \\(P(a \\leq X \\leq b | Y = c)\\) by \\(\\dfrac{P(a \\leq X \\leq b, Y=c)}{P(Y = c)}\\) because \\(P(Y = c)\\) is 0. Instead, we need to find \\(f_{X|Y}(x|y=c)\\) by \\(\\dfrac{f_{X,Y}(x,y=c)}{f_{Y}(y=c)}\\) and THEN integrate over X.\n\n\n\n3. What are we actually finding by solving the double integral. In the first example, we found the probability was 1/16 after integrating but what does 1/16 mean in relation to the random variables X and Y?\nIt means that the volume contained by \\(0\\leq X \\leq 1\\), \\(0\\leq Y \\leq 1/2\\), and their joint pdf is 1/16 of the total volume contained by \\(0\\leq X \\leq 2\\), \\(0\\leq Y \\leq 1\\), and their joint pdf. The probability for a joint pdf is now a measure of the proportion of the volume.\nThis is not be confused with a probability from marginal pdf or pdf from one RV. The probability for marginal/single RV pdfs is the proportion of the area under the pdf for a specific range of values.\n\n\n4. Here’s a 3D plot of one of our joint pdf’s\n\\[\nf_{X,Y}(x,y) = 5e^{-x-3y} \\text{ for } 0 \\leq y \\leq x/2\n\\]\n\nlibrary(plotly)\n\nx = seq(0, 5, 0.1)\ny = seq(0, max(x)/2, 0.1/2)\nfn = expand.grid(x=x,y=y)\nfn$z = ifelse(fn$y&lt;fn$x/2, 5*exp( (-1)*fn$x - 3*fn$y), NA)\n\nz = matrix(fn$z, ncol = 51, nrow = 51, byrow = T)\n\nfig &lt;- plot_ly(x = x, y=y, z=z) %&gt;% add_surface()\n\nfig"
  },
  {
    "objectID": "lessons/12_Joint_distributions/11_Transformations_key_info.html",
    "href": "lessons/12_Joint_distributions/11_Transformations_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 02 assignments are graded!\n\nSolutions and videos are posted!\n\nFinish the discrete distributions notes\n\nThen get into joint distributions"
  },
  {
    "objectID": "lessons/12_Joint_distributions/11_Transformations_key_info.html#announcements",
    "href": "lessons/12_Joint_distributions/11_Transformations_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 02 assignments are graded!\n\nSolutions and videos are posted!\n\nFinish the discrete distributions notes\n\nThen get into joint distributions"
  },
  {
    "objectID": "lessons/12_Joint_distributions/11_Transformations_key_info.html#key-dates",
    "href": "lessons/12_Joint_distributions/11_Transformations_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 03 Assignment due this Thursday at 11pm\n\nI updated the homework assignment on the 18th!"
  },
  {
    "objectID": "lessons/21_Moment_Generating_Functions/21_Moment_Generating_Functions.html",
    "href": "lessons/21_Moment_Generating_Functions/21_Moment_Generating_Functions.html",
    "title": "Chapter 43: Moment Generating Functions Part 2",
    "section": "",
    "text": "Chapter 43: Moment Generating Functions Part 2\nRecap: What is an mgf?\n\nExample 1.   Let \\(X\\) be a random variable with mgf \\[M_X(t)= \\frac{1}{5}e^t + \\frac{3}{10}e^{2t} + \\frac{1}{2}e^{3t}.\\] Find the pmf or pdf of \\(X\\).\n\n\nExample 2.   Let \\(X\\) be a normal random variable with mean \\(\\mu\\) and variance \\(\\sigma^2\\), i.e. \\(X \\sim N(\\mu,\\sigma^2)\\).\n\nFind the mgf of \\(X\\).\nFind \\(\\mathbb{E}[X]\\).\nFind \\(Var(X)\\).\n\n\n\n\nTheorem 3.   Let \\(X\\) have mgf \\(M_X(t)\\), and let \\(Y=aX+b\\), where \\(a\\) and \\(b\\) are constants. Then \\[M_Y(t)=\\]\n\n\nProof. Proof. ◻\n\nQuestion: Do linear transformations always preserve the distribution type?\nI.e., if \\(X\\) has a certain probability distribution, does \\(aX+b\\) always have the same distribution type?\n\n\nExample 4.   Let \\(X \\sim U[0,1]\\), and \\(Y = 2X+3\\). Is \\(Y\\) also a uniform rv? If so, what are its parameters?\n\n\nExample 5.   Let \\(X \\sim Exp(\\lambda=5)\\), and \\(Y = 2X+3\\). Is \\(Y\\) also an exponential rv? If so, what is its parameter?\n\nMgf’s of Sums of Independent rv’s\n\n\nTheorem 6.   Let \\(X_1, X_2, \\ldots, X_n\\) be independent rv’s with respective mgf’s \\(M_{X_i}(t)\\), for \\(i=1,2,\\ldots,n\\). Let \\(Y=\\sum_{i=1}^n a_iX_i\\), where \\(a_i\\) are constants. Then \\[M_Y(t)= %\\Pi_{i=1}^n M_{X_i}(a_it).\\]\n\n\nProof. Proof. ◻\n\n\n\nExample 7.   Let \\(X_i \\sim N(\\mu_i, \\sigma_i^2)\\) be independent normal rv’s. What is the distribution of  \\(Y=\\sum_{i=1}^n X_i\\)?\n\n\n\nExample 8.   Let \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). What is the distribution of  \\(\\bar{X}=\\frac{\\sum_{i=1}^n X_i}{n}\\)?\n\n\nExample 9.   Let \\(Z\\) be a standard normal random variable, i.e. \\(Z \\sim N(0,1)\\). Show that \\(Z^2 \\sim \\chi_1^2\\), i.e. is a chi-squared rv with 1 degree of freedom."
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs_key_info.html",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 videos should be in!\n\nSome presentations today\n\nNeed to grade HW 4 solutions and HW 5 assignment STILL\n\nHappy to be flexible on the HW 5 solutions deadline\n\nAnything else?"
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs_key_info.html#announcements",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 videos should be in!\n\nSome presentations today\n\nNeed to grade HW 4 solutions and HW 5 assignment STILL\n\nHappy to be flexible on the HW 5 solutions deadline\n\nAnything else?"
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs_key_info.html#key-dates",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 6 due\nSunday: HW 5 solutions due\n\nFLEXIBLE"
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs.html",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs.html",
    "title": "Chapter 31-35: Some Important Continuous RVs",
    "section": "",
    "text": "Distinguish between Uniform, Exponential, Gamma, and Normal distributions when reading a story.\nIdentify the variable and the parameters in a story, and state what the variable and parameters mean.\nUse the formulas for the pdf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs.html#properties-of-continuous-uniform-rvs",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs.html#properties-of-continuous-uniform-rvs",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Properties of continuous uniform RVs",
    "text": "Properties of continuous uniform RVs\n\nScenario: Events are equally likely to happen anywhere or anytime in an interval of values\nShorthand: \\(X \\sim \\text{U}[a,b]\\)\n\n\\[\nf_X(x) = \\dfrac{1}{b-a}, \\text{ for }a \\leq x \\leq b\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;a \\quad \\\\\n            \\dfrac{x-a}{b-a} & \\quad a \\leq x \\leq b\\quad \\\\\n            1 & \\quad x&gt;b \\quad\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{a+b}{2} \\text{, } \\text{ Var}(X) = \\dfrac{(b-a)^2}{12}\\]"
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs.html#identifying-continuous-uniform-rv-from-word-problems",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs.html#identifying-continuous-uniform-rv-from-word-problems",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Identifying continuous uniform RV from word problems",
    "text": "Identifying continuous uniform RV from word problems\n\nLook for some indication that all events are equally likely\n\nCould also say “uniformly distributed”\n\nLook for an interval\n\nTime example: Costumer in your store will approach the cash register in next 30 minutes. Approaching the register throughout the 30 minutes is equally likely.\nLength example: You have a 12 inch string that you need to cut. You are equally likely to cut anywhere on the string.\n\nDifferent than the discrete uniform\n\nDiscrete usually includes a countable number of events that are equally likely\nContinuous is not countable\n\nExact time and length can be measured with infinite decimal places"
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs.html#helpful-r-code",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs.html#helpful-r-code",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re looking at equally likely arrival times between 10 am and 11 am.\n\nIf we want to know the probability that someone arrives at 10:30am or earlier:\n\npunif(q = 30, min = 0, max = 60)\n\n[1] 0.5\n\n\nIf we want to know the time, say \\(t\\), where the probability of arriving at \\(t\\) or earlier is 0.35:\n\nqunif(p = 0.35, min = 0, max = 60)\n\n[1] 21\n\n\nIf we want to know the probability that someone arrives between 10:14 and 10:16 am:\n\npunif(q = 16, min = 0, max = 60) - punif(q = 14, min = 0, max = 60)\n\n[1] 0.03333333\n\n\nIf we want to sample 20 arrival times from the distribution:\n\nrunif(n = 20, min = 0, max = 60)\n\n [1] 36.1518032 56.6547857 45.1115403 51.8594366 34.8732771 12.8750386\n [7] 42.5877139 44.3007376 56.7688498 30.0011219 54.6299942 12.6420043\n[13] 44.1304846 19.9011956 28.5120543  5.4834140 31.0400753 46.8370057\n[19] 35.1252265  0.9729805"
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs.html#bird-on-a-wire-tb-31.5",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs.html#bird-on-a-wire-tb-31.5",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Bird on a wire (TB 31.5)",
    "text": "Bird on a wire (TB 31.5)\n\n\n\n\nExample 1\n\n\nA bird lands at a location that is Uniformly distributed along an electrical wire of length 150 feet. The wire is stretched tightly between two poles. What is the probability that the bird is 20 feet or less from one or the other of the poles?"
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs.html#properties-of-exponential-rvs",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs.html#properties-of-exponential-rvs",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Properties of exponential RVs",
    "text": "Properties of exponential RVs\n\nScenario: Modeling the time until the next (first) event\nContinuous analog to the geometric distribution!\nShorthand: \\(X \\sim \\text{Exp}(\\lambda)\\)\n\n\\[\nf_X(x) = \\lambda e^{-\\lambda x}\\text{ for } x&gt;0, \\lambda&gt;0\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;0 \\quad \\\\\n            1 - e^{-\\lambda x} & \\quad x\\geq0 \\\\\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{1}{\\lambda}\\] \\[\\text{Var}(X) = \\dfrac{1}{\\lambda^2}\\]"
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs.html#memoryless-property",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs.html#memoryless-property",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Memoryless Property",
    "text": "Memoryless Property\n   \nIf \\(b&gt;0\\),\n\\[P(X &gt; a +b | X&gt; a) = P(X &gt; b)\\]\n     \n\nThis can be interpreted as:\n\nIf you have waited \\(a\\) seconds (or any other measure of time) without a success\nThen the probability that you have to wait \\(b\\) more seconds is the same as as the probability of waiting \\(b\\) seconds initially."
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs.html#identifying-exponential-rv-from-word-problems",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs.html#identifying-exponential-rv-from-word-problems",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Identifying exponential RV from word problems",
    "text": "Identifying exponential RV from word problems\n\nLook for time between events/successes\nLook for a rate of the events over time period\nHow does it differ from the geometric distribution?\n\nGeometric is number of trials until first success\nExponential is time until first success\n\nRelation to the Poisson distribution?\n\nWhen the time between arrivals is exponential, the number of arrivals in a fixed time interval is Poisson with the mean \\(\\lambda\\)"
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs.html#helpful-r-code-1",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs.html#helpful-r-code-1",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re sitting at the bus stop, measuring the time until our bus arrives. We know the bus comes every 10 minutes on average.\n\nIf we want to know the probability that the bus arrives in the next 5 minutes:\n\npexp(q = 5, rate = 1/10)\n\n[1] 0.3934693\n\n\nIf we want to know the time, say \\(t\\), where the probability of the bus arriving at \\(t\\) or earlier is 0.35:\n\nqexp(p = 0.35, rate = 1/10)\n\n[1] 4.307829\n\n\nIf we want to know the probability that the bus arrives between 3 and 5 minutes:\n\npexp(q = 5, rate = 1/10) - pexp(q = 3, rate = 1/10)\n\n[1] 0.1342876\n\n\nIf we want to sample 20 bus arrival times from the distribution:\n\nrexp(n = 20, rate = 1/10)\n\n [1] 11.3663960 18.3833292 11.9529412  8.0393384  2.9907828  1.8604949\n [7] 16.9187460  9.8558311  0.1888765 10.6110339  7.0503523  9.8269015\n[13]  3.4872349 11.3613407 11.9240648 19.0331605 14.0223053  2.1621659\n[19] 20.1604482  0.2328047"
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs.html#transformation-of-independent-exponential-rvs",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs.html#transformation-of-independent-exponential-rvs",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Transformation of independent exponential RVs",
    "text": "Transformation of independent exponential RVs\n\n\nRevisit after joint notes:\n\n\nExample 1\n\n\nLet \\(X_i \\sim \\textrm{Exp}(\\lambda_i)\\) be independent RVs, for \\(i=1 \\ldots n\\). Find the pdf for the first of the arrival times."
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs.html#properties-of-gamma-rvs",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs.html#properties-of-gamma-rvs",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Properties of gamma RVs",
    "text": "Properties of gamma RVs\n\nScenario: Modeling the time until the \\(r^{th}\\) event.\nContinuous analog to the Negative Binomial distribution\nShorthand: \\(X \\sim \\text{Gamma}(r, \\lambda)\\)\n\n\\[\nf_X(x) = \\dfrac{\\lambda^r}{\\Gamma(r)}x^{r-1} e^{-\\lambda x}\\text{ for } x&gt;0, \\lambda&gt;0, \\Gamma(r) = (r-1)!\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;0 \\quad \\\\\n            1 - e^{-\\lambda x}\\displaystyle\\sum_{j=0}^{r-1}\\dfrac{(\\lambda x)^j}{j!}  & \\quad x\\geq0 \\\\\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{r}{\\lambda}\\text{, }\\text{ Var}(X) = \\dfrac{r}{\\lambda^2}\\]\nCommon to see \\(\\alpha = r\\) and \\(\\beta = \\lambda\\)"
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs.html#identifying-gamma-rv-from-word-problems",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs.html#identifying-gamma-rv-from-word-problems",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Identifying gamma RV from word problems",
    "text": "Identifying gamma RV from word problems\n\nGamma distribution with \\(r=1\\) is same as exponential\n\nJust like Negative Binomial with \\(r=1\\) is same as the geometric distribution\n\nSimilar to exponential\n\nLook for time between or until events/successes\n\nBUT now we are measuring time until more than 1 success\n\nLook for a rate of the events over time period"
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs.html#helpful-r-code-2",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs.html#helpful-r-code-2",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re sitting at the bus stop, measuring the time until 4 buses arrive. We know the bus comes every 10 minutes on average.\n\nIf we want to know the probability that the 4 buses arrive in the next 50 minutes:\n\n\n\n\npgamma(q = 50, rate = 1/10, shape = 4)\n\n[1] 0.7349741\n\n\n\n\npgamma(q = 50, scale = 10, shape = 4)\n\n[1] 0.7349741\n\n\n\n\nIf we want to know the time, say \\(t\\), where the probability of the 4 buses arriving at \\(t\\) or earlier is 0.35:\n\nqgamma(p = 0.35, rate = 1/10, shape = 4)\n\n[1] 29.87645\n\n\nIf we want to know the probability that the 4 buses arrives between 30 and 50 minutes:\n\npgamma(q = 50, scale = 10, shape = 4) - pgamma(q = 30, scale = 10, shape = 4)\n\n[1] 0.382206\n\n\nIf we want to sample 20 arrival times for the 4 buses:\n\nrgamma(n = 20, scale = 10, shape = 4)\n\n [1] 24.17767 15.75058 16.75578 60.37217 36.67145 29.17471 61.12207 33.22881\n [9] 25.03580 39.81007 60.30513 45.66314 26.98178 56.14269 21.37449 36.87710\n[17] 44.48559 25.77701 90.81206 14.69105"
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs.html#remarks",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs.html#remarks",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Remarks",
    "text": "Remarks\n\nThe parameter \\(r\\) in a Gamma(\\(r\\),\\(\\lambda\\)) distribution does NOT need to be a positive integer\n\n\\(r\\) is usually a positive integer\n\nWhen \\(r\\) is a positive integer, the distribution is sometimes called an Erlang(\\(r\\),\\(\\lambda\\)) distribution\n \n \nWhen \\(r\\) is any positive real number, we have a general gamma distribution that is usually instead parameterized by \\(\\alpha&gt;0\\) and \\(\\beta&gt;0\\), where:\n\n\\(\\alpha = \\text{shape parameter}\\) : same as \\(k\\), the total number of events we must witness\n\nIn R code example: 4 buses to wait for\n\n\\(\\beta = \\text{scale parameter}\\) : same as \\(\\lambda\\), the rate parameter\n\nIn R code example: 1 bus per 10 minutes (1/10)"
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs.html#sending-money-orders",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs.html#sending-money-orders",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Sending money orders",
    "text": "Sending money orders\n\n\n\n\nExample 1\n\n\nOn average, someone sends a money order once per 15 minutes. What is the probability someone sends 10 money orders in less than 3 hours?"
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs.html#additional-resource",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs.html#additional-resource",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Additional Resource",
    "text": "Additional Resource\n\nAnother helpful site with R code: https://rpubs.com/mpfoley73/459051"
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs.html#properties-of-normal-rvs",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs.html#properties-of-normal-rvs",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Properties of Normal RVs",
    "text": "Properties of Normal RVs\n\nNo scenario description here because the Normal distribution is so universal\n\nCentral Limit Theorem (next class) makes it applicable to many types of events\n\nShorthand: \\(X \\sim \\text{Normal}(\\mu, \\sigma^2)\\)\n\n\\[\nf_X(x) = \\dfrac{1}{\\sqrt{2\\pi \\sigma^2}}e^{-(x-\\mu)^2/(2\\sigma^2)} \\text{, for} -inf &lt; x &lt; inf\n\\]\n\\[\\text{E}(X) = \\mu \\] \\[\\text{Var}(X) = \\sigma^2\\]"
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs.html#helpful-r-code-3",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs.html#helpful-r-code-3",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re measuring the high temperature today. The average high temperature on this day across many, many years is 50 degrees with a standard deviation of 4 degrees.\n\nIf we want to know the probability that the high temperature is below 45 degrees:\n\npnorm(q = 45, mean = 50, sd = 4)\n\n[1] 0.1056498\n\n\nIf we want to know the temoerature, say \\(t\\), where the probability of that the temperature is at \\(t\\) or lower is 0.35:\n\nqnorm(p = 0.35, mean = 50, sd = 4)\n\n[1] 48.45872\n\n\nIf we want to know the probability that the temperature is between 45 and 50 degrees:\n\npnorm(q = 50, mean = 50, sd = 4) - pnorm(q = 45, mean = 50, sd = 4)\n\n[1] 0.3943502\n\n\nIf we want to sample 20 days’ temperature (over the years) from the distribution:\n\nrnorm(n = 20, mean = 50, sd = 4)\n\n [1] 44.33876 50.08607 50.70593 55.97296 49.52620 51.15660 51.42931 53.65328\n [9] 50.27942 40.35001 49.48731 64.33081 50.43379 54.01803 54.65349 45.49719\n[17] 52.28530 47.64023 52.54549 50.48006"
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs.html#movie-night-while-studying",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs.html#movie-night-while-studying",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Movie night while studying",
    "text": "Movie night while studying\n\n\n\n\nExample 1\n\n\nChildren’s movies run an average of 98 minutes with a standard deviation of 10 minutes. You check out a random movie from the library to entertain your kids so you can study for your test. Assume that your kids will be occupied for the entire length of the movie.\n\nWhat is the probability that your kids will be occupied for at least the 2 hours you would like to study?\nWhat is range for the bottom quartile (lowest 25%) of time they will be occupied?"
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs.html#standard-normal-distribution",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs.html#standard-normal-distribution",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Standard Normal Distribution",
    "text": "Standard Normal Distribution\n\\[ Z \\sim \\text{Normal}(\\mu = 0, \\sigma^2 = 1)\\]\n\nUsed to be more helpful when computing was not as advanced\n\nUse tables of the standard normal\nYou can convert any normal distribution to a standard normal through transformation\n\n\\(Z = \\dfrac{X - \\mu_X}{\\sigma_X}\\)\n\nComes from \\(X = \\sigma_X Z + \\mu_X\\)\nSince \\(\\sigma_X\\) and \\(\\mu_X\\) are constants, then \\(E(X) = \\mu_X\\) and \\(SD(X) = \\sigma_X SD(Z) = \\sigma_X\\)"
  },
  {
    "objectID": "lessons/14_Expected_Values/14_Expected_Values_key_info.html",
    "href": "lessons/14_Expected_Values/14_Expected_Values_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 03 assignment today\nGroup evals will be taken off the assessment breakdown\nMid-quarter feedback will be put on HW 05"
  },
  {
    "objectID": "lessons/14_Expected_Values/14_Expected_Values_key_info.html#announcements",
    "href": "lessons/14_Expected_Values/14_Expected_Values_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 03 assignment today\nGroup evals will be taken off the assessment breakdown\nMid-quarter feedback will be put on HW 05"
  },
  {
    "objectID": "lessons/14_Expected_Values/14_Expected_Values_key_info.html#key-dates",
    "href": "lessons/14_Expected_Values/14_Expected_Values_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 04 assignment due Thursday\nHW 03 solutions due Sunday\n\nAnd we will have a presentation on this one!"
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities.html",
    "href": "lessons/12_Joint_distributions/25_Joint_densities.html",
    "title": "Chapter 25: Joint densities",
    "section": "",
    "text": "Solve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities.html#learning-objectives",
    "href": "lessons/12_Joint_distributions/25_Joint_densities.html#learning-objectives",
    "title": "Chapter 25: Joint densities",
    "section": "",
    "text": "Solve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-13",
    "href": "lessons/12_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-13",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (1/3)",
    "text": "Double Integrals Mini Lesson (1/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 1\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} xy dydx\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-23",
    "href": "lessons/12_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-23",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (2/3)",
    "text": "Double Integrals Mini Lesson (2/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 2\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} (x+y) dydx\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-33",
    "href": "lessons/12_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-33",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (3/3)",
    "text": "Double Integrals Mini Lesson (3/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 3\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} e^{x+y} dydx\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "href": "lessons/12_Joint_distributions/25_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "title": "Chapter 25: Joint densities",
    "section": "How to define the joint pdf for continuous RVs?",
    "text": "How to define the joint pdf for continuous RVs?\n\n\nFor a single continuous RV \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\), \\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\]\n\nFor two continuous RVs (\\(X\\) and \\(Y\\)), we can define the joint pdf, \\(f_{X,Y}(x,y)\\), such that for all real values \\(a,b, c, d\\) with \\(a \\leq b\\) and \\(c \\leq d\\), \\[\\mathbb{P}(a \\leq X \\leq b, c \\leq Y \\leq d) = \\int_a^b \\int_c^d f_{X,Y}(x,y)dydx\\]"
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities.html#important-properties-of-the-joint-pdf",
    "href": "lessons/12_Joint_distributions/25_Joint_densities.html#important-properties-of-the-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Important properties of the joint pdf",
    "text": "Important properties of the joint pdf\n\nNote that \\(f_{X,Y}(x,y)\\neq \\mathbb{P}(X=x, Y=y)\\)!!!\nIn order for \\(f_{X,Y}(x,y)\\) to be a pdf, it needs to satisfy the properties\n\n\\(f_{X,Y}(x,y)\\geq 0\\) for all \\(x,y\\)\n\\(\\displaystyle\\int_{-\\infty}^{\\infty}\\displaystyle\\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dxdy=1\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "href": "lessons/12_Joint_distributions/25_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "title": "Chapter 25: Joint densities",
    "section": "What is the joint cumulative distribution function?",
    "text": "What is the joint cumulative distribution function?\n\n\nDefinition: Joint cumulative distribution function (Joint CDF)\n\n\nThe joint cumulative distribution function (cdf) of continuous random variables \\(X\\) and \\(Y\\), is the function \\(F_{X,Y}(x,y)\\), such that for all real values of \\(x\\) and \\(y\\), \\[F_{X,Y}(x,y)= \\mathbb{P}(X \\leq x, Y \\leq y) = \\int_{-\\infty}^x\\int_{-\\infty}^y f_{X,Y}(s,t)dtds\\]\n\n\nRemarks:\n\nThe definition above for \\(F_{X,Y}(x,y)\\) is a function of \\(x\\) and \\(y\\).\nThe joint cdf at the point \\((a,b)\\), is \\[F_{X,Y}(a,b) = \\mathbb{P}(X \\leq a, Y \\leq b) = \\int_{-\\infty}^a\\int_{-\\infty}^b f_{X,Y}(s,t)dtds\\]"
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities.html#what-are-the-marginal-pdfs",
    "href": "lessons/12_Joint_distributions/25_Joint_densities.html#what-are-the-marginal-pdfs",
    "title": "Chapter 25: Joint densities",
    "section": "What are the marginal pdf’s?",
    "text": "What are the marginal pdf’s?\n\n\nDefinition: Marginal pdf’s\n\n\nSuppose \\(X\\) and \\(Y\\) are continuous r.v.’s, with joint pdf \\(f_{X,Y}(x,y)\\). Then the marginal probability density functions are \\[\\begin{aligned}\nf_X(x)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dy\\\\\nf_Y(y)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dx\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities.html#common-steps-for-solving-problems",
    "href": "lessons/12_Joint_distributions/25_Joint_densities.html#common-steps-for-solving-problems",
    "title": "Chapter 25: Joint densities",
    "section": "Common steps for solving problems",
    "text": "Common steps for solving problems\n\nSet up the domain of the pdf with a picture\nTranslate to needed integrands\n\nFor probability: shade in the area of interest, then translate\nFor expected value: translate domain\n\nSet up integral: \\(dxdy\\) or \\(dydx\\)?\nSolve integral!"
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities.html#example-of-joint-pdf",
    "href": "lessons/12_Joint_distributions/25_Joint_densities.html#example-of-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)."
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities.html#example-of-joint-pdf-1",
    "href": "lessons/12_Joint_distributions/25_Joint_densities.html#example-of-joint-pdf-1",
    "title": "Chapter 25: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "href": "lessons/12_Joint_distributions/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "href": "lessons/12_Joint_distributions/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "title": "Chapter 25: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(\\mathbb{P}(Y &lt; 3)\\)."
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more",
    "href": "lessons/12_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.1\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nFind \\(\\mathbb{P}(|X-Y| &lt; 2)\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "href": "lessons/12_Joint_distributions/25_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "title": "Chapter 25: Joint densities",
    "section": "Finding the pdf of a transformation",
    "text": "Finding the pdf of a transformation\n\nLet \\(M\\) be a transformation of \\(X\\) and \\(Y\\)\nWhen we have a transformation of \\(X\\) and \\(Y\\), \\(M\\), we need to follow a specific process to find the pdf of \\(M\\)\n\nWe follow this process:\n\nStart with the joint pdf for \\(X\\) and \\(Y\\)\n\naka \\(f_{X,Y}(x, y)\\)\n\nTranslate the domain of \\(X\\) and \\(Y\\) to \\(M\\)\nFind the CDF of \\(M\\)\n\naka \\(F_M(m)\\) or \\(P(M \\leq m)\\)\n\nTake the derivative of the CDF of \\(M\\) to find the pdf of \\(M\\)\n\naka \\(f_M(m) = \\dfrac{d}{dm}F_M(m)\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more-1",
    "href": "lessons/12_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more-1",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.2\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(M = \\max(X,Y)\\). Find the pdf for \\(M\\), that is \\(f_M(m)\\)."
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more-2",
    "href": "lessons/12_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more-2",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 3.3\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(Z = \\min(X,Y)\\). Find the pdf for \\(Z\\), that is \\(f_Z(z)\\)."
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-further",
    "href": "lessons/12_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-further",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even further!",
    "text": "Let’s complicate this even further!\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 4\n\n\nLet \\(X\\) and \\(Y\\) have joint density \\(f_{X,Y}(x,y)= \\frac85(x+y)\\) in the region \\(0 &lt; x &lt; 1,\\ \\frac12 &lt; y &lt;1\\). Find the pdf of the r.v. \\(Z\\), where \\(Z=XY\\)."
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities_key_info.html",
    "href": "lessons/12_Joint_distributions/25_Joint_densities_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 6 assignment today!\n\nFeel free to turn in solutions later than 11/24 since I took so long to grade\n\nI made quite a few changes to the homeworks\n\nHW 10 is gone\nHW 9 is optional\nInstead of a HW assignment due over late November break\n\nHW 8 will include material from Week 8 and 9 and be due 12/5\n\n\nI have quite a bit of grading to catch up on!\nRealizing I never gave you mid-quarter feedback forms…\n\nLet’s chat about this and our assessment breakdown in the coming weeks\n\nAnything else?"
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities_key_info.html#announcements",
    "href": "lessons/12_Joint_distributions/25_Joint_densities_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 6 assignment today!\n\nFeel free to turn in solutions later than 11/24 since I took so long to grade\n\nI made quite a few changes to the homeworks\n\nHW 10 is gone\nHW 9 is optional\nInstead of a HW assignment due over late November break\n\nHW 8 will include material from Week 8 and 9 and be due 12/5\n\n\nI have quite a bit of grading to catch up on!\nRealizing I never gave you mid-quarter feedback forms…\n\nLet’s chat about this and our assessment breakdown in the coming weeks\n\nAnything else?"
  },
  {
    "objectID": "lessons/12_Joint_distributions/25_Joint_densities_key_info.html#key-dates",
    "href": "lessons/12_Joint_distributions/25_Joint_densities_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 7 due\nSunday: HW 6 solutions due"
  },
  {
    "objectID": "lessons/12_Joint_distributions/11_Transformations.html",
    "href": "lessons/12_Joint_distributions/11_Transformations.html",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "",
    "text": "Calculate probabilities for a pair of discrete random variables\nCalculate a joint, marginal, and conditional probability mass function (pmf)\nCalculate a joint, marginal, and conditional cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/11_Transformations.html#learning-objectives",
    "href": "lessons/12_Joint_distributions/11_Transformations.html#learning-objectives",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "",
    "text": "Calculate probabilities for a pair of discrete random variables\nCalculate a joint, marginal, and conditional probability mass function (pmf)\nCalculate a joint, marginal, and conditional cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/11_Transformations.html#where-are-we",
    "href": "lessons/12_Joint_distributions/11_Transformations.html#where-are-we",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/12_Joint_distributions/11_Transformations.html#what-is-a-joint-pmf",
    "href": "lessons/12_Joint_distributions/11_Transformations.html#what-is-a-joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is a joint pmf?",
    "text": "What is a joint pmf?\n\n\nDefinition: joint pmf\n\n\nThe joint pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[p_{X,Y}(x,y) = \\mathbb{P}(X=x\\ and\\ Y=y) = \\mathbb{P}(X=x, Y=y)\\]"
  },
  {
    "objectID": "lessons/12_Joint_distributions/11_Transformations.html#this-chapters-main-example",
    "href": "lessons/12_Joint_distributions/11_Transformations.html#this-chapters-main-example",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "This chapter’s main example",
    "text": "This chapter’s main example\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?"
  },
  {
    "objectID": "lessons/12_Joint_distributions/11_Transformations.html#joint-pmf",
    "href": "lessons/12_Joint_distributions/11_Transformations.html#joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Joint pmf",
    "text": "Joint pmf\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/11_Transformations.html#marginal-pmfs",
    "href": "lessons/12_Joint_distributions/11_Transformations.html#marginal-pmfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Marginal pmf’s",
    "text": "Marginal pmf’s\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/11_Transformations.html#remarks-on-the-joint-pmf",
    "href": "lessons/12_Joint_distributions/11_Transformations.html#remarks-on-the-joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the joint pmf",
    "text": "Remarks on the joint pmf\nSome properties of joint pmf’s:\n\nA joint pmf \\(p_{X,Y}(x,y)\\) must satisfy the following properties:\n\n\\(p_{X,Y}(x,y)\\geq 0\\) for all \\(x, y\\).\n\\(\\sum \\limits_{\\{all\\ x\\}} \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)=1\\).\n\nMarginal pmf’s:\n\n\\(p_X(x) = \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)\\)\n\\(p_Y(y) = \\sum \\limits_{\\{all\\ x\\}} p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/11_Transformations.html#what-is-a-joint-cdf",
    "href": "lessons/12_Joint_distributions/11_Transformations.html#what-is-a-joint-cdf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is a joint CDF?",
    "text": "What is a joint CDF?\n\n\nDefinition: joint CDF\n\n\nThe joint CDF of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[F_{X,Y}(x,y) = \\mathbb{P}(X \\leq x\\ and\\ Y \\leq y) = \\mathbb{P}(X \\leq x, Y \\leq y)\\]"
  },
  {
    "objectID": "lessons/12_Joint_distributions/11_Transformations.html#joint-cdfs",
    "href": "lessons/12_Joint_distributions/11_Transformations.html#joint-cdfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Joint CDFs",
    "text": "Joint CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/11_Transformations.html#marginal-cdfs",
    "href": "lessons/12_Joint_distributions/11_Transformations.html#marginal-cdfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Marginal CDFs",
    "text": "Marginal CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/11_Transformations.html#remarks-on-the-joint-and-marginal-cdf",
    "href": "lessons/12_Joint_distributions/11_Transformations.html#remarks-on-the-joint-and-marginal-cdf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the joint and marginal CDF",
    "text": "Remarks on the joint and marginal CDF\n\n\\(F_X(x)\\): right most columns of the CDf table (where the \\(Y\\) values are largest)\n\\(F_Y(y)\\): bottom row of the table (where X values are largest)\n\\(F_X(x)=\\lim\\limits_{y\\rightarrow\\infty}F_{X, Y}(x,y)\\)\n\\(F_Y(y)=\\lim\\limits_{x\\rightarrow\\infty}F_{X, Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/11_Transformations.html#independence-and-conditioning",
    "href": "lessons/12_Joint_distributions/11_Transformations.html#independence-and-conditioning",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Independence and Conditioning",
    "text": "Independence and Conditioning\nRecall that for events \\(A\\) and \\(B\\),\n\n\\(\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}\\)\n\\(A\\) and \\(B\\) are independent if and only if\n\n\\(\\mathbb{P}(A|B) = \\mathbb{P}(A)\\)\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A)\\cdot\\mathbb{P}(B)\\)\n\n\nIndependence and conditioning are defined similarly for r.v.’s, since \\[p_X(x) = \\mathbb{P}(X=x)\\ \\mathrm{and}\\ \\ p_{X,Y}(x,y) = \\mathbb{P}(X = x ,Y = y).\\]"
  },
  {
    "objectID": "lessons/12_Joint_distributions/11_Transformations.html#what-is-the-conditional-pmf",
    "href": "lessons/12_Joint_distributions/11_Transformations.html#what-is-the-conditional-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is the conditional pmf?",
    "text": "What is the conditional pmf?\n\n\nDefinition: conditional pmf\n\n\nThe conditional pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is defined as \\[p_{X|Y}(x|y) = \\mathbb{P}(X = x |Y = y) = \\frac{\\mathbb{P}(X = x\\ and\\ Y = y)}{\\mathbb{P}(Y = y)}\n=\\frac{p_{X,Y}(x,y) }{p_{Y}(y) }\\] if \\(p_{Y}(y) &gt; 0\\)."
  },
  {
    "objectID": "lessons/12_Joint_distributions/11_Transformations.html#remarks-on-the-conditional-pmf",
    "href": "lessons/12_Joint_distributions/11_Transformations.html#remarks-on-the-conditional-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the conditional pmf",
    "text": "Remarks on the conditional pmf\nThe following properties follow from the conditional pmf definition:\n\nIf \\(X \\perp Y\\) (independent)\n\n\\(p_{X|Y}(x|y) = p_X(x)\\) for all \\(x\\) and \\(y\\)\n\\(p_{X,Y}(x,y) = p_X(x)p_Y(y)\\) for all \\(x\\) and \\(y\\)\nWhich also implies (\\(\\Rightarrow\\)): \\(F_{X,Y}(x,y) = F_X(x)F_Y(y)\\) for all \\(x\\) and \\(y\\)\n\nIf \\(X_1, X_2, …, X_n\\) are independent\n\n\\[p_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1=x_1, X_2=x_2, …, X_n=x_n)=\\prod\\limits_{i=1}^np_{X_i}(x_i)\\]\n\\[F_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1\\leq x_1, X_2\\leq x_2, …, X_n\\leq x_n)=\\prod\\limits_{i=1}^nP(X_i \\leq x_i) = \\prod\\limits_{i=1}^nF_{X_i}(x_i)\\]"
  },
  {
    "objectID": "lessons/12_Joint_distributions/11_Transformations.html#conditional-pmfs",
    "href": "lessons/12_Joint_distributions/11_Transformations.html#conditional-pmfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Conditional pmf’s",
    "text": "Conditional pmf’s\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?\n\n\n\n\n\nRemark:\n\nTo show that \\(X\\) and \\(Y\\) are not independent, we just need to find one counter example\nHowever, to show that they are independent, we need to verify this for all possible pairs of \\(x\\) and \\(y\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/11_Transformations.html#hypothetical-4-sided-die",
    "href": "lessons/12_Joint_distributions/11_Transformations.html#hypothetical-4-sided-die",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Hypothetical 4-sided die",
    "text": "Hypothetical 4-sided die\n\n\nExample 3\n\n\n\nSuppose you have a 4-sided die, and you roll the 4-sided die until the first 4 appears.\nLet \\(X\\) be the number of rolls required until (and including) the first 4.\nAfter the first 4, you keep rolling it again until you roll a 3.\nLet \\(Y\\) be the number of rolls, after the first 4, required until (and including) the 3.\n\n\nFind \\(p_{X,Y}(x,y)\\).\nUsing \\(p_{X,Y}(x,y)\\), find \\(p_{Y}(y)\\).\nFind \\(p_{X}(x)\\).\nAre \\(X\\) and \\(Y\\) are independent? Why or why not?\nFind \\(F_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions_key_info.html",
    "href": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "LAST CLASS!!!!\nHomework 7and 6 solutions are graded\nHW 7 meetings are up on Calendly\n\nSee my announcement from Sakai\n\nI will be finalizing and posting HW 9 tomorrow\n\nOptional!\n\nPlease do your course evals!!\n\nEspecially in a small class\n\nFriday 12/13 is the absolute deadline for turning in materials if you are completing the course! _ Check Sakai that I have all your HW grades in!\nAnything else?"
  },
  {
    "objectID": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions_key_info.html#announcements",
    "href": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "LAST CLASS!!!!\nHomework 7and 6 solutions are graded\nHW 7 meetings are up on Calendly\n\nSee my announcement from Sakai\n\nI will be finalizing and posting HW 9 tomorrow\n\nOptional!\n\nPlease do your course evals!!\n\nEspecially in a small class\n\nFriday 12/13 is the absolute deadline for turning in materials if you are completing the course! _ Check Sakai that I have all your HW grades in!\nAnything else?"
  },
  {
    "objectID": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions_key_info.html#key-dates",
    "href": "lessons/20_Moment_Generating_Functions/20_Moment_Generating_Functions_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday (12/5): HW 8 assignment due\nSunday (12/8): HW 7 presentations due at 11pm\n\nI can be pretty flexible until 12/13\n\nThursday (12/12): Optional HW 9 assignment due\nFriday (12/13): HW 8 solutions due"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html",
    "href": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "",
    "text": "Show that a joint pdf consists of two independent, continuous RVs.\nCombine two independent RVs into one joint pdf or CDF.\n\n\n\n\n\nWhat do we know about independence for events and discrete RVs?\nFor events: If \\(A \\perp B\\)\n\\[P(A \\cap B) = P(A)P(B)\\] \\[P(A|B) = P(A)\\]\nFor discrete RVs: If \\(X \\perp Y\\) \\[p_{X,Y}(x,y) = p_{X}(x)p_{Y}(y)\\] \\[F_{X,Y}(x,y) = F_{X}(x)F_{Y}(y)\\] \\[p_{X|Y}(x|y) = p_{X}(x)\\] \\[p_{Y|X}(y|x) = p_{Y}(y)\\]\n\n\n\nWhat does it mean for continuous r.v.’s to be independent?\nFor continuous RVs: If \\(X \\perp Y\\)\n\n\n\n\n\n\n\n\n\nExample 1.1\n\n\nLet \\(X\\) and \\(Y\\) be independent r.v.’s with \\(f_X(x)= \\frac12\\), for \\(0 \\leq x \\leq 2\\) and \\(f_Y(y)= 3y^2\\), for \\(0 \\leq y \\leq 1\\).\n\nFind \\(f_{X,Y}(x,y)\\).\n\n\n\n\n\n\n\n\n\n\n\n\nExample 1.2\n\n\nLet \\(X\\) and \\(Y\\) be independent r.v.’s with \\(f_X(x)= \\frac12\\), for \\(0 \\leq x \\leq 2\\) and \\(f_Y(y)= 3y^2\\), for \\(0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\).\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for \\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\).\n\nAre \\(X\\) and \\(Y\\) independent?\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for \\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(F_{X,Y}(x,y)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 3\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Are \\(X\\) and \\(Y\\) independent?\n\n\n\n\n\n\n\n\nIf \\(f_{X,Y}(x,y)= g(x)h(y)\\), where \\(g(x)\\) and \\(h(y)\\) are pdf’s, then \\(X\\) and \\(Y\\) are independent.\n\nThe domain of the joint pdf needs to be independent as well!!\n\n\n       \n\nIf \\(F_{X,Y}(x,y)= G(x)H(y)\\), where \\(G(x)\\) and \\(H(y)\\) are cdf’s, then \\(X\\) and \\(Y\\) are independent.\n\nThe domain of the joint CDF needs to be independent as well!!"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#how-do-we-represent-independent-continuous-rvs-in-a-joint-pdf",
    "href": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#how-do-we-represent-independent-continuous-rvs-in-a-joint-pdf",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "",
    "text": "What do we know about independence for events and discrete RVs?\nFor events: If \\(A \\perp B\\)\n\\[P(A \\cap B) = P(A)P(B)\\] \\[P(A|B) = P(A)\\]\nFor discrete RVs: If \\(X \\perp Y\\) \\[p_{X,Y}(x,y) = p_{X}(x)p_{Y}(y)\\] \\[F_{X,Y}(x,y) = F_{X}(x)F_{Y}(y)\\] \\[p_{X|Y}(x|y) = p_{X}(x)\\] \\[p_{Y|X}(y|x) = p_{Y}(y)\\]\n\n\n\nWhat does it mean for continuous r.v.’s to be independent?\nFor continuous RVs: If \\(X \\perp Y\\)"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs",
    "href": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "",
    "text": "Example 1.1\n\n\nLet \\(X\\) and \\(Y\\) be independent r.v.’s with \\(f_X(x)= \\frac12\\), for \\(0 \\leq x \\leq 2\\) and \\(f_Y(y)= 3y^2\\), for \\(0 \\leq y \\leq 1\\).\n\nFind \\(f_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs-1",
    "href": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#constructing-a-joint-pdf-from-two-independent-continuous-rvs-1",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "",
    "text": "Example 1.2\n\n\nLet \\(X\\) and \\(Y\\) be independent r.v.’s with \\(f_X(x)= \\frac12\\), for \\(0 \\leq x \\leq 2\\) and \\(f_Y(y)= 3y^2\\), for \\(0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)."
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#showing-independence-from-joint-pdf",
    "href": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#showing-independence-from-joint-pdf",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "",
    "text": "Example 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for \\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\).\n\nAre \\(X\\) and \\(Y\\) independent?"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#finding-cdf-from-two-independent-rvs",
    "href": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#finding-cdf-from-two-independent-rvs",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "",
    "text": "Example 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for \\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(F_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#showing-independence-from-joint-pdf-1",
    "href": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#showing-independence-from-joint-pdf-1",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "",
    "text": "Do this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 3\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Are \\(X\\) and \\(Y\\) independent?"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#final-statement-on-independence",
    "href": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#final-statement-on-independence",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "",
    "text": "If \\(f_{X,Y}(x,y)= g(x)h(y)\\), where \\(g(x)\\) and \\(h(y)\\) are pdf’s, then \\(X\\) and \\(Y\\) are independent.\n\nThe domain of the joint pdf needs to be independent as well!!\n\n\n       \n\nIf \\(F_{X,Y}(x,y)= G(x)H(y)\\), where \\(G(x)\\) and \\(H(y)\\) are cdf’s, then \\(X\\) and \\(Y\\) are independent.\n\nThe domain of the joint CDF needs to be independent as well!!"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#conditional-probabilities-weve-seen-before",
    "href": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#conditional-probabilities-weve-seen-before",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "Conditional probabilities we’ve seen before",
    "text": "Conditional probabilities we’ve seen before\n\n\nWhat do we know about conditional probabilities for events and discrete RVs?    \nFor events:\n\\[P(A | B) = \\dfrac{P(A \\cap B)}{P(B)}\\]    \nFor discrete RVs: \\[p_{X|Y}(x|y) = P(X=x|Y=y) = \\dfrac{p_{X,Y}(x,y)}{p_Y(y)}\\]\n\n\n\nWhat does it mean for conditional densities of continuous RVs?\nFor continuous RVs:"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#example-starting-from-a-joint-pdf-first-try",
    "href": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#example-starting-from-a-joint-pdf-first-try",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "Example starting from a joint pdf: first try!",
    "text": "Example starting from a joint pdf: first try!\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(2&lt;X&lt;10|Y=4)\\)"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#what-is-a-conditional-density",
    "href": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#what-is-a-conditional-density",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "What is a conditional density?",
    "text": "What is a conditional density?\n\n\n\n\nDefinition: Conditional density\n\n\nThe conditional density of a r.v. \\(X\\) given \\(Y=y\\), is \\[f_{X|Y}(x|y)= \\frac{f_{X,Y}(x,y)}{f_Y(y)},\\] for \\(f_Y(y)&gt; 0\\)\n\n\n\n\n\nRemarks\n\nIt follows from the definition for the conditional density \\(f_{X|Y}(x|y)\\), that \\[f_{X,Y}(x,y)= f_{X|Y}(x|y)f_Y(y).\\]\n\n     \n\nFor a fixed value of \\(Y=y\\), the conditional density \\(f_{X|Y}(x|y)\\) is an actual pdf, meaning\n\n\\(f_{X|Y}(x|y)\\geq 0\\) for all \\(x\\) and \\(y\\), and\n\\(\\displaystyle\\int_{-\\infty}^{\\infty} f_{X|Y}(x|y)dx =1\\)."
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#example-starting-from-a-joint-pdf-second-try-12",
    "href": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#example-starting-from-a-joint-pdf-second-try-12",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "Example starting from a joint pdf: second try! (1/2)",
    "text": "Example starting from a joint pdf: second try! (1/2)\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(2&lt;X&lt;10|Y=4)\\)"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#example-starting-from-a-joint-pdf-second-try-22",
    "href": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#example-starting-from-a-joint-pdf-second-try-22",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "Example starting from a joint pdf: second try! (2/2)",
    "text": "Example starting from a joint pdf: second try! (2/2)"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#example-starting-from-a-joint-pdf",
    "href": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#example-starting-from-a-joint-pdf",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "Example starting from a joint pdf",
    "text": "Example starting from a joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(X&gt;20 |Y=5)\\)"
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#finding-probability-with-conditional-domain-and-pdf",
    "href": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#finding-probability-with-conditional-domain-and-pdf",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "Finding probability with conditional domain and pdf",
    "text": "Finding probability with conditional domain and pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 2\n\n\nRandomly choose a point \\(X\\) from the interval \\([0,1]\\), and given \\(X=x\\), randomly choose a point \\(Y\\) from \\([0,x]\\). Find \\(\\mathbb{P}(0 &lt; Y &lt; \\frac14)\\)."
  },
  {
    "objectID": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#independence-and-conditional-distributions",
    "href": "lessons/13_Independence_Conditioning/13_Independence_conditioning.html#independence-and-conditional-distributions",
    "title": "Lesson 13: Independence and Conditioning",
    "section": "Independence and conditional distributions",
    "text": "Independence and conditional distributions\n    Question What is \\(f_{X|Y}(x|y)\\) if \\(X\\) and \\(Y\\) are independent?\n\\[f_{X|Y}(x|y) = \\dfrac{f_{X,Y}(x,y)}{f_y(y)} = \\dfrac{f_{X}(x)f_y(y)}{f_y(y)} = f_{X}(x)\\]\n       \n\nIf \\(f_{X|Y}(x|y)\\) does not depend on \\(y\\) (including the bounds/domain), then \\(X\\) and \\(Y\\) are independent."
  },
  {
    "objectID": "lessons/16_Variance/29_Variance_and_Sums_of_rv.html",
    "href": "lessons/16_Variance/29_Variance_and_Sums_of_rv.html",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "",
    "text": "Calculate expected value of functions of RVs\nCalculate variance of RVs"
  },
  {
    "objectID": "lessons/16_Variance/29_Variance_and_Sums_of_rv.html#learning-objectives",
    "href": "lessons/16_Variance/29_Variance_and_Sums_of_rv.html#learning-objectives",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "",
    "text": "Calculate expected value of functions of RVs\nCalculate variance of RVs"
  },
  {
    "objectID": "lessons/16_Variance/29_Variance_and_Sums_of_rv.html#expected-value-of-a-function-of-a-continuous-rv",
    "href": "lessons/16_Variance/29_Variance_and_Sums_of_rv.html#expected-value-of-a-function-of-a-continuous-rv",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Expected value of a function of a continuous RV",
    "text": "Expected value of a function of a continuous RV\n\n\nHow do we calculate the expected value of a function of a discrete RV or joint RVs?\n   \nFor discrete RVs:\n\\[\\mathbb{E}[g(X)] = \\sum_{\\{all\\ x\\}}\\ g(x) p_X(x).\\] \\[\\mathbb{E}[g(X, Y)] = \\sum_{\\{all\\ x\\}}\\sum_{\\{all\\ y\\}}\\ g(x,y) p_{X,Y}(x,y).\\]\n\n\n\nHow do we calculate the expected value of a function of a continuous RV or joint RVs?\n   \nFor continuous RVs:"
  },
  {
    "objectID": "lessons/16_Variance/29_Variance_and_Sums_of_rv.html#important-properties-of-expected-values-of-functions-of-continuous-rvs",
    "href": "lessons/16_Variance/29_Variance_and_Sums_of_rv.html#important-properties-of-expected-values-of-functions-of-continuous-rvs",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Important properties of expected values of functions of continuous RVs",
    "text": "Important properties of expected values of functions of continuous RVs\n\n\n\n\nFunction of RV with two constants\n\n\n\\(\\mathbb{E}[aX+b] =a\\mathbb{E}[X]+b\\)\n\n\n\n\nFunction of two RVs added\n\n\n\\(\\mathbb{E}[X+Y] =\\mathbb{E}[X]+\\mathbb{E}[Y]\\)\n\n\n\n\nExpected value of sum of independent RVs pt 1\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are continuous RVs and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\[\\mathbb{E}\\Bigg[\\sum_{i=1}^{n} a_i X_i\\Bigg] = \\sum_{i=1}^{n}a_i\\mathbb{E}[X_i]\\]\n\n\n\n\n\nExpected value of multiplication of function of independent RVs\n\n\nIf \\(X\\) and \\(Y\\) are independent continuous RVs, and \\(g\\) and \\(h\\) are functions, then \\[\\mathbb{E}[g(X)h(Y)] =\\mathbb{E}[g(X)]\\mathbb{E}[h(Y)]\\]\n\n\n\n\nExpected value of multiplication of independent RVs\n\n\nIf \\(X\\) and \\(Y\\) are independent continuous RVs, then \\[\\mathbb{E}[XY] = \\mathbb{E}[X] \\mathbb{E}[Y] \\]"
  },
  {
    "objectID": "lessons/16_Variance/29_Variance_and_Sums_of_rv.html#variance-of-continuous-rvs",
    "href": "lessons/16_Variance/29_Variance_and_Sums_of_rv.html#variance-of-continuous-rvs",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Variance of continuous RVs",
    "text": "Variance of continuous RVs\n\n\nHow do we calculate the variance of a discrete RV?\n   \nFor discrete RVs:\n\\[\n\\begin{align}\nVar(X) & =\n\\mathbb{E}[(X-\\mu_X)^2] \\\\ & = \\mathbb{E}[(X-\\mathbb{E}[X])^2] \\\\ &= \\mathbb{E}[X^2]-(\\mathbb{E}[X])^2 \\\\ & = \\sum_{\\{all\\ x\\}}(x-\\mu_x)^2 p_{X}(x)\n\\end{align}\n\\]\n\n\n\nHow do we calculate the variance of a continuous RV?\n    \nFor continuous RVs:"
  },
  {
    "objectID": "lessons/16_Variance/29_Variance_and_Sums_of_rv.html#variance-of-an-uniform-distribution",
    "href": "lessons/16_Variance/29_Variance_and_Sums_of_rv.html#variance-of-an-uniform-distribution",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Variance of an Uniform distribution",
    "text": "Variance of an Uniform distribution\n\n\n\n\nExample 2\n\n\nLet \\(f_X(x)= \\frac{1}{b-a}\\), for \\(a \\leq x \\leq b\\). Find \\(Var[X]\\)."
  },
  {
    "objectID": "lessons/16_Variance/29_Variance_and_Sums_of_rv.html#variance-of-exponential-distribution",
    "href": "lessons/16_Variance/29_Variance_and_Sums_of_rv.html#variance-of-exponential-distribution",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Variance of exponential distribution",
    "text": "Variance of exponential distribution\n\n\nIn the homework:\n\n\nExample 3\n\n\nLet \\(f_X(x)= \\lambda e^{-\\lambda x}\\), for \\(x &gt; 0\\) and \\(\\lambda&gt; 0\\). Find \\(Var[X]\\)."
  },
  {
    "objectID": "lessons/16_Variance/29_Variance_and_Sums_of_rv.html#important-properties-of-variances-of-continuous-rvs",
    "href": "lessons/16_Variance/29_Variance_and_Sums_of_rv.html#important-properties-of-variances-of-continuous-rvs",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Important properties of variances of continuous RVs",
    "text": "Important properties of variances of continuous RVs\n\n\n\n\nFunction of RV with two constants\n\n\n\\[Var[aX+b] = a^2Var[X]\\]\n\n\n\n\n\nVariance of sum of independent RVs pt 1\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous RVs and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\[Var\\Bigg(\\sum_{i=1}^{n} a_i X_i\\Bigg) =\\sum_{i=1}^{n} a^2_i Var(X_i)\\]\n\n\n\n\nVariance of sum of independent RVs pt 2\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous RVs, then \\[Var\\Bigg(\\sum_{i=1}^{n} X_i\\Bigg) = \\sum_{i=1}^{n} Var(X_i)\\]"
  },
  {
    "objectID": "lessons/16_Variance/29_Variance_and_Sums_of_rv.html#find-the-mean-and-sd-from-word-problem",
    "href": "lessons/16_Variance/29_Variance_and_Sums_of_rv.html#find-the-mean-and-sd-from-word-problem",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Find the mean and sd from word problem",
    "text": "Find the mean and sd from word problem\n\n\n\n\nExample 4\n\n\nA machine manufactures cubes with a side length that varies uniformly from 1 to 2 inches. Assume the sides of the base and height are equal. The cost to make a cube is 10 ¢ per cubic inch, and 5 ¢ cents for the general cost per cube. Find the mean and standard deviation of the cost to make 10 cubes."
  },
  {
    "objectID": "lessons/16_Variance/16_Variance_muddy_points.html",
    "href": "lessons/16_Variance/16_Variance_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy Points from Fall 2023:\n\n1. Proof of variance formula\nHere is the variance formula that we worked through on slide 9 of Chapter 12’s notes.\n\n\n\n\n\n\nLemma 6: “Computation formula” for variance\n\n\n\nThe variance of a r.v. \\(X\\), can be computed as \\[\\begin{align}\\sigma_X^2 & =Var(X) \\\\ & = \\mathbb{E}[X^2]-\\mu_X^2 \\\\ & = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2\\end{align}\\]\n\n\nI stepped through this quite quickly and made some implicit steps. So let’s revisit it with explicit steps!\n       \n\n\n2. What progression are we following in the course??\nSomeone asked if this is our progression: RV is function \\(\\to\\) Expected value is function to describe mean of RV \\(\\to\\) Use functions within expected value to set up variance\nBasically, yes! The random variable is a function of a random process. The RV inherits that randomness.\nFrom there, we’ve been working towards calculating the probability of a realized value ($x$) of the RV. The probability can be different for different realized values (as it links back to the random process).\nWe also want to construct ways to describe our random variables. We may want to figure out what to expect from our random variable (which translates to the mean value of the RV). Since our RV is rooted in a random process, we may want to get an idea of how spread out our realized values are. We use our expected value (mean) as an anchor in our spread. Variance is one way to measure this spread."
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "",
    "text": "Distinguish between Bernoulli, Binomial, Geometric, Hypergeometric, Discrete Uniform, Negative Binomial, and Poisson distributions when reading a story.\nIdentify the variable and the parameters in a story, and state what the variable and parameters mean.\nUse the formulas for the pmf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#learning-objectives",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#learning-objectives",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "",
    "text": "Distinguish between Bernoulli, Binomial, Geometric, Hypergeometric, Discrete Uniform, Negative Binomial, and Poisson distributions when reading a story.\nIdentify the variable and the parameters in a story, and state what the variable and parameters mean.\nUse the formulas for the pmf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#where-are-we",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#where-are-we",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#properties-of-bernoulli-rvs",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#properties-of-bernoulli-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Bernoulli RVs",
    "text": "Properties of Bernoulli RVs\n\nScenario: One trial, with outcome success or failure\nShorthand: \\(X \\sim \\text{Bernoulli}(p)\\)\n\n\\[\nX = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\quad \\\\\n            0 & \\quad \\mathrm{with\\ probability}\\ 1-p \\quad\n        \\end{array}\n    \\right.\n\\]\n\\[\np_X(x) = P(X=x) = p^x(1-p)^{1-x} \\text{ for } x=0,1\n\\]\n\\[\\text{E}(X) = p\\]\n\\[\\text{Var}(X) = pq = p(1-p)\\]"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#bernoulli-example-1",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#bernoulli-example-1",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bernoulli Example 1",
    "text": "Bernoulli Example 1\n\n\n\n\nExample 1\n\n\n\nWe roll a fair 6-sided die.\nWe get $1 if we roll a 5, and nothing otherwise.\nLet \\(X\\) be how much money we get.\nFind the mean and variance of \\(X\\)."
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#properties-of-binomial-rvs",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#properties-of-binomial-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Binomial RVs",
    "text": "Properties of Binomial RVs\n\nScenario: There are \\(n\\) independent trials, each resulting in a success or failure, with constant probability, \\(p\\), in each trial. We are counting the number of successes (or failures).\nShorthand: \\(X \\sim \\text{Binomial}(n, p)\\)\n\n\\[\nX = \\text{Number of successes of } n \\text{ independent trials}\n\\]\n\\[\np_X(x) = P(X=x) = {n \\choose x}p^x(1-p)^{n-x} \\text{ for } x=0,1,2,  ..., n\n\\]\n\\[\\text{E}(X) = np\\] \\[\\text{Var}(X) = npq = np(1-p)\\]"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#our-beloved-fair-sided-die",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#our-beloved-fair-sided-die",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Our beloved fair-sided die",
    "text": "Our beloved fair-sided die\n\n\n\n\nExample 2\n\n\n\nSuppose we roll a fair 6-sided die 50 times.\nWe get $1 every time we roll a 5, and nothing otherwise.\nLet \\(X\\) be how much money we get on the 50 rolls.\nFind the mean and variance of \\(X\\)."
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#geometric-rvs",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#geometric-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Geometric RVs",
    "text": "Geometric RVs\n\nScenario: There are repeated independent trials, each resulting in a success or failure, with constant probability of success for each trial. We are counting the number of trials until the first success.\nShorthand: \\(X \\sim \\text{Geo}(p)\\) or \\(X \\sim \\text{Geometric}(p)\\) or \\(X \\sim \\text{G}(p)\\)\n\n\n\n\n\n\n\n\n\\(X =\\) Number of trials needed for first success (count \\(x\\) includes the success)\n\\(X =\\) Number of failures before first success (count \\(x\\) does not include the success)\n\n\n\n\n\\(p _\nX( x ) = P(X=x) = (1-p)^{x-1}p\\)\nfor \\(x=1,2, 3,...\\)\n\\[F_\nX(x ) = P(X\\leq x) = 1-(1-p)^x\\]\nfor \\(x=1,2, 3,...\\)\n\\(p _X (x)= P(X=x) = (1-p)^{x}p\\)\nfor \\(x=0, 1,2,...\\)\n\\[F_X ( x\n)\n= P(X\\leq x) = 1-(1-p)^{x+1}\\]\nfor \\(x=0, 1,2,...\\)\n\n\n\\(E(X)=\\dfrac{1}{p}\\)\n\\(Var(X)= \\dfrac{1-p}{p^2}\\)\n\\(E(X)=\\dfrac{1-p}{p}\\)\n\\(Var(X) = \\dfrac{1-p}{p^2}\\)"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#bullseye-14",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#bullseye-14",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (1/4)",
    "text": "Bullseye (1/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the pmf for the number of throws needed to hit the bullseye?\nWhat are the mean and variance for the number of throws needed to hit the bullseye?\nFind the probability that our first bullseye:\n\nis on one of the first fifty tries\nis after the \\(50^{th}\\) try, given that it did not happen on the first 20 tries"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#bullseye-24",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#bullseye-24",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (2/4)",
    "text": "Bullseye (2/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the pmf for the number of throws needed to hit the bullseye?"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#bullseye-34",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#bullseye-34",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (3/4)",
    "text": "Bullseye (3/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat are the mean and variance for the number of throws needed to hit the bullseye?"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#bullseye-44",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#bullseye-44",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (4/4)",
    "text": "Bullseye (4/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nFind the probability that our first bullseye:\n\nis on one of the first fifty tries\nis after the \\(50^{th}\\) try, given that it did not happen on the first 20 tries"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#memoryless-property-for-geometric-rvs",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#memoryless-property-for-geometric-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Memoryless property for Geometric RVs",
    "text": "Memoryless property for Geometric RVs\nIf we know \\(X\\) is greater than some number (aka given \\(X &gt;j\\)), then the probability of \\(X &gt; k+j\\) is just the probability that \\(X&gt;k\\).\n \n\\(P(X &gt; k+j |X &gt; j) = P(X &gt; k)\\) \\[ P(X &gt; k+j |X &gt; j) = \\dfrac{P(X&gt;k+j \\text{ and } X&gt;j)}{P(X&gt;j)} = \\dfrac{P(X&gt;k+j)}{P(X&gt;j)} = \\dfrac{(1-p)^{k+j}}{(1-p)^{j}} = (1-p)^{k} \\]"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#properties-of-negative-binomial-rvs",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#properties-of-negative-binomial-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Negative Binomial RVs",
    "text": "Properties of Negative Binomial RVs\n\nScenario: There are repeated independent trials, each resulting in a success or failure, with constant probability of success for each trial. We are counting the number of trials until the \\(r^{th}\\) success.\nShorthand: \\(X \\sim \\text{NegBin}(p, r)\\) or \\(X \\sim \\text{NB}(p, r)\\)\nNegative binomial is sum of \\(r\\) geometric distributions\n\n\\[\nX = \\text{Number of independent trials until } r^{th} \\text{ success}\n\\]\n\\[ p_X(x) = P(X=x) = {x-1 \\choose r-1}(1-p)^{x-r}p^r \\text{ for } x = r, r+1, r+2, ...\\]\n\\[ E(X) = \\dfrac{r}{p}\\]\n\\[Var(X) = \\dfrac{rq}{p^2} = \\dfrac{r(1-p)}{p^2}\\]"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#hitting-more-than-1-bullseye",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#hitting-more-than-1-bullseye",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Hitting more than 1 bullseye",
    "text": "Hitting more than 1 bullseye\n\n\n\n\nExample 1\n\n\nConsider again the bullseye example, where we throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the expected value and variance of the number of throws needed to hit 5 bullseyes?"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#hitting-more-than-1-bullseye-1",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#hitting-more-than-1-bullseye-1",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Hitting more than 1 bullseye",
    "text": "Hitting more than 1 bullseye\n\n\n\n\nExample 1\n\n\nConsider again the bullseye example, where we throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the probability that the \\(5^{th}\\) bullseye is on the \\(20^{th}\\) throw?"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#properties-of-poisson-rvs",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#properties-of-poisson-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Poisson RVs",
    "text": "Properties of Poisson RVs\n\nScenario: We are counting the number of successes in a fixed time period, which has a constant rate of successes\nShorthand: \\(X \\sim \\text{Poisson}(\\lambda)\\) or \\(X \\sim \\text{Pois}(\\lambda)\\)\n\n\\[\nX = \\text{Number of successes in a given period}\n\\]\n\\[ p_X(x) = P(X=x) = \\dfrac{e^{-\\lambda}\\lambda^x}{x!} \\text{ for } x = 0, 1, 2,3, ...\\]\n\\[ \\text{E}(X) = \\lambda\\]\n\\[\\text{Var}(X) = \\lambda\\]"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#distinguishing-between-binomial-and-poisson-rvs",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#distinguishing-between-binomial-and-poisson-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Distinguishing between Binomial and Poisson RVs",
    "text": "Distinguishing between Binomial and Poisson RVs\n\nRecall that if \\(X\\sim \\text{Binomial}(n,p)\\), then\n\n\\(X\\) models the number of successes …\nin \\(n\\) independent (Bernoulli) trials …\nthat each have the same probability of success \\(p\\).\n\nPoisson r.v.’s are similar,\n\nexcept that instead of having \\(n\\) discrete independent trials,\nthere is a fixed time period (or space) during which the successes happen"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#examples-of-poisson-rvs",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#examples-of-poisson-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Examples of Poisson RVs",
    "text": "Examples of Poisson RVs\n\nNumber of visitors to an emergency room in an hour during a weekend night\nNumber of study participants enrolled in a study per week\nNumber of pedestrians walking through a square mile\nAny more?"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#emergency-room-visitors",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#emergency-room-visitors",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Emergency Room Visitors",
    "text": "Emergency Room Visitors\n\n\n\n\nExample 1\n\n\nSuppose an emergency room has an average of 50 visitors per day. Find the following probabilities.\n\nProbability of 30 visitors in a day.\nProbability of 8 visitors in an hour.\nProbability of at least 8 visitors in an hour."
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#combining-independent-poisson-distributions",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#combining-independent-poisson-distributions",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Combining independent Poisson distributions",
    "text": "Combining independent Poisson distributions\n\n\nTheorem 1\n\n\nIf \\(X\\sim Pois(\\lambda_1)\\) and \\(Y\\sim Pois(\\lambda_2)\\) are independent of each other, then \\(Z=X+Y\\sim Pois(\\lambda_1 + \\lambda_2)\\)."
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#two-emergency-rooms",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#two-emergency-rooms",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Two emergency rooms",
    "text": "Two emergency rooms\n\n\n\n\nExample 2\n\n\nSuppose emergency room 1 has an average of 50 visitors per day, and emergency room 2 has an average of 70 visitors per day, independently of each other. What is the probability distribution to model of the total number of visitors to both?"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#poisson-approximation-of-the-binomial",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#poisson-approximation-of-the-binomial",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Poisson Approximation of the Binomial",
    "text": "Poisson Approximation of the Binomial\nBoth Poisson and Binomial r.v.’s are counting the number of successes\n\nIf for a Binomial r.v.\n\nthe number of trials \\(n\\) is very large, and\nthe probability of success \\(p\\) is close to 0 or 1,\n\nThen the Poisson distribution can be used to approximate Binomial probabilities\n\nand we use \\(\\lambda = np\\)\n\nRule of thumb: We can use the Poisson approximation when \\(\\dfrac{1}{10} \\leq np(1-p) \\leq 10\\)"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#medical-lab-errors",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#medical-lab-errors",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Medical lab errors",
    "text": "Medical lab errors\n\n\n\n\nExample 3\n\n\nSuppose that in the long run, errors in a medical testing lab are made 0.1% of the time. Find the probability that fewer than 4 mistakes are made in the next 2,000 tests.\n\nFind the probability using the Binomial distribution.\nApproximate the probability in part (1) using the Poisson distribution.\n\n\n\n\nTo do for extra practice - will also see a similar problem in BSTA 511"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#hypergeometric-rvs",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#hypergeometric-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Hypergeometric RVs",
    "text": "Hypergeometric RVs\n\nScenario: There are a fixed number of successes and failures (which are known in advance), from which we make \\(n\\) draws without replacement. We are counting the number of successes from the \\(n\\) trials.\n\nThere is a finite population of \\(N\\) items\nEach item in the population is either a success or a failure, and there are \\(M\\) successes total.\nWe randomly select (sample) \\(n\\) items from the population without replacement\n\nShorthand: \\(X \\sim \\text{Hypergeo}(M, N, n)\\)\n\n\n\n\\[\nX = \\text{Number of successes in } n \\text{ draws}\n\\]\n\\[\np_X(x) = P(X=x) = \\dfrac{{M \\choose x}{N-M \\choose n-x}}{{N \\choose n}}\n\\] \\[\\text{ for } x \\text{ integer-valued } \\\\ \\max(0, n-(N-M)) \\leq x \\leq \\min(n, M)\\]\n\n\\[\\text{E}(X) =\\dfrac{nM}{N}\\]\n\\[\\text{Var}(X) = n \\dfrac{M}{N} \\bigg(1- \\dfrac{M}{N} \\bigg)\\bigg(\\dfrac{N-n}{N-1} \\bigg)\\]"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#wolf-population",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#wolf-population",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Wolf population",
    "text": "Wolf population\n\n\n\n\nExample 4\n\n\nA wildlife biologist is using mark-recapture to research a wolf population. Suppose a specific study region is known to have 24 wolves, of which 11 have already been tagged. If 5 wolves are randomly captured, what is the probability that 3 of them have already been tagged?"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#binomial-approximation-of-the-hypergeometric-rv",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#binomial-approximation-of-the-hypergeometric-rv",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Binomial approximation of the hypergeometric RV",
    "text": "Binomial approximation of the hypergeometric RV\nSuppose a hypergeometric RV \\(X\\) has the following properties:\n\nthe population size \\(N\\) is really big,\nthe number of successes \\(M\\) in the population is relatively large,\n\n\\(\\frac{M}{N}\\) shouldn’t be close to 0 or 1\n\nand the number of items \\(n\\) selected is small\nRule of thumb: \\(\\dfrac{n}{N}&lt;0.05\\) or \\(N&gt;20n\\)\n\nThen, in this case, making \\(n\\) draws from the population doesn’t change the probability of success much, and the hypergeometric RV. can be approximated by a binomial RV"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#wolf-population-revisited",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#wolf-population-revisited",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Wolf population revisited",
    "text": "Wolf population revisited\n\n\n\n\nExample 5\n\n\nSuppose a specific study region is known to have 2400 wolves, of which 1100 have already been tagged.\n\nIf 50 wolves are randomly captured, what is the probability that 20 of them have already been tagged?\nApproximate the probability in part (1) using the binomial distribution."
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#discrete-uniform-rvs",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#discrete-uniform-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Discrete Uniform RVs",
    "text": "Discrete Uniform RVs\n\nScenario: There are \\(N\\) possible outcomes, which are all equally likely.\nShorthand: \\(X \\sim \\text{Uniform}(N)\\)\n\n\\[\nX = \\text{Outcome of interest, with } x=1, 2, ..., N\n\\]\n\\[\np_X(x) = P(X=x) = \\dfrac{1}{N} \\text{ for } x=1, 2, 3, ..., N\n\\]\n\\[\\text{E}(X) =\\dfrac{N+1}{2}\\]\n\\[\\text{Var}(X) = \\dfrac{N^2 -1}{12}\\]"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#what-discrete-uniform-rvs-have-we-seen-already",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs.html#what-discrete-uniform-rvs-have-we-seen-already",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "What discrete uniform RVs have we seen already?",
    "text": "What discrete uniform RVs have we seen already?\n\n\n\n\nExample 6\n\n\nExamples of discrete uniform RVs"
  },
  {
    "objectID": "lessons/17_Discrete_RVs/17_Discrete_RVs_muddy_points.html",
    "href": "lessons/17_Discrete_RVs/17_Discrete_RVs_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "1. In-class example of the Poisson distribution\n\nlibrary(tidyverse)\n\nx &lt;- 0:250\n# n = c(6,14,30,60)\np = c(0.1, 0.5)\n\ngeom = expand.grid(x = x, p = p) %&gt;%\n  mutate(y = dgeom(x, prob = p))\n\nggplot(geom %&gt;% filter(y &gt; 1e-5), \n       aes(x, y, color=factor(p))) +\n  geom_point(size=1) +\n  geom_segment(aes(x=x, xend=x, y=0, yend=y, color=factor(p)), lwd=0.8, alpha=0.5) +\n  facet_grid(rows = vars(p), scales=\"free_x\", space=\"free_x\") +\n  theme(legend.position = \"none\",\n        axis.title = element_text(size = 14),    # Axis title size\n        axis.text = element_text(size = 12),     # Axis text size\n        strip.text = element_text(size = 13)) +  # Facet label size\n  labs(x = \"Number of trials\", y = \"Probability\")"
  },
  {
    "objectID": "lessons/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html",
    "href": "lessons/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Homework 7 presentations due soon!\n\nI will check your HW 7 solutions ASAP!\n\nDepending on how far we get today and Wednesday, I might cancel the 12/9 class\nAnything else?"
  },
  {
    "objectID": "lessons/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#announcements",
    "href": "lessons/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Homework 7 presentations due soon!\n\nI will check your HW 7 solutions ASAP!\n\nDepending on how far we get today and Wednesday, I might cancel the 12/9 class\nAnything else?"
  },
  {
    "objectID": "lessons/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#key-dates",
    "href": "lessons/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 8 assignment due\nSunday: HW 7 presentations due at 11pm"
  },
  {
    "objectID": "lessons/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html",
    "href": "lessons/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "",
    "text": "Calculate the mean (expected value) of a joint distribution of continuous RV"
  },
  {
    "objectID": "lessons/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#learning-objectives",
    "href": "lessons/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#learning-objectives",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "",
    "text": "Calculate the mean (expected value) of a joint distribution of continuous RV"
  },
  {
    "objectID": "lessons/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#remark-on-expected-value-of-one-rv-from-joint-pdf",
    "href": "lessons/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#remark-on-expected-value-of-one-rv-from-joint-pdf",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "Remark on expected value of one RV from joint pdf",
    "text": "Remark on expected value of one RV from joint pdf\nIf you are given \\(f_{X,Y}(x,y)\\) and want to calculate \\(\\mathbb{E}[X]\\), you have two options:\n\nFind \\(f_X(x)\\) and use it to calculate \\(\\mathbb{E}[X]\\).\nOr, calculate \\(\\mathbb{E}[X]\\) using the joint density: \\[\\mathbb{E}[X] = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}x f_{X,Y}(x,y)dydx.\\]"
  },
  {
    "objectID": "lessons/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-1-expected-value-from-a-joint-distribution",
    "href": "lessons/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-1-expected-value-from-a-joint-distribution",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "Option 1: Expected value from a joint distribution",
    "text": "Option 1: Expected value from a joint distribution\n\n\n\n\nExample 3\n\n\nLet \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-2-expected-value-from-a-joint-distribution",
    "href": "lessons/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-2-expected-value-from-a-joint-distribution",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "Option 2: Expected value from a joint distribution",
    "text": "Option 2: Expected value from a joint distribution\n\n\n\n\nExample 1\n\n\nLet \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#learning-objectives",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#learning-objectives",
    "title": "Lesson 12: Joint densities",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate probabilities for a pair of discrete random variables\nCalculate a joint, marginal, and conditional probability mass function (pmf)\nCalculate a joint, marginal, and conditional cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#where-are-we",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#where-are-we",
    "title": "Lesson 12: Joint densities",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#what-is-a-joint-pmf",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#what-is-a-joint-pmf",
    "title": "Lesson 12: Joint densities",
    "section": "What is a joint pmf?",
    "text": "What is a joint pmf?\n\n\nDefinition: joint pmf\n\n\nThe joint pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[p_{X,Y}(x,y) = \\mathbb{P}(X=x\\ and\\ Y=y) = \\mathbb{P}(X=x, Y=y)\\]"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#this-chapters-main-example",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#this-chapters-main-example",
    "title": "Lesson 12: Joint densities",
    "section": "This chapter’s main example",
    "text": "This chapter’s main example\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#joint-pmf",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#joint-pmf",
    "title": "Lesson 12: Joint densities",
    "section": "Joint pmf",
    "text": "Joint pmf\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#marginal-pmfs",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#marginal-pmfs",
    "title": "Lesson 12: Joint densities",
    "section": "Marginal pmf’s",
    "text": "Marginal pmf’s\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#remarks-on-the-joint-pmf",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#remarks-on-the-joint-pmf",
    "title": "Lesson 12: Joint densities",
    "section": "Remarks on the joint pmf",
    "text": "Remarks on the joint pmf\nSome properties of joint pmf’s:\n\nA joint pmf \\(p_{X,Y}(x,y)\\) must satisfy the following properties:\n\n\\(p_{X,Y}(x,y)\\geq 0\\) for all \\(x, y\\).\n\\(\\sum \\limits_{\\{all\\ x\\}} \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)=1\\).\n\nMarginal pmf’s:\n\n\\(p_X(x) = \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)\\)\n\\(p_Y(y) = \\sum \\limits_{\\{all\\ x\\}} p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#what-is-a-joint-cdf",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#what-is-a-joint-cdf",
    "title": "Lesson 12: Joint densities",
    "section": "What is a joint CDF?",
    "text": "What is a joint CDF?\n\n\nDefinition: joint CDF\n\n\nThe joint CDF of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[F_{X,Y}(x,y) = \\mathbb{P}(X \\leq x\\ and\\ Y \\leq y) = \\mathbb{P}(X \\leq x, Y \\leq y)\\]"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#joint-cdfs",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#joint-cdfs",
    "title": "Lesson 12: Joint densities",
    "section": "Joint CDFs",
    "text": "Joint CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#marginal-cdfs",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#marginal-cdfs",
    "title": "Lesson 12: Joint densities",
    "section": "Marginal CDFs",
    "text": "Marginal CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#remarks-on-the-joint-and-marginal-cdf",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#remarks-on-the-joint-and-marginal-cdf",
    "title": "Lesson 12: Joint densities",
    "section": "Remarks on the joint and marginal CDF",
    "text": "Remarks on the joint and marginal CDF\n\n\\(F_X(x)\\): right most columns of the CDf table (where the \\(Y\\) values are largest)\n\\(F_Y(y)\\): bottom row of the table (where X values are largest)\n\\(F_X(x)=\\lim\\limits_{y\\rightarrow\\infty}F_{X, Y}(x,y)\\)\n\\(F_Y(y)=\\lim\\limits_{x\\rightarrow\\infty}F_{X, Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#independence-and-conditioning",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#independence-and-conditioning",
    "title": "Lesson 12: Joint densities",
    "section": "Independence and Conditioning",
    "text": "Independence and Conditioning\nRecall that for events \\(A\\) and \\(B\\),\n\n\\(\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}\\)\n\\(A\\) and \\(B\\) are independent if and only if\n\n\\(\\mathbb{P}(A|B) = \\mathbb{P}(A)\\)\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A)\\cdot\\mathbb{P}(B)\\)\n\n\nIndependence and conditioning are defined similarly for r.v.’s, since \\[p_X(x) = \\mathbb{P}(X=x)\\ \\mathrm{and}\\ \\ p_{X,Y}(x,y) = \\mathbb{P}(X = x ,Y = y).\\]"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#what-is-the-conditional-pmf",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#what-is-the-conditional-pmf",
    "title": "Lesson 12: Joint densities",
    "section": "What is the conditional pmf?",
    "text": "What is the conditional pmf?\n\n\nDefinition: conditional pmf\n\n\nThe conditional pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is defined as \\[p_{X|Y}(x|y) = \\mathbb{P}(X = x |Y = y) = \\frac{\\mathbb{P}(X = x\\ and\\ Y = y)}{\\mathbb{P}(Y = y)}\n=\\frac{p_{X,Y}(x,y) }{p_{Y}(y) }\\] if \\(p_{Y}(y) &gt; 0\\)."
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#remarks-on-the-conditional-pmf",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#remarks-on-the-conditional-pmf",
    "title": "Lesson 12: Joint densities",
    "section": "Remarks on the conditional pmf",
    "text": "Remarks on the conditional pmf\nThe following properties follow from the conditional pmf definition:\n\nIf \\(X \\perp Y\\) (independent)\n\n\\(p_{X|Y}(x|y) = p_X(x)\\) for all \\(x\\) and \\(y\\)\n\\(p_{X,Y}(x,y) = p_X(x)p_Y(y)\\) for all \\(x\\) and \\(y\\)\nWhich also implies (\\(\\Rightarrow\\)): \\(F_{X,Y}(x,y) = F_X(x)F_Y(y)\\) for all \\(x\\) and \\(y\\)\n\nIf \\(X_1, X_2, …, X_n\\) are independent\n\n\\[p_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1=x_1, X_2=x_2, …, X_n=x_n)=\\prod\\limits_{i=1}^np_{X_i}(x_i)\\]\n\\[F_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1\\leq x_1, X_2\\leq x_2, …, X_n\\leq x_n)=\\prod\\limits_{i=1}^nP(X_i \\leq x_i) = \\prod\\limits_{i=1}^nF_{X_i}(x_i)\\]"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#conditional-pmfs",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#conditional-pmfs",
    "title": "Lesson 12: Joint densities",
    "section": "Conditional pmf’s",
    "text": "Conditional pmf’s\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?\n\n\n\n\n\nRemark:\n\nTo show that \\(X\\) and \\(Y\\) are not independent, we just need to find one counter example\nHowever, to show that they are independent, we need to verify this for all possible pairs of \\(x\\) and \\(y\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#learning-objectives-1",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#learning-objectives-1",
    "title": "Lesson 12: Joint densities",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nSolve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#double-integrals-mini-lesson-13",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#double-integrals-mini-lesson-13",
    "title": "Lesson 12: Joint densities",
    "section": "Double Integrals Mini Lesson (1/3)",
    "text": "Double Integrals Mini Lesson (1/3)\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 1\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} xy dydx\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#double-integrals-mini-lesson-23",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#double-integrals-mini-lesson-23",
    "title": "Lesson 12: Joint densities",
    "section": "Double Integrals Mini Lesson (2/3)",
    "text": "Double Integrals Mini Lesson (2/3)\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 2\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} (x+y) dydx\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#double-integrals-mini-lesson-33",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#double-integrals-mini-lesson-33",
    "title": "Lesson 12: Joint densities",
    "section": "Double Integrals Mini Lesson (3/3)",
    "text": "Double Integrals Mini Lesson (3/3)\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 3\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} e^{x+y} dydx\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "title": "Lesson 12: Joint densities",
    "section": "How to define the joint pdf for continuous RVs?",
    "text": "How to define the joint pdf for continuous RVs?\n\n\nFor a single continuous RV \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\), \\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\]\n\nFor two continuous RVs (\\(X\\) and \\(Y\\)), we can define the joint pdf, \\(f_{X,Y}(x,y)\\), such that for all real values \\(a,b, c, d\\) with \\(a \\leq b\\) and \\(c \\leq d\\), \\[\\mathbb{P}(a \\leq X \\leq b, c \\leq Y \\leq d) = \\int_a^b \\int_c^d f_{X,Y}(x,y)dydx\\]"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#important-properties-of-the-joint-pdf",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#important-properties-of-the-joint-pdf",
    "title": "Lesson 12: Joint densities",
    "section": "Important properties of the joint pdf",
    "text": "Important properties of the joint pdf\n\nNote that \\(f_{X,Y}(x,y)\\neq \\mathbb{P}(X=x, Y=y)\\)!!!\nIn order for \\(f_{X,Y}(x,y)\\) to be a pdf, it needs to satisfy the properties\n\n\\(f_{X,Y}(x,y)\\geq 0\\) for all \\(x,y\\)\n\\(\\displaystyle\\int_{-\\infty}^{\\infty}\\displaystyle\\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dxdy=1\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "title": "Lesson 12: Joint densities",
    "section": "What is the joint cumulative distribution function?",
    "text": "What is the joint cumulative distribution function?\n\n\nDefinition: Joint cumulative distribution function (Joint CDF)\n\n\nThe joint cumulative distribution function (cdf) of continuous random variables \\(X\\) and \\(Y\\), is the function \\(F_{X,Y}(x,y)\\), such that for all real values of \\(x\\) and \\(y\\), \\[F_{X,Y}(x,y)= \\mathbb{P}(X \\leq x, Y \\leq y) = \\int_{-\\infty}^x\\int_{-\\infty}^y f_{X,Y}(s,t)dtds\\]\n\n\nRemarks:\n\nThe definition above for \\(F_{X,Y}(x,y)\\) is a function of \\(x\\) and \\(y\\).\nThe joint cdf at the point \\((a,b)\\), is \\[F_{X,Y}(a,b) = \\mathbb{P}(X \\leq a, Y \\leq b) = \\int_{-\\infty}^a\\int_{-\\infty}^b f_{X,Y}(s,t)dtds\\]"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#what-are-the-marginal-pdfs",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#what-are-the-marginal-pdfs",
    "title": "Lesson 12: Joint densities",
    "section": "What are the marginal pdf’s?",
    "text": "What are the marginal pdf’s?\n\n\nDefinition: Marginal pdf’s\n\n\nSuppose \\(X\\) and \\(Y\\) are continuous r.v.’s, with joint pdf \\(f_{X,Y}(x,y)\\). Then the marginal probability density functions are \\[\\begin{aligned}\nf_X(x)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dy\\\\\nf_Y(y)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dx\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#common-steps-for-solving-problems",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#common-steps-for-solving-problems",
    "title": "Lesson 12: Joint densities",
    "section": "Common steps for solving problems",
    "text": "Common steps for solving problems\n\nSet up the domain of the pdf with a picture\nTranslate to needed integrands\n\nFor probability: shade in the area of interest, then translate\nFor expected value: translate domain\n\nSet up integral: \\(dxdy\\) or \\(dydx\\)?\nSolve integral!"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#example-of-joint-pdf",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#example-of-joint-pdf",
    "title": "Lesson 12: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)."
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#example-of-joint-pdf-1",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#example-of-joint-pdf-1",
    "title": "Lesson 12: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "title": "Lesson 12: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "title": "Lesson 12: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(\\mathbb{P}(Y &lt; 3)\\)."
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#lets-complicate-this-even-more",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#lets-complicate-this-even-more",
    "title": "Lesson 12: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.1\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nFind \\(\\mathbb{P}(|X-Y| &lt; 2)\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "title": "Lesson 12: Joint densities",
    "section": "Finding the pdf of a transformation",
    "text": "Finding the pdf of a transformation\n\nLet \\(M\\) be a transformation of \\(X\\) and \\(Y\\)\nWhen we have a transformation of \\(X\\) and \\(Y\\), \\(M\\), we need to follow a specific process to find the pdf of \\(M\\)\n\nWe follow this process:\n\nStart with the joint pdf for \\(X\\) and \\(Y\\)\n\naka \\(f_{X,Y}(x, y)\\)\n\nTranslate the domain of \\(X\\) and \\(Y\\) to \\(M\\)\nFind the CDF of \\(M\\)\n\naka \\(F_M(m)\\) or \\(P(M \\leq m)\\)\n\nTake the derivative of the CDF of \\(M\\) to find the pdf of \\(M\\)\n\naka \\(f_M(m) = \\dfrac{d}{dm}F_M(m)\\)"
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#lets-complicate-this-even-more-1",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#lets-complicate-this-even-more-1",
    "title": "Lesson 12: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.2\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(M = \\max(X,Y)\\). Find the pdf for \\(M\\), that is \\(f_M(m)\\)."
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#lets-complicate-this-even-more-2",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#lets-complicate-this-even-more-2",
    "title": "Lesson 12: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 3.3\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(Z = \\min(X,Y)\\). Find the pdf for \\(Z\\), that is \\(f_Z(z)\\)."
  },
  {
    "objectID": "lessons/12_Joint_distributions/12_Joint_densities.html#lets-complicate-this-even-further",
    "href": "lessons/12_Joint_distributions/12_Joint_densities.html#lets-complicate-this-even-further",
    "title": "Lesson 12: Joint densities",
    "section": "Let’s complicate this even further!",
    "text": "Let’s complicate this even further!\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 4\n\n\nLet \\(X\\) and \\(Y\\) have joint density \\(f_{X,Y}(x,y)= \\frac85(x+y)\\) in the region \\(0 &lt; x &lt; 1,\\ \\frac12 &lt; y &lt;1\\). Find the pdf of the r.v. \\(Z\\), where \\(Z=XY\\)."
  },
  {
    "objectID": "lessons/11_Transformations/11_Transformations.html#cdf-method",
    "href": "lessons/11_Transformations/11_Transformations.html#cdf-method",
    "title": "Lesson 11: Transformations",
    "section": "Distributions of transformations of random variables",
    "text": "Distributions of transformations of random variables\nIt is common in many scientific, mathematical, and statistical context to transform variables. A function of a random variable is a random variable: if \\(X\\) is a random variable and \\(g\\) is a function then \\(Y=g(X)\\) is a random variable. Since \\(g(X)\\) is a random variable it has a distribution. In general, the distribution of \\(g(X)\\) will have a different shape than the distribution of \\(X\\). This section discusses some techniques for determining how a transformation changes the shape of a distribution."
  },
  {
    "objectID": "lessons/11_Transformations/11_Transformations.html#linear-rescaling",
    "href": "lessons/11_Transformations/11_Transformations.html#linear-rescaling",
    "title": "Lesson 11: Transformations",
    "section": "Linear rescaling",
    "text": "Linear rescaling\nIn general, the distribution of \\(g(X)\\) will have a different shape than the distribution of \\(X\\). The exception is when \\(g\\) is a linear rescaling.\nA linear rescaling is a transformation of the form \\(g(u) = a + bu\\), where \\(a\\) (intercept) and \\(b\\) (slope1) are constants. For example, converting temperature from Celsius to Fahrenheit using \\(g(u) = 32 + 1.8u\\) is a linear rescaling.\nA linear rescaling “preserves relative interval length” in the following sense.\n\nIf interval A and interval B have the same length in the original measurement units, then the rescaled intervals A and B will have the same length in the rescaled units. For example, [0, 10] and [10, 20] Celsius, both length 10 degrees Celsius, correspond to [32, 50] and [50, 68] Fahrenheit, both length 18 degrees Fahrenheit.\nIf the ratio of the lengths of interval A and B is \\(r\\) in the original measurement units, then the ratio of the lengths in the rescaled units is also \\(r\\). For example, [10, 30] is twice as long as [0, 10] in Celsius; for the corresponding Fahrenheit intervals, [50, 86] is twice as long as [32, 50].\n\nYou might be familiar with “\\(mx+b\\)” where \\(b\\) denotes the intercept. In Statistics, \\(b\\) is often used to denote slope. For example, in R abline(a = 32, b = 1.8) draws a line with intercept 32 and slope 1.8."
  },
  {
    "objectID": "lessons/11_Transformations/11_Transformations.html#sim-nonlinear",
    "href": "lessons/11_Transformations/11_Transformations.html#sim-nonlinear",
    "title": "Lesson 11: Transformations",
    "section": "Nonlinear transformations of random variables",
    "text": "Nonlinear transformations of random variables\nA linear rescaling does not change the shape of a distribution, only the range of possible values. But what about a nonlinear transformation, like a logarithmic or square root transformation? In contrast to a linear rescaling, a nonlinear rescaling does not preserve relative interval length, so we might expect that a nonlinear rescaling can change the shape of a distribution. We’ll investigate by considering the Uniform(0, 1) spinner and a logarithmic1 transformation.\nLet \\(U\\) represent the result of a single spin of the Uniform(0, 1) spinner. We’ll basically consider \\(\\log(U)\\), but this leads to to two minor technicalities.\n\nSince \\(U\\in[0, 1]\\), \\(\\log(U)\\le 0\\). To obtain positive values we consider \\(-\\log(U)\\), which takes values in \\([0,\\infty)\\).\nTechnically, applying \\(-\\log(u)\\) to the values on the axis of the Uniform(0, 1) spinner, the resulting values would decrease from \\(\\infty\\) to 0 clockwise. To make the values start at 0 and increase to \\(\\infty\\) clockwise, we consider \\(-\\log(1-U)\\). (We saw in the previous section the transformation \\(u \\to 1-u\\) basically just changes direction from clockwise to counterclockwise.)\n\nAs in many other contexts and programming languages, in this text any reference to logarithms or \\(\\log\\) refers to natural (base \\(e\\)) logarithms. In the instances we need to consider another base, we’ll make that explicit."
  },
  {
    "objectID": "lessons/11_Transformations/11_Transformations.html#linear",
    "href": "lessons/11_Transformations/11_Transformations.html#linear",
    "title": "Lesson 11: Transformations",
    "section": "linear",
    "text": "linear\nThink of a linear rescaling as just a consistent relabeling of the variable axis; every 1 unit increment in the original scale corresponds to a \\(b\\) unit increment in the linear rescaling.\nSuppose that SAT Math score \\(X\\) follows a Uniform(200, 800) distribution. (It doesn’t but go with in for now). One way to simulate values of \\(X\\) is to simulate values of \\(U\\) from a Uniform(0, 1) distribution and let \\(X = 200 + (800 - 200)U= 200 + 600U\\). Then \\(X\\) is a linear rescaling of \\(U\\), and \\(X\\) takes values in the interval [200, 800]. We can define and simulate values of \\(X\\) in Symbulate. Before looking at the results, sketch a plot of the distribution of \\(X\\) and make an educated guess for its mean and standard deviation."
  },
  {
    "objectID": "lessons/11_Transformations/11_Transformations.html#section",
    "href": "lessons/11_Transformations/11_Transformations.html#section",
    "title": "Lesson 11: Transformations",
    "section": "",
    "text": "We see that \\(X\\) has a Uniform(200, 800) distribution. The linear rescaling changes the range of possible values, but the general shape of the distribution is still Uniform. We can see why by inspecting a few intervals on both the original and revised scale.\n\n\n\n\n\n\n\n\n\nInterval of \\(U\\) values\nProbability that \\(U\\) lies in the interval\nInterval of \\(X\\) values\nProbability that \\(X\\) lies in the interval\n\n\n\n\n(0.0, 0.1)\n0.1\n(200, 260)\n\\(\\frac{60}{600}\\)\n\n\n(0.9, 1.0)\n0.1\n(740, 800)\n\\(\\frac{60}{600}\\)\n\n\n(0.0, 0.2)\n0.2\n(200, 320)\n\\(\\frac{120}{600}\\)\n\n\n\nFor a Uniform distribution the long run average is the midpoint of possible values. The long run average value of \\(U\\) is 0.5, and of \\(X\\) is 500. These two values are related through the same formula mapping \\(U\\) to \\(X\\) values: \\(500 = 200 + 600\\times 0.5\\)."
  },
  {
    "objectID": "lessons/11_Transformations/11_Transformations.html#section-1",
    "href": "lessons/11_Transformations/11_Transformations.html#section-1",
    "title": "Lesson 11: Transformations",
    "section": "",
    "text": "For a Uniform distribution, the standard deviation the about 0.289 times the length of the interval: \\(|b-a|/\\sqrt{12}\\). The standard deviation of \\(U\\) is about 0.289, and of \\(X\\) is about 173.\nThe standard deviation of \\(X\\) is 600 times the standard deviation of \\(U\\). Multiplying the \\(U\\) values by 600 rescales the distance between the values. Two values of \\(U\\) that are 0.1 units apart correspond to two values of \\(X\\) that are 60 units apart. A \\(U\\) value of 0.6 is 0.1 units above the mean of \\(U\\), and the corresponding \\(X\\) value 560 is 60 units about the mean of \\(X\\). However, adding the constant 200 to all values just shifts the distribution and does affect degree of variability.\n\nDoes \\(V\\) result from a linear rescaling of \\(U\\)?\nWhat are the possible values of \\(V\\)?\nIs \\(V\\) the same random variable as \\(U\\)?\nFind \\(\\IP(U \\le 0.1)\\) and \\(\\IP(V \\le 0.1)\\).\nSketch a plot of what the histogram of many simulated values of \\(V\\) would look like.\nDoes \\(V\\) have the same distribution as \\(U\\)?"
  },
  {
    "objectID": "lessons/11_Transformations/11_Transformations.html#section-2",
    "href": "lessons/11_Transformations/11_Transformations.html#section-2",
    "title": "Lesson 11: Transformations",
    "section": "",
    "text": "Let’s consider a non-uniform example. Now let’s suppose that SAT Math score \\(X\\) follows a Normal(500, 100) distribution. We can simulate values of \\(X\\) by simulating \\(Z\\) from the standard Normal(0, 1) distribution and setting \\(X = 500 + 100Z\\). (Remember that the standard Normal spinner returns standardized values, so \\(Z = 1\\) corresponds to 1 standard deviation above the mean, that is, \\(X= 600\\).) The reason this works is because the linear rescaling doesn’t change the Normal shape.\nThe linear rescaling changes the range of observed values; almost all of the values of \\(Z\\) lie in the interval \\((-3, 3)\\) while almost all of the values of \\(X\\) lie in the interval \\((200, 800)\\). However, the distribution of \\(X\\) still has the general Normal shape. The means are related by the conversion formula: \\(500 = 500 + 100 \\times 0\\). Multiplying the values of \\(Z\\) by 100 rescales the distance between values; two values of \\(Z\\) that are 1 unit apart correspond to two values of \\(X\\) that are 100 units apart. However, adding the constant 500 to all the values just shifts the center of the distribution and does not affect variability. Therefore, the standard deviation of \\(X\\) is 100 times the standard deviation of \\(Z\\)."
  },
  {
    "objectID": "lessons/11_Transformations/11_Transformations.html#section-3",
    "href": "lessons/11_Transformations/11_Transformations.html#section-3",
    "title": "Lesson 11: Transformations",
    "section": "",
    "text": "In general, if \\(Z\\) has a Normal(0, 1) distribution then \\(X = \\mu + \\sigma Z\\) has a Normal(\\(\\mu\\), \\(\\sigma\\)) distribution.\n\nIs \\(Y\\) the same random variable as \\(X\\)?\nDoes \\(Y\\) have the same distribution as \\(X\\)?\nDonny Don’t says that the distribution of \\(-Z\\) will look like an “upside-down bell”. Is Donny correct? If not, explain why not and describe the distribution of \\(-Z\\).\nDonny Don’t says that the standard deviation of \\(-Z\\) is -1. Is Donny correct? If not, explain why not and determine the standard deviation of \\(-Z\\)."
  },
  {
    "objectID": "lessons/11_Transformations/11_Transformations.html#summary",
    "href": "lessons/11_Transformations/11_Transformations.html#summary",
    "title": "Lesson 11: Transformations",
    "section": "Summary",
    "text": "Summary\n\nA linear rescaling is a transformation of the form \\(g(u) = a + bu\\).\nA linear rescaling of a random variable does not change the basic shape of its distribution, just the range of possible values.\n\nHowever, remember that the possible values are part of the distribution. So a linear rescaling does technically change the distribution, even if the basic shape is the same. (For example, Normal(500, 100) and Normal(0, 1) are two different distributions.)\n\nA linear rescaling transforms the mean in the same way the individual values are transformed.\nAdding a constant to a random variable does not affect its standard deviation.\nMultiplying a random variable by a constant multiplies its standard deviation by the absolute value of the constant.\nWhether in the short run or the long run, \\[\\begin{align*}\n\\text{Average of $a+bX$} & = a+b(\\text{Average of $X$})\\\\\n\\text{SD of $a+bX$} & = |b|(\\text{SD of $X$})\\\\\n\\text{Variance of $a+bX$} & = b^2(\\text{Variance of $X$})\n\\end{align*}\\]\nIf \\(U\\) has a Uniform(0, 1) distribution then \\(X = a + (b-a)U\\) has a Uniform(\\(a\\), \\(b\\)) distribution.\nIf \\(Z\\) has a Normal(0, 1) distribution then \\(X = \\mu + \\sigma Z\\) has a Normal(\\(\\mu\\), \\(\\sigma\\)) distribution.\nRemember, do NOT confuse a random variable with its distribution.\n\nThe random variable is the numerical quantity being measured\nThe distribution is the long run pattern of variation of many observed values of the random variable"
  },
  {
    "objectID": "lessons/11_Transformations/11_Transformations.html#section-4",
    "href": "lessons/11_Transformations/11_Transformations.html#section-4",
    "title": "Lesson 11: Transformations",
    "section": "",
    "text": "Therefore, it’s a little more convenient to consider the random variable \\(X=-\\log(1-U)\\) which takes values in \\([0,\\infty)\\). It also turns out, as we saw in earlier, that \\(-\\log(1-u)\\) is the quantile function of the Exponential(1) distribution. We have already seen that \\(X\\) has an Exponential(1) distribution. Now we’ll take a closer look why.\nThe following code defines \\(X\\) and plots a few simulated values.\nNotice that values near 0 occur with higher frequency than larger values. For example, there are many more simulated values of \\(X\\) that lie in the interval \\([0, 1]\\) than in the interval \\([3, 4]\\), even though these intervals both have length 1. Let’s see why this is happening.\n\n\n\n\n\n\n\n\n\n\n\n\nInterval of U\nLength of U interval\nProbability\nInterval of X\nLength of X interval\n\n\n\n\n(0, 0.1)\n\n\n\n\n\n\n(0.1, 0.2)\n\n\n\n\n\n\n(0.2, 0.3)\n\n\n\n\n\n\n(0.3, 0.4)\n\n\n\n\n\n\n(0.4, 0.5)\n\n\n\n\n\n\n(0.5, 0.6)\n\n\n\n\n\n\n(0.6, 0.7)\n\n\n\n\n\n\n(0.7, 0.8)\n\n\n\n\n\n\n(0.8, 0.9)\n\n\n\n\n\n\n(0.9, 1)"
  },
  {
    "objectID": "lessons/11_Transformations/11_Transformations.html#section-5",
    "href": "lessons/11_Transformations/11_Transformations.html#section-5",
    "title": "Lesson 11: Transformations",
    "section": "",
    "text": "Plug the endpoints into the conversion formula \\(u\\mapsto -\\log(1-u)\\) to find the corresponding \\(X\\) interval. For example, the \\(U\\) interval \\((0.1, 0.2)\\) corresponds to the \\(X\\) interval \\((-\\log(1-0.1), -\\log(1-0.2)) = (0.105, 0.223)\\). Since \\(U\\) has a Uniform(0, 1) distribution the probability is just the length of the \\(U\\) interval.\n\n\n\n\n\n\n\n\n\n\n\n\nInterval of U\nLength of U interval\nProbability\nInterval of X\nLength of X interval\n\n\n\n\n(0, 0.1)\n0.1\n0.1\n(0, 0.105)\n0.105\n\n\n(0.1, 0.2)\n0.1\n0.1\n(0.105, 0.223)\n0.118\n\n\n(0.2, 0.3)\n0.1\n0.1\n(0.223, 0.357)\n0.134\n\n\n(0.3, 0.4)\n0.1\n0.1\n(0.357, 0.511)\n0.154\n\n\n(0.4, 0.5)\n0.1\n0.1\n(0.511, 0.693)\n0.182\n\n\n(0.5, 0.6)\n0.1\n0.1\n(0.693, 0.916)\n0.223\n\n\n(0.6, 0.7)\n0.1\n0.1\n(0.916, 1.204)\n0.288\n\n\n(0.7, 0.8)\n0.1\n0.1\n(1.204, 1.609)\n0.405\n\n\n(0.8, 0.9)\n0.1\n0.1\n(1.609, 2.303)\n0.693\n\n\n(0.9, 1)\n0.1\n0.1\n(2.303, Inf)\nInf"
  },
  {
    "objectID": "lessons/11_Transformations/11_Transformations.html#section-6",
    "href": "lessons/11_Transformations/11_Transformations.html#section-6",
    "title": "Lesson 11: Transformations",
    "section": "",
    "text": "We see that the logarithmic transformation does not preserve relative interval length. Each of the original intervals of \\(U\\) values has the same length, but the nonlinear logarithmic transformation “stretches out” these intervals in different ways. The probability that \\(U\\) lies in each of these intervals is 0.1. As the transformation stretches the intervals, the 0.1 probability gets “spread” over intervals of different length. Since probability/relative frequency is represented by area in a histogram, if two regions of differing length have the same area, then they must have different heights. Thus the shape of the distribution of \\(X\\) will not be Uniform.\nThe following plot illustrates the results of Example @ref(exm:uniform-log-transform-calcs). Each bar in the top histogram corresponds to the same color bar in the bottom histogram. All bars have area 0.1. In the top histogram, the bins have equal width so the heights are the same. However, in the bottom histogram the bars have different widths but the same area, so they must have different heights, and we start to see where the Exponential(1) shape comes from."
  },
  {
    "objectID": "lessons/11_Transformations/11_Transformations.html#section-7",
    "href": "lessons/11_Transformations/11_Transformations.html#section-7",
    "title": "Lesson 11: Transformations",
    "section": "",
    "text": "The following example provides a similar illustration, but from the reverse perspective.\n\n\n\n\n\n\n\n\n\n\n\n\nInterval of X\nLength of X interval\nProbability\nInterval of U\nLength of U interval\n\n\n\n\n(0, 0.5)\n\n\n\n\n\n\n(0.5, 1)\n\n\n\n\n\n\n(1, 1.5)\n\n\n\n\n\n\n(1.5, 2)\n\n\n\n\n\n\n(2, 2.5)\n\n\n\n\n\n\n(2.5, 3)\n\n\n\n\n\n\n(3, 3.5)\n\n\n\n\n\n\n(3.5, 4)\n\n\n\n\n\n\n(4, 4.5)\n\n\n\n\n\n\n(4.5, 5)"
  },
  {
    "objectID": "lessons/11_Transformations/11_Transformations.html#section-8",
    "href": "lessons/11_Transformations/11_Transformations.html#section-8",
    "title": "Lesson 11: Transformations",
    "section": "",
    "text": "The corresponding \\(U\\) intervals are obtained by applying the inverse transformation \\(v\\mapsto 1-e^{-v}\\). For example, the \\(X\\) interval \\((0.5, 1)\\) corresponds to the \\(U\\) interval \\((1-e^{-0.5}, 1-e^{-1}) = (0.393, 0.632)\\).\n\n\n\n\n\n\n\n\n\n\n\n\nInterval of X\nLength of X interval\nProbability\nInterval of U\nLength of U interval\n\n\n\n\n(0, 0.5)\n0.5\n0.393\n(0, 0.393)\n0.393\n\n\n(0.5, 1)\n0.5\n0.239\n(0.393, 0.632)\n0.239\n\n\n(1, 1.5)\n0.5\n0.145\n(0.632, 0.777)\n0.145\n\n\n(1.5, 2)\n0.5\n0.088\n(0.777, 0.865)\n0.088\n\n\n(2, 2.5)\n0.5\n0.053\n(0.865, 0.918)\n0.053\n\n\n(2.5, 3)\n0.5\n0.032\n(0.918, 0.95)\n0.032\n\n\n(3, 3.5)\n0.5\n0.020\n(0.95, 0.97)\n0.020\n\n\n(3.5, 4)\n0.5\n0.012\n(0.97, 0.982)\n0.012\n\n\n(4, 4.5)\n0.5\n0.007\n(0.982, 0.989)\n0.007\n\n\n(4.5, 5)\n0.5\n0.004\n(0.989, 0.993)\n0.004\n\n\n\n\n\nSince \\(U\\) has a Uniform(0, 1) distribution the probability is just the length of the \\(U\\) interval. Each of the \\(X\\) intervals has the same length but they correspond to intervals of differing length in the original \\(U\\) scale, and hence intervals of different probability."
  },
  {
    "objectID": "lessons/11_Transformations/11_Transformations.html#section-9",
    "href": "lessons/11_Transformations/11_Transformations.html#section-9",
    "title": "Lesson 11: Transformations",
    "section": "",
    "text": "The following plot illustrates the results of Example @ref(exm:uniform-log-transform-calcs2) (plots on the right). These two examples give some insight into how the transformed random variable \\(X = -\\log(1-U)\\) has an Exponential(1) distribution.\n\n“Spreadsheet” calculations like those in the previous two examples can help when sketching the distribution of a transformed random variable.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor a linear rescaling, we could just plug the mean of the original variable into the conversion formula to find the mean of the transformed variable. However, this will not work for nonlinear transformations."
  },
  {
    "objectID": "lessons/11_Transformations/11_Transformations.html#section-10",
    "href": "lessons/11_Transformations/11_Transformations.html#section-10",
    "title": "Lesson 11: Transformations",
    "section": "",
    "text": "We know that since \\(U\\) has a Uniform(0, 1) distribution its long run average value is 0.5, and since \\(X\\) has an Exponential(1) distribution its long run average value is 1, but \\(-\\log(1 - 0.5) \\neq 1\\). The nonlinear “stretching” of the axis makes some value relatively larger and others relatively smaller than they were on the original scale, which influences the average. Remember, in general: whether in the short run or the long run \\[\n\\text{Average of } g(X) \\neq g(\\text{Average of }X).\n\\]\nRecall that a function of a random variable is also a random variable. If \\(X\\) is a random variable, then \\(Y=g(X)\\) is also a random variable and so it has a probability distribution. Unless \\(g\\) represents a linear rescaling, a transformation will change the shape of the distribution. So the question is: what is the distribution of \\(g(X)\\)? We’ll focus on transformations of continuous random variables, in which case the key to answering the question is to work with cdfs.\n\nIdentify the possible values of \\(X\\). (We have done this already, but this should always be your first step.)\nLet \\(F_X\\) denote the cdf of \\(X\\). Find \\(F_X(1)\\).\nFind \\(F_X(2)\\).\nFind the cdf \\(F_X(x)\\).\nFind the pdf \\(f_X(x)\\).\nWhy should we not be surprised that \\(X=-\\log(1-U)\\) has cdf \\(F_X(x) = 1 - e^{-x}\\)? Hint: what is the function \\(u\\mapsto -\\log(1-u)\\) in this case?\n\n(ref:cap-log-function-plot) A plot of the function \\(u\\mapsto -\\log(1-u)\\). The dotted lines illustrate that \\(-\\log(1-u)\\le 1\\) if and only if \\(u\\le 1-e^{-1}\\approx 0.632\\).\n\n(ref:cap-log-function-plot)"
  },
  {
    "objectID": "lessons/11_Transformations/11_Transformations.html#section-11",
    "href": "lessons/11_Transformations/11_Transformations.html#section-11",
    "title": "Lesson 11: Transformations",
    "section": "",
    "text": "If \\(X\\) is a continuous random variable whose distribution is known, the cdf method can be used to find the pdf of \\(Y=g(X)\\)\n\nDetermine the possible values of \\(Y\\). Let \\(y\\) represent a generic possible value of \\(Y\\).\nThe cdf of \\(Y\\) is \\(F_Y(y) = \\IP(Y\\le y) = \\IP(g(X) \\le y)\\).\nRearrange \\(\\{g(X) \\le y\\}\\) to get an event involving \\(X\\). Warning: it is not always \\(\\{X \\le g^{-1}(y)\\}\\). Sketching a picture of the function \\(g\\) helps.\nObtain an expression for the cdf of \\(Y\\) which involves \\(F_X\\) and some transformation of the value \\(y\\).\nDifferentiate the expression for \\(F_Y(y)\\) with respect to \\(y\\), and use what is known about \\(F'_X = f_X\\), to obtain the pdf of \\(Y\\). You will typically need to apply the chain rule when differentiating.\n\nYou will need to use information about \\(X\\) at some point in the last step above. You can either:\n\nPlug in the cdf of \\(X\\) and then differentiate with respect to \\(y\\).\nDifferentiate with respect to \\(y\\) and then plug in the pdf of \\(X\\).\n\nEither way gets you to the correct answer, but depending on the problem one way might be easier than the other. We’ll illustrate both methods in the next example.\n\nIdentify the possible values of \\(Y\\).\nSketch the pdf of \\(Y\\). Hint: consider a few equally spaced intervals of \\(Y\\) values and see what \\(X\\) values they correspond to.\nRun a simulation to approximate the pdf of \\(Y\\).\nFind \\(F_Y(0.49)\\).\nUse the cdf method to find the pdf of \\(Y\\). Is the pdf consistent with your simulation results?\n\n(ref:cap-square-function-plot) A plot of the function \\(x\\mapsto x^2\\) for \\(-1&lt;x&lt;1\\). The dotted lines illustrate that \\(x^2\\le 0.49\\) if and only if \\(-\\sqrt{0.49}\\le x\\le \\sqrt{0.49}\\).\n\n(ref:cap-square-function-plot)The table below helps us see how the transformation \\(Y = X^2\\) “pushes” density towards 0 if \\(X\\) has a Uniform(-1, 1) distribution.\n\n\n\n\n\nY interval\nX interval\nLength of X interval\nProbability\nLength of Y interval\nHeight of Y interval\n\n\n\n\n(0, 0.1)\n(-0.3162, 0) U (0,0.3162)\n0.6324\n0.3162\n0.1\n3.162\n\n\n(0.1, 0.2)\n(-0.4472, -0.3162) U (0.3162,0.4472)\n0.2620\n0.1310\n0.1\n1.310\n\n\n(0.2, 0.3)\n(-0.5477, -0.4472) U (0.4472,0.5477)\n0.2010\n0.1005\n0.1\n1.005\n\n\n(0.3, 0.4)\n(-0.6325, -0.5477) U (0.5477,0.6325)\n0.1696\n0.0848\n0.1\n0.848\n\n\n(0.4, 0.5)\n(-0.7071, -0.6325) U (0.6325,0.7071)\n0.1492\n0.0746\n0.1\n0.746\n\n\n(0.5, 0.6)\n(-0.7746, -0.7071) U (0.7071,0.7746)\n0.1350\n0.0675\n0.1\n0.675\n\n\n(0.6, 0.7)\n(-0.8367, -0.7746) U (0.7746,0.8367)\n0.1242\n0.0621\n0.1\n0.621\n\n\n(0.7, 0.8)\n(-0.8944, -0.8367) U (0.8367,0.8944)\n0.1154\n0.0577\n0.1\n0.577\n\n\n(0.8, 0.9)\n(-0.9487, -0.8944) U (0.8944,0.9487)\n0.1086\n0.0543\n0.1\n0.543\n\n\n(0.9, 1)\n(-1, -0.9487) U (0.9487,1)\n0.1026\n0.0513\n0.1\n0.513\n\n\n\n\n\n\n\nWe can use the table to sketch a histogram.\nIf we continued the above process with narrower and narrower \\(Y\\) intervals we would arrive at the smooth pdf given by \\(f_Y(y) = \\frac{1}{2\\sqrt{y}}, 0&lt;y&lt;1\\); see the black curve in the plot below.\nNow we’ll approximate the pdf via simulation. The density blows up at 0 so it’s hard for the chunky histogram to capture that, but we see the simulated values follow a distribution described by the smooth \\(f_Y(y) = \\frac{1}{2\\sqrt{y}}, 0&lt;y&lt;1\\) in the black curve."
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities_muddy_points.html",
    "href": "lessons/11_Transformations/25_Joint_densities_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n1. How do pdf, CDF, and probability interact with each other?\nLet’s say we have a pdf, \\(f_X(x) = \\dfrac{1}{9}x^2\\) for \\(0 \\leq x \\leq 3\\). This is just a function. The pdf is not used on its own to report any probability. We must integrate over the pdf to find a probability.\n\nlibrary(\"ggplot2\")\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3)\n\n\n\n\n\n\n\n\nThe total area under the pdf is 1. This makes our pdf valid.\n\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 3),\n                geom = \"area\", \n                aes(fill = \"red\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 1\", color = \"black\")\n\n\n\n\n\n\n\n\nIf we only look at a proportion of the area under the pdf, then we start constructing our probabilities. For example, we can look at probability that we have a value between 0 and 1.5.\n\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 1.5),\n                geom = \"area\", \n                aes(fill = \"blue\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 0.125\", color = \"black\")\n\n\n\n\n\n\n\n\nInstead of calculating the EXACT probability for each value between 0 and 3, we can find the CDF of the pdf.\nThe CDF is: \\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;3 \\quad \\\\\n            \\dfrac{1}{27}x^3 & \\quad 0 \\leq x \\leq 3\\quad \\\\\n            1 & \\quad x&gt;3 \\quad\n        \\end{array}\n    \\right.\n\\]\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nWhen \\(x=1.5\\), we can calculate the probability using the CDF. Remember that \\(F_X(x) = P(X \\leq x)\\). So we can say \\(P(X \\leq 1.5) = F_X(1.5) = \\dfrac{1}{27}(1.5)^3\\), which equals 0.125.\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\") +\n  geom_point(aes(x=1.5, y=.125), colour=\"blue\", size=3) +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"CDF = 0.125\", color = \"black\")\n\nWarning in geom_point(aes(x = 1.5, y = 0.125), colour = \"blue\", size = 3): All aesthetics have length 1, but the data has 2 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\nWe can also calculate the probability with an integral: \\(P(X \\leq 1.5) = \\displaystyle\\int_0^{1.5} \\dfrac{1}{9}x^2 dx\\).\nWe can also find the probability that X is between two numbers. \\(P(1\\leq X \\leq 1.5) = F_X(1.5) - F_X(1)\\) or \\(P(1\\leq X \\leq 1.5) = \\displaystyle\\int_1^{1.5} \\dfrac{1}{9}x^2 dx\\).\n\n\n2. Joint vs marginal vs conditional: How are we calculating the probability?\nIf we start at a joint probability \\(f_{X,Y}(x,y)\\)…. we can look at a few probabilities:\n\nJoint probability: \\(P(a \\leq X \\leq b, c \\leq Y \\leq d)\\)\n\\[P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=c}^{y=d} f_{X,Y}(x,y) dydx\\]\nMarginal probability: \\(P(a \\leq X \\leq b)\\)\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b} f_{X}(x) dx\\]\nOR\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=-\\inf}^{y=\\inf} f_{X,Y}(x,y) dydx\\]\nConditional probability: \\(P(a \\leq X \\leq b | Y = c)\\)\n\\[P(a \\leq X \\leq b | Y=c) = \\displaystyle\\int_{x=a}^{x=b} f_{X|Y}(x|y=c) dx\\]\nYou cannot calculate \\(P(a \\leq X \\leq b | Y = c)\\) by \\(\\dfrac{P(a \\leq X \\leq b, Y=c)}{P(Y = c)}\\) because \\(P(Y = c)\\) is 0. Instead, we need to find \\(f_{X|Y}(x|y=c)\\) by \\(\\dfrac{f_{X,Y}(x,y=c)}{f_{Y}(y=c)}\\) and THEN integrate over X.\n\n\n\n3. What are we actually finding by solving the double integral. In the first example, we found the probability was 1/16 after integrating but what does 1/16 mean in relation to the random variables X and Y?\nIt means that the volume contained by \\(0\\leq X \\leq 1\\), \\(0\\leq Y \\leq 1/2\\), and their joint pdf is 1/16 of the total volume contained by \\(0\\leq X \\leq 2\\), \\(0\\leq Y \\leq 1\\), and their joint pdf. The probability for a joint pdf is now a measure of the proportion of the volume.\nThis is not be confused with a probability from marginal pdf or pdf from one RV. The probability for marginal/single RV pdfs is the proportion of the area under the pdf for a specific range of values.\n\n\n4. Here’s a 3D plot of one of our joint pdf’s\n\\[\nf_{X,Y}(x,y) = 5e^{-x-3y} \\text{ for } 0 \\leq y \\leq x/2\n\\]\n\nlibrary(plotly)\n\nx = seq(0, 5, 0.1)\ny = seq(0, max(x)/2, 0.1/2)\nfn = expand.grid(x=x,y=y)\nfn$z = ifelse(fn$y&lt;fn$x/2, 5*exp( (-1)*fn$x - 3*fn$y), NA)\n\nz = matrix(fn$z, ncol = 51, nrow = 51, byrow = T)\n\nfig &lt;- plot_ly(x = x, y=y, z=z) %&gt;% add_surface()\n\nfig"
  },
  {
    "objectID": "lessons/11_Transformations/11_Transformations_key_info.html",
    "href": "lessons/11_Transformations/11_Transformations_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 02 assignments are graded!\n\nSolutions and videos are posted!\n\nFinish the discrete distributions notes\n\nThen get into joint distributions"
  },
  {
    "objectID": "lessons/11_Transformations/11_Transformations_key_info.html#announcements",
    "href": "lessons/11_Transformations/11_Transformations_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 02 assignments are graded!\n\nSolutions and videos are posted!\n\nFinish the discrete distributions notes\n\nThen get into joint distributions"
  },
  {
    "objectID": "lessons/11_Transformations/11_Transformations_key_info.html#key-dates",
    "href": "lessons/11_Transformations/11_Transformations_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 03 Assignment due this Thursday at 11pm\n\nI updated the homework assignment on the 18th!"
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities.html",
    "href": "lessons/11_Transformations/25_Joint_densities.html",
    "title": "Chapter 25: Joint densities",
    "section": "",
    "text": "Solve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities.html#learning-objectives",
    "href": "lessons/11_Transformations/25_Joint_densities.html#learning-objectives",
    "title": "Chapter 25: Joint densities",
    "section": "",
    "text": "Solve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities.html#double-integrals-mini-lesson-13",
    "href": "lessons/11_Transformations/25_Joint_densities.html#double-integrals-mini-lesson-13",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (1/3)",
    "text": "Double Integrals Mini Lesson (1/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 1\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} xy dydx\\)"
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities.html#double-integrals-mini-lesson-23",
    "href": "lessons/11_Transformations/25_Joint_densities.html#double-integrals-mini-lesson-23",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (2/3)",
    "text": "Double Integrals Mini Lesson (2/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 2\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} (x+y) dydx\\)"
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities.html#double-integrals-mini-lesson-33",
    "href": "lessons/11_Transformations/25_Joint_densities.html#double-integrals-mini-lesson-33",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (3/3)",
    "text": "Double Integrals Mini Lesson (3/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 3\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} e^{x+y} dydx\\)"
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "href": "lessons/11_Transformations/25_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "title": "Chapter 25: Joint densities",
    "section": "How to define the joint pdf for continuous RVs?",
    "text": "How to define the joint pdf for continuous RVs?\n\n\nFor a single continuous RV \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\), \\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\]\n\nFor two continuous RVs (\\(X\\) and \\(Y\\)), we can define the joint pdf, \\(f_{X,Y}(x,y)\\), such that for all real values \\(a,b, c, d\\) with \\(a \\leq b\\) and \\(c \\leq d\\), \\[\\mathbb{P}(a \\leq X \\leq b, c \\leq Y \\leq d) = \\int_a^b \\int_c^d f_{X,Y}(x,y)dydx\\]"
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities.html#important-properties-of-the-joint-pdf",
    "href": "lessons/11_Transformations/25_Joint_densities.html#important-properties-of-the-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Important properties of the joint pdf",
    "text": "Important properties of the joint pdf\n\nNote that \\(f_{X,Y}(x,y)\\neq \\mathbb{P}(X=x, Y=y)\\)!!!\nIn order for \\(f_{X,Y}(x,y)\\) to be a pdf, it needs to satisfy the properties\n\n\\(f_{X,Y}(x,y)\\geq 0\\) for all \\(x,y\\)\n\\(\\displaystyle\\int_{-\\infty}^{\\infty}\\displaystyle\\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dxdy=1\\)"
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "href": "lessons/11_Transformations/25_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "title": "Chapter 25: Joint densities",
    "section": "What is the joint cumulative distribution function?",
    "text": "What is the joint cumulative distribution function?\n\n\nDefinition: Joint cumulative distribution function (Joint CDF)\n\n\nThe joint cumulative distribution function (cdf) of continuous random variables \\(X\\) and \\(Y\\), is the function \\(F_{X,Y}(x,y)\\), such that for all real values of \\(x\\) and \\(y\\), \\[F_{X,Y}(x,y)= \\mathbb{P}(X \\leq x, Y \\leq y) = \\int_{-\\infty}^x\\int_{-\\infty}^y f_{X,Y}(s,t)dtds\\]\n\n\nRemarks:\n\nThe definition above for \\(F_{X,Y}(x,y)\\) is a function of \\(x\\) and \\(y\\).\nThe joint cdf at the point \\((a,b)\\), is \\[F_{X,Y}(a,b) = \\mathbb{P}(X \\leq a, Y \\leq b) = \\int_{-\\infty}^a\\int_{-\\infty}^b f_{X,Y}(s,t)dtds\\]"
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities.html#what-are-the-marginal-pdfs",
    "href": "lessons/11_Transformations/25_Joint_densities.html#what-are-the-marginal-pdfs",
    "title": "Chapter 25: Joint densities",
    "section": "What are the marginal pdf’s?",
    "text": "What are the marginal pdf’s?\n\n\nDefinition: Marginal pdf’s\n\n\nSuppose \\(X\\) and \\(Y\\) are continuous r.v.’s, with joint pdf \\(f_{X,Y}(x,y)\\). Then the marginal probability density functions are \\[\\begin{aligned}\nf_X(x)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dy\\\\\nf_Y(y)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dx\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities.html#common-steps-for-solving-problems",
    "href": "lessons/11_Transformations/25_Joint_densities.html#common-steps-for-solving-problems",
    "title": "Chapter 25: Joint densities",
    "section": "Common steps for solving problems",
    "text": "Common steps for solving problems\n\nSet up the domain of the pdf with a picture\nTranslate to needed integrands\n\nFor probability: shade in the area of interest, then translate\nFor expected value: translate domain\n\nSet up integral: \\(dxdy\\) or \\(dydx\\)?\nSolve integral!"
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities.html#example-of-joint-pdf",
    "href": "lessons/11_Transformations/25_Joint_densities.html#example-of-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)."
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities.html#example-of-joint-pdf-1",
    "href": "lessons/11_Transformations/25_Joint_densities.html#example-of-joint-pdf-1",
    "title": "Chapter 25: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "href": "lessons/11_Transformations/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "href": "lessons/11_Transformations/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "title": "Chapter 25: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(\\mathbb{P}(Y &lt; 3)\\)."
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities.html#lets-complicate-this-even-more",
    "href": "lessons/11_Transformations/25_Joint_densities.html#lets-complicate-this-even-more",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.1\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nFind \\(\\mathbb{P}(|X-Y| &lt; 2)\\)"
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "href": "lessons/11_Transformations/25_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "title": "Chapter 25: Joint densities",
    "section": "Finding the pdf of a transformation",
    "text": "Finding the pdf of a transformation\n\nLet \\(M\\) be a transformation of \\(X\\) and \\(Y\\)\nWhen we have a transformation of \\(X\\) and \\(Y\\), \\(M\\), we need to follow a specific process to find the pdf of \\(M\\)\n\nWe follow this process:\n\nStart with the joint pdf for \\(X\\) and \\(Y\\)\n\naka \\(f_{X,Y}(x, y)\\)\n\nTranslate the domain of \\(X\\) and \\(Y\\) to \\(M\\)\nFind the CDF of \\(M\\)\n\naka \\(F_M(m)\\) or \\(P(M \\leq m)\\)\n\nTake the derivative of the CDF of \\(M\\) to find the pdf of \\(M\\)\n\naka \\(f_M(m) = \\dfrac{d}{dm}F_M(m)\\)"
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities.html#lets-complicate-this-even-more-1",
    "href": "lessons/11_Transformations/25_Joint_densities.html#lets-complicate-this-even-more-1",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.2\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(M = \\max(X,Y)\\). Find the pdf for \\(M\\), that is \\(f_M(m)\\)."
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities.html#lets-complicate-this-even-more-2",
    "href": "lessons/11_Transformations/25_Joint_densities.html#lets-complicate-this-even-more-2",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 3.3\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(Z = \\min(X,Y)\\). Find the pdf for \\(Z\\), that is \\(f_Z(z)\\)."
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities.html#lets-complicate-this-even-further",
    "href": "lessons/11_Transformations/25_Joint_densities.html#lets-complicate-this-even-further",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even further!",
    "text": "Let’s complicate this even further!\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 4\n\n\nLet \\(X\\) and \\(Y\\) have joint density \\(f_{X,Y}(x,y)= \\frac85(x+y)\\) in the region \\(0 &lt; x &lt; 1,\\ \\frac12 &lt; y &lt;1\\). Find the pdf of the r.v. \\(Z\\), where \\(Z=XY\\)."
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities_key_info.html",
    "href": "lessons/11_Transformations/25_Joint_densities_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 6 assignment today!\n\nFeel free to turn in solutions later than 11/24 since I took so long to grade\n\nI made quite a few changes to the homeworks\n\nHW 10 is gone\nHW 9 is optional\nInstead of a HW assignment due over late November break\n\nHW 8 will include material from Week 8 and 9 and be due 12/5\n\n\nI have quite a bit of grading to catch up on!\nRealizing I never gave you mid-quarter feedback forms…\n\nLet’s chat about this and our assessment breakdown in the coming weeks\n\nAnything else?"
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities_key_info.html#announcements",
    "href": "lessons/11_Transformations/25_Joint_densities_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 6 assignment today!\n\nFeel free to turn in solutions later than 11/24 since I took so long to grade\n\nI made quite a few changes to the homeworks\n\nHW 10 is gone\nHW 9 is optional\nInstead of a HW assignment due over late November break\n\nHW 8 will include material from Week 8 and 9 and be due 12/5\n\n\nI have quite a bit of grading to catch up on!\nRealizing I never gave you mid-quarter feedback forms…\n\nLet’s chat about this and our assessment breakdown in the coming weeks\n\nAnything else?"
  },
  {
    "objectID": "lessons/11_Transformations/25_Joint_densities_key_info.html#key-dates",
    "href": "lessons/11_Transformations/25_Joint_densities_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 7 due\nSunday: HW 6 solutions due"
  },
  {
    "objectID": "lessons/09_pdfs/09_pdfs.html#learning-objectives",
    "href": "lessons/09_pdfs/09_pdfs.html#learning-objectives",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDistinguish between discrete and continuous random variables.\nCalculate probabilities for continuous random variables.\nCalculate and graph a density (i.e., probability density function, PDF).\nCalculate and graph a CDF (i.e., a cumulative distribution function)"
  },
  {
    "objectID": "lessons/09_pdfs/09_pdfs.html#discrete-vs.-continuous-rvs",
    "href": "lessons/09_pdfs/09_pdfs.html#discrete-vs.-continuous-rvs",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Discrete vs. Continuous RVs",
    "text": "Discrete vs. Continuous RVs\n\n\n\nFor a discrete RV, the set of possible values is either finite or can be put into a countably infinite list.\n \nContinuous RVs take on values from continuous intervals, or unions of continuous intervals\n\n\n\n\n\nFigure from Introduction to Probability TB (pg. 301)"
  },
  {
    "objectID": "lessons/09_pdfs/09_pdfs.html#how-to-define-probabilities-for-continuous-rvs",
    "href": "lessons/09_pdfs/09_pdfs.html#how-to-define-probabilities-for-continuous-rvs",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "How to define probabilities for continuous RVs?",
    "text": "How to define probabilities for continuous RVs?\n\n\nDiscrete RV \\(X\\):\n\n\n\n\n\n\n\n\n\n\npmf: \\(p_X(x) = P(X=x)\\)\n\n\nContinuous RV \\(X\\):\n\n\n\n\n\n\n\n\n\n\ndensity: \\(f_X(x)\\)\nprobability: \\(P(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\)"
  },
  {
    "objectID": "lessons/09_pdfs/09_pdfs.html#what-is-a-probability-density-function",
    "href": "lessons/09_pdfs/09_pdfs.html#what-is-a-probability-density-function",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "What is a probability density function?",
    "text": "What is a probability density function?\n\n\nProbability density function\n\n\nThe probability distribution, or probability density function (pdf), of a continuous random variable \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\),\n\\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\]\n\n\nRemarks:\n\nNote that \\(f_X(x) \\neq \\mathbb{P}(X=x)\\)!!!\nIn order for \\(f_X(x)\\) to be a pdf, it needs to satisfy the properties\n\n\\(f_X(x) \\geq 0\\) for all \\(x\\)\n\\(\\int_{-\\infty}^{\\infty} f_X(x)dx=1\\)"
  },
  {
    "objectID": "lessons/09_pdfs/09_pdfs.html#lets-demonstrate-the-pdf-with-an-example-15",
    "href": "lessons/09_pdfs/09_pdfs.html#lets-demonstrate-the-pdf-with-an-example-15",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (1/5)",
    "text": "Let’s demonstrate the PDF with an example (1/5)\n\n\n\n\nExample 1.1\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind the value of \\(a\\) so that \\(f_X(x)\\) is a pdf."
  },
  {
    "objectID": "lessons/09_pdfs/09_pdfs.html#lets-demonstrate-the-pdf-with-an-example-25",
    "href": "lessons/09_pdfs/09_pdfs.html#lets-demonstrate-the-pdf-with-an-example-25",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (2/5)",
    "text": "Let’s demonstrate the PDF with an example (2/5)\n\n\n\n\nExample 1.2\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(2.7 \\leq X \\leq 2.9)\\)."
  },
  {
    "objectID": "lessons/09_pdfs/09_pdfs.html#lets-demonstrate-the-pdf-with-an-example-35",
    "href": "lessons/09_pdfs/09_pdfs.html#lets-demonstrate-the-pdf-with-an-example-35",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (3/5)",
    "text": "Let’s demonstrate the PDF with an example (3/5)\n\n\n\n\nExample 1.3\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(2.7 &lt; X \\leq 2.9)\\)."
  },
  {
    "objectID": "lessons/09_pdfs/09_pdfs.html#lets-demonstrate-the-pdf-with-an-example-45",
    "href": "lessons/09_pdfs/09_pdfs.html#lets-demonstrate-the-pdf-with-an-example-45",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (4/5)",
    "text": "Let’s demonstrate the PDF with an example (4/5)\n\n\n\n\nExample 1.4\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(X = 2.9)\\)."
  },
  {
    "objectID": "lessons/09_pdfs/09_pdfs.html#lets-demonstrate-the-pdf-with-an-example-55",
    "href": "lessons/09_pdfs/09_pdfs.html#lets-demonstrate-the-pdf-with-an-example-55",
    "title": "Chapter 24: Continuous RVs and PDFs",
    "section": "Let’s demonstrate the PDF with an example (5/5)",
    "text": "Let’s demonstrate the PDF with an example (5/5)\n\n\n\n\nExample 1.5\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(X \\leq 2.8)\\)."
  },
  {
    "objectID": "lessons/18_Cont_RVs/18_Cont_RVs.html#where-are-we",
    "href": "lessons/18_Cont_RVs/18_Cont_RVs.html#where-are-we",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#probability-axioms",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#probability-axioms",
    "title": "Lesson 3: Language of Probability",
    "section": "Probability Axioms",
    "text": "Probability Axioms\n\n\n\n\nAxiom 1\n\n\nFor every event \\(A\\), \\(0\\leq\\mathbb{P}(A)\\leq 1\\). Probability is between 0 and 1.\n\n\n\n\nAxiom 2\n\n\nFor the sample space \\(S\\), \\(\\mathbb{P}(S)=1\\).\n\n\n\n\nAxiom 3\n\n\nIf \\(A_1, A_2, A_3, \\ldots\\), is a collection of disjoint events, then \\[\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i).\\] The probability of at least one \\(A_i\\) is the sum of the individual probabilities of each."
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#some-probability-properties",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#some-probability-properties",
    "title": "Lesson 3: Language of Probability",
    "section": "Some probability properties",
    "text": "Some probability properties\nUsing the Axioms, we can prove all other probability properties! Events A, B, and C are not necessarily disjoint!\n\n\n\n\nProposition 1\n\n\nFor any event \\(A\\), \\(\\mathbb{P}(A)= 1 - \\mathbb{P}(A^C)\\)\n\n\n\n\nProposition 2\n\n\n\\(\\mathbb{P}(\\emptyset)=0\\)\n\n\n\n\nProposition 3\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\n\n\n\n\n\nProposition 4\n\n\n\\[\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\] where \\(A\\) and \\(B\\) are not necessarily disjoint\n\n\n\n\nProposition 5\n\n\n\\(\\begin{aligned} \\mathbb{P}(A \\cup B & \\cup C) = \\mathbb{P}(A) + \\mathbb{P}(B) + \\\\ & \\mathbb{P}(C) - \\mathbb{P}(A \\cap B) - \\mathbb{P}(A \\cap C) - \\\\ & \\mathbb{P}(B \\cap C) + \\mathbb{P}(A \\cap B \\cap C) \\end{aligned}\\)"
  },
  {
    "objectID": "lessons/02_Lang_prob/02_Lang_prob.html#partitions",
    "href": "lessons/02_Lang_prob/02_Lang_prob.html#partitions",
    "title": "Lesson 3: Language of Probability",
    "section": "Partitions",
    "text": "Partitions\n\n\n\n\nDefinition: Partition\n\n\nA set of events \\(\\{A_i\\}_{i=1}^{n}\\) create a partition of \\(A\\), if\n\nthe \\(A_i\\)’s are disjoint (mutually exclusive) and\n\\(\\bigcup \\limits_{i=1}^n A_i = A\\)\n\n\n\n\n\nExample 2\n\n\n\nIf \\(A \\subset B\\), then \\(\\{A, B \\cap A^C\\}\\) is a partition of \\(B\\).\nIf \\(S = \\bigcup \\limits_{i=1}^n A_i\\), and the \\(A_i\\)’s are disjoint, then the \\(A_i\\)’s are a partition of the sample space.\n\n\n\n\n\n\nCreating partitions is sometimes used to help calculate probabilities, since by Axiom 3 we can add the probabilities of disjoint events."
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html",
    "href": "lessons/03_Simulations/03_Simulations.html",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "",
    "text": "Definition: Outcome\n\n\nThe possible results in a random phenomenon.\n\n\n\n\nDefinition: Sample Space\n\n\nThe sample space \\(S\\) is the set of all outcomes\n\n\n\n\nDefinition: Event\n\n\nAn event is a collection of some outcomes. An event can include multiple outcomes or no outcomes (a subset of the sample space).\n\n\nWhen thinking about events, think about outcomes that you might be asking the probability of. For example, what is the probability that you get a heads or a tails in one flip? (Answer: 1)\n\n\n\nSimulation involves using a probability model to artificially recreate a random phenomenon, many times, usually using a computer."
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#recall-outcomes-events-sample-spaces",
    "href": "lessons/03_Simulations/03_Simulations.html#recall-outcomes-events-sample-spaces",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "Recall: Outcomes, events, sample spaces",
    "text": "Recall: Outcomes, events, sample spaces\n\n\nDefinition: Outcome\n\n\nThe possible results in a random phenomenon.\n\n\n\n\nDefinition: Sample Space\n\n\nThe sample space \\(S\\) is the set of all outcomes\n\n\n\n\nDefinition: Event\n\n\nAn event is a collection of some outcomes. An event can include multiple outcomes or no outcomes (a subset of the sample space).\n\n\nWhen thinking about events, think about outcomes that you might be asking the probability of. For example, what is the probability that you get a heads or a tails in one flip? (Answer: 1)"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#what-is-a-simulation",
    "href": "lessons/03_Simulations/03_Simulations.html#what-is-a-simulation",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "What is a simulation?",
    "text": "What is a simulation?\nA probability model for a random phenomenon includes a sample space, events, random variables, and a probability measure.\n\n\nSimulation\n\n\nSimulation involves using a probability model to artificially recreate a random phenomenon, many times, usually using a computer.\n\n\nWe simulate outcomes and values of random variables according to the model’s assumptions."
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#what-is-simulation",
    "href": "lessons/03_Simulations/03_Simulations.html#what-is-simulation",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "What is Simulation?",
    "text": "What is Simulation?\nA probability model for a random phenomenon includes a sample space, events, random variables, and a probability measure.\nSimulation is the process of using this model to artificially recreate a random phenomenon many times, typically with a computer.\nWe simulate outcomes and values of random variables according to the model’s assumptions."
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#the-foundation-relative-frequencies",
    "href": "lessons/03_Simulations/03_Simulations.html#the-foundation-relative-frequencies",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "The Foundation: Relative Frequencies",
    "text": "The Foundation: Relative Frequencies\n\nProbabilities can be interpreted as long-run relative frequencies\n\n \n\nBy simulating a random phenomenon a large number of times, we can approximate the probability of an event by calculating the relative frequency of its occurrence\n\nBasically, out of all the trials we run, how many times did the event happen?\n\n\n \n\nSimulation is a powerful tool to approximate a few things:\n\nProbabilities\nDistributions of random variables\nLong-run averages"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#steps-of-a-simulation",
    "href": "lessons/03_Simulations/03_Simulations.html#steps-of-a-simulation",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "4 (S)teps of a Simulation",
    "text": "4 (S)teps of a Simulation\n\n\n\nSet up\n\n\n\nDefine the probability space and related random variables and events, including assumptions.\n\n\n\n\n\nSimulate\n\n\n\nRun the simulation to generate outcomes according to the assumptions.\n\n\n\n\n\nSummarize\n\n\n\nAnalyze the output using plots and summary statistics like relative frequencies and averages.\n\n\n\n\n\nSensitivity analysis\n\n\n\nInvestigate how results change when assumptions or parameters of the model are altered."
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#why-use-simulation",
    "href": "lessons/03_Simulations/03_Simulations.html#why-use-simulation",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "Why Use Simulation?",
    "text": "Why Use Simulation?\n\nIn many cases, it is difficult or impossible to calculate probabilities explicitly or to enumerate all possible outcomes.\nA model might not provide a simple formula for an event’s probability. For example, a hurricane model can’t provide a formula for the probability of landfall, but it can simulate many possible paths to approximate it.\nSimulation provides a powerful and flexible way to investigate complex probability models."
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#tactile-simulation-boxes-and-spinners",
    "href": "lessons/03_Simulations/03_Simulations.html#tactile-simulation-boxes-and-spinners",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "Tactile Simulation: Boxes and Spinners",
    "text": "Tactile Simulation: Boxes and Spinners"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#box-models",
    "href": "lessons/03_Simulations/03_Simulations.html#box-models",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "Box Models",
    "text": "Box Models\n\nA box model uses a box of “tickets” with labels to represent possible outcomes.\nFair coin flip: A box with two tickets (H and T).\n90% free throw shooter: A box with 10 tickets (9 “make” and 1 “miss”).\nDraws can be with replacement (e.g., coin flips) or without replacement (e.g., dealing a poker hand)."
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#spinners",
    "href": "lessons/03_Simulations/03_Simulations.html#spinners",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "Spinners",
    "text": "Spinners\n\nIf draws are with replacement, we can use a single circular spinner instead of a box.\nThe area of each sector corresponds to the probability of an outcome.\n\n\n\nExample: Dice Rolls\n\nProblem: Let \\(X\\) be the sum of two rolls of a fair four-sided die, and \\(Y\\) be the larger of the two rolls. How to simulate?\nSolution (Box Model): Use a box with tickets labeled 1, 2, 3, 4. Draw two tickets with replacement. Let \\(X\\) be the sum and \\(Y\\) be the larger value.\nSolution (Spinner): Use a spinner with four equally-sized sectors labeled 1, 2, 3, 4. Spin it twice."
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#example-dice-rolls",
    "href": "lessons/03_Simulations/03_Simulations.html#example-dice-rolls",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "Example: Dice Rolls",
    "text": "Example: Dice Rolls\n\n\nExample: Simulating Two Rolls of a Fair Four-Sided Die\n\n\nWe’re going to roll two four-sided die. Let \\(X\\) be the sum of two rolls, and \\(Y\\) be the larger of the two rolls. How would we simulate \\(X\\) and \\(Y\\) separately?\n\n\n\nUse the steps to run simulation for for \\(Y\\) now"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#simulating-continuous-outcomes-the-meeting-problem",
    "href": "lessons/03_Simulations/03_Simulations.html#simulating-continuous-outcomes-the-meeting-problem",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "Simulating Continuous Outcomes: The Meeting Problem",
    "text": "Simulating Continuous Outcomes: The Meeting Problem"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#the-problem",
    "href": "lessons/03_Simulations/03_Simulations.html#the-problem",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "The Problem",
    "text": "The Problem\n\nRegina and Cady’s arrival times are between noon (0 minutes) and 1 PM (60 minutes).\nThe arrival times are a continuous random variable on the interval \\([0, 60]\\).\nWe cannot use a box model because there are uncountably many possible outcomes.\nA spinner with a continuous axis is the tactile analog."
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#uniform-model",
    "href": "lessons/03_Simulations/03_Simulations.html#uniform-model",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "Uniform Model",
    "text": "Uniform Model\n\nWe can construct a spinner where the needle is equally likely to land on any value between 0 and 60.\nWe would spin it twice to get Regina’s and Cady’s arrival times."
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#normal-model",
    "href": "lessons/03_Simulations/03_Simulations.html#normal-model",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "Normal Model",
    "text": "Normal Model\n\nWhat if Regina is more likely to arrive around 12:30?\nWe can create a spinner where values near 30 are “stretched” to occupy more area.\nThis is an example of a Normal distribution, where probabilities are concentrated around a central value."
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#computer-simulation-in-r",
    "href": "lessons/03_Simulations/03_Simulations.html#computer-simulation-in-r",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "Computer Simulation in R",
    "text": "Computer Simulation in R\n\nWe can use R to perform simulations without a dedicated package like Symbulate.\nR has built-in functions for generating random numbers from different distributions."
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#still-confused-about-long-run-relative-frequencies",
    "href": "lessons/03_Simulations/03_Simulations.html#still-confused-about-long-run-relative-frequencies",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "Still confused about long-run relative frequencies?",
    "text": "Still confused about long-run relative frequencies?\nSeeing Theory, Chapter 1: Basic Probability, Chance Events We’ll flip a coin many many times"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#simulating-outcomes",
    "href": "lessons/03_Simulations/03_Simulations.html#simulating-outcomes",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "Simulating Outcomes",
    "text": "Simulating Outcomes\n\n\nExample: Simulating Two Rolls of a Fair Four-Sided Die\n\n\nWe’re going to roll two four-sided die. Let \\(X\\) be the sum of two rolls, and \\(Y\\) be the larger of the two rolls. How would we simulate \\(X\\) and \\(Y\\) separately?\n\n\n\nWe’ve seen how to simulate a single pair of rolls\n\n\nrolls &lt;- sample(x = c(1, 2, 3, 4), size = 2, replace = TRUE)\n\n\nWe can use the replicate() function to repeat this process many times (we’ll do 10)\n\n\nreps &lt;- 10\nreplicate(reps, sample(x = 1:4, size = 2, replace = TRUE))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n[1,]    2    3    3    3    3    3    3    1    3     3\n[2,]    1    1    2    2    2    1    4    1    4     2"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#simulating-random-variables",
    "href": "lessons/03_Simulations/03_Simulations.html#simulating-random-variables",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "Simulating Random Variables",
    "text": "Simulating Random Variables\nWe can apply functions to the simulated outcomes to get the values of our random variables.\nLet’s simulate X (sum) and Y (max).\n\n# Calculate X (the sum) for each repetition\nX_simulated &lt;- apply(simulations, 2, sum)\n\n# Calculate Y (the max) for each repetition\nY_simulated &lt;- apply(simulations, 2, max)\n\n# Display the first 10 values for X and Y\nhead(X_simulated, 10)\n\n [1] 8 5 3 5 5 3 3 5 6 5\n\nhead(Y_simulated, 10)\n\n [1] 4 4 2 3 4 2 2 3 4 4"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#types-of-simulations",
    "href": "lessons/03_Simulations/03_Simulations.html#types-of-simulations",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "Types of simulations",
    "text": "Types of simulations\n\nWe can simulate discrete and continuous random variables\n\n \n\nDiscrete random variables (RVs) are a little easier to understand\n\nWe can use “tactile” simulations to give us a sense of what the computer is doing\n\n\n \n\nContinuous random variables (RVs) are more complex\n\nUsing the computer is the best way to simulate these\nWe will explore these more when we get to the continuous distributions"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#tactile-simulations",
    "href": "lessons/03_Simulations/03_Simulations.html#tactile-simulations",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "Tactile simulations",
    "text": "Tactile simulations\n\nWe’ve already seen coin flips!\nWe can also use cards, dice, and other objects to simulate discrete random variables\n\n \n\nOther common method: A box model uses a box/hat/bucket of “tickets” with labels to represent possible outcomes\n\nAllows us to increase the number of “tickets” with appropriate labels\nCoin flip as box model: A box with two tickets (H and T).\n90% free throw shooter: A box with 10 tickets (9 “make” and 1 “miss”).\nDraws can be with replacement (e.g., coin flips) or without replacement (e.g., dealing a poker hand)."
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#tactile-simulations-spinners",
    "href": "lessons/03_Simulations/03_Simulations.html#tactile-simulations-spinners",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "Tactile simulations: Spinners",
    "text": "Tactile simulations: Spinners\n\nIf draws are with replacement, we can use a single circular spinner instead of a box\n\n \n\nThe area of each sector corresponds to the probability of an outcome\n\n \n\nLet’s Google “spinner” and see what we find!\n\nWe can try to make a spinner for a coin flip"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#how-do-we-extend-a-single-simulation-to-useful-simulations",
    "href": "lessons/03_Simulations/03_Simulations.html#how-do-we-extend-a-single-simulation-to-useful-simulations",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "How do we extend a single simulation to useful simulations?",
    "text": "How do we extend a single simulation to useful simulations?\n\nWe can set size to be larger than 1 to simulate multiple draws at once\n\n\nsample(x = c(\"H\", \"T\"), size = 5, replace = TRUE)\n\n[1] \"T\" \"T\" \"H\" \"T\" \"T\"\n\n\n\nWe can simulate our example of the two four-sided die\n\n\nsample(x = c(1, 2, 3, 4), size = 2, replace = TRUE)\n\n[1] 1 2\n\n\n \n\nWhat happens if we set replace = FALSE?\n\n\nsample(x = c(1, 2, 3, 4), size = 2, replace = FALSE)\n\n[1] 4 3\n\nsample(x = c(1, 2, 3, 4), size = 4, replace = FALSE)\n\n[1] 1 3 4 2"
  },
  {
    "objectID": "homeworks.html#file-naming",
    "href": "homeworks.html#file-naming",
    "title": "Homework",
    "section": "File Naming",
    "text": "File Naming\n\nFor HW Assignments, please use the following file naming: “HW01_LastName_FirstInitial”\n\nFor homeworks without R, this should be a pdf file\nFor homeworks with R, this may be a pdf file (with the code in the pdf) or an html file"
  },
  {
    "objectID": "homeworks.html#rubric",
    "href": "homeworks.html#rubric",
    "title": "Homework",
    "section": "Rubric",
    "text": "Rubric\n\nAssignments\nA total of 1 point will be given for a complete homework. The following rubric will be used:\n\n\n\n\n\n\n\n\n\n1 point\n0 points\n\n\n\n\nCompleteness\n75% of the question parts are thoroughly worked out and have an answer. “Question parts” means the sub-questions labeled “Part _.” Answers can be incorrect or correct. For parts with longer processes and calculations, solution set up and calculations are required.\nLess than 75% of question parts are thoroughly worked out. Attempts do not count as thoroughly worked out."
  },
  {
    "objectID": "quiz.html",
    "href": "quiz.html",
    "title": "Quiz Info",
    "section": "",
    "text": "Below is the general timing and lessons for each quiz:\nQuizzes will be mostly conceptual questions with 10-15 multiple choice questions. Some calculations will need to be done for certain questions, but the focus will be on understanding concepts.\nMore information specific to each quiz will be posted below."
  },
  {
    "objectID": "lessons/00_Intro/00_Intro_key_info.html#key-dates",
    "href": "lessons/00_Intro/00_Intro_key_info.html#key-dates",
    "title": "Key Info and Announcements",
    "section": "Key dates",
    "text": "Key dates\n\nHomework 0 is due THIS THURSDAY at 11pm!"
  },
  {
    "objectID": "lessons/00_Intro/00_Intro_key_info.html#last-class",
    "href": "lessons/00_Intro/00_Intro_key_info.html#last-class",
    "title": "Key Info and Announcements",
    "section": "Last class",
    "text": "Last class\n\nThere wasn’t one heh"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#what-is-a-random-variable",
    "href": "lessons/01_Probability/01_Probability.html#what-is-a-random-variable",
    "title": "Lesson 1: Introduction to Probability",
    "section": "What is a random variable?",
    "text": "What is a random variable?\n\n\nDefinition: Random Variable\n\n\nFor a given sample space \\(S\\), a random variable (r.v.) is a function whose domain is \\(S\\) and whose range is the set of real numbers \\(\\mathbb{R}\\). A random variable assigns a real number to each outcome in the sample space.\n\n\n\nA random variable’s value is completely determined by the outcome \\(\\omega\\), where \\(\\omega \\in S\\)\n\nWhat is random is the outcome \\(\\omega\\)\n\nA random variable is a function from the sample space (with outcomes \\(\\omega\\)) to the set of real numbers\n\nWe typically write \\(X\\) instead of \\(X(\\omega)\\), where \\(X\\) is our random variable\n\nThus, we can take our sample space (all outcomes) and make functional transformations to it"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#some-remarks-on-random-variables",
    "href": "lessons/01_Probability/01_Probability.html#some-remarks-on-random-variables",
    "title": "Lesson 1: Introduction to Probability",
    "section": "Some remarks on random variables",
    "text": "Some remarks on random variables\n\nA random variable’s value is completely determined by the outcome \\(\\omega\\), where \\(\\omega \\in S\\)\n\nWhat is random is the outcome \\(\\omega\\)\n\nA random variable is a function from the sample space (with outcomes \\(\\omega\\)) to the set of real numbers\n\nWe typically write \\(X\\) instead of \\(X(\\omega)\\), where \\(X\\) is our random variable\n\nThus, we can take our sample space (all outcomes) and make functional transformations to it\nFor example, if we roll three dice, there are \\(6^3 = 216\\) possible outcomes (which is \\(\\omega\\))\n\nWe can define a random variable as the sum of the of the three dice\nIf our outcome is the set of numbers the dice landed on ( \\(\\omega=(a,b,c)\\) ), then \\[ X(\\omega) = X = a + b + c \\]"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#discrete-vs.-continuous-r.v.s",
    "href": "lessons/01_Probability/01_Probability.html#discrete-vs.-continuous-r.v.s",
    "title": "Lesson 1: Introduction to Probability",
    "section": "Discrete vs. Continuous r.v.’s",
    "text": "Discrete vs. Continuous r.v.’s\n\nFor a discrete r.v., the set of possible values is either finite or can be put into a countably infinite list\n\nYou could theoretically list the specific possible outcomes that the variable can take\nIf you sum the rolls of three dice, you must get a whole number. For example, you can’t get any number between 3 and 4.\n\n\n   \n\nContinuous r.v.’s take on values from continuous intervals, or unions of continuous intervals\n\nVariable takes on a range of values, but there are infinitely possible values within the range\nIf you keep track of the time you sleep, you can sleep for 8 hours or 7.9 hours or 7.99 hours or 7.999 hours …"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#the-cool-and-tricky-thing-about-random-variables",
    "href": "lessons/01_Probability/01_Probability.html#the-cool-and-tricky-thing-about-random-variables",
    "title": "Lesson 1: Introduction to Probability",
    "section": "The cool (and tricky) thing about random variables",
    "text": "The cool (and tricky) thing about random variables\nLet’s say we have a pair of 6-sided die.\n\nFor each dice, the sample size includes rolling a number 1-6.\nIf we want the sample space for both dice rolls, then we have combinations of 1-6 and 1-6"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#we-need-to-understand-random-variables",
    "href": "lessons/03_Simulations/03_Simulations.html#we-need-to-understand-random-variables",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "We need to understand random variables",
    "text": "We need to understand random variables\n\n\nDefinition: Random Variable\n\n\nFor a given sample space \\(S\\), a random variable (r.v.) is a function whose domain is \\(S\\) and whose range is the set of real numbers \\(\\mathbb{R}\\). A random variable assigns a real number to each outcome in the sample space.\n\n\n\nA random variable’s value is completely determined by the outcome \\(\\omega\\), where \\(\\omega \\in S\\)\n\nWhat is random is the outcome \\(\\omega\\)\n\nA random variable is a function from the sample space (with outcomes \\(\\omega\\)) to the set of real numbers\n\nWe typically write \\(X(\\omega)\\) (or \\(X\\) for short), where \\(X\\) is our random variable\n\nThus, we can take our sample space (all outcomes) and make functional transformations to it"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#the-cool-and-tricky-thing-about-random-variables",
    "href": "lessons/03_Simulations/03_Simulations.html#the-cool-and-tricky-thing-about-random-variables",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "The cool (and tricky) thing about random variables",
    "text": "The cool (and tricky) thing about random variables\nDo you remember our coin example from Lesson 1? We tossed one or two coins.\n\nFor each coin, the sample space is heads and tails (\\(S = \\{H,T\\}\\))\nIf we want the sample space for both coins in order, then we have combinations (\\(S=\\{(H,H), (H,T), (T,H), (T,T)\\}\\))\n\n \nWe make the random variable a function of the sample space.\n\nFor one coin toss, we can say random variable \\(X\\) is \\(1\\) if we toss a heads (\\(\\omega = \\text{H}\\)) and \\(X=0\\) if we get a tails\nFor the two coins, we can say \\(X\\) is the count of heads, so if \\(\\omega = \\text{(H, T)}\\), then \\(X=1\\)"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#discrete-vs.-continuous-r.v.s",
    "href": "lessons/03_Simulations/03_Simulations.html#discrete-vs.-continuous-r.v.s",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "Discrete vs. Continuous r.v.’s",
    "text": "Discrete vs. Continuous r.v.’s\n\nFor a discrete r.v., the set of possible values is either finite or can be put into a countably infinite list\n\nYou could theoretically list the specific possible outcomes that the variable can take\nIf you sum the rolls of three dice, you must get a whole number. For example, you can’t get any number between 3 and 4.\n\n\n   \n\nContinuous r.v.’s take on values from continuous intervals, or unions of continuous intervals\n\nVariable takes on a range of values, but there are infinitely possible values within the range\nIf you keep track of the time you sleep, you can sleep for 8 hours or 7.9 hours or 7.99 hours or 7.999 hours …"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#types-of-random-variables",
    "href": "lessons/03_Simulations/03_Simulations.html#types-of-random-variables",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "Types of random variables",
    "text": "Types of random variables\nThere are two types of random variables:\n\n\n\n\n\nDiscrete random variables (RVs): the set of possible values is either finite or can be put into a countably infinite list\n\nYou could theoretically list the specific possible outcomes that the variable can take\nIf you sum the rolls of three dice, you must get a whole number. For example, you can’t get any number between 3 and 4.\n\n\n\n\n\n\n\n\nContinuous random variables (RVs): take on values from continuous intervals, or unions of continuous intervals\n\nVariable takes on a range of values, but there are infinitely possible values within the range\nIf you keep track of the time you sleep, you can sleep for 8 hours or 7.9 hours or 7.99 hours or 7.999 hours …\n\n\n\n\n\n\nDiscrete random variables (RVs) are a little easier to simulate right now\n\nWe will only do discrete RVs today"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#how-do-we-simulate-something-like-a-single-dice-roll",
    "href": "lessons/03_Simulations/03_Simulations.html#how-do-we-simulate-something-like-a-single-dice-roll",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "How do we simulate something like a single dice roll?",
    "text": "How do we simulate something like a single dice roll?\n\nWe can also use R to sample from the box or spinner\nThe sample() function is a powerful tool for simulating draws from a box model.\nFor example, we can simulate a coin flip\n\nWhat is x?\nWhat is size?\n\n\n\nsample(x = c(\"H\", \"T\"), size = 1)\n\n[1] \"T\"\n\n\n \n\nOr a dice roll\n\n\nsample(x = c(1, 2, 3, 4), size = 1)\n\n[1] 1"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#how-do-we-extend-a-single-simulation-to-multiple-simulations",
    "href": "lessons/03_Simulations/03_Simulations.html#how-do-we-extend-a-single-simulation-to-multiple-simulations",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "How do we extend a single simulation to multiple simulations?",
    "text": "How do we extend a single simulation to multiple simulations?\n\nWe can set size to be larger than 1 to simulate multiple draws at once\n\n\nsample(x = c(\"H\", \"T\"), size = 5, replace = TRUE)\n\n[1] \"H\" \"T\" \"T\" \"H\" \"T\"\n\n\n\nWe can simulate our example of the two four-sided die\n\n\nsample(x = c(1, 2, 3, 4), size = 2, replace = TRUE)\n\n[1] 2 2\n\n\n \n\nWhat happens if we set replace = FALSE?\n\n\nsample(x = c(1, 2, 3, 4), size = 2, replace = FALSE)\n\n[1] 3 1\n\nsample(x = c(1, 2, 3, 4), size = 4, replace = FALSE)\n\n[1] 3 4 1 2"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#what-if-we-have-multiple-phenomena-at-once",
    "href": "lessons/03_Simulations/03_Simulations.html#what-if-we-have-multiple-phenomena-at-once",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "What if we have multiple phenomena at once?",
    "text": "What if we have multiple phenomena at once?\n\nWe can set size to be larger than 1 to simulate multiple draws at once\n\n\nsample(x = c(\"H\", \"T\"), size = 5, replace = TRUE)\n\n[1] \"T\" \"T\" \"T\" \"H\" \"T\"\n\n\n\nWe can simulate our example of the two four-sided die\n\n\nsample(x = c(1, 2, 3, 4), size = 2, replace = TRUE)\n\n[1] 3 3\n\n\n \n\nWhat happens if we set replace = FALSE?\n\n\nsample(x = c(1, 2, 3, 4), size = 2, replace = FALSE)\n\n[1] 4 2\n\nsample(x = c(1, 2, 3, 4), size = 4, replace = FALSE)\n\n[1] 2 1 3 4"
  },
  {
    "objectID": "lessons/00_Intro/00_Intro.html#lets-visit-the-website-syllabus-12",
    "href": "lessons/00_Intro/00_Intro.html#lets-visit-the-website-syllabus-12",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website: Syllabus (1/2)",
    "text": "Let’s visit the website: Syllabus (1/2)\n\nCourse learning objectives\nTextbook online! (different than last year)\nResources: PennState STAT 414 site!\nR: you will get a lot of help in BSTA 511 and we will use some!\nAssessments and grade breakdowns\n\nMostly homework + quizzes\n\nFeedback from you to me: in the form of exit tickets, midterm feedback, and final course eval\nHow to succeed in this course: resources and assignments explained\nLate work policy / Attendance policy\nChatGPT and other AI technology\nCourse expectations: a few ways that I will show you respect and commitment to you as students\n\nAnd a few ways I expect from you!\n\nCommunicating with me: give me 24 hours to reply M-F\n\nI try really hard to keep emails from taking over my life"
  },
  {
    "objectID": "lessons/00_Intro/00_Intro.html#lets-visit-the-website-syllabus-12-1",
    "href": "lessons/00_Intro/00_Intro.html#lets-visit-the-website-syllabus-12-1",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website: Syllabus (1/2)",
    "text": "Let’s visit the website: Syllabus (1/2)"
  },
  {
    "objectID": "lessons/00_Intro/00_Intro.html#lets-visit-the-website-syllabus-22",
    "href": "lessons/00_Intro/00_Intro.html#lets-visit-the-website-syllabus-22",
    "title": "Welcome to BSTA 550!",
    "section": "Let’s visit the website: Syllabus (2/2)",
    "text": "Let’s visit the website: Syllabus (2/2)"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability.html#coin-toss-example-revisited-2-coins",
    "href": "lessons/01_Probability/01_Probability.html#coin-toss-example-revisited-2-coins",
    "title": "Lesson 1: Introduction to Probability",
    "section": "Coin Toss Example Revisited: 2 coins",
    "text": "Coin Toss Example Revisited: 2 coins\n\nFrom our sample space and events:\n\nSample space: \\(S = \\{HH, HT, TH, TT\\}\\)\nEvent A: \\(A = \\text{exactly one H} = \\{HT, TH\\}\\)\nEvent B: \\(B = \\text{at least one H} = \\{HT, TH, HH\\}\\)\n\n\n \n\nCalculate \\(P(A)\\) and \\(P(B)\\)"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html#birthday-example",
    "href": "lessons/05_Equally_likely_outcomes/22_Counting_Intro.html#birthday-example",
    "title": "Lesson 5: Equally Likely Outcomes",
    "section": "Birthday example",
    "text": "Birthday example"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html",
    "href": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html",
    "title": "Lesson 5: Equally Likely Outcomes",
    "section": "",
    "text": "Define permutations and combinations\nCharacterize difference between sampling with and without replacement\nCharacterize difference between sampling when order matters and when order does not matter\nCalculate the probability of sampling any combination of the following: with or without replacement and order does or does not matter"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#learning-objectives",
    "href": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#learning-objectives",
    "title": "Lesson 5: Equally Likely Outcomes and Counting",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDefine permutations and combinations\nCharacterize difference between sampling with and without replacement\nCharacterize difference between sampling when order matters and when order does not matter\nCalculate the probability of sampling any combination of the following: with or without replacement and order does or does not matter"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#where-are-we",
    "href": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#where-are-we",
    "title": "Lesson 5: Equally Likely Outcomes and Counting",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#birthday-example",
    "href": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#birthday-example",
    "title": "Lesson 5: Equally Likely Outcomes and Counting",
    "section": "Birthday example",
    "text": "Birthday example"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#basic-counting-examples-13",
    "href": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#basic-counting-examples-13",
    "title": "Lesson 5: Equally Likely Outcomes and Counting",
    "section": "Basic Counting Examples (1/3)",
    "text": "Basic Counting Examples (1/3)\n\n\nExample 1\n\n\nSuppose we have 10 (distinguishable) subjects for study.\n\nHow many possible ways are there to order them?\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?\n\nHow many ways to order them without replacement and only need 6?\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#basic-counting-examples-23",
    "href": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#basic-counting-examples-23",
    "title": "Lesson 5: Equally Likely Outcomes and Counting",
    "section": "Basic Counting Examples (2/3)",
    "text": "Basic Counting Examples (2/3)\nSuppose we have 10 (distinguishable) subjects for study.\n\n\n\n\nExample 1.1\n\n\nHow many possible ways are there to order them?\n\n\n \n\n\nExample 1.2\n\n\nHow many ways to order them if we can reuse the same subject and\n\nneed 10 total?\nneed 6 total?"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#basic-counting-examples-33",
    "href": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#basic-counting-examples-33",
    "title": "Lesson 5: Equally Likely Outcomes and Counting",
    "section": "Basic Counting Examples (3/3)",
    "text": "Basic Counting Examples (3/3)\nSuppose we have 10 (distinguishable) subjects for study.\n\n\n\n\nExample 1.3\n\n\nHow many ways to order them without replacement and only need 6?\n\n\n \n\n\nExample 1.4\n\n\nHow many ways to choose 6 subjects without replacement if the order doesn’t matter?"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#permutations-and-combinations-1",
    "href": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#permutations-and-combinations-1",
    "title": "Lesson 5: Equally Likely Outcomes and Counting",
    "section": "Permutations and Combinations",
    "text": "Permutations and Combinations\n\n\nDefinition: Permutations\n\n\nPermutations are the number of ways to arrange in order \\(r\\) distinct objects when there are \\(n\\) total.\n\\[nPr = \\frac{n!}{(n-r)!}\\]\n\n\n\n\nDefinition: Combinations\n\n\nCombinations are the number of ways to choose (order doesn’t matter) \\(r\\) objects from \\(n\\) without replacement.\n\\[nCr = \\textrm{\"n choose r\"} = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#some-combinations-properties",
    "href": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#some-combinations-properties",
    "title": "Lesson 5: Equally Likely Outcomes and Counting",
    "section": "Some combinations properties",
    "text": "Some combinations properties\n\n\n\n\n\n\n\n\nProperty\n\nProof\n\n\n\n\n\\[\\binom{n}{r} = \\binom{n}{n-r}\\]\n\n\\(\\binom{n}{r} = \\dfrac{n!}{r!(n-r)!}\\) and \\(\\binom{n}{n-r} = \\dfrac{n!}{(n-r)!(n-(n-r))!} = \\dfrac{n!}{(n-r)!r!}\\)\n\n\n\\[\\binom{n}{1} = n\\]\n\n\\[\\binom{n}{1} = \\dfrac{n!}{1!(n-1)!}=\\dfrac{n\\cdot(n-1)\\cdot(n-2)\\cdots1}{1! \\cdot (n-1)\\cdot(n-2)\\cdots1} = \\dfrac{n\\cdot(n-1)!}{1\\cdot (n-1)!} = \\dfrac{n}{1}=n\\]\n\n\n\\[\\binom{n}{0} = 1\\]\n\n\\[\\binom{n}{0} = \\dfrac{n!}{0!(n-0)!}=\\dfrac{n!}{1\\cdot n!} = 1\\]"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#table-of-different-cases",
    "href": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#table-of-different-cases",
    "title": "Lesson 5: Equally Likely Outcomes and Counting",
    "section": "Table of different cases",
    "text": "Table of different cases\n\n\\(n\\) = total number of objects\n\\(r\\) = number objects needed\n\n\n\n\n\n\n\n\n\nwith replacement\nwithout replacement\n\n\n\n\norder matters\n\\[n^r\\]\n\\[n\\text{P}r = \\frac{n!}{(n-r)!}\\]\n\n\norder doesn’t matter\n\\[ \\binom{n+r-1}{r}\\]\n\\[n\\text{C}r = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#enumerating-events-and-sample-space",
    "href": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#enumerating-events-and-sample-space",
    "title": "Lesson 5: Equally Likely Outcomes and Counting",
    "section": "Enumerating Events and Sample Space",
    "text": "Enumerating Events and Sample Space\n\nRecall, \\(P(A) = \\dfrac{|A|}{|S|}\\)\n\nWithin combinatorics, we can use the previous equations to help enumerate the event and sample space\nBut \\(A\\) might be a combination of enumerations\n\n\n \n\nFor example in the following example drawing 2 spades when order does not matter, we actually need to enumerate the other cards that are NOT spades. So the event is choosing 2 spades out of 13 AND choosing 0 other cards of 39 cards (13 hearts + 13 clubs + 13 diamonds).\nThus the probability is actually:\n\n\\[ P(\\text{two spades}) = \\dfrac{{13 \\choose 2}{39 \\choose 0}}{{52 \\choose 2}} \\]\n\nNote that \\(13 + 39 = 52\\) and \\(2+ 0 = 2\\). So the numerator’s \\(n\\)’s add up to the denominator’s \\(n\\) and the numerator’s \\(r\\)’s add up to the denominator’s \\(r\\)’s"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#more-examples-order-matters-vs.-not-12",
    "href": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#more-examples-order-matters-vs.-not-12",
    "title": "Lesson 5: Equally Likely Outcomes and Counting",
    "section": "More examples: order matters vs. not (1/2)",
    "text": "More examples: order matters vs. not (1/2)\n\n\n\n\nExample 2\n\n\nSuppose we draw 2 cards from a standard deck without replacement. What is the probability that both are spades when\n\norder matters?\norder doesn’t matter?"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#we-saw-an-example-of-long-run-relative-frequency-in-our-coin-flip",
    "href": "lessons/03_Simulations/03_Simulations.html#we-saw-an-example-of-long-run-relative-frequency-in-our-coin-flip",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "We saw an example of long-run relative frequency in our coin flip",
    "text": "We saw an example of long-run relative frequency in our coin flip\nIn Lesson 1, we flipped a coin 100 times and recorded the proportion of heads.\n\nWe tossed 50 heads out of the 100 flips\nOur long-run frequency was \\(50/100 = 0.5\\), which approximated the probability of getting a head on any one flip"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#where-are-we",
    "href": "lessons/03_Simulations/03_Simulations.html#where-are-we",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#need-more-reps-for-a-long-run-relative-frequency",
    "href": "lessons/03_Simulations/03_Simulations.html#need-more-reps-for-a-long-run-relative-frequency",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "Need more reps for a long-run relative frequency",
    "text": "Need more reps for a long-run relative frequency\n\nreps &lt;- 1000\nsimulations &lt;- replicate(reps, sample(x = 1:4, size = 2, replace = TRUE))\n\n\nLet’s show the first 14 simulations\n\n\nsimulations[, 1:14]\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n[1,]    4    1    2    2    4    2    1    2    4     1     4     2     2     3\n[2,]    4    4    1    3    1    1    2    3    2     4     1     2     2     2"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#need-more-reps-for-a-long-run-distribution",
    "href": "lessons/03_Simulations/03_Simulations.html#need-more-reps-for-a-long-run-distribution",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "Need more reps for a long-run distribution",
    "text": "Need more reps for a long-run distribution\n\nreps &lt;- 10000\nsimulations &lt;- replicate(reps, sample(x = 1:4, size = 2, replace = TRUE))\n\n\nLet’s show the first 14 simulations\n\n\nsimulations[, 1:14]\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n[1,]    4    1    2    2    4    2    1    2    4     1     4     2     2     3\n[2,]    4    4    1    3    1    1    2    3    2     4     1     2     2     2\n\n\n\n\\(X\\) is the sum of the two rolls: we could calculate that for each column\n\n\nX_simulated &lt;- apply(simulations, 2, sum)\nX_simulated[1:14]\n\n [1] 8 5 3 5 5 3 3 5 6 5 5 4 4 5"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#we-can-look-at-the-plot-of-random-variable-x",
    "href": "lessons/03_Simulations/03_Simulations.html#we-can-look-at-the-plot-of-random-variable-x",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "We can look at the plot of random variable \\(X\\)",
    "text": "We can look at the plot of random variable \\(X\\)"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#example-dice-rolls-1",
    "href": "lessons/03_Simulations/03_Simulations.html#example-dice-rolls-1",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "Example: Dice Rolls",
    "text": "Example: Dice Rolls\n\n\nExample: Simulating Two Rolls of a Fair Four-Sided Die\n\n\nWe’re going to roll two four-sided die. Let \\(X\\) be the sum of two rolls, and \\(Y\\) be the larger of the two rolls. How would we simulate \\(X\\) and \\(Y\\) separately?\n\n\n\nUse the steps to run simulation for for \\(Y\\) now"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#set-up",
    "href": "lessons/03_Simulations/03_Simulations.html#set-up",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "1. Set up",
    "text": "1. Set up\n\n\n\nSet up\n\n\n\nDefine the probability space and related random variables and events, including assumptions.\n\n\n\nRandom variable: \\(Y(\\omega)\\) is the larger of the two rolls in outcome \\(\\omega\\)\nGoal: simulate \\(Y\\), the larger of two rolls of a fair four-sided die\nSample space: all possible outcomes of rolling two four-sided die\n\nNot necessary, but helpful to define the sample space\n\n\n\\[\\begin{aligned} S =  \\{ &(1,1), (1,2), (1,3), (1,4), (2,1), (2,2), (2,3), (2,4),\\\\ & (3,1), (3,2), (3,3), (3,4), (4,1), (4,2), (4,3), (4,4)\\} \\end{aligned}\\]\n\nAssumptions: each die is fair and rolls are independent\n\nEach outcome in \\(S\\) is equally likely with probability \\(1/16\\)"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#simulate",
    "href": "lessons/03_Simulations/03_Simulations.html#simulate",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "2. Simulate",
    "text": "2. Simulate\n\n\n\nSimulate\n\n\n\nRun the simulation to generate outcomes according to the assumptions.\n\n\n\nreps &lt;- 10000\nsimulations &lt;- replicate(reps, sample(x = 1:4, size = 2, replace = TRUE))\nY_simulated &lt;- apply(simulations, 2, max)\n\n\nWe can look at the first 30 simulations\n\n\nY_simulated[1:30]\n\n [1] 3 4 4 4 2 4 4 4 2 3 4 4 1 4 4 3 4 4 2 4 4 4 1 4 2 2 4 4 3 3"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#summarize",
    "href": "lessons/03_Simulations/03_Simulations.html#summarize",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "3. Summarize",
    "text": "3. Summarize\n\n\n\nSummarize\n\n\n\nAnalyze the output using plots and summary statistics like relative frequencies and averages.\n\n\n\n\n\n\nShow/Hide Code for plotting Y\nY_df &lt;- as.data.frame(Y_simulated) %&gt;%\n  rename(Y = Y_simulated)\n\nggplot(Y_df, aes(x = Y)) +\n  geom_histogram(binwidth = 1, color = \"black\", fill = \"lightblue\") +\n  scale_x_continuous(breaks = seq(2, 8, by = 1)) +\n  labs(title = \"Simulated Distribution of Y (Larger of Two Rolls)\",\n       x = \"Value of Y\",\n       y = \"Frequency\") +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(size = 20), \n    axis.text.y = element_text(size = 20),\n    axis.title.x = element_text(size = 20),\n    axis.title.y = element_text(size = 20), \n    plot.title = element_text(size = 20)\n    )\n\n\n\n\n\n\n\n\n\n\nIf the problem asked us for something else, we could compute it:\n\nAverage:\n\n\nmean(Y_simulated)\n\n[1] 3.1199\n\n\n\nProbability that \\(Y=3\\):\n\n\nsum(Y_simulated == 3) / reps\n\n[1] 0.3121"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#sensitivity-analysis",
    "href": "lessons/03_Simulations/03_Simulations.html#sensitivity-analysis",
    "title": "Lesson 3: Introduction to Simulations",
    "section": "4. Sensitivity analysis",
    "text": "4. Sensitivity analysis\n\n\n\nSensitivity analysis\n\n\n\nInvestigate how results change when assumptions or parameters of the model are altered."
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#section",
    "href": "lessons/03_Simulations/03_Simulations.html#section",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "",
    "text": "Set up\n\n\n\nDefine the probability space and related random variables and events, including assumptions.\n\n\n\nRandom variable: \\(Y(\\omega)\\) is the larger of the two rolls in outcome \\(\\omega\\)\nGoal: simulate \\(Y\\), the larger of two rolls of a fair four-sided die\nSample space: all possible outcomes of rolling two four-sided die\n\nNot necessary, but helpful to define the sample space\n\n\n\\[\\begin{aligned} S =  \\{ &(1,1), (1,2), (1,3), (1,4), (2,1), (2,2), (2,3), (2,4),\\\\ & (3,1), (3,2), (3,3), (3,4), (4,1), (4,2), (4,3), (4,4)\\} \\end{aligned}\\]\n\nAssumptions: each die is fair and rolls are independent\n\nEach outcome in \\(S\\) is equally likely with probability \\(1/16\\)"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#section-1",
    "href": "lessons/03_Simulations/03_Simulations.html#section-1",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "",
    "text": "Simulate\n\n\n\nRun the simulation to generate outcomes according to the assumptions.\n\n\n\nreps &lt;- 10000\nsimulations &lt;- replicate(reps, sample(x = 1:4, size = 2, replace = TRUE))\nY_simulated &lt;- apply(simulations, 2, max)\n\n \n\nWe can look at the first 30 simulations\n\n\nY_simulated[1:30]\n\n [1] 3 4 4 4 2 4 4 4 2 3 4 4 1 4 4 3 4 4 2 4 4 4 1 4 2 2 4 4 3 3"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#section-2",
    "href": "lessons/03_Simulations/03_Simulations.html#section-2",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "",
    "text": "Summarize\n\n\n\nAnalyze the output using plots and summary statistics like relative frequencies and averages.\n\n\n\n\n\n\nShow/Hide Code for plotting Y\nY_df &lt;- as.data.frame(Y_simulated) %&gt;%\n  rename(Y = Y_simulated)\n\nggplot(Y_df, aes(x = Y)) +\n  geom_histogram(binwidth = 1, color = \"black\", fill = \"#B3C8BF\") +\n  scale_x_continuous(breaks = seq(1, 4, by = 1)) +\n  labs(title = \"Simulated Distribution of Y (Larger of Two Rolls)\",\n       x = \"Value of Y\",\n       y = \"Frequency\") +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(size = 20), \n    axis.text.y = element_text(size = 20),\n    axis.title.x = element_text(size = 20),\n    axis.title.y = element_text(size = 20), \n    plot.title = element_text(size = 20)\n    )\n\n\n\n\n\n\n\n\n\n\nIf the problem asked us for something else, we could compute it:\n\nAverage:\n\n\nmean(Y_simulated)\n\n[1] 3.1199\n\n\n\nProbability that \\(Y=1\\):\n\n\nsum(Y_simulated == 1) / reps\n\n[1] 0.0634\n\n\n\nProbability that \\(Y&gt;3\\):\n\n\nsum(Y_simulated &gt; 3) / reps\n\n[1] 0.4356"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#section-3",
    "href": "lessons/03_Simulations/03_Simulations.html#section-3",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "",
    "text": "Sensitivity analysis\n\n\n\nInvestigate how results change when assumptions or parameters of the model are altered.\n\n\nWhat if we rolled three die instead of two?\n\n\n\nreps &lt;- 10000\ndie &lt;- 3\nsimulations &lt;- replicate(\n  reps, \n  sample(x = 1:4, \n         size = die, \n         replace = TRUE)\n)\nsimulations[, 1:6]\n\n     [,1] [,2] [,3] [,4] [,5] [,6]\n[1,]    1    3    1    4    2    3\n[2,]    4    1    2    1    2    3\n[3,]    4    4    4    4    3    3\n\nY_simulated &lt;- apply(simulations, 2, max)\n\n\n\n\nShow/Hide Code for plotting Y\nY_df &lt;- as.data.frame(Y_simulated) %&gt;%\n  rename(Y = Y_simulated)\n\nggplot(Y_df, aes(x = Y)) +\n  geom_histogram(binwidth = 1, color = \"black\", fill = \"#B3C8BF\") +\n  scale_x_continuous(breaks = seq(1, 4, by = 1)) +\n  labs(title = \"Simulated Distribution of Y (Larger of Two Rolls)\",\n       x = \"Value of Y\",\n       y = \"Frequency\") +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(size = 20), \n    axis.text.y = element_text(size = 20),\n    axis.title.x = element_text(size = 20),\n    axis.title.y = element_text(size = 20), \n    plot.title = element_text(size = 20)\n    )"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#example-to-build-our-simulation-skills",
    "href": "lessons/03_Simulations/03_Simulations.html#example-to-build-our-simulation-skills",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "Example to build our simulation skills",
    "text": "Example to build our simulation skills\n\n\nExample: Simulating Two Rolls of a Fair Four-Sided Die\n\n\nWe’re going to roll two four-sided die. Let \\(X\\) be the sum of two rolls, and \\(Y\\) be the larger of the two rolls. How would we simulate \\(X\\) and \\(Y\\) separately?\n\n\n \n\nNote: this example is not asking for a probability!\n\nWe can simulate a random variable and looks at its distribution without calculating any probabilities.\n\n\n \n\nWe will focus on simulating \\(X\\) first\n\n \nLet’s build up some coding tools to do this!"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#what-if-we-have-multiple-rolls-at-once",
    "href": "lessons/03_Simulations/03_Simulations.html#what-if-we-have-multiple-rolls-at-once",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "What if we have multiple rolls at once?",
    "text": "What if we have multiple rolls at once?\n\nWe can set size to be larger than 1 to simulate multiple draws at once\n\n\nsample(x = c(\"H\", \"T\"), size = 5, replace = TRUE)\n\n[1] \"T\" \"T\" \"T\" \"H\" \"T\"\n\n\n\nWe can simulate our example of the two four-sided dice\n\n\nsample(x = c(1, 2, 3, 4), size = 2, replace = TRUE)\n\n[1] 3 3\n\n\n \n\nWhat happens if we set replace = FALSE?\n\n\nsample(x = c(1, 2, 3, 4), size = 2, replace = FALSE)\n\n[1] 4 2\n\nsample(x = c(1, 2, 3, 4), size = 4, replace = FALSE)\n\n[1] 2 1 3 4"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#can-we-start-to-simulate-many-rolls-of-two-dice",
    "href": "lessons/03_Simulations/03_Simulations.html#can-we-start-to-simulate-many-rolls-of-two-dice",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "Can we start to simulate many rolls of two dice?",
    "text": "Can we start to simulate many rolls of two dice?\n\n\nExample: Simulating Two Rolls of a Fair Four-Sided Die\n\n\nWe’re going to roll two four-sided dice. Let \\(X\\) be the sum of two rolls, and \\(Y\\) be the larger of the two rolls. How would we simulate \\(X\\) and \\(Y\\) separately?\n\n\n\nWe’ve seen how to simulate a single pair of rolls\n\n\nrolls &lt;- sample(x = c(1, 2, 3, 4), size = 2, replace = TRUE)\n\n\nWe can use the replicate() function to repeat this process many times (we’ll do 10)\n\n\nreps &lt;- 10\nreplicate(reps, sample(x = 1:4, size = 2, replace = TRUE))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n[1,]    2    3    3    3    3    3    3    1    3     3\n[2,]    1    1    2    2    2    1    4    1    4     2"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#we-need-more-reps-for-long-run-relative-frequencies",
    "href": "lessons/03_Simulations/03_Simulations.html#we-need-more-reps-for-long-run-relative-frequencies",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "We need more reps for long-run relative frequencies",
    "text": "We need more reps for long-run relative frequencies\n\nreps &lt;- 10000\nsimulations &lt;- replicate(reps, sample(x = 1:4, size = 2, replace = TRUE))\n\n\nLet’s show the first 14 simulations\n\n\nsimulations[, 1:14]\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n[1,]    4    1    2    2    4    2    1    2    4     1     4     2     2     3\n[2,]    4    4    1    3    1    1    2    3    2     4     1     2     2     2\n\n\n \n\n\\(X\\) is the sum of the two rolls: we could calculate that for each column\n\n\nX_simulated &lt;- apply(simulations, 2, sum)\nX_simulated[1:14]\n\n [1] 8 5 3 5 5 3 3 5 6 5 5 4 4 5"
  },
  {
    "objectID": "lessons/03_Simulations/03_Simulations.html#if-we-want-to-calculate-something-else-we-can",
    "href": "lessons/03_Simulations/03_Simulations.html#if-we-want-to-calculate-something-else-we-can",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "If we want to calculate something else, we can!",
    "text": "If we want to calculate something else, we can!\n\n\n\nAverage:\n\n\nmean(X_simulated)\n\n[1] 5.0044\n\n\n\nStandard deviation:\n\n\nsd(X_simulated)\n\n[1] 1.574303\n\n\n\nProbability that \\(X=5\\):\n\n\nsum(X_simulated == 5) / reps\n\n[1] 0.2468\n\n\n\nProbability that \\(X&lt;3\\):\n\n\nsum(X_simulated &lt; 3) / reps\n\n[1] 0.0584\n\n\n\n \n \n \n \n \n \n \n\n\nProbabilities (relative frequencies) are calculated by:\n\nsumming the number of times an event occurs and\ndividing by the total number of simulations (reps)"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations.html#where-are-we",
    "href": "lessons/02_Simulations/02_Simulations.html#where-are-we",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations.html#recall-outcomes-events-sample-spaces",
    "href": "lessons/02_Simulations/02_Simulations.html#recall-outcomes-events-sample-spaces",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "Recall: Outcomes, events, sample spaces",
    "text": "Recall: Outcomes, events, sample spaces\n\n\nDefinition: Outcome\n\n\nThe possible results in a random phenomenon.\n\n\n\n\nDefinition: Sample Space\n\n\nThe sample space \\(S\\) is the set of all outcomes\n\n\n\n\nDefinition: Event\n\n\nAn event is a collection of some outcomes. An event can include multiple outcomes or no outcomes (a subset of the sample space).\n\n\nWhen thinking about events, think about outcomes that you might be asking the probability of. For example, what is the probability that you get a heads or a tails in one flip? (Answer: 1)"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations.html#we-need-to-understand-random-variables",
    "href": "lessons/02_Simulations/02_Simulations.html#we-need-to-understand-random-variables",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "We need to understand random variables",
    "text": "We need to understand random variables\n\n\nDefinition: Random Variable\n\n\nFor a given sample space \\(S\\), a random variable (r.v.) is a function whose domain is \\(S\\) and whose range is the set of real numbers \\(\\mathbb{R}\\). A random variable assigns a real number to each outcome in the sample space.\n\n\n\nA random variable’s value is completely determined by the outcome \\(\\omega\\), where \\(\\omega \\in S\\)\n\nWhat is random is the outcome \\(\\omega\\)\n\nA random variable is a function from the sample space (with outcomes \\(\\omega\\)) to the set of real numbers\n\nWe typically write \\(X(\\omega)\\) (or \\(X\\) for short), where \\(X\\) is our random variable\n\nThus, we can take our sample space (all outcomes) and make functional transformations to it"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations.html#the-cool-and-tricky-thing-about-random-variables",
    "href": "lessons/02_Simulations/02_Simulations.html#the-cool-and-tricky-thing-about-random-variables",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "The cool (and tricky) thing about random variables",
    "text": "The cool (and tricky) thing about random variables\nDo you remember our coin example from Lesson 1? We tossed one or two coins.\n\nFor each coin, the sample space is heads and tails (\\(S = \\{H,T\\}\\))\nIf we want the sample space for both coins in order, then we have combinations (\\(S=\\{(H,H), (H,T), (T,H), (T,T)\\}\\))\n\n \nWe make the random variable a function of the sample space.\n\nFor one coin toss, we can say random variable \\(X\\) is \\(1\\) if we toss a heads (\\(\\omega = \\text{H}\\)) and \\(X=0\\) if we get a tails\nFor the two coins, we can say \\(X\\) is the count of heads, so if \\(\\omega = \\text{(H, T)}\\), then \\(X=1\\)"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations.html#types-of-random-variables",
    "href": "lessons/02_Simulations/02_Simulations.html#types-of-random-variables",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "Types of random variables",
    "text": "Types of random variables\nThere are two types of random variables:\n\n\n\n\n\nDiscrete random variables (RVs): the set of possible values is either finite or can be put into a countably infinite list\n\nYou could theoretically list the specific possible outcomes that the variable can take\nIf you sum the rolls of three dice, you must get a whole number. For example, you can’t get any number between 3 and 4.\n\n\n\n\n\n\n\n\nContinuous random variables (RVs): take on values from continuous intervals, or unions of continuous intervals\n\nVariable takes on a range of values, but there are infinitely possible values within the range\nIf you keep track of the time you sleep, you can sleep for 8 hours or 7.9 hours or 7.99 hours or 7.999 hours …\n\n\n\n\n\n\nDiscrete random variables (RVs) are a little easier to simulate right now\n\nWe will only do discrete RVs today"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations.html#what-is-a-simulation",
    "href": "lessons/02_Simulations/02_Simulations.html#what-is-a-simulation",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "What is a simulation?",
    "text": "What is a simulation?\nA probability model for a random phenomenon includes a sample space, events, random variables, and a probability measure.\n\n\nSimulation\n\n\nSimulation involves using a probability model to artificially recreate a random phenomenon, many times, usually using a computer.\n\n\nWe simulate outcomes and values of random variables according to the model’s assumptions."
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations.html#the-foundation-relative-frequencies",
    "href": "lessons/02_Simulations/02_Simulations.html#the-foundation-relative-frequencies",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "The Foundation: Relative Frequencies",
    "text": "The Foundation: Relative Frequencies\n\nProbabilities can be interpreted as long-run relative frequencies\n\n \n\nBy simulating a random phenomenon a large number of times, we can approximate the probability of an event by calculating the relative frequency of its occurrence\n\nBasically, out of all the trials we run, how many times did the event happen?\n\n\n \n\nSimulation is a powerful tool to approximate a few things:\n\nProbabilities\nDistributions of random variables\nLong-run averages"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations.html#we-saw-an-example-of-long-run-relative-frequency-in-our-coin-flip",
    "href": "lessons/02_Simulations/02_Simulations.html#we-saw-an-example-of-long-run-relative-frequency-in-our-coin-flip",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "We saw an example of long-run relative frequency in our coin flip",
    "text": "We saw an example of long-run relative frequency in our coin flip\nIn Lesson 1, we flipped a coin 100 times and recorded the proportion of heads.\n\nWe tossed 50 heads out of the 100 flips\nOur long-run frequency was \\(50/100 = 0.5\\), which approximated the probability of getting a head on any one flip"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations.html#tactile-simulations",
    "href": "lessons/02_Simulations/02_Simulations.html#tactile-simulations",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "Tactile simulations",
    "text": "Tactile simulations\n\nWe’ve already seen coin flips!\nWe can also use cards, dice, and other objects to simulate discrete random variables\n\n \n\nOther common method: A box model uses a box/hat/bucket of “tickets” with labels to represent possible outcomes\n\nAllows us to increase the number of “tickets” with appropriate labels\nCoin flip as box model: A box with two tickets (H and T).\n90% free throw shooter: A box with 10 tickets (9 “make” and 1 “miss”).\nDraws can be with replacement (e.g., coin flips) or without replacement (e.g., dealing a poker hand)."
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations.html#example-to-build-our-simulation-skills",
    "href": "lessons/02_Simulations/02_Simulations.html#example-to-build-our-simulation-skills",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "Example to build our simulation skills",
    "text": "Example to build our simulation skills\n\n\nExample: Simulating Two Rolls of a Fair Four-Sided Die\n\n\nWe’re going to roll two four-sided die. Let \\(X\\) be the sum of two rolls, and \\(Y\\) be the larger of the two rolls. How would we simulate \\(X\\) and \\(Y\\) separately?\n\n\n \n\nNote: this example is not asking for a probability!\n\nWe can simulate a random variable and looks at its distribution without calculating any probabilities.\n\n\n \n\nWe will focus on simulating \\(X\\) first\n\n \nLet’s build up some coding tools to do this!"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations.html#how-do-we-simulate-something-like-a-single-dice-roll",
    "href": "lessons/02_Simulations/02_Simulations.html#how-do-we-simulate-something-like-a-single-dice-roll",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "How do we simulate something like a single dice roll?",
    "text": "How do we simulate something like a single dice roll?\n\nWe can also use R to sample from the box or spinner\nThe sample() function is a powerful tool for simulating draws from a box model.\nFor example, we can simulate a coin flip\n\nWhat is x?\nWhat is size?\n\n\n\nsample(x = c(\"H\", \"T\"), size = 1)\n\n[1] \"T\"\n\n\n \n\nOr a dice roll\n\n\nsample(x = c(1, 2, 3, 4), size = 1)\n\n[1] 1"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations.html#what-if-we-have-multiple-rolls-at-once",
    "href": "lessons/02_Simulations/02_Simulations.html#what-if-we-have-multiple-rolls-at-once",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "What if we have multiple rolls at once?",
    "text": "What if we have multiple rolls at once?\n\nWe can set size to be larger than 1 to simulate multiple draws at once\n\n\nsample(x = c(\"H\", \"T\"), size = 5, replace = TRUE)\n\n[1] \"T\" \"T\" \"T\" \"H\" \"T\"\n\n\n\nWe can simulate our example of the two four-sided dice\n\n\nsample(x = c(1, 2, 3, 4), size = 2, replace = TRUE)\n\n[1] 3 3\n\n\n \n\nWhat happens if we set replace = FALSE?\n\n\nsample(x = c(1, 2, 3, 4), size = 2, replace = FALSE)\n\n[1] 4 2\n\nsample(x = c(1, 2, 3, 4), size = 4, replace = FALSE)\n\n[1] 2 1 3 4"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations.html#can-we-start-to-simulate-many-rolls-of-two-dice",
    "href": "lessons/02_Simulations/02_Simulations.html#can-we-start-to-simulate-many-rolls-of-two-dice",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "Can we start to simulate many rolls of two dice?",
    "text": "Can we start to simulate many rolls of two dice?\n\n\nExample: Simulating Two Rolls of a Fair Four-Sided Die\n\n\nWe’re going to roll two four-sided dice. Let \\(X\\) be the sum of two rolls, and \\(Y\\) be the larger of the two rolls. How would we simulate \\(X\\) and \\(Y\\) separately?\n\n\n\nWe’ve seen how to simulate a single pair of rolls\n\n\nrolls &lt;- sample(x = c(1, 2, 3, 4), size = 2, replace = TRUE)\n\n\nWe can use the replicate() function to repeat this process many times (we’ll do 10)\n\n\nreps &lt;- 10\nreplicate(reps, sample(x = 1:4, size = 2, replace = TRUE))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n[1,]    2    3    3    3    3    3    3    1    3     3\n[2,]    1    1    2    2    2    1    4    1    4     2"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations.html#we-need-more-reps-for-long-run-relative-frequencies",
    "href": "lessons/02_Simulations/02_Simulations.html#we-need-more-reps-for-long-run-relative-frequencies",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "We need more reps for long-run relative frequencies",
    "text": "We need more reps for long-run relative frequencies\n\nreps &lt;- 10000\nsimulations &lt;- replicate(reps, sample(x = 1:4, size = 2, replace = TRUE))\n\n\nLet’s show the first 14 simulations\n\n\nsimulations[, 1:14]\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n[1,]    4    1    2    2    4    2    1    2    4     1     4     2     2     3\n[2,]    4    4    1    3    1    1    2    3    2     4     1     2     2     2\n\n\n \n\n\\(X\\) is the sum of the two rolls: we could calculate that for each column\n\n\nX_simulated &lt;- apply(simulations, 2, sum)\nX_simulated[1:14]\n\n [1] 8 5 3 5 5 3 3 5 6 5 5 4 4 5"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations.html#we-can-look-at-the-plot-of-random-variable-x",
    "href": "lessons/02_Simulations/02_Simulations.html#we-can-look-at-the-plot-of-random-variable-x",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "We can look at the plot of random variable \\(X\\)",
    "text": "We can look at the plot of random variable \\(X\\)"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations.html#if-we-want-to-calculate-something-else-we-can",
    "href": "lessons/02_Simulations/02_Simulations.html#if-we-want-to-calculate-something-else-we-can",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "If we want to calculate something else, we can!",
    "text": "If we want to calculate something else, we can!\n\n\n\nAverage:\n\n\nmean(X_simulated)\n\n[1] 5.0044\n\n\n\nStandard deviation:\n\n\nsd(X_simulated)\n\n[1] 1.574303\n\n\n\nProbability that \\(X=5\\):\n\n\nsum(X_simulated == 5) / reps\n\n[1] 0.2468\n\n\n\nProbability that \\(X&lt;3\\):\n\n\nsum(X_simulated &lt; 3) / reps\n\n[1] 0.0584\n\n\n\n \n \n \n \n \n \n \n\n\nProbabilities (relative frequencies) are calculated by:\n\nsumming the number of times an event occurs and\ndividing by the total number of simulations (reps)"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations.html#steps-of-a-simulation",
    "href": "lessons/02_Simulations/02_Simulations.html#steps-of-a-simulation",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "4 (S)teps of a Simulation",
    "text": "4 (S)teps of a Simulation\n\n\n\nSet up\n\n\n\nDefine the probability space and related random variables and events, including assumptions.\n\n\n\n\n\nSimulate\n\n\n\nRun the simulation to generate outcomes according to the assumptions.\n\n\n\n\n\nSummarize\n\n\n\nAnalyze the output using plots and summary statistics like relative frequencies and averages.\n\n\n\n\n\nSensitivity analysis\n\n\n\nInvestigate how results change when assumptions or parameters of the model are altered."
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations.html#example-dice-rolls",
    "href": "lessons/02_Simulations/02_Simulations.html#example-dice-rolls",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "Example: Dice Rolls",
    "text": "Example: Dice Rolls\n\n\nExample: Simulating Two Rolls of a Fair Four-Sided Die\n\n\nWe’re going to roll two four-sided die. Let \\(X\\) be the sum of two rolls, and \\(Y\\) be the larger of the two rolls. How would we simulate \\(X\\) and \\(Y\\) separately?\n\n\n\nUse the steps to run simulation for for \\(Y\\) now"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations.html#section",
    "href": "lessons/02_Simulations/02_Simulations.html#section",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "",
    "text": "Set up\n\n\n\nDefine the probability space and related random variables and events, including assumptions.\n\n\n\nRandom variable: \\(Y(\\omega)\\) is the larger of the two rolls in outcome \\(\\omega\\)\nGoal: simulate \\(Y\\), the larger of two rolls of a fair four-sided die\nSample space: all possible outcomes of rolling two four-sided die\n\nNot necessary, but helpful to define the sample space\n\n\n\\[\\begin{aligned} S =  \\{ &(1,1), (1,2), (1,3), (1,4), (2,1), (2,2), (2,3), (2,4),\\\\ & (3,1), (3,2), (3,3), (3,4), (4,1), (4,2), (4,3), (4,4)\\} \\end{aligned}\\]\n\nAssumptions: each die is fair and rolls are independent\n\nEach outcome in \\(S\\) is equally likely with probability \\(1/16\\)"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations.html#section-1",
    "href": "lessons/02_Simulations/02_Simulations.html#section-1",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "",
    "text": "Simulate\n\n\n\nRun the simulation to generate outcomes according to the assumptions.\n\n\n\nreps &lt;- 10000\nsimulations &lt;- replicate(reps, sample(x = 1:4, size = 2, replace = TRUE))\nY_simulated &lt;- apply(simulations, 2, max)\n\n \n\nWe can look at the first 30 simulations\n\n\nY_simulated[1:30]\n\n [1] 3 4 4 4 2 4 4 4 2 3 4 4 1 4 4 3 4 4 2 4 4 4 1 4 2 2 4 4 3 3"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations.html#section-2",
    "href": "lessons/02_Simulations/02_Simulations.html#section-2",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "",
    "text": "Summarize\n\n\n\nAnalyze the output using plots and summary statistics like relative frequencies and averages.\n\n\n\n\n\n\nShow/Hide Code for plotting Y\nY_df &lt;- as.data.frame(Y_simulated) %&gt;%\n  rename(Y = Y_simulated)\n\nggplot(Y_df, aes(x = Y)) +\n  geom_histogram(binwidth = 1, color = \"black\", fill = \"#B3C8BF\") +\n  scale_x_continuous(breaks = seq(1, 4, by = 1)) +\n  labs(title = \"Simulated Distribution of Y (Larger of Two Rolls)\",\n       x = \"Value of Y\",\n       y = \"Frequency\") +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(size = 20), \n    axis.text.y = element_text(size = 20),\n    axis.title.x = element_text(size = 20),\n    axis.title.y = element_text(size = 20), \n    plot.title = element_text(size = 20)\n    )\n\n\n\n\n\n\n\n\n\n\nIf the problem asked us for something else, we could compute it:\n\nAverage:\n\n\nmean(Y_simulated)\n\n[1] 3.1199\n\n\n\nProbability that \\(Y=1\\):\n\n\nsum(Y_simulated == 1) / reps\n\n[1] 0.0634\n\n\n\nProbability that \\(Y&gt;3\\):\n\n\nsum(Y_simulated &gt; 3) / reps\n\n[1] 0.4356"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations.html#section-3",
    "href": "lessons/02_Simulations/02_Simulations.html#section-3",
    "title": "Lesson 2: Introduction to Simulations",
    "section": "",
    "text": "Sensitivity analysis\n\n\n\nInvestigate how results change when assumptions or parameters of the model are altered.\n\n\nWhat if we rolled three die instead of two?\n\n\n\nreps &lt;- 10000\ndie &lt;- 3\nsimulations &lt;- replicate(\n  reps, \n  sample(x = 1:4, \n         size = die, \n         replace = TRUE)\n)\nsimulations[, 1:6]\n\n     [,1] [,2] [,3] [,4] [,5] [,6]\n[1,]    1    3    1    4    2    3\n[2,]    4    1    2    1    2    3\n[3,]    4    4    4    4    3    3\n\nY_simulated &lt;- apply(simulations, 2, max)\n\n\n\n\nShow/Hide Code for plotting Y\nY_df &lt;- as.data.frame(Y_simulated) %&gt;%\n  rename(Y = Y_simulated)\n\nggplot(Y_df, aes(x = Y)) +\n  geom_histogram(binwidth = 1, color = \"black\", fill = \"#B3C8BF\") +\n  scale_x_continuous(breaks = seq(1, 4, by = 1)) +\n  labs(title = \"Simulated Distribution of Y (Larger of Two Rolls)\",\n       x = \"Value of Y\",\n       y = \"Frequency\") +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(size = 20), \n    axis.text.y = element_text(size = 20),\n    axis.title.x = element_text(size = 20),\n    axis.title.y = element_text(size = 20), \n    plot.title = element_text(size = 20)\n    )"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob_muddy_points.html",
    "href": "lessons/03_Lang_prob/03_Lang_prob_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "See below for questions on De Morgan’s laws and propositions from last year."
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations_muddy_points.html",
    "href": "lessons/02_Simulations/02_Simulations_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "When we say “with replacement,” it means that after we select an item (like drawing a card from a deck), we put it back before selecting again. This means that the probability of selecting that item remains the same for each draw. For example, if you draw a card from a standard deck of 52 cards and then put it back, the probability of drawing any specific card (like an Ace) remains 1/52 for each draw.\nOn the other hand, “without replacement” means that once an item is selected, it is not put back. This means that the probability of selecting that item changes for subsequent draws because there are fewer items left to choose from. For example, if you draw a card from a deck and do not put it back, the probability of drawing an Ace on the next draw changes because there are now only 51 cards left in the deck.\nIt’s less about the importance of replacement, but that we accurately represent whatever scenario we want to simulate!"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations_muddy_points.html#proofs-of-propositions",
    "href": "lessons/02_Simulations/02_Simulations_muddy_points.html#proofs-of-propositions",
    "title": "Muddy Points",
    "section": "1. Proofs of propositions",
    "text": "1. Proofs of propositions\nFurther explanations of the propositions can be found in the textbook from pages 24-27. For many of the explanations in class, I was working to produce a union of disjoint events, so that the probability could easily be calculated. Proposition 3 and 4 were specifically mentioned, so I will include some writing notes on them here:\n\nProposition 3\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\nIn this proposition, I want to define event \\(B\\) as a union of disjoint events so that I can show \\(P(B)\\) is the sum of \\(P(A)\\) and some greater-than-or-equal-to 0 probability event. If the following is my venn diagram of A and B:\n\n\n\n\n\nThen I can define B as the union of disjoint events: \nIf we then take the probability of each side of the equation \\(B = A \\cup (A^c \\cap B)\\), we get \\[P(B) = P\\big(A \\cup (A^c \\cap B)\\big)\\]\nSince events \\(A\\) and \\(A^c \\cap B\\) are disjoint, the probability of their union is just: \\[P(A) + P(A^c \\cap B)\\]\nThus, our equation is now \\[P(B) = P(A) + P(A^c \\cap B)\\]\nFrom Axiom 1, we know for event \\(A^c \\cap B\\), \\(P(A^c \\cap B) \\geq 0\\).\nSo the probability of event B is the sum of the probability of event A and an event that is \\(\\geq\\) 0. This means \\(P(B) \\geq P(A)\\).\n\n\nProposition 4\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)\n\n\nFrom the pictures above, we can see some similar disjoint events.\nIf we look back at \\(A \\cup B\\), we can start manipulating the right side of the equation:"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations_muddy_points.html#example-at-end-of-chapter-2-slides-venn-diagram",
    "href": "lessons/02_Simulations/02_Simulations_muddy_points.html#example-at-end-of-chapter-2-slides-venn-diagram",
    "title": "Muddy Points",
    "section": "2. Example at end of Chapter 2 slides (Venn Diagram)",
    "text": "2. Example at end of Chapter 2 slides (Venn Diagram)\nI will post this in the previous week’s Muddy Points as well. Please follow this link for my work through of the example. And here is the PDF with my work.\nSub-question: why don’t we just multiply the probability of A and B to get the intersection? This is a specific property of probability when A and B are independent. Only when A and B are independent can we conclude that \\(P(A \\cap B) = P(A)P(B)\\)."
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations_muddy_points.html#partition-of-events",
    "href": "lessons/02_Simulations/02_Simulations_muddy_points.html#partition-of-events",
    "title": "Muddy Points",
    "section": "3. Partition of events",
    "text": "3. Partition of events\nWe’ve been working with event partitions throughout Chapter 2, but we have not formally identified them. Partitions are advantageous to define for two reasons:\n\nThe partitions may be easier to calculate. We can then use the partitions to reconstruct other probabilities that may be more difficult to calculate\nPartitions have nice properties as a consequence of being disjoint. For example, the probability of the union of partitions is the sum of the probabilities across each partition: \\[P\\bigg(\\bigcup_{i=1}^n A_i\\bigg) = P(A_1)P(A_2)P(A_3) \\cdot \\cdot \\cdot P(A_n)\\]"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations_key_info.html",
    "href": "lessons/02_Simulations/02_Simulations_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Attendance policy: a little confusing"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations_key_info.html#announcements",
    "href": "lessons/02_Simulations/02_Simulations_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Attendance policy: a little confusing"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html",
    "title": "Lesson 3: Language of Probability",
    "section": "",
    "text": "Use set notation, Venn diagrams, and the concepts of unions, intersections, complements, and mutually exclusive events to represent and describe events.\nApply the axioms of probability and related properties to calculate probabilities and prove simple results.\nExplain and use De Morgan’s Laws to simplify and solve probability problems.\nConnect partitions and all rules of probability to calculate probabilities."
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#set-theory-12",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#set-theory-12",
    "title": "Lesson 3: Language of Probability",
    "section": "Set Theory (1/2)",
    "text": "Set Theory (1/2)\n\n\n \n\n\nDefinition: Union\n\n\nThe union of events \\(A\\) and \\(B\\), denoted by \\(A \\cup B\\), contains all outcomes that are in \\(A\\) or \\(B\\) or both\n\n\n\n\nDefinition: Intersection\n\n\nThe intersection of events \\(A\\) and \\(B\\), denoted by \\(A \\cap B\\), contains all outcomes that are both in \\(A\\) and \\(B\\).\n\n\n\nVenn diagrams"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#set-theory-22",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#set-theory-22",
    "title": "Lesson 3: Language of Probability",
    "section": "Set Theory (2/2)",
    "text": "Set Theory (2/2)\n\n\n \n\n\nDefinition: Complement\n\n\nThe complement of event \\(A\\), denoted by \\(A^C\\) or \\(A'\\), contains all outcomes in the sample space \\(S\\) that are not in \\(A\\) .\n\n\n\n\nDefinition: Mutually Exclusive\n\n\nEvents \\(A\\) and \\(B\\) are mutually exclusive, or disjoint, if they have no outcomes in common. In this case \\(A \\cap B = \\emptyset\\), where \\(\\emptyset\\) is the empty set.\n\n\n\nVenn diagrams"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#probability-axioms",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#probability-axioms",
    "title": "Lesson 3: Language of Probability",
    "section": "Probability Axioms",
    "text": "Probability Axioms\n\n\n\n\nAxiom 1\n\n\nFor every event \\(A\\), \\(0\\leq\\mathbb{P}(A)\\leq 1\\). Probability is between 0 and 1.\n\n\n\n\nAxiom 2\n\n\nFor the sample space \\(S\\), \\(\\mathbb{P}(S)=1\\).\n\n\n\n\nAxiom 3\n\n\nIf \\(A_1, A_2, A_3, \\ldots\\), is a collection of disjoint events, then \\[\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i).\\] The probability of at least one \\(A_i\\) is the sum of the individual probabilities of each."
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#some-probability-properties",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#some-probability-properties",
    "title": "Lesson 3: Language of Probability",
    "section": "Some probability properties",
    "text": "Some probability properties\nUsing the Axioms, we can prove all other probability properties! Events A, B, and C are not necessarily disjoint!\n\n\n\n\nProposition 1\n\n\nFor any event \\(A\\), \\(\\mathbb{P}(A)= 1 - \\mathbb{P}(A^C)\\)\n\n\n\n\nProposition 2\n\n\n\\(\\mathbb{P}(\\emptyset)=0\\)\n\n\n\n\nProposition 3\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\n\n\n\n\n\nProposition 4\n\n\n\\[\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\] where \\(A\\) and \\(B\\) are not necessarily disjoint\n\n\n\n\nProposition 5\n\n\n\\(\\begin{aligned} \\mathbb{P}(A \\cup B & \\cup C) = \\mathbb{P}(A) + \\mathbb{P}(B) + \\\\ & \\mathbb{P}(C) - \\mathbb{P}(A \\cap B) - \\mathbb{P}(A \\cap C) - \\\\ & \\mathbb{P}(B \\cap C) + \\mathbb{P}(A \\cap B \\cap C) \\end{aligned}\\)"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#proposition-1-proof",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#proposition-1-proof",
    "title": "Lesson 3: Language of Probability",
    "section": "Proposition 1 Proof",
    "text": "Proposition 1 Proof\n\n\n\n\nProposition 1\n\n\nFor any event \\(A\\), \\(\\mathbb{P}(A)= 1 - \\mathbb{P}(A^C)\\)\n\n\n\n\n\nUse Axioms!\n\n\nA1: \\(0\\leq\\mathbb{P}(A)\\leq 1\\)\nA2: \\(\\mathbb{P}(S)=1\\)\nA3: For disjoint \\(A_i\\),\n\\(\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i)\\)"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#proposition-2-proof",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#proposition-2-proof",
    "title": "Lesson 3: Language of Probability",
    "section": "Proposition 2 Proof",
    "text": "Proposition 2 Proof\n\n\n\n\nProposition 2\n\n\n\\(\\mathbb{P}(\\emptyset)=0\\)\n\n\n\n\n\nUse Axioms!\n\n\nA1: \\(0\\leq\\mathbb{P}(A)\\leq 1\\)\nA2: \\(\\mathbb{P}(S)=1\\)\nA3: For disjoint \\(A_i\\),\n\\(\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i)\\)"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#proposition-3-proof",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#proposition-3-proof",
    "title": "Lesson 3: Language of Probability",
    "section": "Proposition 3 Proof",
    "text": "Proposition 3 Proof\n\n\n\n\nProposition 3\n\n\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\n\n\n\n\n\nUse Axioms!\n\n\nA1: \\(0\\leq\\mathbb{P}(A)\\leq 1\\)\nA2: \\(\\mathbb{P}(S)=1\\)\nA3: For disjoint \\(A_i\\),\n\\(\\mathbb{P}\\Big( \\bigcup \\limits_{i=1}^{\\infty}A_i\\Big) =  \\sum_{i=1}^{\\infty}\\mathbb{P}(A_i)\\)"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#proposition-4-visual-proof",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#proposition-4-visual-proof",
    "title": "Lesson 3: Language of Probability",
    "section": "Proposition 4 Visual Proof",
    "text": "Proposition 4 Visual Proof\n\n\nProposition 4\n\n\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#proposition-5-visual-proof",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#proposition-5-visual-proof",
    "title": "Lesson 3: Language of Probability",
    "section": "Proposition 5 Visual Proof",
    "text": "Proposition 5 Visual Proof\n\n\nProposition 5\n\n\n\\(\\mathbb{P}(A \\cup B \\cup C) = \\mathbb{P}(A) + \\mathbb{P}(B) + \\mathbb{P}(C) - \\mathbb{P}(A \\cap B) - \\mathbb{P}(A \\cap C) - \\mathbb{P}(B \\cap C) + \\mathbb{P}(A \\cap B \\cap C)\\)"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#some-final-remarks-on-these-proposition",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#some-final-remarks-on-these-proposition",
    "title": "Lesson 3: Language of Probability",
    "section": "Some final remarks on these proposition",
    "text": "Some final remarks on these proposition\n\nNotice how we spliced events into multiple disjoint events\n\nIt is often easier to work with disjoint events\n\n\n \n\nIf we want to calculate the probability for one event, we may need to get creative with how we manipulate other events and the sample space\n\nHelps us use any incomplete information we have"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#de-morgans-laws",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#de-morgans-laws",
    "title": "Lesson 3: Language of Probability",
    "section": "De Morgan’s Laws",
    "text": "De Morgan’s Laws\n\n\nTheorem: De Morgan’s 1st Law\n\n\nFor a collection of events (sets) \\(A_1, A_2, A_3, \\ldots\\)\n\\[\\bigcap\\limits_{i=1}^{n}A_i^C = \\Big(\\bigcup\\limits_{i=1}^{n}A_i\\Big)^C\\]\n\n\n“all not A = \\((\\)at least one event A\\()^C\\)” or “intersection of the complements is the complement of the union”\n\n\nTheorem: De Morgan’s 2nd Law\n\n\nFor a collection of events (sets) \\(A_1, A_2, A_3, \\ldots\\)\n\\[\\bigcup\\limits_{i=1}^{n}A_i^C = \\Big(\\bigcap\\limits_{i=1}^{n}A_i\\Big)^C\\]\n\n\n“at least one event not A = \\((\\)all A\\()^C\\)” or “union of complements is complement of the intersection”"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#bp-example-variation-13",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#bp-example-variation-13",
    "title": "Lesson 3: Language of Probability",
    "section": "BP example variation (1/3)",
    "text": "BP example variation (1/3)\n\nSuppose you have \\(n\\) subjects in a study.\nLet \\(H_i\\) be the event that person \\(i\\) has high BP, for \\(i=1\\ldots n\\).\n\n \nUse set theory notation to denote the following events:\n\nEvent subject \\(i\\) does not have high BP\nEvent all \\(n\\) subjects have high BP\nEvent at least one subject has high BP\nEvent all of them do not have high BP\nEvent at least one subject does not have high BP"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#bp-example-variation-23",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#bp-example-variation-23",
    "title": "Lesson 3: Language of Probability",
    "section": "BP example variation (2/3)",
    "text": "BP example variation (2/3)\n\nSuppose you have \\(n\\) subjects in a study.\nLet \\(H_i\\) be the event that person \\(i\\) has high BP, for \\(i=1\\ldots n\\).\n\nUse set theory notation to denote the following events:\n\nEvent subject \\(i\\) does not have high BP\n \nEvent all \\(n\\) subjects have high BP\n \n \nEvent at least one subject has high BP"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#bp-example-variation-33",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#bp-example-variation-33",
    "title": "Lesson 3: Language of Probability",
    "section": "BP example variation (3/3)",
    "text": "BP example variation (3/3)\n\nEvent all of them do not have high BP\n \n \n \nEvent at least one subject does not have high BP"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#remarks-on-de-morgans-laws",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#remarks-on-de-morgans-laws",
    "title": "Lesson 3: Language of Probability",
    "section": "Remarks on De Morgan’s Laws",
    "text": "Remarks on De Morgan’s Laws\n\nThese laws also hold for infinite collections of events.\n \nDraw Venn diagrams to convince yourself that these are true!\n \nThese laws are very useful when calculating probabilities.\n\nThis is because calculating the probability of the intersection of events is often much easier than the union of events.\nThis is not obvious right now, but we will see in the coming chapters why."
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#partitions",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#partitions",
    "title": "Lesson 3: Language of Probability",
    "section": "Partitions",
    "text": "Partitions\n\n\n\n\nDefinition: Partition\n\n\nA set of events \\(\\{A_i\\}_{i=1}^{n}\\) create a partition of \\(A\\), if\n\nthe \\(A_i\\)’s are disjoint (mutually exclusive) and\n\\(\\bigcup \\limits_{i=1}^n A_i = A\\)\n\n\n\n\n\nExample 2\n\n\n\nIf \\(A \\subset B\\), then \\(\\{A, B \\cap A^C\\}\\) is a partition of \\(B\\).\nIf \\(S = \\bigcup \\limits_{i=1}^n A_i\\), and the \\(A_i\\)’s are disjoint, then the \\(A_i\\)’s are a partition of the sample space.\n\n\n\n\n\n\nCreating partitions is sometimes used to help calculate probabilities, since by Axiom 3 we can add the probabilities of disjoint events."
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#weekly-medications",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#weekly-medications",
    "title": "Lesson 3: Language of Probability",
    "section": "Weekly medications",
    "text": "Weekly medications\n\n\n\n\nExample 3\n\n\nIf a subject has an\n\n80% chance of taking their medication this week,\n70% chance of taking their medication next week, and\n10% chance of not taking their medication either week,\n\nthen find the probability of them taking their medication exactly one of the two weeks.\n\n\n\nHint: Draw a Venn diagram labelling each of the parts to find the probability."
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations_key_info.html#key-dates",
    "href": "lessons/02_Simulations/02_Simulations_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key dates",
    "text": "Key dates\n\nHomework 0 is due TOMORROW at 11pm!"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations_key_info.html#last-class",
    "href": "lessons/02_Simulations/02_Simulations_key_info.html#last-class",
    "title": "Key Info",
    "section": "Last class",
    "text": "Last class\n\nDid not finish Lesson 1, so we will finish!"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability_muddy_points.html#fall-2024",
    "href": "lessons/01_Probability/01_Probability_muddy_points.html#fall-2024",
    "title": "Muddy Points",
    "section": "",
    "text": "In class, we were wondering why/if \\(2^{|S|}\\) is the general formula for calculating the total number of possible events. We were specifically wondering if the \\(2\\) came from the fact that we had two options (heads and tails) for our outcome. Let’s work through the example of a 6-sided die to explain this further. The sample space is \\(S=\\{1, 2, 3, 4, 5, 6\\}\\). So is the total number of possible events \\(2^6\\) or \\(6^6\\) or something else? We can actually think about an event by using an indicator variable for each outcome of the sample space. An indicator variable is just a way to give us a yes/no answer to a question. So in this case, we are wondering: is this outcome a part of our event? If our event is \\(\\{1\\}\\) then for the outcome \\(1\\), the answer is “yes, the outcome is part of the event. For outcomes \\(2-6\\), the answer is”no, the outcome is not apart of the event.”\n\nFor each outcome, we have a “yes” or “no” answer. We can look at another example of an event. Let’s say our event is rolling an even number:\n\nFor \\(2\\), \\(4\\), and \\(6\\), the answer is “yes.” We can define the indicator variable for whether an outcome is in an event or not. The indicator gives a 1 or 0 for yes and no respectively.\n\nAs stated above, the \\(2\\) in \\(2^6\\) comes from the \\(2\\) options from our indicator. Each side has two options, and there are \\(6\\) sides. Thus, \\(2^6\\) possible events.\n\n\n\nI think this will become clearer when we start thinking about events in the context of probability. When we think of events outside of probability, we may think of something we actually do or something that happens, like going to a concert or coming to class or missing the streetcar. In this case, we think of the event as the single thing (out of all the options) that actually occured. For example, if I’m taking the streetcar to class, I can think of two definitive options of what might occur: I miss the streetcar or I get on the streetcar. Only one of these things can occur, which I may call an event colloquially.\nIt is important to make the distinction with events defined within probability. Events are not necessarily a single thing that occurred. Instead it can be a collection of things that may occur. In the example of the streetcar, I can define my event to include both options. Thus, my event is that I make the streetcar or I miss it. Both of these things cannot happen simultaneously, but if I want to calculate the probability that I miss or make the streetcar, then it is helpful to have the event defined.\n\n\nAn outcome is a single result. The two options in the above example, missing the streetcar or getting on the streetcar, are two potential outcomes. Events are the collection of 0, 1, or more outcomes. So the possible events are: the empty set, missing the streetcar, getting on the streetcar, or the set of missing the streetcar and getting on the streetcar."
  },
  {
    "objectID": "lessons/01_Probability/01_Probability_muddy_points_F24.html",
    "href": "lessons/01_Probability/01_Probability_muddy_points_F24.html",
    "title": "Muddy Points",
    "section": "",
    "text": "The muddy points from this year were a subset of the ones from last year, so I just decided to copy those below!"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability_muddy_points_F24.html#proofs-of-propositions",
    "href": "lessons/01_Probability/01_Probability_muddy_points_F24.html#proofs-of-propositions",
    "title": "Muddy Points",
    "section": "1. Proofs of propositions",
    "text": "1. Proofs of propositions\nFurther explanations of the propositions can be found in the textbook from pages 24-27. For many of the explanations in class, I was working to produce a union of disjoint events, so that the probability could easily be calculated. Proposition 3 and 4 were specifically mentioned, so I will include some writing notes on them here:\n\nProposition 3\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\nIn this proposition, I want to define event \\(B\\) as a union of disjoint events so that I can show \\(P(B)\\) is the sum of \\(P(A)\\) and some greater-than-or-equal-to 0 probability event. If the following is my venn diagram of A and B:\n\n\n\n\n\nThen I can define B as the union of disjoint events: \nIf we then take the probability of each side of the equation \\(B = A \\cup (A^c \\cap B)\\), we get \\[P(B) = P\\big(A \\cup (A^c \\cap B)\\big)\\]\nSince events \\(A\\) and \\(A^c \\cap B\\) are disjoint, the probability of their union is just: \\[P(A) + P(A^c \\cap B)\\]\nThus, our equation is now \\[P(B) = P(A) + P(A^c \\cap B)\\]\nFrom Axiom 1, we know for event \\(A^c \\cap B\\), \\(P(A^c \\cap B) \\geq 0\\).\nSo the probability of event B is the sum of the probability of event A and an event that is \\(\\geq\\) 0. This means \\(P(B) \\geq P(A)\\).\n\n\nProposition 4\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)\n\n\nFrom the pictures above, we can see some similar disjoint events.\nIf we look back at \\(A \\cup B\\), we can start manipulating the right side of the equation:"
  },
  {
    "objectID": "lessons/01_Probability/01_Probability_muddy_points_F24.html#example-at-end-of-chapter-2-slides-venn-diagram",
    "href": "lessons/01_Probability/01_Probability_muddy_points_F24.html#example-at-end-of-chapter-2-slides-venn-diagram",
    "title": "Muddy Points",
    "section": "2. Example at end of Chapter 2 slides (Venn Diagram)",
    "text": "2. Example at end of Chapter 2 slides (Venn Diagram)\nI will post this in the previous week’s Muddy Points as well. Please follow this link for my work through of the example. And here is the PDF with my work.\nSub-question: why don’t we just multiply the probability of A and B to get the intersection? This is a specific property of probability when A and B are independent. Only when A and B are independent can we conclude that \\(P(A \\cap B) = P(A)P(B)\\)."
  },
  {
    "objectID": "lessons/01_Probability/01_Probability_muddy_points_F24.html#partition-of-events",
    "href": "lessons/01_Probability/01_Probability_muddy_points_F24.html#partition-of-events",
    "title": "Muddy Points",
    "section": "3. Partition of events",
    "text": "3. Partition of events\nWe’ve been working with event partitions throughout Chapter 2, but we have not formally identified them. Partitions are advantageous to define for two reasons:\n\nThe partitions may be easier to calculate. We can then use the partitions to reconstruct other probabilities that may be more difficult to calculate\nPartitions have nice properties as a consequence of being disjoint. For example, the probability of the union of partitions is the sum of the probabilities across each partition: \\[P\\bigg(\\bigcup_{i=1}^n A_i\\bigg) = P(A_1)P(A_2)P(A_3) \\cdot \\cdot \\cdot P(A_n)\\]"
  },
  {
    "objectID": "lessons/02_Simulations/02_Simulations_muddy_points.html#fall-2025",
    "href": "lessons/02_Simulations/02_Simulations_muddy_points.html#fall-2025",
    "title": "Muddy Points",
    "section": "",
    "text": "When we say “with replacement,” it means that after we select an item (like drawing a card from a deck), we put it back before selecting again. This means that the probability of selecting that item remains the same for each draw. For example, if you draw a card from a standard deck of 52 cards and then put it back, the probability of drawing any specific card (like an Ace) remains 1/52 for each draw.\nOn the other hand, “without replacement” means that once an item is selected, it is not put back. This means that the probability of selecting that item changes for subsequent draws because there are fewer items left to choose from. For example, if you draw a card from a deck and do not put it back, the probability of drawing an Ace on the next draw changes because there are now only 51 cards left in the deck.\nIt’s less about the importance of replacement, but that we accurately represent whatever scenario we want to simulate!"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob_key_info.html",
    "href": "lessons/03_Lang_prob/03_Lang_prob_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Q: Can we still turn in exit tickets even if its not the same day? For example I was here the first day but forgot to do the exit ticket, if I did it today would it still count towards my grade?\n\nYes! I check them for “attendance” after 7 (sometimes more) days after the class\n\nFor muddy points, it really helps if you can asked a specific question about what you found confusing\n\nI can then address it in a more targeted way"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob_key_info.html#announcements",
    "href": "lessons/03_Lang_prob/03_Lang_prob_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Q: Can we still turn in exit tickets even if its not the same day? For example I was here the first day but forgot to do the exit ticket, if I did it today would it still count towards my grade?\n\nYes! I check them for “attendance” after 7 (sometimes more) days after the class\n\nFor muddy points, it really helps if you can asked a specific question about what you found confusing\n\nI can then address it in a more targeted way"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob_key_info.html#key-dates",
    "href": "lessons/03_Lang_prob/03_Lang_prob_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 1 Assignment due this Thursday at 11pm"
  },
  {
    "objectID": "homework/HW_02.html#from-old-hw-1",
    "href": "homework/HW_02.html#from-old-hw-1",
    "title": "Homework 2",
    "section": "From old HW 1",
    "text": "From old HW 1\n\n\n\n\n\n\n\n\n\nChapter\nTurn In\nExtra Problems\n\n\n\n\n1\n\nTB # 3, 7, 9, 11\n\n\n2\nTB # 30\nNTB # 1\nTB # 1, 4, 8, 16, 19, 23\nNTB # 2"
  },
  {
    "objectID": "homework/HW_02.html#non-textbook-problems-ntb-1",
    "href": "homework/HW_02.html#non-textbook-problems-ntb-1",
    "title": "Homework 2",
    "section": "Non-textbook problems (NTB)",
    "text": "Non-textbook problems (NTB)\n\nSuppose the following are the percentage of US adults with the following conditions:\n\n\\(A\\): Hypertension 33%\n\\(B\\): Diabetes 9%\n\\(C\\): Metabolic syndrome 24%\n\\(A\\) or \\(B\\): 39%\n\\(A\\) or \\(C\\): 45%\n\\(B\\) or \\(C\\): 28%\n\\(A\\) or \\(B\\) or \\(C\\): 48%\n\n\nMake a Venn diagram of the 3 conditions labeling the percentage (or probability) for ALL of the 8 “sections”. Hint: Start from the last condition and work your way up!\nFor each of the following (1. - 7. below), (\\(i\\)) write out the event using unions, intersections, and/or complements of the events \\(A\\), \\(B\\), and \\(C\\) (this is NOT finding the probability, that’s in \\(ii\\)); (\\(ii\\)) find the probability of the event; and (\\(iii\\)) write a sentence explaining what the probability is of in terms of the context of the problem.\n\n\\(\\mathbb{P}\\)(event at least one of the 3)\n\\(\\mathbb{P}\\)(event none)\n\\(\\mathbb{P}\\)(event \\(A\\) only)\n\\(\\mathbb{P}\\)(event exactly one)\n\\(\\mathbb{P}\\)(event \\(A\\) and \\(B\\))\n\\(\\mathbb{P}\\)(event \\(A\\) and \\(B\\) but not \\(C\\))\n\\(\\mathbb{P}\\)(event all 3)\n\n\n\n\nExtra problem\n\nJudith has a penny, nickel, dime, and quarter in her pocket. So does Joe. They both reach into their pockets and choose a coin (all four coins are equally likely to be selected). Let X be the larger value (in cents) of the coins selected by Judith and Joe. For reference, the penny is 1 cent, nickel is 5 cents, dime is 10 cents, and quarter is 25 cents.\n\nHow many possible combinations is there for the pair of Judith’s and Joe’s selected coins? (Hint: we know to whom each coin belongs) \nDefine the sample space for X in this experiment. \nFind the probability for each possible value of X. \nFind the probability of the event that Judith’s coin is worth more than Joe’s."
  },
  {
    "objectID": "homework/HW_01.html#questions",
    "href": "homework/HW_01.html#questions",
    "title": "Homework 1",
    "section": "Questions",
    "text": "Questions\n\n1. Outcomes, events, and sample space\nIn the below parts, please list (i) one specific outcome, (ii) one event that contains more than one outcome, and (iii) the sample space.\n\nChris has an 5-pack of Gatorade sports drink: 1 orange, 2 lemon-lime, and 2 fruit punch. He blindly grabs one out of the pack over and over if necessary, without replacement, until he finds an orange one. Note, each lemon-lime is indistinguishable, and each fruit punch is indistinguishable.\nA claw machine contains 10 plush toys: 5 Red Squishies (R), 3 Blue Dinosaurs (B), and 2 Yellow Star Puffs (Y). You successfully grab a toy, remove it, and then grab a second toy (sampling without replacement). The result is the ordered pair of the two toys’ colors.\nYou are opening a series of mofusound Cat blind boxes. There are 4 possible figurines to collect: 1 shark cat (S), 1 orange striped fish cat (O), and 1 hen cat (H), and 1 cow cat (C). You buy a single blind box.\n\n\n\n2. Running a simulation!\nThis assignment requires you to use the four-step simulation process in R to approximate the probability of a specific event.\nScenario: The Mystic Orb Blind Boxes The “Mystic Orb” collectible series has 5 total figures you can find in the blind boxes:\n\n1 Rare Mystery Toy (M) - The figure Nicky wants.\n4 Common Figures (C) - All other figures.\n\nWhen you buy a blind box, you receive one of the 5 figures, and each figure is equally likely.\nNicky decides to buy three Mystic Orb blind boxes. She really wants to get the Rare Mystery Toy!! The random variable of interest is X, the number of boxes out of the three that contain the Rare Mystery Toy.\nUsing the four-step simulation process, approximate the probability that Nicky gets at least one Rare Mystery Toy when she buys three boxes."
  },
  {
    "objectID": "hw_answers/HW_02_ans.html#non-textbook-problems-1",
    "href": "hw_answers/HW_02_ans.html#non-textbook-problems-1",
    "title": "Homework 2 Answers",
    "section": "Non-textbook problems",
    "text": "Non-textbook problems"
  },
  {
    "objectID": "hw_answers/HW_02_ans.html#textbook-problems-1",
    "href": "hw_answers/HW_02_ans.html#textbook-problems-1",
    "title": "Homework 2 Answers",
    "section": "Textbook problems",
    "text": "Textbook problems\nThere are some answers at the back of the book!! Selected answers (or hints) not provided at the end the book:\n\nChapter 2\n\n# 4: 0.35\n# 8: 0.03125\n# 16: 0.48\n# 23: 0.47\n# 30: (a) 0.189     (b) 0.811     (c) 0.189"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#where-are-we",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#where-are-we",
    "title": "Lesson 3: Language of Probability",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#the-problem-exactly-one-week",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#the-problem-exactly-one-week",
    "title": "Lesson 3: Language of Probability",
    "section": "The Problem: Exactly One Week",
    "text": "The Problem: Exactly One Week\nLet \\(W\\) be the event the subject takes the medication this week. Let \\(N\\) be the event the subject takes the medication next week.\nWe are given:\n\n\\(P(W) = 0.80\\)\n\\(P(N) = 0.70\\)\n\\(P(W^c \\cap N^c) = 0.10\\) (Not taking it either week)\n\nWe want to find the probability of the subject taking their medication exactly one of the two weeks: \\[P((W \\cap N^c) \\cup (W^c \\cap N))\\]"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#calculating-the-theoretical-answer",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#calculating-the-theoretical-answer",
    "title": "Lesson 3: Language of Probability",
    "section": "Calculating the Theoretical Answer",
    "text": "Calculating the Theoretical Answer\nThe problem provides three probabilities. The four disjoint elementary outcomes cover the entire sample space:\n\nTakes both weeks: \\(P(W \\cap N)\\)\nTakes only this week: \\(P(W \\cap N^c)\\)\nTakes only next week: \\(P(W^c \\cap N)\\)\nTakes neither week: \\(P(W^c \\cap N^c) = 0.10\\)\n\nSince the probabilities of all outcomes must sum to 1: \\[P(W \\cap N) + P(W \\cap N^c) + P(W^c \\cap N) + P(W^c \\cap N^c) = 1\\]\nWe can also use the given marginal probabilities to find \\(P(W \\cap N)\\): \\[P(W) + P(N) - P(W \\cap N) = P(W \\cup N)\\] And we know \\(P(W \\cup N) = 1 - P(W^c \\cap N^c) = 1 - 0.10 = 0.90\\).\n\\[0.80 + 0.70 - P(W \\cap N) = 0.90\\] \\[1.50 - P(W \\cap N) = 0.90\\] \\[P(W \\cap N) = 1.50 - 0.90 = \\mathbf{0.60}\\]"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#the-theoretical-answer-cont.",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#the-theoretical-answer-cont.",
    "title": "Lesson 3: Language of Probability",
    "section": "The Theoretical Answer (Cont.)",
    "text": "The Theoretical Answer (Cont.)\nNow we can find the probabilities of taking it in exactly one week:\n\nOnly this week: \\(P(W \\cap N^c) = P(W) - P(W \\cap N) = 0.80 - 0.60 = \\mathbf{0.20}\\)\nOnly next week: \\(P(W^c \\cap N) = P(N) - P(W \\cap N) = 0.70 - 0.60 = \\mathbf{0.10}\\)\n\nThe probability of taking it exactly one of the two weeks is the sum of these two disjoint events:\n\\[P(\\text{Exactly One Week}) = P(W \\cap N^c) + P(W^c \\cap N) = 0.20 + 0.10 = \\mathbf{0.30}\\]\n\n\n\nOutcome\nProbability\n\n\n\n\nBoth Weeks (\\(W \\cap N\\))\n\\(0.60\\)\n\n\nOnly This Week (\\(W \\cap N^c\\))\n\\(0.20\\)\n\n\nOnly Next Week (\\(W^c \\cap N\\))\n\\(0.10\\)\n\n\nNeither Week (\\(W^c \\cap N^c\\))\n\\(0.10\\)\n\n\nTotal\n\\(\\mathbf{1.00}\\)"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#simulation-in-r-setup",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#simulation-in-r-setup",
    "title": "Lesson 3: Language of Probability",
    "section": "Simulation in R: Setup",
    "text": "Simulation in R: Setup\nWe will simulate this experiment a large number of times (\\(N=10,000\\)) to see if the proportion of “Exactly One Week” matches our theoretical probability of 0.30.\nWe’ll use the elementary outcomes and their calculated probabilities.\n\nOutcomes (Events)\n\nBoth: Takes this week and next week.\nOnly W: Takes this week, not next.\nOnly N: Not this week, takes next.\nNeither: Not this week, not next.\n\n\n\nProbabilities (Weights)\n\nBoth: \\(0.60\\)\nOnly W: \\(0.20\\)\nOnly N: \\(0.10\\)\nNeither: \\(0.10\\)\n\n\n\nThe events we are interested in (taking medication exactly once) are Only W and Only N."
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#simulation-in-r-code",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#simulation-in-r-code",
    "title": "Lesson 3: Language of Probability",
    "section": "Simulation in R: Code",
    "text": "Simulation in R: Code\nWe use the sample() function in R to select an outcome based on our calculated probabilities.\n\nset.seed(42) # For reproducibility\nN_SIMS &lt;- 10000 # Number of subjects to simulate\n\n# 1. Define the possible elementary outcomes\noutcomes &lt;- c(\"Both\", \"Only W\", \"Only N\", \"Neither\")\n\n# 2. Define the probability for each outcome (calculated previously)\nprobabilities &lt;- c(\n  \"Both\" = 0.60,      # P(W and N)\n  \"Only W\" = 0.20,    # P(W and N^c)\n  \"Only N\" = 0.10,    # P(W^c and N)\n  \"Neither\" = 0.10    # P(W^c and N^c)\n)\n\n# Verify the probabilities sum to 1\nsum(probabilities)\n\n[1] 1"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#simulation-in-r-the-simulation-run",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#simulation-in-r-the-simulation-run",
    "title": "Lesson 3: Language of Probability",
    "section": "Simulation in R: The Simulation Run",
    "text": "Simulation in R: The Simulation Run\nNow we run the simulation for 10,000 subjects and count the results.\n\n# Simulate the outcomes for N_SIMS subjects\nsimulated_outcomes &lt;- sample(\n  x = outcomes,\n  size = N_SIMS,\n  replace = TRUE,\n  prob = probabilities\n)\n\n# Count the frequency of each outcome\nresults_table &lt;- table(simulated_outcomes)\nprint(results_table)\n\nsimulated_outcomes\n   Both Neither  Only N  Only W \n   5977    1031     967    2025 \n\n# Calculate the empirical probability of *Exactly One Week*\n# This corresponds to \"Only W\" + \"Only N\"\nexactly_one_count &lt;- results_table[\"Only W\"] + results_table[\"Only N\"]\n\nempirical_probability &lt;- exactly_one_count / N_SIMS\n\n# Print the final result\ncat(\"Simulated Probability (Empirical): \", round(empirical_probability, 4), \"\\n\")\n\nSimulated Probability (Empirical):  0.2992 \n\ncat(\"Theoretical Probability (Calculated): \", 0.30, \"\\n\")\n\nTheoretical Probability (Calculated):  0.3"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#where-are-we",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#where-are-we",
    "title": "Lesson 4: Rules of probability",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "homework/HW_02.html#questions",
    "href": "homework/HW_02.html#questions",
    "title": "Homework 2",
    "section": "Questions",
    "text": "Questions\n\nSuppose the following are the percentage of US adults with the following conditions:\n\n\\(A\\): Hypertension 33%\n\\(B\\): Diabetes 9%\n\\(C\\): Metabolic syndrome 24%\n\\(A\\) or \\(B\\): 39%\n\\(A\\) or \\(C\\): 45%\n\\(B\\) or \\(C\\): 28%\n\\(A\\) or \\(B\\) or \\(C\\): 48%\n\n\nMake a Venn diagram of the 3 conditions labeling the percentage (or probability) for ALL of the 8 “sections”. Hint: Start from the last condition and work your way up!\nFor each of the following (1. - 7. below), (\\(i\\)) write out the event using unions, intersections, and/or complements of the events \\(A\\), \\(B\\), and \\(C\\) (this is NOT finding the probability, that’s in \\(ii\\)); (\\(ii\\)) find the probability of the event; and (\\(iii\\)) write a sentence explaining what the probability is of in terms of the context of the problem.\n\n\\(\\mathbb{P}\\)(event at least one of the 3)\n\\(\\mathbb{P}\\)(event none)\n\\(\\mathbb{P}\\)(event \\(A\\) only)\n\\(\\mathbb{P}\\)(event exactly one)\n\\(\\mathbb{P}\\)(event \\(A\\) and \\(B\\))\n\\(\\mathbb{P}\\)(event \\(A\\) and \\(B\\) but not \\(C\\))\n\\(\\mathbb{P}\\)(event all 3)\n\n\nGuessing on an exam. While taking a probability exam, you come to three questions that you have no clue how to answer. You would have known the answers if you had taken the time to study the night before instead of going to a party, but you did not make a good life choice, and you vow to never party on a school night again if you fail this exam. Each question on the exam is multiple choice with the correct answer being either a, b, c, d, or e. (Your guesses are independent.) What is the probability that:\n\nyou randomly guess the right answer to all three questions?\nyou randomly guess the right answer to none of the three questions?\nyou randomly guess the right answer to exactly one of the three questions?\nyou randomly guess the right answer to exactly two of the three questions?\nDo the probabilities in parts a–d sum to 1?\n\nRecall from class, that we defined events \\(A,B,\\) and \\(C\\) to mutually independent if both (1) and (2) below hold. This point of this exercise is to show that \\((1)\\nRightarrow (2),\\) and \\((2)\\nRightarrow (1).\\) \\[\\begin{array}{cc}\n    (1) & \\mathbb{P}(A\\cap B\\cap C)=\\mathbb{P}(A)\\mathbb{P(}B)\\mathbb{P(}C) \\\\\n    (2) & \\mathbb{P}(A\\cap B)=\\mathbb{P}(A)\\mathbb{P(}B) \\\\\n    & \\mathbb{P}(A\\cap C)=\\mathbb{P}(A)\\mathbb{P(}C) \\\\\n    & \\mathbb{P}(B\\cap C)=\\mathbb{P}(B)\\mathbb{P(}C)%\n    \\end{array}%\\]\n\nSuppose two different fair dice are rolled. Let events \\(A,B,\\) and \\(C\\) be defined in the following way: \\[\\begin{array}{cl}\nA: & \\text{Roll a total of 7} \\\\\nB: & \\text{First die is a 6} \\\\\nC: & \\text{Second die is a 2}%\n\\end{array}%\\]\nShow that condition \\((2)\\) holds, but that condition \\((1)\\) does not.\nSuppose two different fair dice are rolled. Let events \\(A,B,\\) and \\(C\\) be defined in the following way: \\[\\begin{array}{cl}\nA: & \\text{Roll a 1 or 2 on the first die} \\\\\nB: & \\text{Roll a 3, 4, or 5 on the second die} \\\\\nC: & \\text{Roll a total of 4, 11, or 12}%\n\\end{array}%\\]\nShow that condition \\((1)\\) holds, but that condition \\((2)\\) does not.\n\nParity of spinning. A spinner has the left side (numbers 1, 2, 3, 4, and 5) colored red and the right side colored white (numbers 6, 7, 8, and 9), with all numbers equally likely.\n\nWhat is the probability the spinner lands on an odd number?\nGiven that the spinner landed on an odd number, what is the chance the spinner landed on a white number?\nGiven that the spinner landed on a white number, what is the chance it landed on an odd number?\n\nWeather. The weather on any given day can either be sunny, cloudy, or partially cloudy. Each day is also classified as dry or rainy. The probability of a sunny day is 0.48, and the probability of a cloudy day is 0.39. The probability of having a sunny and dry day is 0.48. The probability of a cloudy and dry day is 0.14. The probability of a partially cloudy and dry day is 0.09.\n\nFind the probability of a dry day.\nFind the probability of a rainy day.\nFind the probability of a sunny day given that it is a dry day.\nFind the probability of a dry day given that it is a sunny day.\nFind the probability of a cloudy day given that it is a rainy day.\nFind the probability that it is a rainy day given that it is a cloudy day\n\n\n\nExtra problems\n\nJudith has a penny, nickel, dime, and quarter in her pocket. So does Joe. They both reach into their pockets and choose a coin (all four coins are equally likely to be selected). Let X be the larger value (in cents) of the coins selected by Judith and Joe. For reference, the penny is 1 cent, nickel is 5 cents, dime is 10 cents, and quarter is 25 cents.\n\nHow many possible combinations is there for the pair of Judith’s and Joe’s selected coins? (Hint: we know to whom each coin belongs) \nDefine the sample space for X in this experiment. \nFind the probability for each possible value of X. \nFind the probability of the event that Judith’s coin is worth more than Joe’s."
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#how-can-we-code-some-of-these",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#how-can-we-code-some-of-these",
    "title": "Lesson 3: Language of Probability",
    "section": "How can we code some of these?",
    "text": "How can we code some of these?\n\n\nExample: Simulating Two Rolls of a Fair Four-Sided Die\n\n\nWe’re going to roll two four-sided dice. This time, let’s say event A is rolling matching numbers and event B is rolling at least one 2.\n\n\n\n\n\n\nMath\nCode\n\n\n\n\nUnion\n\\(A \\cup B\\)\nA | B\n\n\nIntersection\n\\(A \\cap B\\)\nA & B\n\n\nComplement\n\\(A^c\\) or \\(A'\\)\n!= A\n\n\nMutually exclusive\n\\(A \\cap B = \\emptyset\\)\nA & B == NA"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#how-can-we-code-some-of-these-12",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#how-can-we-code-some-of-these-12",
    "title": "Lesson 3: Language of Probability",
    "section": "How can we code some of these? (1/2)",
    "text": "How can we code some of these? (1/2)\n\n\nExample: Simulating Two Rolls of a Fair Four-Sided Die\n\n\nWe’re going to roll two four-sided dice. This time, let’s say event A is rolling matching numbers and event B is rolling at least one 2.\n\n\n\nFirst, we simulate rolling two four-sided dice 10,000 times\n\n\nset.seed(1002)\nrolls = replicate(10000, sample(x = 1:4, size = 2, replace = TRUE))\n\n\nNow, we can create logical vectors for events A and B\n\n\nevent_A = ( rolls[1, ] == rolls[2, ] )\nhead(event_A, 10)\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE\n\nevent_B = ( rolls[1, ] == 2 | rolls[2, ] == 2 )\nhead(event_B, 10)\n\n [1] FALSE FALSE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE FALSE"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob.html#how-can-we-code-some-of-these-22",
    "href": "lessons/03_Lang_prob/03_Lang_prob.html#how-can-we-code-some-of-these-22",
    "title": "Lesson 3: Language of Probability",
    "section": "How can we code some of these? (2/2)",
    "text": "How can we code some of these? (2/2)\n\n\n\n\nUnion\n\n\n\\(A \\cup B\\)\nA | B\n\nevent_A_or_B = event_A | event_B\nhead(event_A_or_B, 10)\n\n [1] FALSE FALSE FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE\n\n\n\n\n\n\n\nIntersection\n\n\n\\(A \\cap B\\) A & B\n\nevent_A_and_B = event_A & event_B\nhead(event_A_and_B, 10)\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\n\n\n\n\n\n\nComplement\n\n\n\\(A^c\\) or \\(A'\\) != A\n\nevent_not_A = !event_A\nevent_not_B = event_B != TRUE\nhead(event_not_A, 10)\n\n [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE\n\n\n\n\n\n\n\nMutually Exclusive\n\n\n\\(A \\cap B = \\emptyset\\) A & B == NA\n\nsum(event_A_and_B == TRUE)\n\n[1] 621"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob_key_info.html",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "No office hours from me this week - I have a standing appointment\n\nBut we will start next week!\n\nDrop deadline with 100% refund: this Friday, 10/10\nNew AI Video Tutorials! If anyone is looking for course materials on the responsible use of generative AI tools such as ChatGPT, I wanted to highlight that the OHSU library has released a new set of AI video tutorials!\n\nCreated by librarian David Carson, this series of short videos (3-4 minutes each) is based on the Kickstart Your Writing with AI workshop taught with writing specialist Zoe Speidel. Each video is standalone and can be viewed in any order, so faculty can share and reuse whichever are most relevant. The topics include effective prompting, AI and publishing, and how to cite or disclose AI. The videos are designed to be flexible resources and are available to embed directly into Sakai. This series is available on the Library’s Generative AI student guide."
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob_key_info.html#announcements",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "No office hours from me this week - I have a standing appointment\n\nBut we will start next week!\n\nDrop deadline with 100% refund: this Friday, 10/10\nNew AI Video Tutorials! If anyone is looking for course materials on the responsible use of generative AI tools such as ChatGPT, I wanted to highlight that the OHSU library has released a new set of AI video tutorials!\n\nCreated by librarian David Carson, this series of short videos (3-4 minutes each) is based on the Kickstart Your Writing with AI workshop taught with writing specialist Zoe Speidel. Each video is standalone and can be viewed in any order, so faculty can share and reuse whichever are most relevant. The topics include effective prompting, AI and publishing, and how to cite or disclose AI. The videos are designed to be flexible resources and are available to embed directly into Sakai. This series is available on the Library’s Generative AI student guide."
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob_key_info.html#key-dates",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 1 Assignment due this Sunday at 11pm"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob_muddy_points.html",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "When trying to figure out what theorem/rule/property to use, the most helpful thing is to (1) write the probability statement for your answer and (2) write the information you know in probability statements. Then you want to examine all the rules/theorems/properties we learned to see which can help you connect the information you know to the probability statement for the question."
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob_muddy_points.html#fall-2024",
    "href": "lessons/03_Lang_prob/03_Lang_prob_muddy_points.html#fall-2024",
    "title": "Muddy Points",
    "section": "Fall 2024",
    "text": "Fall 2024\n\n3. Confusion on De Morgan’s law and the high blood pressure example\nThis is in reference to the Lesson 3 notes on “BP example variation (3/3)” slide. I explained the event that at least one subject does not have high blood pressure using a venn diagram. In this venn diagram, I assumed \\(n=4\\), and I wanted to show that the union of complements is equal to the complement of unions: \\(\\bigcup\\limits_{i=1}^{n}H_i^C = \\Big(\\bigcap\\limits_{i=1}^{n}H_i\\Big)^C\\), which is De Morgan’s 2nd Law.\n\n Now we can look at \\(\\bigcup\\limits_{i=1}^{4}H_i^C\\). We first need to define \\(H_i^c\\)\n\n\n\n\n\n4. Proofs of propositions\nFurther explanations of the propositions can be found in the textbook from pages 24-27. For many of the explanations in class, I was working to produce a union of disjoint events, so that the probability could easily be calculated. Proposition 3 and 4 were specifically mentioned, so I will include some writing notes on them here:\n\nProposition 3\nIf \\(A \\subseteq B\\), then \\(\\mathbb{P}(A) \\leq \\mathbb{P}(B)\\)\nIn this proposition, I want to define event \\(B\\) as a union of disjoint events so that I can show \\(P(B)\\) is the sum of \\(P(A)\\) and some greater-than-or-equal-to 0 probability event. If the following is my venn diagram of A and B:\n\n\n\n\n\nThen I can define B as the union of disjoint events: \nIf we then take the probability of each side of the equation \\(B = A \\cup (A^c \\cap B)\\), we get \\[P(B) = P\\big(A \\cup (A^c \\cap B)\\big)\\]\nSince events \\(A\\) and \\(A^c \\cap B\\) are disjoint, the probability of their union is just: \\[P(A) + P(A^c \\cap B)\\]\nThus, our equation is now \\[P(B) = P(A) + P(A^c \\cap B)\\]\nFrom Axiom 1, we know for event \\(A^c \\cap B\\), \\(P(A^c \\cap B) \\geq 0\\).\nSo the probability of event B is the sum of the probability of event A and an event that is \\(\\geq\\) 0. This means \\(P(B) \\geq P(A)\\).\n\n\nProposition 4\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\)\n\n\nFrom the pictures above, we can see some similar disjoint events.\nIf we look back at \\(A \\cup B\\), we can start manipulating the right side of the equation:\n\n \n\n\n\n5. Example at end of Chapter 2 slides (Venn Diagram)\nI will post this in the previous week’s Muddy Points as well. Please follow this link for my work through of the example. And here is the PDF with my work.\nSub-question: why don’t we just multiply the probability of A and B to get the intersection? This is a specific property of probability when A and B are independent. Only when A and B are independent can we conclude that \\(P(A \\cap B) = P(A)P(B)\\).\n\n\n6. Partition of events\nWe’ve been working with event partitions throughout Chapter 2, but we have not formally identified them. Partitions are advantageous to define for two reasons:\n\nThe partitions may be easier to calculate. We can then use the partitions to reconstruct other probabilities that may be more difficult to calculate\nPartitions have nice properties as a consequence of being disjoint. For example, the probability of the union of partitions is the sum of the probabilities across each partition: \\[P\\bigg(\\bigcup_{i=1}^n A_i\\bigg) = P(A_1)P(A_2)P(A_3) \\cdot \\cdot \\cdot P(A_n)\\]"
  },
  {
    "objectID": "lessons/03_Lang_prob/03_Lang_prob_muddy_points.html#fall-2025",
    "href": "lessons/03_Lang_prob/03_Lang_prob_muddy_points.html#fall-2025",
    "title": "Muddy Points",
    "section": "",
    "text": "See below for questions on De Morgan’s laws and propositions from last year."
  },
  {
    "objectID": "hw_answers/HW_02_ans.html#questions",
    "href": "hw_answers/HW_02_ans.html#questions",
    "title": "Homework 2 Answers",
    "section": "Questions",
    "text": "Questions\n\n\n (b) Answers for part (ii) for each:\n\n\n0.48\n0.52\n0.2\n0.32\n0.03\n0.01\n0.02\n\n\n0.384 If you have the right answer to (c), then you should be able to figure out the rest (see (e)).\n\n\n1 does not hold because \\(0 \\neq \\dfrac{1}{216}\\)      (b) 2 does not hold because \\(P(B \\cap C) \\neq P(B)P(C)\\)\n\n\n5/9; b. 2/5; c. 2/4\n\n\n0.71; b. 0.29; c. 48/71; d. 1; e. 25/29; f. 25/39\n\n\n\nExtra problem\n\n\n16, (c) for one, \\(P(X=10) = \\dfrac{5}{16}\\), (d) 0.375"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#can-we-flip-the-conditional-probability",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#can-we-flip-the-conditional-probability",
    "title": "Lesson 4: Rules of probability",
    "section": "Can we flip the conditional probability?",
    "text": "Can we flip the conditional probability?\n\nSo we learned about conditional probabilities\n\nWe learned how the occurrence of event A affects event B (B conditional on A)\n\n\n \n\nCan we figure out information on how the occurrence of event B affects event A?\n\n \n\nWe can use the conditional probability (\\(\\mathbb{P}(A|B)\\)) to get information on the flipped conditional probability (\\(\\mathbb{P}(B|A)\\))"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#example-of-two-dice-simulating-in-r",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#example-of-two-dice-simulating-in-r",
    "title": "Lesson 4: Rules of probability",
    "section": "Example of two dice: simulating in R",
    "text": "Example of two dice: simulating in R\n\n\nExample 1\n\n\nTwo dice (green and blue) are rolled. Let \\(A =\\) event a total of 7 appears, and \\(B =\\) event green die is a six. Are events \\(A\\) and \\(B\\) independent?\n\n\n\nset.seed(1002)\nrolls = replicate(10000, sample(x = 1:6, size = 2, replace = TRUE))\nrolls[, 1:10]\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n[1,]    4    5    5    5    6    5    2    4    3     4\n[2,]    1    4    6    3    1    1    5    5    6     3\n\nevent_A = ( rolls[1, ] + rolls[2, ] == 7)\nhead(event_A, 10)\n\n [1] FALSE FALSE FALSE FALSE  TRUE FALSE  TRUE FALSE FALSE  TRUE\n\nevent_B = ( rolls[1, ] == 6 )\nhead(event_B, 10)\n\n [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#example-of-two-dice-simulating-in-r-12",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#example-of-two-dice-simulating-in-r-12",
    "title": "Lesson 4: Rules of probability",
    "section": "Example of two dice: simulating in R (1/2)",
    "text": "Example of two dice: simulating in R (1/2)\n\n\nExample 1\n\n\nTwo dice (green and blue) are rolled. Let \\(A =\\) event a total of 7 appears, and \\(B =\\) event green die is a six. Are events \\(A\\) and \\(B\\) independent?\n\n\n\nset.seed(1002)\nreps = 10000\nrolls = replicate(reps, sample(x = 1:6, size = 2, replace = TRUE))\nrolls[, 1:10]\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n[1,]    4    5    5    5    6    5    2    4    3     4\n[2,]    1    4    6    3    1    1    5    5    6     3\n\nevent_A = ( rolls[1, ] + rolls[2, ] == 7 )\nhead(event_A, 10)\n\n [1] FALSE FALSE FALSE FALSE  TRUE FALSE  TRUE FALSE FALSE  TRUE\n\nevent_B = ( rolls[1, ] == 6 )\nhead(event_B, 10)\n\n [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#example-of-two-dice-simulating-in-r-12-1",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#example-of-two-dice-simulating-in-r-12-1",
    "title": "Lesson 4: Rules of probability",
    "section": "Example of two dice: simulating in R (1/2)",
    "text": "Example of two dice: simulating in R (1/2)\n\n\nExample 1\n\n\nTwo dice (green and blue) are rolled. Let \\(A =\\) event a total of 7 appears, and \\(B =\\) event green die is a six. Are events \\(A\\) and \\(B\\) independent?\n\n\n\n( sum(event_A) / reps ) * ( sum(event_B) / reps )\n\n[1] 0.0286608\n\nevent_A_and_B = ( rolls[1, ] + rolls[2, ] == 7 ) & ( rolls[1, ] == 6 )\nhead(event_A_and_B, 10)\n\n [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE\n\nsum(event_A_and_B) / reps\n\n[1] 0.0284"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#conditional-probability-with-two-dice-simulations",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob.html#conditional-probability-with-two-dice-simulations",
    "title": "Lesson 4: Rules of probability",
    "section": "Conditional probability with two dice: simulations",
    "text": "Conditional probability with two dice: simulations\n\n\nExample 3\n\n\nTwo dice (green and blue) are rolled. If the dice do not show the same face, what is the probability that one of the dice is a 1?\n\n\n\nset.seed(1002)\nrolls = replicate(reps, sample(x = 1:6, size = 2, replace = TRUE))\nrolls[, 1:10]\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n[1,]    4    5    5    5    6    5    2    4    3     4\n[2,]    1    4    6    3    1    1    5    5    6     3\n\nevent_A = ( rolls[1, ] != rolls[2, ] )\nhead(event_A, 10)\n\n [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n\nevent_B = ( rolls[1, ] == 1 | rolls[2, ] == 1 )\nhead(event_B, 10)\n\n [1]  TRUE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE\n\nsum(event_B & event_A) / sum(event_A)\n\n[1] 0.3315328"
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob_muddy_points.html#fall-2024",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob_muddy_points.html#fall-2024",
    "title": "Muddy Points",
    "section": "Fall 2024",
    "text": "Fall 2024\n\n1. How do I know if two events are independent?\nMy main piece of advice for independence is to rely on the math to show it, not logic! Don’t go into a problem thinking “Logically, these two events are independent.” If the problem does not say “Assume independence,” then we need to show it mathematically.\nSame goes with the definition of independence. When we say “knowing the outcome of one provides no information about the outcome of the other,” we once again need to show this mathematically, not just using logic. We translate the previous statement to \\[P(A) = P(A|B)\\] And we need to show this mathematically!\n\n\n2. Disjoint vs. Independent Events\nHere is a pretty good video breaking down disjoint (mutually exclusive) events and independent events. It includes examples as well."
  },
  {
    "objectID": "lessons/04_Rules_of_prob/04_Rules_of_prob_muddy_points.html#fall-2025",
    "href": "lessons/04_Rules_of_prob/04_Rules_of_prob_muddy_points.html#fall-2025",
    "title": "Muddy Points",
    "section": "",
    "text": "When trying to figure out what theorem/rule/property to use, the most helpful thing is to (1) write the probability statement for your answer and (2) write the information you know in probability statements. Then you want to examine all the rules/theorems/properties we learned to see which can help you connect the information you know to the probability statement for the question."
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes_key_info.html",
    "href": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes_key_info.html",
    "title": "Key Info and Announcements",
    "section": "",
    "text": "Thanks for being flexible on Monday!\n\nI’m sorry if this messed up your morning flow\n\nToday: need to finish lesson 4, then start lesson 5\nFire drills this week!\nNotes on homework\n\nLook at Charles’ feedback on Sakai\nSet your seed for reproducibility\nself-contained: true\nMake sure to include the full sample space\n\nIf drawing 2, then sample space is each combo of two\n\nDon’t forget to do all the steps in the simulations!"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes_key_info.html#announcements",
    "href": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes_key_info.html#announcements",
    "title": "Key Info and Announcements",
    "section": "Announcements",
    "text": "Announcements\n\nHomework 2 due this Sunday at 11pm\nQuiz 1 opens on 10/22 at 3pm"
  },
  {
    "objectID": "homework/HW_03.html#questions",
    "href": "homework/HW_03.html#questions",
    "title": "Homework 3",
    "section": "Questions",
    "text": "Questions\n\nCookies. Consider a jar of 9 chocolate chip and 11 peanut butter cookies. You randomly select 2 cookies to eat. All possible choices are equally likely.\n\nWhat is the probability that the 2 you select will both will be chocolate chip? Calculate your answer “by hand.”\nWhat is the probability that at least one of your cookies will be peanut butter? Calculate your answer “by hand” then verify your answer by simulating the experiment in R at least 1000 times.\nWhat is the probability that last 2 cookies left in the jar (after 18 have been eaten) will be chocolate chip? (Is this answer the same or different than part a? Why or why not?) Calculate your answer “by hand” then verify your answer by simulating the experiment in R at least 1000 times.\n\nRaffle tickets. There are 30 raffle tickets in a bowl. Three winning tickets will be selected. Each ticket can win at most one prize. How many ways can the prizes be distributed if the following additional information is known?\n\nAll 3 winners receive goldfish (the goldfish are indistinguishable).\nThe 1st winner receives a car, the 2nd a bicycle, and the 3rd a goldfish.\n\nA new drug is packaged to contain 30 pills in a bottle. Suppose that 98% of all bottles contain no defective pills, 1.5% contain one defective pill, and 0.5% contain two defective pills. Two pills from a bottle are randomly selected and tested. What is the probability that there are 2 defective pills in the bottle given that one of the two tested pills is defective?"
  },
  {
    "objectID": "homework/HW_03.html#extra-problems",
    "href": "homework/HW_03.html#extra-problems",
    "title": "Homework 3",
    "section": "Extra Problems",
    "text": "Extra Problems\n\nRead the Washington Post article The amazing woman who can smell Parkinson’s disease - before symptoms appear (http://www.washingtonpost.com/news/morning-mix/wp/2015/10/23/scottish-woman-detects-a-musky-smell-that-could-radically-improve-how-parkinsons-disease-is-diagnosed/)\nAssuming Joy Milne does not have the ability to detect Parkinson’s disease via smell, answer the following questions:\n\nWhat is the probability of her correctly detecting Parkinson’s by smelling one t-shirt?\nWhat is the probability of her correctly detecting Parkinson’s in 12 out of 12 t-shirts?\n\nCalculus Review\n\n\\[\\int_0^yc(x+y)dx\\]\n\\[\\frac{d}{dx}\\bigg(\\frac{4}{9}x^2y^2+\\frac{5}{9}xy^4\\bigg)\\]\n\\[\\frac{d}{dy}\\bigg(\\frac{4}{9}x^2y^2+\\frac{5}{9}xy^4\\bigg)\\]\n\\[\\int_0^y2e^{-x}e^{-y}dx\\]\n\\[\\int_0^\\infty xye^{-(x+y)}dy\\]\n\\[\\int_x^{2x} 2e^{-(x+3y)}dy\\]\nFind the area of the region bounded by the graphs of \\(f(x)=2-x^2\\) and \\(g(x)=x\\) by integrating with respect to \\(x\\).\nFind the area of the region bounded by the graphs of \\(f(x)=2-x^2\\) and \\(g(x)=x\\) by integrating with respect to \\(y\\).\nFind the area of the region bounded by the graphs of \\(x=3-y^2\\) and \\(y=x-1\\) by integrating with respect to \\(x\\).\nFind the area of the region bounded by the graphs of \\(x=3-y^2\\) and \\(y=x-1\\) by integrating with respect to \\(y\\)."
  },
  {
    "objectID": "hw_answers/HW_03_ans.html#questions",
    "href": "hw_answers/HW_03_ans.html#questions",
    "title": "Homework 3 Answers",
    "section": "",
    "text": "0.189     (b) 0.811     (c) 0.189\n\n\n4060; b. 24,360;\n\n0.3916"
  },
  {
    "objectID": "hw_answers/HW_03_ans.html#extra-problems",
    "href": "hw_answers/HW_03_ans.html#extra-problems",
    "title": "Homework 3 Answers",
    "section": "Extra Problems",
    "text": "Extra Problems\n\nCalculus review\n\n\\(c(\\frac{y^{2}}{2}+y^{2})\\)\n\\(\\frac{8}{9}xy^{2}+\\frac{5}{9}y^{4}\\)\n\\(\\frac{8}{9}x^{2}y+\\frac{20}{9}xy^{3}\\)\n\\(-2e^{-2y}+2e^{-y}\\)\n\\(xe^{-x}\\)\n\\(-\\frac{2}{3}(e^{-7x}-e^{-4x})\\)\n\\(\\frac{9}{2}\\)\n\\(\\frac{9}{2}\\)\n\\(\\frac{9}{2}\\)\n\\(\\frac{9}{2}\\)"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes_key_info.html#key-info",
    "href": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes_key_info.html#key-info",
    "title": "Key Info and Announcements",
    "section": "",
    "text": "Thanks for being flexible on Monday!\n\nI’m sorry if this messed up your morning flow\n\nToday: need to finish lesson 4, then start lesson 5\nFire drills this week!\nNotes on homework\n\nLook at Charles’ feedback on Sakai\nSet your seed for reproducibility\nself-contained: true\nMake sure to include the full sample space\n\nIf drawing 2, then sample space is each combo of two\n\nDon’t forget to do all the steps in the simulations!"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#learning-objectives",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#learning-objectives",
    "title": "Lesson 6: Calculus Review",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nFind derivatives of continuous functions with one variable\nFind antiderivatives and integrals of functions with one variable"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#where-are-we",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#where-are-we",
    "title": "Lesson 6: Calculus Review",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-derivative-of-the-following-function",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-derivative-of-the-following-function",
    "title": "Lesson 6: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.1\n\n\n\\(f(x) = 2\\)\n\n\n\n\nDerivative of a constant\n\n\n\\[\\dfrac{d}{dx} c = 0\\]"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-derivative-of-the-following-function-1",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-derivative-of-the-following-function-1",
    "title": "Lesson 6: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.2\n\n\n\\(f(x) = 2x\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-derivative-of-the-following-function-2",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-derivative-of-the-following-function-2",
    "title": "Lesson 6: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.3\n\n\n\\(f(x) = 2x+2\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-derivative-of-the-following-function-3",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-derivative-of-the-following-function-3",
    "title": "Lesson 6: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.4\n\n\n\\(f(x) = x^2\\)\n\n\n\n\nDerivative of \\(x\\) to a constant\n\n\n\\[\\dfrac{d}{dx} x^n = nx^{n-1}\\]"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-derivative-of-the-following-function-4",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-derivative-of-the-following-function-4",
    "title": "Lesson 6: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.5\n\n\n\\(f(x) = 3\\sqrt{x}+\\frac2x+5\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-derivative-of-the-following-function-5",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-derivative-of-the-following-function-5",
    "title": "Lesson 6: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.6\n\n\n\\(f(x) = e^x\\)\n\n\n\n\nDerivative of exponential function\n\n\n\\(\\dfrac{d}{dx} e^x = e^x\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-derivative-of-the-following-function-6",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-derivative-of-the-following-function-6",
    "title": "Lesson 6: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.7\n\n\n\\(f(x) = \\ln(x)\\)\n\n\n\n\nDerivative of logarithm\n\n\n\\(\\dfrac{d}{dx} ln(x) = \\dfrac{1}{x}\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-derivative-of-the-following-function-7",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-derivative-of-the-following-function-7",
    "title": "Lesson 6: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.8\n\n\n\\(f(x) = x^2 e^x\\)\n\n\n\n\nProduct Rule\n\n\n\\(\\dfrac{d}{dx} f(x)g(x) = f'(x)g(x) + f(x)g'(x)\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-derivative-of-the-following-function-8",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-derivative-of-the-following-function-8",
    "title": "Lesson 6: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.9\n\n\n\\(f(x) = \\dfrac{x^5}{2x+7}\\)\n\n\n\n\nQuotient Rule\n\n\n\\(\\dfrac{d}{dx} \\dfrac{f(x)}{g(x)} = \\dfrac{g(x)f'(x) - f(x)g'(x)}{\\big(g(x)\\big)^2}\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-derivative-of-the-following-function-9",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-derivative-of-the-following-function-9",
    "title": "Lesson 6: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.10\n\n\n\\(f(x) = e^{-2x+7}\\)\n\n\n\n\nChain Rule\n\n\n\\(\\dfrac{d}{dx} f\\big(g(x)\\big)= f'\\big(g(x)\\big)g'(x)\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-derivative-of-the-following-function-10",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-derivative-of-the-following-function-10",
    "title": "Lesson 6: Calculus Review",
    "section": "Find the derivative of the following function",
    "text": "Find the derivative of the following function\n\n\n\n\nExample 1.11\n\n\n\\(f(x) = \\ln(x^2)\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-antiderivative-of-the-following-function",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-antiderivative-of-the-following-function",
    "title": "Lesson 6: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.1\n\n\n\\(f(x) = 2\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-antiderivative-of-the-following-function-1",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-antiderivative-of-the-following-function-1",
    "title": "Lesson 6: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.2\n\n\n\\(f(x) = x\\)\n\n\n\n\nIntegration of x to a constant\n\n\n\\(\\displaystyle\\int x^n dx = \\dfrac{x^{n+1}}{n+1} + c\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-antiderivative-of-the-following-function-2",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-antiderivative-of-the-following-function-2",
    "title": "Lesson 6: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.3\n\n\n\\(f(x) = \\frac1x\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-antiderivative-of-the-following-function-3",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-antiderivative-of-the-following-function-3",
    "title": "Lesson 6: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.4\n\n\n\\(f(x) = x^{3/2}\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-antiderivative-of-the-following-function-4",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-antiderivative-of-the-following-function-4",
    "title": "Lesson 6: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.5\n\n\n\\(f(x) = e^x\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-antiderivative-of-the-following-function-5",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-antiderivative-of-the-following-function-5",
    "title": "Lesson 6: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.6\n\n\n\\(f(x) = e^{-x}\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-antiderivative-of-the-following-function-6",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#find-the-antiderivative-of-the-following-function-6",
    "title": "Lesson 6: Calculus Review",
    "section": "Find the antiderivative of the following function",
    "text": "Find the antiderivative of the following function\n\n\n\n\nExample 2.7\n\n\n\\(f(x) = e^{-2x}\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#solve-the-following-integral",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#solve-the-following-integral",
    "title": "Lesson 6: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.1\n\n\n\\(\\displaystyle\\int_0^1 (2x+x^5)dx\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#solve-the-following-integral-1",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#solve-the-following-integral-1",
    "title": "Lesson 6: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.2\n\n\n\\(\\displaystyle\\int_2^3 e^{-x}dx\\)\n\n\n\n\nU-substitution\n\n\n\\(\\displaystyle\\int f\\big(g(x)\\big) g'(x) dx = \\displaystyle\\int f(u) dx\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#solve-the-following-integral-2",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#solve-the-following-integral-2",
    "title": "Lesson 6: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.3\n\n\n\\(\\displaystyle\\int_2^3 x e^{x^2}dx\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#solve-the-following-integral-3",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#solve-the-following-integral-3",
    "title": "Lesson 6: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.4\n\n\n\\(\\displaystyle\\int_0^{\\infty} x e^{-x}dx\\)\n\n\n\n\nIntegrating by Parts\n\n\n\\(\\displaystyle\\int f(x) g'(x) dx = f(x)g(x) -\\)\n\\(\\displaystyle\\int f'(x) g(x) dx\\)\nOR\n\\(\\displaystyle\\int_a^b u dv = uv\\bigg|^b_a - \\displaystyle\\int_a^b vdu\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#solve-the-following-integral-4",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#solve-the-following-integral-4",
    "title": "Lesson 6: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.5\n\n\n\\(\\displaystyle\\int_1^2 x^2 \\ln(x)dx\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#solve-the-following-integral-5",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#solve-the-following-integral-5",
    "title": "Lesson 6: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.6\n\n\n\\(\\displaystyle\\int_1^2 \\ln(x)dx\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review.html#solve-the-following-integral-6",
    "href": "lessons/06_Calculus_review/06_Calculus_review.html#solve-the-following-integral-6",
    "title": "Lesson 6: Calculus Review",
    "section": "Solve the following integral",
    "text": "Solve the following integral\n\n\n\n\nExample 3.7\n\n\n\\(\\displaystyle\\int_1^2 x^2 e^{x}dx\\)"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review_key_info.html",
    "href": "lessons/06_Calculus_review/06_Calculus_review_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "This class is optional!\nFire drills this week!"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review_key_info.html#announcements",
    "href": "lessons/06_Calculus_review/06_Calculus_review_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "This class is optional!\nFire drills this week!"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review_key_info.html#key-dates",
    "href": "lessons/06_Calculus_review/06_Calculus_review_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 2 due Sunday\nQuiz 1 will open next Wednesday after class"
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review_muddy_points.html",
    "href": "lessons/06_Calculus_review/06_Calculus_review_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Here is a pretty helpful StackExchange post talking about this!\n\n\n\nI have two approaches to identifying \\(u\\) and \\(dv\\):\n\nTry to find a \\(u\\) that will eventually differentiate into a constant. This usually works unless you’re left with a \\(dv\\) that is hard to integrate.\n\nFor example, \\(u=x^6\\). the first derivative, \\(u'=6x^5\\), which may lead us to do another integration by parts, but eventually, at the 6th derivative, we get 720. This means, in our integration by parts, we eventually get an integral that only has \\(x\\) in the function once.\n\nIn this example, \\(x^6\\) would result in many integration by parts. I feel like we don’t typically see that many in our work.\n\nIn Example 3.5 in Calculus Review, setting \\(u=x^2\\) is a bad idea because we don’t really know how to integrate \\(dv=ln(x)\\) into \\(v\\).\n\nTry to find a \\(u\\) where \\(du\\) is the reciprocal of \\(v\\) or \\(du\\) cancels with \\(v\\).\n\nLook again at Example 3.5 in the notes! Hint: What is the derivative of \\(ln(x)\\)? And what does \\(\\dfrac{1}{x}x^3\\) equal?\n\n\n\n\n\nI just stumbled upon this website! Just a bunch of calculus practice problems! Might be some help."
  },
  {
    "objectID": "lessons/06_Calculus_review/06_Calculus_review_muddy_points.html#fall-2023",
    "href": "lessons/06_Calculus_review/06_Calculus_review_muddy_points.html#fall-2023",
    "title": "Muddy Points",
    "section": "",
    "text": "Here is a pretty helpful StackExchange post talking about this!\n\n\n\nI have two approaches to identifying \\(u\\) and \\(dv\\):\n\nTry to find a \\(u\\) that will eventually differentiate into a constant. This usually works unless you’re left with a \\(dv\\) that is hard to integrate.\n\nFor example, \\(u=x^6\\). the first derivative, \\(u'=6x^5\\), which may lead us to do another integration by parts, but eventually, at the 6th derivative, we get 720. This means, in our integration by parts, we eventually get an integral that only has \\(x\\) in the function once.\n\nIn this example, \\(x^6\\) would result in many integration by parts. I feel like we don’t typically see that many in our work.\n\nIn Example 3.5 in Calculus Review, setting \\(u=x^2\\) is a bad idea because we don’t really know how to integrate \\(dv=ln(x)\\) into \\(v\\).\n\nTry to find a \\(u\\) where \\(du\\) is the reciprocal of \\(v\\) or \\(du\\) cancels with \\(v\\).\n\nLook again at Example 3.5 in the notes! Hint: What is the derivative of \\(ln(x)\\)? And what does \\(\\dfrac{1}{x}x^3\\) equal?\n\n\n\n\n\nI just stumbled upon this website! Just a bunch of calculus practice problems! Might be some help."
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#another-example-order-matters-vs.-not-12",
    "href": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#another-example-order-matters-vs.-not-12",
    "title": "Lesson 5: Equally Likely Outcomes and Counting",
    "section": "Another example: order matters vs. not (1/2)",
    "text": "Another example: order matters vs. not (1/2)\n\n\n\n\nExample 2\n\n\nSuppose we draw 2 cards from a standard deck without replacement. What is the probability that both are spades when\n\norder matters?\norder doesn’t matter?"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#another-example-order-matters-vs.-not-12-1",
    "href": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#another-example-order-matters-vs.-not-12-1",
    "title": "Lesson 5: Equally Likely Outcomes and Counting",
    "section": "Another example: order matters vs. not (1/2)",
    "text": "Another example: order matters vs. not (1/2)\n\n\n\n\nExample 2\n\n\nSuppose we draw 2 cards from a standard deck without replacement. What is the probability that both are spades when\n\norder matters?\norder doesn’t matter?\n\n\n\n\nWe can do a simulation!\n\nset.seed(1234)\nn_sim &lt;- 1000000\ncards = c(rep(\"S\", 13), \n          rep(\"H\", 13), \n          rep(\"C\", 13), \n          rep(\"D\", 13))\ndraws &lt;- replicate(n_sim, \n                   sample(cards, 2, replace = FALSE))\ndraws[, 1:10]\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n[1,] \"C\"  \"H\"  \"D\"  \"S\"  \"C\"  \"S\"  \"C\"  \"H\"  \"H\"  \"D\"  \n[2,] \"H\"  \"C\"  \"D\"  \"S\"  \"H\"  \"C\"  \"H\"  \"S\"  \"H\"  \"H\"  \n\nspades_2 = sum( draws[1, ] == \"S\" & draws[2, ] == \"S\" )\nspades_2 / n_sim\n\n[1] 0.058727"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#another-example-order-matters-vs.-not-22",
    "href": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes.html#another-example-order-matters-vs.-not-22",
    "title": "Lesson 5: Equally Likely Outcomes and Counting",
    "section": "Another example: order matters vs. not (2/2)",
    "text": "Another example: order matters vs. not (2/2)\n\n\n\n\nExample 2\n\n\nSuppose we draw 2 cards from a standard deck without replacement. What is the probability that both are spades when\n\norder matters?\norder doesn’t matter?\n\n\n\n\nWe can do a simulation!\n\nset.seed(1234)\nn_sim &lt;- 1000000\ncards = c(rep(\"S\", 13), \n          rep(\"H\", 13), \n          rep(\"C\", 13), \n          rep(\"D\", 13))\ndraws &lt;- replicate(n_sim, \n                   sample(cards, 2, replace = FALSE))\ndraws[, 1:10]\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n[1,] \"C\"  \"H\"  \"D\"  \"S\"  \"C\"  \"S\"  \"C\"  \"H\"  \"H\"  \"D\"  \n[2,] \"H\"  \"C\"  \"D\"  \"S\"  \"H\"  \"C\"  \"H\"  \"S\"  \"H\"  \"H\"  \n\nspades_2 = sum( draws[1, ] == \"S\" & draws[2, ] == \"S\" )\nspades_2 / n_sim\n\n[1] 0.058727"
  },
  {
    "objectID": "homework/HW_04.html#questions",
    "href": "homework/HW_04.html#questions",
    "title": "Homework 4",
    "section": "Questions",
    "text": "Questions\n\nMystery constant. Suppose \\(X\\) is a discrete random variable with a probability mass function \\(p_X(x) = c(4- x)\\) for \\(x\\) in \\(\\{-1, 2, 3\\}\\) and \\(p_X(x) = 0\\) otherwise.\n\nWhat is the value of c so that \\(p_X(x)\\) is a mass?\nMake a plot of the probability mass function and write the piecewise pmf\nWhat is the CDF of \\(X\\)? Write the piecewise CDF.\nMake a plot of the CDF.\n\nWastebasket basketball. Chris tries to throw a ball of paper in the wastebasket behind his back (without looking). He estimates that his chance of success each time, regardless of the outcome of the other attempts, is \\(1/3\\). Let \\(X\\) be the number of attempts required. If he is not successful within the first 5 attempts, then he quits, and he lets \\(X = 6\\) in such a case.\n\nDraw the mass of \\(X\\) and define the piecewise pmf.\nDraw the CDF of \\(X\\) and define the piecewise CDF.\nSimulate 10,000 trials of this experiment in R and plot the approximate probability distribution.\n\nSuppose a density \\(f_X(x)\\) increases linearly from \\((16, 0)\\) to \\(\\left(24, \\dfrac{1}{4}\\right)\\).\n\nFind the CDF of \\(X\\).\nWhat is the value of \\(a\\) so that \\(P(X &gt; a) = 0.75\\)?\n\nFor the following pdf \\[f_X(x) = \\begin{cases} kx^9(1-x)^2 & \\text{if } 0 \\leq x \\leq 1 \\\\ 0 & \\text{otherwise} \\end{cases}\\]\n\nWhat is the constant \\(k\\) that makes the following function a valid density?\nWhat is the cumulative distribution function (cdf) \\(F_X(x)\\)?"
  },
  {
    "objectID": "homework/HW_04.html#extra-problems",
    "href": "homework/HW_04.html#extra-problems",
    "title": "Homework 4",
    "section": "Extra Problems",
    "text": "Extra Problems"
  },
  {
    "objectID": "hw_answers/HW_04_ans.html#questions",
    "href": "hw_answers/HW_04_ans.html#questions",
    "title": "Homework 4 Answers",
    "section": "",
    "text": "Not given\nNot given\n\n\\[F_X(x) = \\left\\{\n         \\begin{array}{ll}\n             0 & \\quad x \\leq 16 \\\\\n             \\frac{1}{64}x^2 - \\frac{1}{2}x + 4 & \\quad 16 &lt; x\\leq 24 \\\\\n             1 & \\quad x &gt; 24 \\\\\n         \\end{array}\n     \\right.\\]\n\\(a=20\\)\n\n\n\\(k=660\\)\n\\[F_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x &lt; 0 \\\\\n            55x^{12} - 120x^{11} + 66x^{10} & \\quad 0 \\leq x\\leq 1 \\\\\n            1 & \\quad x &gt; 24 \\\\\n        \\end{array}\n    \\right.\\]"
  },
  {
    "objectID": "hw_answers/HW_04_ans.html#extra-problems",
    "href": "hw_answers/HW_04_ans.html#extra-problems",
    "title": "Homework 4 Answers",
    "section": "Extra Problems",
    "text": "Extra Problems"
  },
  {
    "objectID": "quiz.html#quiz-1",
    "href": "quiz.html#quiz-1",
    "title": "Quiz Info",
    "section": "Quiz 1",
    "text": "Quiz 1\n\nA practice quiz is posted if you would like to do a trial run before the actual quiz\nIncludes Lessons 1-5\n\nCovers some probability rules and calculations (about half the questions)\n\nThree problems have calculations with probabilities\nOne (ish) question on counting, but not too complicated\nFor most questions, you will be given a scenario, and you will need to connect it back to probability rules\n\nExample: If two events are mutually exclusive, what is the probability of their intersection?"
  },
  {
    "objectID": "quiz.html#quiz-2",
    "href": "quiz.html#quiz-2",
    "title": "Quiz Info",
    "section": "Quiz 2",
    "text": "Quiz 2\n\nIncludes lesson 7-9\n\nLesson 6 not technically included, but will be covered\nMight have one question from Lesson 10 about process of transformations"
  },
  {
    "objectID": "quiz.html#quiz-3",
    "href": "quiz.html#quiz-3",
    "title": "Quiz Info",
    "section": "Quiz 3",
    "text": "Quiz 3\n\nIncludes lessons 10-16\n\nIncludes 15-16 since we extended from previous lessons to important distributions\n\nOnly 1 question about the relationships between distributions (so make sure to do the last problem in HW 8)\n\nTransformations, joint distributions, independence and conditioning, expected values, and variance\n\nJust from the topics, I’d say this will be the hardest quiz"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#learning-objectives",
    "href": "lessons/07_pmfs/07_pmfs.html#learning-objectives",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate probabilities for discrete random variables\nCalculate and graph a probability mass function (pmf)\nCalculate and graph a cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#where-are-we",
    "href": "lessons/07_pmfs/07_pmfs.html#where-are-we",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#what-is-a-probability-mass-function",
    "href": "lessons/07_pmfs/07_pmfs.html#what-is-a-probability-mass-function",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "What is a probability mass function?",
    "text": "What is a probability mass function?\n\n\nDefinition: probability distribution or probability mass function (pmf)\n\n\nThe probability distribution or probability mass function (pmf) of a discrete r.v. \\(X\\) is defined for every number \\(x\\) by \\[p_X(x) = \\mathbb{P}(X=x) = \\mathbb{P}(\\mathrm{all }\\ \\omega\\in S:X(\\omega) = x)\\]"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#lets-demonstrate-this-definition-with-our-coin-toss",
    "href": "lessons/07_pmfs/07_pmfs.html#lets-demonstrate-this-definition-with-our-coin-toss",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Let’s demonstrate this definition with our coin toss",
    "text": "Let’s demonstrate this definition with our coin toss\n\n\n\n\nExample 1\n\n\nSuppose we toss 3 coins with probability of tails \\(p\\). If \\(X\\) is the random variable counting the number of tails, what are the probabilities of each value of \\(X\\)?"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#remarks-on-the-pmf",
    "href": "lessons/07_pmfs/07_pmfs.html#remarks-on-the-pmf",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Remarks on the pmf",
    "text": "Remarks on the pmf\n\n\nProperties of pmf\n\n\nA pmf \\(p_X(x)\\) must satisfy the following properties:\n\n\\(0 \\leq p_X(x) \\leq 1\\) for all \\(x\\)\n\\(\\sum \\limits_{\\{all\\ x\\}}p_X(x)=1\\)\n\n\n\n\nSome distributions depend on parameters\n\nEach value of a parameter gives a different pmf\nIn previous example, the number of dice rolled was a parameter\n\nWe rolled 2 dice\nIf we rolled 4 dice, we’d get a different pmf!\n\nThe collection of all pmf’s for different values of the parameters is called a family of pmf’s"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#binomial-family-of-rvs",
    "href": "lessons/07_pmfs/07_pmfs.html#binomial-family-of-rvs",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Binomial family of RVs",
    "text": "Binomial family of RVs\n\n\n\n\nExample 2\n\n\nSuppose you toss \\(n\\) coins, each with probability of tails \\(p\\). If \\(X\\) is the number of tails, what is the pmf of \\(X\\)?"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#bernoulli-family-of-rvs",
    "href": "lessons/07_pmfs/07_pmfs.html#bernoulli-family-of-rvs",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Bernoulli family of RVs",
    "text": "Bernoulli family of RVs\n\n\n\n\nExample 3\n\n\nSuppose you toss 1 coin, with probability of tails \\(p\\). If \\(X\\) is the number of tails, what is the pmf of \\(X\\)?"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#household-size-15",
    "href": "lessons/07_pmfs/07_pmfs.html#household-size-15",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Household size (1/5)",
    "text": "Household size (1/5)\n\n\n\n\nExample 1: Falls in Older Adults\n\n\nA major public health concern is falls among older adults (age 65+). National data suggests that 25% of older adults will experience at least one fall within a given year. A community health program is tracking a random group of \\(n = 8\\) older adults for one year. Assume the likelihood of falling is independent from person to person.\nLet \\(X\\) be the random variable representing the number of individuals in this group who experience at least one fall.\n\nWhat is the sample space for the random variable \\(X\\)?\nDefine the random variable \\(X\\).\nCalculate the probability mass function (pmf) for \\(X\\) and present it in a table.\nDo these values create a valid pmf?\nMake a bar plot of the pmf."
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#household-size-25",
    "href": "lessons/07_pmfs/07_pmfs.html#household-size-25",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Household size (2/5)",
    "text": "Household size (2/5)\n\n\n\n\nExample 1: Falls in Older Adults\n\n\n\nWhat is the sample space for the random variable \\(X\\)?\nWrite the probability mass function (pmf) for \\(X\\).\nDo these values create a valid pmf?\nMake a bar plot of the pmf.\nSimulate \\(X\\) for 10000 groups and plot the approximated pmf."
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#household-size-35",
    "href": "lessons/07_pmfs/07_pmfs.html#household-size-35",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Household size (3/5)",
    "text": "Household size (3/5)\n\n\n\n\nExample 1: Falls in Older Adults\n\n\n\nWhat is the sample space for the random variable \\(X\\)?\nWrite the probability mass function (pmf) for \\(X\\).\nDo these values create a valid pmf?\nMake a bar plot of the pmf.\nSimulate \\(X\\) for 10000 groups and plot the approximated pmf."
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#what-is-a-cumulative-distribution-function",
    "href": "lessons/07_pmfs/07_pmfs.html#what-is-a-cumulative-distribution-function",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "What is a cumulative distribution function?",
    "text": "What is a cumulative distribution function?\n\n\nDefinition: cumulative distribution function (CDF)\n\n\nThe cumulative distribution function (cdf) of a discrete r.v. \\(X\\) with pmf \\(p_X(x)\\), is defined for every value \\(x\\) by \\[F_X(x) = \\mathbb{P}(X \\leq x) = \\sum \\limits_{\\{all\\ y:\\ y\\leq x\\}}p_X(y)\\]"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#household-size-45",
    "href": "lessons/07_pmfs/07_pmfs.html#household-size-45",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Household size (4/5)",
    "text": "Household size (4/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nWrite the cdf as a function."
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#household-size-55",
    "href": "lessons/07_pmfs/07_pmfs.html#household-size-55",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Household size (5/5)",
    "text": "Household size (5/5)\n\n\n\n\nExample 4\n\n\nThe table below shows household sizes in 2019. Data are from the U.S. Census.\n\n\n\n\nSize\n1\n2\n3\n4\n5 or more\n\n\n\n\nPercent\n28%\n35%\n15%\n13%\n9%\n\n\n\n\n\nGraph the cdf of household sizes in 2019."
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#properties-of-discrete-cdfs",
    "href": "lessons/07_pmfs/07_pmfs.html#properties-of-discrete-cdfs",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Properties of discrete CDFs",
    "text": "Properties of discrete CDFs\n\n\\(F(x)\\) is increasing or flat (never decreasing)\n\\(\\min\\limits_x F(x) = 0\\)\n\\(\\max\\limits_xF(x)=1\\)\nCDF is a step function"
  },
  {
    "objectID": "lessons/08_pdfs/08_pdfs.html#learning-objectives",
    "href": "lessons/08_pdfs/08_pdfs.html#learning-objectives",
    "title": "Lesson 8: Probability distribution functions (PDFs)",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDistinguish between discrete and continuous random variables.\nCalculate probabilities for continuous random variables.\nCalculate and graph a density (i.e., probability density function, PDF)."
  },
  {
    "objectID": "lessons/08_pdfs/08_pdfs.html#discrete-vs.-continuous-rvs",
    "href": "lessons/08_pdfs/08_pdfs.html#discrete-vs.-continuous-rvs",
    "title": "Lesson 8: Probability density functions (PDFs)",
    "section": "Discrete vs. Continuous RVs",
    "text": "Discrete vs. Continuous RVs\n\n\n\nFor a discrete RV, the set of possible values is either finite or can be put into a countably infinite list.\n \nContinuous RVs take on values from continuous intervals, or unions of continuous intervals\n\n\n\n\n\nFigure from Introduction to Probability TB (pg. 301)"
  },
  {
    "objectID": "lessons/08_pdfs/08_pdfs.html#how-to-define-probabilities-for-continuous-rvs",
    "href": "lessons/08_pdfs/08_pdfs.html#how-to-define-probabilities-for-continuous-rvs",
    "title": "Lesson 8: Probability density functions (PDFs)",
    "section": "How to define probabilities for continuous RVs?",
    "text": "How to define probabilities for continuous RVs?\n\n\nDiscrete RV \\(X\\):\n\n\n\n\n\n\n\n\n\n\npmf: \\(p_X(x) = P(X=x)\\)\n\n\nContinuous RV \\(X\\):\n\n\n\n\n\n\n\n\n\n\ndensity: \\(f_X(x)\\)\nprobability: \\(P(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\)"
  },
  {
    "objectID": "lessons/08_pdfs/08_pdfs.html#what-is-a-probability-density-function",
    "href": "lessons/08_pdfs/08_pdfs.html#what-is-a-probability-density-function",
    "title": "Lesson 8: Probability density functions (PDFs)",
    "section": "What is a probability density function?",
    "text": "What is a probability density function?\n\n\nProbability density function\n\n\nThe probability distribution, or probability density function (pdf), of a continuous random variable \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\),\n\\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\]\n\n\nRemarks:\n\nNote that \\(f_X(x) \\neq \\mathbb{P}(X=x)\\)!!!\nIn order for \\(f_X(x)\\) to be a pdf, it needs to satisfy the properties\n\n\\(f_X(x) \\geq 0\\) for all \\(x\\)\n\\(\\int_{-\\infty}^{\\infty} f_X(x)dx=1\\)"
  },
  {
    "objectID": "lessons/08_pdfs/08_pdfs.html#lets-demonstrate-the-pdf-with-an-example-15",
    "href": "lessons/08_pdfs/08_pdfs.html#lets-demonstrate-the-pdf-with-an-example-15",
    "title": "Lesson 8: Probability density functions (PDFs)",
    "section": "Let’s demonstrate the PDF with an example (1/5)",
    "text": "Let’s demonstrate the PDF with an example (1/5)\n\n\n\n\nExample 1.1\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind the value of \\(a\\) so that \\(f_X(x)\\) is a pdf."
  },
  {
    "objectID": "lessons/08_pdfs/08_pdfs.html#lets-demonstrate-the-pdf-with-an-example-25",
    "href": "lessons/08_pdfs/08_pdfs.html#lets-demonstrate-the-pdf-with-an-example-25",
    "title": "Lesson 8: Probability density functions (PDFs)",
    "section": "Let’s demonstrate the PDF with an example (2/5)",
    "text": "Let’s demonstrate the PDF with an example (2/5)\n\n\n\n\nExample 1.2\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(2.7 \\leq X \\leq 2.9)\\)."
  },
  {
    "objectID": "lessons/08_pdfs/08_pdfs.html#lets-demonstrate-the-pdf-with-an-example-35",
    "href": "lessons/08_pdfs/08_pdfs.html#lets-demonstrate-the-pdf-with-an-example-35",
    "title": "Lesson 8: Probability density functions (PDFs)",
    "section": "Let’s demonstrate the PDF with an example (3/5)",
    "text": "Let’s demonstrate the PDF with an example (3/5)\n\n\n\n\nExample 1.3\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(2.7 &lt; X \\leq 2.9)\\)."
  },
  {
    "objectID": "lessons/08_pdfs/08_pdfs.html#lets-demonstrate-the-pdf-with-an-example-45",
    "href": "lessons/08_pdfs/08_pdfs.html#lets-demonstrate-the-pdf-with-an-example-45",
    "title": "Lesson 8: Probability density functions (PDFs)",
    "section": "Let’s demonstrate the PDF with an example (4/5)",
    "text": "Let’s demonstrate the PDF with an example (4/5)\n\n\n\n\nExample 1.4\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(X = 2.9)\\)."
  },
  {
    "objectID": "lessons/08_pdfs/08_pdfs.html#lets-demonstrate-the-pdf-with-an-example-55",
    "href": "lessons/08_pdfs/08_pdfs.html#lets-demonstrate-the-pdf-with-an-example-55",
    "title": "Lesson 8: Probability density functions (PDFs)",
    "section": "Let’s demonstrate the PDF with an example (5/5)",
    "text": "Let’s demonstrate the PDF with an example (5/5)\n\n\n\n\nExample 1.5\n\n\nLet \\(f_X(x)= 2\\), for \\(a \\leq x \\leq 3\\).\n\nFind \\(\\mathbb{P}(X \\leq 2.8)\\)."
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs.html#what-is-a-cumulative-distribution-function",
    "href": "lessons/09_CDFs/09_CDFs.html#what-is-a-cumulative-distribution-function",
    "title": "Lesson 9: Cumulative distribution functions (CDFs)",
    "section": "What is a cumulative distribution function?",
    "text": "What is a cumulative distribution function?\n\n\n\n\nCumulative distribution function (CDF) for discrete random variable\n\n\nThe cumulative distribution function (cdf) of a discrete RV \\(X\\) with pmf \\(p_X(x)\\), is defined for every value \\(x\\) by \\[F_X(x) = \\mathbb{P}(X \\leq x) = \\sum \\limits_{\\{all\\ y:\\ y\\leq x\\}}p_X(y)\\]\n\n\n\n\\(F(x)\\) is increasing or flat (never decreasing)\n\\(\\min\\limits_x F(x) = 0\\)\n\\(\\max\\limits_xF(x)=1\\)\nCDF is a step function\n\n\n\n\nCumulative distribution function (CDF) for continuous random variable\n\n\nThe cumulative distribution function (cdf) of a continuous RV \\(X\\), is the function \\(F_X(x)\\), such that for all real values of \\(x\\), \\[F_X(x)= \\mathbb{P}(X \\leq x) = \\int_{-\\infty}^x f_X(s)ds\\]\n\n\nRemarks: In general, \\(F_X(x)\\) is increasing and\n\n\\(\\lim_{x\\rightarrow -\\infty} F_X(x)= 0\\)\n\\(\\lim_{x\\rightarrow \\infty} F_X(x)= 1\\)\n\\(P(X &gt; a) = 1 - P(X \\leq a) = 1 - F_X(a)\\)\n\\(P(a \\leq X \\leq b) = F_X(b) - F_X(a)\\)"
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs.html#lets-demonstrate-the-cdf-with-an-example",
    "href": "lessons/09_CDFs/09_CDFs.html#lets-demonstrate-the-cdf-with-an-example",
    "title": "Lesson 9: Cumulative distribution functions (CDFs)",
    "section": "Let’s demonstrate the CDF with an example",
    "text": "Let’s demonstrate the CDF with an example\n\n\n\n\nExample 2\n\n\nLet \\(f_X(x)= 2\\), for \\(2.5 \\leq x \\leq 3\\). Find \\(F_X(x)\\)."
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs.html#derivatives-of-the-cdf",
    "href": "lessons/09_CDFs/09_CDFs.html#derivatives-of-the-cdf",
    "title": "Lesson 9: Cumulative distribution functions (CDFs)",
    "section": "Derivatives of the CDF",
    "text": "Derivatives of the CDF\n\n\nTheorem 1\n\n\nIf \\(X\\) is a continuous random variable with pdf \\(f_X(x)\\) and cdf \\(F_X(x)\\), then for all real values of \\(x\\) at which \\(F'_X(x)\\) exists, \\[\\frac{d}{dx} F_X(x)= F'_X(x) = f_X(x)\\]"
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs.html#finding-the-pdf-from-a-cdf",
    "href": "lessons/09_CDFs/09_CDFs.html#finding-the-pdf-from-a-cdf",
    "title": "Lesson 9: Cumulative distribution functions (CDFs)",
    "section": "Finding the PDF from a CDF",
    "text": "Finding the PDF from a CDF\n\n\n\n\nExample 3\n\n\nLet \\(X\\) be a RV with cdf \\[F_X(x)= \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x &lt; 2.5 \\\\\n            2x-5 & \\quad 2.5 \\leq x \\leq 3 \\\\\n            1 & \\quad x &gt; 3\n        \\end{array}\n    \\right.\\] Find the pdf \\(f_X(x)\\)."
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs.html#lets-go-through-another-example-17",
    "href": "lessons/09_CDFs/09_CDFs.html#lets-go-through-another-example-17",
    "title": "Lesson 9: Cumulative distribution functions (CDFs)",
    "section": "Let’s go through another example (1/7)",
    "text": "Let’s go through another example (1/7)\n\n\n\n\nExample 4\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nShow \\(f_X(x)\\) is a pdf.\nFind \\(\\mathbb{P}(1 \\leq X \\leq 3)\\).\nFind \\(F_X(x)\\).\nGiven \\(F_X(x)\\), find \\(f_X(x)\\).\nFind \\(\\mathbb{P}(X \\geq 1 | X \\leq 3)\\).\nFind the median of the distribution of \\(X\\)."
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs.html#lets-go-through-another-example-27",
    "href": "lessons/09_CDFs/09_CDFs.html#lets-go-through-another-example-27",
    "title": "Lesson 9: Cumulative distribution functions (CDFs)",
    "section": "Let’s go through another example (2/7)",
    "text": "Let’s go through another example (2/7)\n\n\n\n\nExample 4.1\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nShow \\(f_X(x)\\) is a pdf."
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs.html#lets-go-through-another-example-37",
    "href": "lessons/09_CDFs/09_CDFs.html#lets-go-through-another-example-37",
    "title": "Lesson 9: Cumulative distribution functions (CDFs)",
    "section": "Let’s go through another example (3/7)",
    "text": "Let’s go through another example (3/7)\n\n\n\nDo this problem at home for extra practice.\n\n\n\n\n\n\n\nExample 4.2\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nFind \\(\\mathbb{P}(1 \\leq X \\leq 3)\\)."
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs.html#lets-go-through-another-example-47",
    "href": "lessons/09_CDFs/09_CDFs.html#lets-go-through-another-example-47",
    "title": "Lesson 9: Cumulative distribution functions (CDFs)",
    "section": "Let’s go through another example (4/7)",
    "text": "Let’s go through another example (4/7)\n\n\n\n\nExample 4.3\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nFind \\(F_X(x)\\)."
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs.html#lets-go-through-another-example-57",
    "href": "lessons/09_CDFs/09_CDFs.html#lets-go-through-another-example-57",
    "title": "Lesson 9: Cumulative distribution functions (CDFs)",
    "section": "Let’s go through another example (5/7)",
    "text": "Let’s go through another example (5/7)\n\n\n\nDo this problem at home for extra practice.\n\n\n\n\n\n\n\nExample 4.4\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nGiven \\(F_X(x)\\), find \\(f_X(x)\\)."
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs.html#lets-go-through-another-example-67",
    "href": "lessons/09_CDFs/09_CDFs.html#lets-go-through-another-example-67",
    "title": "Lesson 9: Cumulative distribution functions (CDFs)",
    "section": "Let’s go through another example (6/7)",
    "text": "Let’s go through another example (6/7)\n\n\n\n\nExample 4.5\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nFind \\(\\mathbb{P}(X \\geq 1 | X \\leq 3)\\)."
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs.html#lets-go-through-another-example-77",
    "href": "lessons/09_CDFs/09_CDFs.html#lets-go-through-another-example-77",
    "title": "Lesson 9: Cumulative distribution functions (CDFs)",
    "section": "Let’s go through another example (7/7)",
    "text": "Let’s go through another example (7/7)\n\n\n\n\nExample 4.6\n\n\nLet \\(X\\) be a RV with pdf \\(f_X(x)= 2e^{-2x}\\), for \\(x&gt;0\\).\n\nFind the median of the distribution of \\(X\\)."
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#from-lesson-2-types-of-random-variables",
    "href": "lessons/07_pmfs/07_pmfs.html#from-lesson-2-types-of-random-variables",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "From Lesson 2: Types of random variables",
    "text": "From Lesson 2: Types of random variables\nThere are two types of random variables:\n\n\n\n\n\nDiscrete random variables (RVs): the set of possible values is either finite or can be put into a countably infinite list\n\nYou could theoretically list the specific possible outcomes that the variable can take\nIf you sum the rolls of three dice, you must get a whole number. For example, you can’t get any number between 3 and 4.\n\n\n\n\n\n\n\n\nContinuous random variables (RVs): take on values from continuous intervals, or unions of continuous intervals\n\nVariable takes on a range of values, but there are infinitely possible values within the range\nIf you keep track of the time you sleep, you can sleep for 8 hours or 7.9 hours or 7.99 hours or 7.999 hours …\n\n\n\n\n\n\n\nDiscrete random variables (RVs) are a little easier to simulate right now\n\nWe will only do discrete RVs today"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#from-lesson-2-we-need-more-reps-for-long-run-relative-frequencies",
    "href": "lessons/07_pmfs/07_pmfs.html#from-lesson-2-we-need-more-reps-for-long-run-relative-frequencies",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "From Lesson 2: We need more reps for long-run relative frequencies",
    "text": "From Lesson 2: We need more reps for long-run relative frequencies\n\nreps &lt;- 10000\nsimulations &lt;- replicate(reps, sample(x = 1:4, size = 2, replace = TRUE))\n\n\nLet’s show the first 14 simulations\n\n\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n[1,]    3    2    1    1    4    2    4    2    1     3     3     2     4     1\n[2,]    1    1    4    1    3    1    2    2    1     4     2     3     3     3\n\n\n \n\n\\(X\\) is the sum of the two rolls: we could calculate that for each column\n\n\n\n [1] 4 3 5 2 7 3 6 4 2 7 5 5 7 4"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#from-lesson-2-we-can-look-at-the-plot-of-random-variable-x",
    "href": "lessons/07_pmfs/07_pmfs.html#from-lesson-2-we-can-look-at-the-plot-of-random-variable-x",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "From Lesson 2: We can look at the plot of random variable \\(X\\)",
    "text": "From Lesson 2: We can look at the plot of random variable \\(X\\)"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#from-lesson-2-simulating-two-rolls",
    "href": "lessons/07_pmfs/07_pmfs.html#from-lesson-2-simulating-two-rolls",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "From Lesson 2: Simulating two rolls",
    "text": "From Lesson 2: Simulating two rolls\n\n\nExample: Simulating Two Rolls of a Fair Four-Sided Die\n\n\nWe’re going to roll two four-sided die. Let \\(X\\) be the sum of two rolls. How would we simulate \\(X\\)?\n\n\n\nreps &lt;- 10000\nsimulations &lt;- replicate(reps, sample(x = 1:4, size = 2, replace = TRUE))\n\n\nLet’s show the first 14 simulations\n\n\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n[1,]    2    3    4    3    2    3    1    2    3     3     4     1     1     1\n[2,]    4    3    1    3    4    3    1    1    1     3     3     3     2     4\n\n\n \n\n\\(X\\) is the sum of the two rolls: we could calculate that for each column\n\n\n\n [1] 6 6 5 6 6 6 2 3 4 6 7 4 3 5"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#from-lesson-2-simulating-two-rolls-12",
    "href": "lessons/07_pmfs/07_pmfs.html#from-lesson-2-simulating-two-rolls-12",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "From Lesson 2: Simulating two rolls (1/2)",
    "text": "From Lesson 2: Simulating two rolls (1/2)\n\n\nExample: Simulating Two Rolls of a Fair Four-Sided Die\n\n\nWe’re going to roll two four-sided die. Let \\(X\\) be the sum of two rolls. How would we simulate \\(X\\)?\n\n\n\nreps &lt;- 100000\nsimulations &lt;- replicate(reps, sample(x = 1:4, size = 2, replace = TRUE))\n\n\nLet’s show the first 14 simulations\n\n\nsimulations[, 1:14]\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n[1,]    3    2    1    1    1    3    3    4    1     4     4     2     3     3\n[2,]    4    2    2    3    4    1    4    2    1     1     4     4     3     3\n\n\n\n\\(X\\) is the sum of the two rolls: we could calculate that for each column\n\n\nX_simulated &lt;- apply(simulations, 2, sum)\nX_simulated[1:14]\n\n [1] 7 4 3 4 5 4 7 6 2 5 8 6 6 6"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#from-lesson-2-simulating-two-rolls-22",
    "href": "lessons/07_pmfs/07_pmfs.html#from-lesson-2-simulating-two-rolls-22",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "From Lesson 2: Simulating two rolls (2/2)",
    "text": "From Lesson 2: Simulating two rolls (2/2)\n\n\n\n\nPlot simulated distribution of X\nX_df &lt;- as.data.frame(X_simulated) %&gt;%\n  rename(X = X_simulated)\n\nggplot(X_df, aes(x = X, after_stat(density))) +\n  geom_histogram(binwidth = 1, color = \"black\", fill = \"lightblue\") +\n  scale_x_continuous(breaks = seq(2, 8, by = 1)) +\n  labs(title = \"Simulated Distribution of X (Sum of Two Rolls)\",\n       x = \"Value of X\",\n       y = \"Approximated probablity\")\n\n\n\n\n\n\n\n\n\n\n\nFor the RV \\(X\\), we can find the probability for each possible value, \\(P(X=x) = p_X(x)\\): \\[\np_X(x) =\n\\begin{cases}\n\\frac{4-|x-5|}{16}, & x = 2, 3, 4, 5, 6,7, 8,\\\\\n0, & \\text{otherwise}\n\\end{cases}\n\\]"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#binomial-random-variable",
    "href": "lessons/07_pmfs/07_pmfs.html#binomial-random-variable",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Binomial random variable",
    "text": "Binomial random variable\n\nOne specific type of discrete random variable is a binomial random variable\n\n\n\nBinomial random variable\n\n\n\n\\(X\\) is a binomial random variable if it represents the number of successes in \\(n\\) independent replications (or trials) of an experiment where\n\nEach replicate has two possible outcomes: either success or failure\nThe probability of success is \\(p\\)\nThe probability of failure is \\(q=1-p\\)\n\n\n\n\n\nA binomial random variable takes on values \\(0, 1, 2, \\dots, n\\).\nIf a r.v. \\(X\\) is modeled by a Binomial distribution, then we write in shorthand \\(X \\sim \\text{Binom}(n,p)\\)\nQuick example: The number of heads in 3 tosses of a fair coin is a binomial random variable with parameters \\(n = 3\\) and \\(p = 0.5\\)."
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#poll-everywhere-question-3",
    "href": "lessons/07_pmfs/07_pmfs.html#poll-everywhere-question-3",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Poll Everywhere Question 3",
    "text": "Poll Everywhere Question 3"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#bernoulli-distribution",
    "href": "lessons/07_pmfs/07_pmfs.html#bernoulli-distribution",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Bernoulli distribution",
    "text": "Bernoulli distribution\n\nWhen \\(n=1\\), aka we have a single trial, we give a different name to the random variable: Bernoulli\n\n\n\nBernoulli random variable\n\n\nBernoulli random variable. If \\(X\\) is a random variable that takes value 1 with probability of success \\(p\\) and 0 with probability \\(1-p\\) (or \\(q\\)), then \\(X\\) is a Bernoulli random variable.\n\n\n\nWe call the probability of success \\(p\\) the parameter of the Bernoulli distribution.\nIf a r.v. \\(X\\) is modeled by a Bernoulli distribution, then we write in shorthand \\(X \\sim \\text{Bernoulli}(p)\\) or \\(X \\sim \\text{Bern}(p)\\)\n\n\n\nMean and SD of a Bernoulli r.v.\n\n\nIf* \\(X\\) is a Bernoulli r.v. with probability of success \\(p\\), then \\(E(X) = p\\) and \\(\\text{Var}(X) = p(1-p)\\)"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#relationship-between-bernoulli-and-binomial1",
    "href": "lessons/07_pmfs/07_pmfs.html#relationship-between-bernoulli-and-binomial1",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Relationship between Bernoulli and Binomial1",
    "text": "Relationship between Bernoulli and Binomial1\n\nThe Bernoulli distribution is a special case of the Binomial distribution where \\(n=1\\)\n\nSpecifically: \\[\\text{Binomial}(1, p) = \\text{Bernoulli}(p) \\]\n\nTo get a Binomial distribution, we simply extend the scenario from a single trial to multiple independent trials.\n\nIf we conduct \\(n\\) independent Bernoulli trials with the same success probability \\(p\\), the total number of successes across these \\(n\\) trials will follow a Binomial distribution\n\n\n \n\nQuick example:\n\nBernoulli: If you flip a coin once, with probability \\(p=0.5\\) of landing heads, that is a Bernoulli trial.\nBinomial: If you flip the coin 5 times, and you want to know how many times it will land heads, the number of heads will follow a Binomial distribution with parameters \\(n=5\\) and \\(p=0.5\\)\n\n\nInformation on slide heavily borrowed from ChatGPT with prompt: “can you explain how we go from a bernoulli distribution to a binomial”"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#binomial-distribution",
    "href": "lessons/07_pmfs/07_pmfs.html#binomial-distribution",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Binomial distribution",
    "text": "Binomial distribution\n\n\nDistribution of a Binomial random variable\n\n\nLet \\(X\\) be the total number of successes in \\(n\\) independent trials, each with probability \\(p\\) of a success. Then probability of observing exactly \\(k\\) successes in \\(n\\) independent trials is\n\\[P(X = x) = \\binom{n}{x} p^x (1-p)^{n-x},  x= 0, 1, 2, \\dots, n \\]\n\n\n\nThe parameters of a binomial distribution are \\(p\\) and \\(n\\)."
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#binomial-distribution-r-commands",
    "href": "lessons/07_pmfs/07_pmfs.html#binomial-distribution-r-commands",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Binomial distribution: R commands",
    "text": "Binomial distribution: R commands\nR commands with their input and output:\n\n\n\n\n\n\n\n\n\nR code\nWhat does it return?\n\n\n\n\nrbinom()\nreturns sample of random variables with specified binomial distribution\n\n\ndbinom()\nreturns probability of getting certain number of successes\n\n\npbinom()\nreturns cumulative probability of getting certain number or less successes\n\n\nqbinom()\nreturns number of successes corresponding to desired quantile"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#binomial-distribution-example-15",
    "href": "lessons/07_pmfs/07_pmfs.html#binomial-distribution-example-15",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Binomial distribution example (1/5)",
    "text": "Binomial distribution example (1/5)\n\n\nVaccinated people testing positive for Covid-19\n\n\nAbout 25% of people that test positive for Covid-19 are vaccinated for Covid-19. Suppose 10 people have tested positive for Covid-19 (independently of each other). Let \\(X\\) denote the number of people that are vaccinated among the 10 that tested positive.\n\nWhat is the expected value of \\(X\\)?\nWhat is the SD of \\(X\\)?\nWhat is the probability that exactly 4 of the 10 people that tested positive are vaccinated?\nWhat is the probability that at most 3 of the 10 people that tested positive are vaccinated?\nWhat is the probability that at least 5 of the 10 people that tested positive are vaccinated?"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#binomial-distribution-example-25",
    "href": "lessons/07_pmfs/07_pmfs.html#binomial-distribution-example-25",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Binomial distribution example (2/5)",
    "text": "Binomial distribution example (2/5)\n\n\nVaccinated people testing positive for Covid-19\n\n\nAbout 25% of people that test positive for Covid-19 are vaccinated for Covid-19. Suppose 10 people have tested positive for Covid-19 (independently of each other). Let \\(X\\) denote the number of people that are vaccinated among the 10 that tested positive.\n\nWhat is the expected value of \\(X\\)?\nWhat is the SD of \\(X\\)?"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#binomial-distribution-example-35",
    "href": "lessons/07_pmfs/07_pmfs.html#binomial-distribution-example-35",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Binomial distribution example (3/5)",
    "text": "Binomial distribution example (3/5)\n\n\nVaccinated people testing positive for Covid-19\n\n\nAbout 25% of people that test positive for Covid-19 are vaccinated for Covid-19. Suppose 10 people have tested positive for Covid-19 (independently of each other). Let \\(X\\) denote the number of people that are vaccinated among the 10 that tested positive.\n\nWhat is the probability that exactly 4 of the 10 people that tested positive are vaccinated?\n\n\n\n\\[P(X=4) = {10 \\choose 4} 0.25^2 (1-0.25)^{10-4}  = 0.146\\]\n\ndbinom(x = 4, size = 10, prob = 0.25) # d for distribution\n\n[1] 0.145998\n\n\n\nIn general, for \\(P(X=k)\\) we code: dbinom(x = k, size = n, prob = p)"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#binomial-distribution-example-45",
    "href": "lessons/07_pmfs/07_pmfs.html#binomial-distribution-example-45",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Binomial distribution example (4/5)",
    "text": "Binomial distribution example (4/5)\n\n\nVaccinated people testing positive for Covid-19\n\n\nAbout 25% of people that test positive for Covid-19 are vaccinated for Covid-19. Suppose 10 people have tested positive for Covid-19 (independently of each other). Let \\(X\\) denote the number of people that are vaccinated among the 10 that tested positive.\n\nWhat is the probability that at most 3 of the 10 people that tested positive are vaccinated?\n\n\n\n\\[\\begin{aligned}\nP(X \\leq 3) = & P(X =0) + P(X = 1) + P(X =2) + P(X = 3) \\\\ = &{10 \\choose 0} 0.25^0 (0.75)^{10} + {10 \\choose 1} 0.25^1 (0.75)^{9} + {10 \\choose 2} 0.25^2 (0.75)^{8}+ {10 \\choose 3} 0.25^3 (0.75)^{7} \\\\\n= & 0.7758\n\\end{aligned}\\]\n\npbinom(q = 3, size = 10, prob = 0.25, lower.tail = T)\n\n[1] 0.7758751\n\n\n\nIn general, for \\(P(X \\leq k)\\) we code: pbinom(q = k, size = n, prob = p) with lower.tail = T as a default option"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#binomial-distribution-example-55",
    "href": "lessons/07_pmfs/07_pmfs.html#binomial-distribution-example-55",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Binomial distribution example (5/5)",
    "text": "Binomial distribution example (5/5)\n\n\nVaccinated people testing positive for Covid-19\n\n\nAbout 25% of people that test positive for Covid-19 are vaccinated for Covid-19. Suppose 10 people have tested positive for Covid-19 (independently of each other). Let \\(X\\) denote the number of people that are vaccinated among the 10 that tested positive.\n\nWhat is the probability that at least 5 of the 10 people that tested positive are vaccinated?\n\n\n\n\\[\\begin{aligned}\nP(X \\geq 5) = & P(X =5) + P(X = 6) + P(X =7) + P(X = 8) + P(X = 9)+ P(X = 10) \\\\ = &{10 \\choose 5} 0.25^5 (0.75)^{5} + {10 \\choose 6} 0.25^6 (0.75)^{4} + \\ldots + {10 \\choose 10} 0.25^10 (0.75)^{0}\\\\\n= & 0.7758\n\\end{aligned}\\]\n\npbinom(q = 4, size = 10, prob = 0.25, lower.tail = F) # for greater than!\n\n[1] 0.07812691\n\n1 - pbinom(q = 4, size = 10, prob = 0.25, lower.tail = T)\n\n[1] 0.07812691\n\n\n\nIn general, for \\(P(X &gt; k)\\) we code: pbinom(q = k, size = n, prob = p, lower.tail = F)"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#binomial-family-of-distributions",
    "href": "lessons/07_pmfs/07_pmfs.html#binomial-family-of-distributions",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Binomial family of distributions",
    "text": "Binomial family of distributions\n\n\nDistribution (or pmf) of a Binomial random variable\n\n\nLet \\(X\\) be the total number of successes in \\(n\\) independent trials, each with probability \\(p\\) of a success. Then probability of observing exactly \\(k\\) successes in \\(n\\) independent trials is\n\\[P(X = x) = \\binom{n}{x} p^x (1-p)^{n-x},  x= 0, 1, 2, \\dots, n \\]\n\n\n\nThe parameters of a binomial distribution are \\(p\\) and \\(n\\)."
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#binomial-random-variables",
    "href": "lessons/07_pmfs/07_pmfs.html#binomial-random-variables",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Binomial random variables",
    "text": "Binomial random variables\n\nOne specific type of discrete random variable is a binomial random variable\n\n\n\nBinomial random variable\n\n\n\n\\(X\\) is a binomial random variable if it represents the number of successes in \\(n\\) independent replications (or trials) of an experiment where\n\nEach replicate has two possible outcomes: either success or failure\nThe probability of success is \\(p\\)\nThe probability of failure is \\(q=1-p\\)\n\n\n\n\n\nA binomial random variable takes on values \\(0, 1, 2, \\dots, n\\).\nIf a r.v. \\(X\\) is modeled by a Binomial distribution, then we write in shorthand \\(X \\sim \\text{Binom}(n,p)\\)\nQuick example: The number of heads in 3 tosses of a fair coin is a binomial random variable with parameters \\(n = 3\\) and \\(p = 0.5\\)."
  },
  {
    "objectID": "lessons/08_pdfs/24_01_Continuous_rv_muddy_points.html",
    "href": "lessons/08_pdfs/24_01_Continuous_rv_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n1. Why we are allowed to “split” the operator d/dx into two pieces as if it were a fraction when it’s an operator\nHere is a pretty helpful StackExchange post talking about this!\n\n\n2. How to know what to use as \\(u\\) and \\(dv\\) for integration by parts\nI have two approaches to identifying \\(u\\) and \\(dv\\):\n\nTry to find a \\(u\\) that will eventually differentiate into a constant. This usually works unless you’re left with a \\(dv\\) that is hard to integrate.\n\nFor example, \\(u=x^6\\). the first derivative, \\(u'=6x^5\\), which may lead us to do another integration by parts, but eventually, at the 6th derivative, we get 720. This means, in our integration by parts, we eventually get an integral that only has \\(x\\) in the function once.\n\nIn this example, \\(x^6\\) would result in many integration by parts. I feel like we don’t typically see that many in our work.\n\nIn Example 3.5 in Calculus Review, setting \\(u=x^2\\) is a bad idea because we don’t really know how to integrate \\(dv=ln(x)\\) into \\(v\\).\n\nTry to find a \\(u\\) where \\(du\\) is the reciprocal of \\(v\\) or \\(du\\) cancels with \\(v\\).\n\nLook again at Example 3.5 in the notes! Hint: What is the derivative of \\(ln(x)\\)? And what does \\(\\dfrac{1}{x}x^3\\) equal?\n\n\n\n\n3. Looking for more practice in calculus?\nI just stumbled upon this website! Just a bunch of calculus practice problems! Might be some help."
  },
  {
    "objectID": "lessons/08_pdfs/24_01_Continuous_rv_key_info.html",
    "href": "lessons/08_pdfs/24_01_Continuous_rv_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Graded: HW 4 assignment and HW 3 solutions\nCalendly is up!!"
  },
  {
    "objectID": "lessons/08_pdfs/24_01_Continuous_rv_key_info.html#announcements",
    "href": "lessons/08_pdfs/24_01_Continuous_rv_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Graded: HW 4 assignment and HW 3 solutions\nCalendly is up!!"
  },
  {
    "objectID": "lessons/08_pdfs/24_01_Continuous_rv_key_info.html#key-dates",
    "href": "lessons/08_pdfs/24_01_Continuous_rv_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 5 due\nSunday: HW 4 solutions due\nWeek of 11/11\n\nMake a meeting with me\n11/12: recordings due if you are making that\nNow on Sakai"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#falls-in-older-adults-15",
    "href": "lessons/07_pmfs/07_pmfs.html#falls-in-older-adults-15",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Falls in Older Adults (1/5)",
    "text": "Falls in Older Adults (1/5)\n\n\n\n\nExample 1: Falls in Older Adults\n\n\nA major public health concern is falls among older adults (age 65+). National data suggests that 25% of older adults will experience at least one fall within a given year. A community health program is tracking a random group of \\(n = 8\\) older adults for one year. Assume the likelihood of falling is independent from person to person.\nLet \\(X\\) be the random variable representing the number of individuals in this group who experience at least one fall.\n\nWhat is the sample space for the random variable \\(X\\)?\nWrite the probability mass function (pmf) for \\(X\\).\nUse R to calculate the probability for each possible value of \\(X\\).\nMake a bar plot of the pmf.\nSimulate \\(X\\) for 10000 groups and plot the approximated pmf."
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#falls-in-older-adults-25",
    "href": "lessons/07_pmfs/07_pmfs.html#falls-in-older-adults-25",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Falls in Older Adults (2/5)",
    "text": "Falls in Older Adults (2/5)\n\n\n\n\nExample 1: Falls in Older Adults\n\n\n\nWhat is the sample space for the random variable \\(X\\)?"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#falls-in-older-adults-35",
    "href": "lessons/07_pmfs/07_pmfs.html#falls-in-older-adults-35",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Falls in Older Adults (3/5)",
    "text": "Falls in Older Adults (3/5)\n\n\n\n\nExample 1: Falls in Older Adults\n\n\n\nWrite the probability mass function (pmf) for \\(X\\).\n\n\n\n\n\n\\[P(X = x) = \\binom{n}{x} p^x (1-p)^{n-x},  x= 0, 1, 2, \\dots, n \\]"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#falls-in-older-adults-45",
    "href": "lessons/07_pmfs/07_pmfs.html#falls-in-older-adults-45",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Falls in Older Adults (4/5)",
    "text": "Falls in Older Adults (4/5)\n\n\n\n\nExample 1: Falls in Older Adults\n\n\n\nMake a bar plot of the pmf.\n\n\n\n\n\n\nPlot pmf of X\nlibrary(ggplot2)\n\nggplot(falls, aes(x = x, y = prob)) +\n  geom_col() + \n  labs(\n    title = \"Probability distribution (pmf) of X: number of adults who fell\",\n    x = \"Number of adults (x)\",\n    y = \"Probability\"\n  )"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#falls-in-older-adults-55",
    "href": "lessons/07_pmfs/07_pmfs.html#falls-in-older-adults-55",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Falls in Older Adults (5/5)",
    "text": "Falls in Older Adults (5/5)\n\n\n\n\nExample 1: Falls in Older Adults\n\n\n\nSimulate \\(X\\) for 10000 groups and plot the approximated pmf."
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#falls-in-older-adults-35-1",
    "href": "lessons/07_pmfs/07_pmfs.html#falls-in-older-adults-35-1",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Falls in Older Adults (3/5)",
    "text": "Falls in Older Adults (3/5)\n\n\n\n\nExample 1: Falls in Older Adults\n\n\n\nUse R to calculate the probability for each possible value of \\(X\\).\n\n\n\n\nn = 8\np = 0.25\n\ndbinom(0, size = n, prob = p)  #P(X=0)\n\n[1] 0.1001129\n\nfalls &lt;- tibble(\n  x = 0:n,\n  prob = dbinom(x, size = n, prob = p)\n)\n\n\n \n \n\nfalls\n\n# A tibble: 9 × 2\n      x      prob\n  &lt;int&gt;     &lt;dbl&gt;\n1     0 0.100    \n2     1 0.267    \n3     2 0.311    \n4     3 0.208    \n5     4 0.0865   \n6     5 0.0231   \n7     6 0.00385  \n8     7 0.000366 \n9     8 0.0000153"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#falls-in-older-adults-46",
    "href": "lessons/07_pmfs/07_pmfs.html#falls-in-older-adults-46",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Falls in Older Adults (4/6)",
    "text": "Falls in Older Adults (4/6)\n\n\n\n\nExample 1: Falls in Older Adults\n\n\n\nUse R to calculate the probability for each possible value of \\(X\\).\n\n\n\n\nn = 8\np = 0.25\n\ndbinom(0, size = n, prob = p)  #P(X=0)\n\n[1] 0.1001129\n\nfalls &lt;- tibble(\n  x = 0:n,\n  prob = dbinom(x, size = n, prob = p)\n)\n\n\n \n \n\nfalls\n\n# A tibble: 9 × 2\n      x      prob\n  &lt;int&gt;     &lt;dbl&gt;\n1     0 0.100    \n2     1 0.267    \n3     2 0.311    \n4     3 0.208    \n5     4 0.0865   \n6     5 0.0231   \n7     6 0.00385  \n8     7 0.000366 \n9     8 0.0000153"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#falls-in-older-adults-56",
    "href": "lessons/07_pmfs/07_pmfs.html#falls-in-older-adults-56",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Falls in Older Adults (5/6)",
    "text": "Falls in Older Adults (5/6)\n\n\n\n\nExample 1: Falls in Older Adults\n\n\n\nMake a bar plot of the pmf.\n\n\n\n\n\n\nlibrary(ggplot2)\n\nggplot(falls, aes(x = x, y = prob)) +\n  geom_col() + \n  labs(\n    title = \"Probability mass function (pmf) of X\",\n    x = \"Number of adults (x)\",\n    y = \"Probability\"\n  )"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html#falls-in-older-adults-66",
    "href": "lessons/07_pmfs/07_pmfs.html#falls-in-older-adults-66",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "Falls in Older Adults (6/6)",
    "text": "Falls in Older Adults (6/6)\n\n\n\n\nExample 1: Falls in Older Adults\n\n\n\nSimulate \\(X\\) for 10000 groups and plot the approximated pmf.\n\n\n\n\nset.seed(4764)\nreps = 10000\n\nsims = rbinom(n = reps, \n              size = n, \n              prob = p)\n\nsims %&gt;% head(., 14)\n\n [1] 2 1 2 1 3 3 2 2 4 2 3 0 2 0\n\nfalls2 &lt;- tibble(x = 0:n) %&gt;%\n  rowwise() %&gt;%\n  mutate(prob = sum(sims == x) / reps)\n\n\n\nggplot(falls2, aes(x = x, y = prob)) +\n  geom_col() + \n  labs(\n    title = \"Approximate probability mass function (pmf) of X\",\n    x = \"Number of adults (x)\",\n    y = \"Approximate Probability\"\n  )"
  },
  {
    "objectID": "lessons/08_pdfs/08_pdfs.html#use-r-to-simulate-continuous-random-variables.",
    "href": "lessons/08_pdfs/08_pdfs.html#use-r-to-simulate-continuous-random-variables.",
    "title": "Lesson 8: Probability distribution functions (PDFs)",
    "section": "Use R to simulate continuous random variables.",
    "text": "Use R to simulate continuous random variables.\n\nWe can use R to simulate continuous random variables and visualize their distributions\nFor example, we can simulate a uniform distribution between 2.5 and 3\n\n\n\nuniform = tibble(\n  x = runif(n=10000, min=2.5, max=3)\n)\n\nggplot(uniform, \n       aes(x = x, \n           y = after_stat(density))) +\n  geom_histogram( binwidth = 0.001) + \n  geom_abline(intercept = 2, slope = 0) + \n  labs(\n    title = \"Probability distribution function (pdf) of X\",\n    x = \"x\",\n    y = \"pdf\"\n  )"
  },
  {
    "objectID": "lessons/08_pdfs/08_pdfs.html#use-r-to-simulate-known-distributions",
    "href": "lessons/08_pdfs/08_pdfs.html#use-r-to-simulate-known-distributions",
    "title": "Lesson 8: Probability density functions (PDFs)",
    "section": "Use R to simulate known distributions",
    "text": "Use R to simulate known distributions\n\nWe can use R to simulate continuous random variables and visualize their distributions\nFor example, we can simulate a uniform distribution between 2.5 and 3\n\n\n\nuniform = tibble(\n  x = runif(n=10000, min=2.5, max=3)\n)\n\nggplot(uniform, \n       aes(x = x, \n           y = after_stat(density))) +\n  geom_histogram( binwidth = 0.001) + \n  geom_abline(intercept = 2, slope = 0) + \n  labs(\n    title = \"Probability density function (pdf) of X\",\n    x = \"x\",\n    y = \"pdf\"\n  )"
  },
  {
    "objectID": "lessons/08_pdfs/08_pdfs.html#use-r-to-simulate-any-continuous-distribution",
    "href": "lessons/08_pdfs/08_pdfs.html#use-r-to-simulate-any-continuous-distribution",
    "title": "Lesson 8: Probability density functions (PDFs)",
    "section": "Use R to simulate any continuous distribution",
    "text": "Use R to simulate any continuous distribution\n\nWe will discuss other ways to simulate continuous distributions once we cover cumulative distribution functions (CDFs) and inverse CDFs"
  },
  {
    "objectID": "lessons/08_pdfs/08_pdfs.html#where-are-we",
    "href": "lessons/08_pdfs/08_pdfs.html#where-are-we",
    "title": "Lesson 8: Probability density functions (PDFs)",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs_key_info.html",
    "href": "lessons/07_pmfs/07_pmfs_key_info.html",
    "title": "Key Info and Announcements",
    "section": "",
    "text": "Quiz 1 info"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs_key_info.html#key-info",
    "href": "lessons/07_pmfs/07_pmfs_key_info.html#key-info",
    "title": "Key Info and Announcements",
    "section": "",
    "text": "Quiz 1 info"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs_key_info.html#announcements",
    "href": "lessons/07_pmfs/07_pmfs_key_info.html#announcements",
    "title": "Key Info and Announcements",
    "section": "Announcements",
    "text": "Announcements\n\nHomework 3 due this Sunday at 11pm\nQuiz 1 opens on 10/22 at 3pm"
  },
  {
    "objectID": "lessons/07_pmfs/Untitled.html",
    "href": "lessons/07_pmfs/Untitled.html",
    "title": "Untitled",
    "section": "",
    "text": "Let’s write the pdf for a binomial distribution: \\[f(x) = \\binom{n}{x} p^x (1-p)^{n-x}\\] where \\(x = 0, 1, 2, \\ldots, n\\).\nLet’s take the integral of this function from \\(-\\infty\\) to \\(\\infty\\):\n\\[\nF_X(x) = \\int_{-\\infty}^{\\infty} f(x) \\, dx\n\\]"
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs_muddy_points.html",
    "href": "lessons/07_pmfs/07_pmfs_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "I think you’re on the right track… \\(P(X)\\), \\(P(X=x)\\), and \\(p_X(x)\\) represent probabilities.\nFor discrete random variables, we can use \\(P(X=x)\\) or \\(p_X(x)\\) to represent the probability that the random variable \\(X\\) takes on the value \\(x\\). And then we can discuss the probability mass function (pmf) as the probability distribution as well!\nFor continuous random variables, we use \\(f_X(x)\\) to represent the probability density function (pdf) of \\(X\\) at the value \\(x\\), BUT it is not equal to the actual probability! Aka \\(f_X(x)\\) does not represent a probability, but the area under the curve of \\(f_X(x)\\) over an interval gives us the probability."
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs_muddy_points.html#fall-2025",
    "href": "lessons/07_pmfs/07_pmfs_muddy_points.html#fall-2025",
    "title": "Muddy Points",
    "section": "",
    "text": "I think you’re on the right track… \\(P(X)\\), \\(P(X=x)\\), and \\(p_X(x)\\) represent probabilities.\nFor discrete random variables, we can use \\(P(X=x)\\) or \\(p_X(x)\\) to represent the probability that the random variable \\(X\\) takes on the value \\(x\\). And then we can discuss the probability mass function (pmf) as the probability distribution as well!\nFor continuous random variables, we use \\(f_X(x)\\) to represent the probability density function (pdf) of \\(X\\) at the value \\(x\\), BUT it is not equal to the actual probability! Aka \\(f_X(x)\\) does not represent a probability, but the area under the curve of \\(f_X(x)\\) over an interval gives us the probability."
  },
  {
    "objectID": "lessons/08_pdfs/08_pdfs_muddy_points.html",
    "href": "lessons/08_pdfs/08_pdfs_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "I think you’re on the right track… \\(P(X)\\), \\(P(X=x)\\), and \\(p_X(x)\\) represent probabilities.\nFor discrete random variables, we can use \\(P(X=x)\\) or \\(p_X(x)\\) to represent the probability that the random variable \\(X\\) takes on the value \\(x\\). And then we can discuss the probability mass function (pmf) as the probability distribution as well!\nFor continuous random variables, we use \\(f_X(x)\\) to represent the probability density function (pdf) of \\(X\\) at the value \\(x\\), BUT it is not equal to the actual probability! Aka \\(f_X(x)\\) does not represent a probability, but the area under the curve of \\(f_X(x)\\) over an interval gives us the probability."
  },
  {
    "objectID": "lessons/07_pmfs/07_pmfs.html",
    "href": "lessons/07_pmfs/07_pmfs.html",
    "title": "Lesson 7: Probability Mass Functions (pmf’s)",
    "section": "",
    "text": "Identify a probability mass function (pmf) from past simulations\nIdentify a binomial random variable and its parameters from a word problem\nUse R to calculate probabilities and simulate binomial random variables"
  },
  {
    "objectID": "lessons/08_pdfs/08_pdfs_muddy_points.html#fall-2025",
    "href": "lessons/08_pdfs/08_pdfs_muddy_points.html#fall-2025",
    "title": "Muddy Points",
    "section": "",
    "text": "I think you’re on the right track… \\(P(X)\\), \\(P(X=x)\\), and \\(p_X(x)\\) represent probabilities.\nFor discrete random variables, we can use \\(P(X=x)\\) or \\(p_X(x)\\) to represent the probability that the random variable \\(X\\) takes on the value \\(x\\). And then we can discuss the probability mass function (pmf) as the probability distribution as well!\nFor continuous random variables, we use \\(f_X(x)\\) to represent the probability density function (pdf) of \\(X\\) at the value \\(x\\), BUT it is not equal to the actual probability! Aka \\(f_X(x)\\) does not represent a probability, but the area under the curve of \\(f_X(x)\\) over an interval gives us the probability."
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes_muddy_points.html",
    "href": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Here’s the slide: \nLet’s think of a different scenario (Scenario 1): Let’s find the probability of drawing a spade and a heart from a standard deck of cards when drawing two cards without replacement.\nThere are 52 cards in a standard deck, with 13 spades and 13 hearts.\n\nLet’s look at the sample space size, \\(|S|\\). We need to enumerate all the possible combinations of two cards. \\[\\binom{52}{2} = \\frac{52 \\times 51}{2} = 1326\\]\nThe more difficult part is the size of our event A, \\(|A|\\). We need to enumerate all the ways to draw 1 spade and 1 heart:\n\nWays to choose 1 spade from 13: \\(\\binom{13}{1} = 13\\)\nWays to choose 1 heart from 13: \\(\\binom{13}{1} = 13\\)\nFor each potential spade we draw, there are 13 potential hearts we could draw. So we can multiply the two together to get the total number of ways to draw a spade and a heart: \\[|A| = 13 \\times 13 = 169\\]\n\n\nThen we could calculate the probability of drawing a spade and a heart as: \\[P(A) = \\frac{|A|}{|S|} = \\frac{13 \\times 13}{1326} = \\frac{169}{1326} = 0.1275\\]\nWe can keep expanding our scenario (Scenario 2): Let’s find the probability of drawing one spade, one heart, one diamond, and one club without replacement.\n\nLet’s look at the sample space size, \\(|S|\\). We need to enumerate all the possible combinations of two cards. \\[\\binom{52}{4} = \\frac{52 \\times 51 \\times 50 \\times 49}{4 \\times 3 \\times 2 \\times 1} = 270725\\]\nNow, size of event A, \\(|A|\\). We need to enumerate all the ways to draw one spade, one heart, one diamond, and one club:\n\nWays to choose 1 spade from 13: \\(\\binom{13}{1} = 13\\)\nWays to choose 1 heart from 13: \\(\\binom{13}{1} = 13\\)\nWays to choose 1 diamond from 13: \\(\\binom{13}{1} = 13\\)\nWays to choose 1 club from 13: \\(\\binom{13}{1} = 13\\)\nFor each potential spade we draw, there are 13 potential hearts we could draw. And from each specific spade and heart combo, there are 13 potential diamonds, etc. So we can multiply all four together to get the total number of ways to draw a spade and a heart: \\[|A| = 13 \\times 13 \\times 13 \\times 13 = 28561\\]\n\n\nThen we could calculate the probability of drawing a spade and a heart as: \\[P(A) = \\frac{|A|}{|S|} = \\frac{13 \\times 13 \\times 13 \\times 13}{270725} = \\frac{28561}{270725} = 0.1055\\]\nIn both the above scenarios, we calculated the size of event A only with the cards we DRAW I just wanted to emphasize that for each suit of cards, we can technically enumerate all the ways to draw a certain number of cards, including 0.\nIf we go back to scenario 1, we could also calculate the size of our event A, \\(|A|\\) as:\n\nWays to choose 1 spade from 13: \\(\\binom{13}{1} = 13\\)\nWays to choose 1 heart from 13: \\(\\binom{13}{1} = 13\\)\nWays to choose 0 diamonds from 13: \\(\\binom{13}{0} = 1\\)\nWays to choose 0 clubs from 13: \\(\\binom{13}{0} = 1\\)\nFor each potential spade we draw, there are 13 potential hearts we could draw. So we can multiply the four together to get the total number of ways to draw a spade and a heart and 0 diamonds and 0 clubs: \\[|A| = 13 \\times 13 \\times 1 \\times 1 = 169\\]"
  },
  {
    "objectID": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes_muddy_points.html#fall-2025",
    "href": "lessons/05_Equally_likely_outcomes/05_Equally_likely_outcomes_muddy_points.html#fall-2025",
    "title": "Muddy Points",
    "section": "",
    "text": "Here’s the slide: \nLet’s think of a different scenario (Scenario 1): Let’s find the probability of drawing a spade and a heart from a standard deck of cards when drawing two cards without replacement.\nThere are 52 cards in a standard deck, with 13 spades and 13 hearts.\n\nLet’s look at the sample space size, \\(|S|\\). We need to enumerate all the possible combinations of two cards. \\[\\binom{52}{2} = \\frac{52 \\times 51}{2} = 1326\\]\nThe more difficult part is the size of our event A, \\(|A|\\). We need to enumerate all the ways to draw 1 spade and 1 heart:\n\nWays to choose 1 spade from 13: \\(\\binom{13}{1} = 13\\)\nWays to choose 1 heart from 13: \\(\\binom{13}{1} = 13\\)\nFor each potential spade we draw, there are 13 potential hearts we could draw. So we can multiply the two together to get the total number of ways to draw a spade and a heart: \\[|A| = 13 \\times 13 = 169\\]\n\n\nThen we could calculate the probability of drawing a spade and a heart as: \\[P(A) = \\frac{|A|}{|S|} = \\frac{13 \\times 13}{1326} = \\frac{169}{1326} = 0.1275\\]\nWe can keep expanding our scenario (Scenario 2): Let’s find the probability of drawing one spade, one heart, one diamond, and one club without replacement.\n\nLet’s look at the sample space size, \\(|S|\\). We need to enumerate all the possible combinations of two cards. \\[\\binom{52}{4} = \\frac{52 \\times 51 \\times 50 \\times 49}{4 \\times 3 \\times 2 \\times 1} = 270725\\]\nNow, size of event A, \\(|A|\\). We need to enumerate all the ways to draw one spade, one heart, one diamond, and one club:\n\nWays to choose 1 spade from 13: \\(\\binom{13}{1} = 13\\)\nWays to choose 1 heart from 13: \\(\\binom{13}{1} = 13\\)\nWays to choose 1 diamond from 13: \\(\\binom{13}{1} = 13\\)\nWays to choose 1 club from 13: \\(\\binom{13}{1} = 13\\)\nFor each potential spade we draw, there are 13 potential hearts we could draw. And from each specific spade and heart combo, there are 13 potential diamonds, etc. So we can multiply all four together to get the total number of ways to draw a spade and a heart: \\[|A| = 13 \\times 13 \\times 13 \\times 13 = 28561\\]\n\n\nThen we could calculate the probability of drawing a spade and a heart as: \\[P(A) = \\frac{|A|}{|S|} = \\frac{13 \\times 13 \\times 13 \\times 13}{270725} = \\frac{28561}{270725} = 0.1055\\]\nIn both the above scenarios, we calculated the size of event A only with the cards we DRAW I just wanted to emphasize that for each suit of cards, we can technically enumerate all the ways to draw a certain number of cards, including 0.\nIf we go back to scenario 1, we could also calculate the size of our event A, \\(|A|\\) as:\n\nWays to choose 1 spade from 13: \\(\\binom{13}{1} = 13\\)\nWays to choose 1 heart from 13: \\(\\binom{13}{1} = 13\\)\nWays to choose 0 diamonds from 13: \\(\\binom{13}{0} = 1\\)\nWays to choose 0 clubs from 13: \\(\\binom{13}{0} = 1\\)\nFor each potential spade we draw, there are 13 potential hearts we could draw. So we can multiply the four together to get the total number of ways to draw a spade and a heart and 0 diamonds and 0 clubs: \\[|A| = 13 \\times 13 \\times 1 \\times 1 = 169\\]"
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs.html#where-are-we",
    "href": "lessons/09_CDFs/09_CDFs.html#where-are-we",
    "title": "Lesson 9: Cumulative distribution functions (CDFs)",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs.html#how-to-define-cdfs-for-discrete-and-continuous-rvs",
    "href": "lessons/09_CDFs/09_CDFs.html#how-to-define-cdfs-for-discrete-and-continuous-rvs",
    "title": "Lesson 9: Cumulative distribution functions (CDFs)",
    "section": "How to define CDFs for discrete and continuous RVs?",
    "text": "How to define CDFs for discrete and continuous RVs?\n\n\nDiscrete RV \\(X\\):\n\n\n\n\n\n\n\n\n\n\npmf: \\(p_X(x) = P(X=x)\\)\nCDF: \\(F_X(x) = P(X \\leq x) = \\sum\\limits_{\\{all\\ y:\\ y\\leq x\\}} p_X(y)\\)\n\n\nContinuous RV \\(X\\):\n\n\n\n\n\n\n\n\n\n\ndensity: \\(f_X(x)\\)\nprobability: \\(P(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\)\nCDF: \\(F_X(x) = P(X \\leq x) = \\int_{-\\infty}^x f_X(s)ds\\)"
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs.html#falls-in-older-adults-revisited-14",
    "href": "lessons/09_CDFs/09_CDFs.html#falls-in-older-adults-revisited-14",
    "title": "Lesson 9: Cumulative distribution functions (CDFs)",
    "section": "Falls in Older Adults Revisited (1/4)",
    "text": "Falls in Older Adults Revisited (1/4)\n\n\n\n\nExample 1: Falls in Older Adults\n\n\nA major public health concern is falls among older adults (age 65+). National data suggests that 25% of older adults will experience at least one fall within a given year. A community health program is tracking a random group of \\(n = 8\\) older adults for one year. Assume the likelihood of falling is independent from person to person.\nLet \\(X\\) be the random variable representing the number of individuals in this group who experience at least one fall.\n\nWrite the CDF of \\(X\\) and make a table of values.\nUse R to calculate the cumulative probability for each possible value of \\(X\\).\nPlot the CDF of \\(X\\).\nSimulate \\(X\\) for 10000 groups and plot the approximated CDF.\n\n\n\n\nRecall our pmf: \\[P(X = x) = \\binom{8}{x} 0.25^x 0.75^{8-x},  x= 0, 1, 2, \\dots, 8 \\]"
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs.html#falls-in-older-adults-revisited-14-1",
    "href": "lessons/09_CDFs/09_CDFs.html#falls-in-older-adults-revisited-14-1",
    "title": "Lesson 9: Cumulative distribution functions (CDFs)",
    "section": "Falls in Older Adults Revisited (1/4)",
    "text": "Falls in Older Adults Revisited (1/4)\n\n\n\n\nExample 1: Falls in Older Adults\n\n\n\nWrite the CDF of \\(X\\).\n\n\n\n\nRecall our pmf: \\[P(X = x) = \\binom{8}{x} 0.25^x 0.75^{8-x},  x= 0, 1, 2, \\dots, 8 \\]"
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs.html#falls-in-older-adults-revisited-24",
    "href": "lessons/09_CDFs/09_CDFs.html#falls-in-older-adults-revisited-24",
    "title": "Lesson 9: Cumulative distribution functions (CDFs)",
    "section": "Falls in Older Adults Revisited (2/4)",
    "text": "Falls in Older Adults Revisited (2/4)\n\n\n\n\nExample 1: Falls in Older Adults\n\n\n\nWrite the CDF of \\(X\\).\n\n\n\n\nRecall our pmf: \\[P(X = x) = \\binom{8}{x} 0.25^x 0.75^{8-x},  x= 0, 1, 2, \\dots, 8 \\]\n\\[F_X(x) = P(X \\leq x) = \\sum \\limits_{k=0}^{x} \\binom{8}{k} 0.25^y 0.75^{8-k}\\]"
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs.html#falls-in-older-adults-revisited-34",
    "href": "lessons/09_CDFs/09_CDFs.html#falls-in-older-adults-revisited-34",
    "title": "Lesson 9: Cumulative distribution functions (CDFs)",
    "section": "Falls in Older Adults Revisited (3/4)",
    "text": "Falls in Older Adults Revisited (3/4)\n\n\n\n\nExample 1: Falls in Older Adults\n\n\n\nUse R to calculate the cumulative probability for each possible value of \\(X\\).\n\n\n\n\nn = 8\np = 0.25\n\nfalls_cdf &lt;- tibble(\n  x = 0:n,\n  prob = pbinom(x, size = n, prob = p)\n)\n\n\n \n \n\nfalls_cdf\n\n# A tibble: 9 × 2\n      x  prob\n  &lt;int&gt; &lt;dbl&gt;\n1     0 0.100\n2     1 0.367\n3     2 0.679\n4     3 0.886\n5     4 0.973\n6     5 0.996\n7     6 1.00 \n8     7 1.00 \n9     8 1"
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs.html#falls-in-older-adults-revisited-15",
    "href": "lessons/09_CDFs/09_CDFs.html#falls-in-older-adults-revisited-15",
    "title": "Lesson 9: Cumulative distribution functions (CDFs)",
    "section": "Falls in Older Adults Revisited (1/5)",
    "text": "Falls in Older Adults Revisited (1/5)\n\n\n\n\nExample 1: Falls in Older Adults\n\n\nA major public health concern is falls among older adults (age 65+). National data suggests that 25% of older adults will experience at least one fall within a given year. A community health program is tracking a random group of \\(n = 8\\) older adults for one year. Assume the likelihood of falling is independent from person to person.\nLet \\(X\\) be the random variable representing the number of individuals in this group who experience at least one fall.\n\nWrite the CDF of \\(X\\) and make a table of values.\nUse R to calculate the cumulative probability for each possible value of \\(X\\).\nPlot the CDF of \\(X\\).\nSimulate \\(X\\) for 10000 groups and plot the approximated CDF.\n\n\n\n\nRecall our pmf: \\[P(X = x) = \\binom{8}{x} 0.25^x 0.75^{8-x},  x= 0, 1, 2, \\dots, 8 \\]"
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs.html#falls-in-older-adults-revisited-25",
    "href": "lessons/09_CDFs/09_CDFs.html#falls-in-older-adults-revisited-25",
    "title": "Lesson 9: Cumulative distribution functions (CDFs)",
    "section": "Falls in Older Adults Revisited (2/5)",
    "text": "Falls in Older Adults Revisited (2/5)\n\n\n\n\nExample 1: Falls in Older Adults\n\n\n\nWrite the CDF of \\(X\\).\n\n\n\n\nRecall our pmf: \\[P(X = x) = \\binom{8}{x} 0.25^x 0.75^{8-x},  x= 0, 1, 2, \\dots, 8 \\]\n\\[F_X(x) = P(X \\leq x) = \\sum \\limits_{k=0}^{x} \\binom{8}{k} 0.25^y 0.75^{8-k}\\]"
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs.html#falls-in-older-adults-revisited-35",
    "href": "lessons/09_CDFs/09_CDFs.html#falls-in-older-adults-revisited-35",
    "title": "Lesson 9: Cumulative distribution functions (CDFs)",
    "section": "Falls in Older Adults Revisited (3/5)",
    "text": "Falls in Older Adults Revisited (3/5)\n\n\n\n\nExample 1: Falls in Older Adults\n\n\n\nUse R to calculate the cumulative probability for each possible value of \\(X\\).\n\n\n\n\nn = 8\np = 0.25\n\nfalls_cdf &lt;- tibble(\n  x = 0:n,\n  c_prob = pbinom(x, size = n, prob = p)\n)\n\n\n \n \n\nfalls_cdf\n\n# A tibble: 9 × 2\n      x c_prob\n  &lt;int&gt;  &lt;dbl&gt;\n1     0  0.100\n2     1  0.367\n3     2  0.679\n4     3  0.886\n5     4  0.973\n6     5  0.996\n7     6  1.00 \n8     7  1.00 \n9     8  1"
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs.html#falls-in-older-adults-revisited-45",
    "href": "lessons/09_CDFs/09_CDFs.html#falls-in-older-adults-revisited-45",
    "title": "Lesson 9: Cumulative distribution functions (CDFs)",
    "section": "Falls in Older Adults Revisited (4/5)",
    "text": "Falls in Older Adults Revisited (4/5)\n\n\nExample 1: Falls in Older Adults\n\n\n\nPlot the CDF of \\(X\\).\n\n\n\n\n\nggplot(\n  falls_cdf,\n  aes(x = x, y = c_prob)\n       ) +\n  geom_step(\n    size = 1, \n    color = \"black\"\n    ) +\n  labs(\n    x = \"Number of Falls\",\n    y = \"Cumulative Probability\",\n    title = \"CDF of X\"\n    )"
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs.html#falls-in-older-adults-revisited-45-1",
    "href": "lessons/09_CDFs/09_CDFs.html#falls-in-older-adults-revisited-45-1",
    "title": "Lesson 9: Cumulative distribution functions (CDFs)",
    "section": "Falls in Older Adults Revisited (4/5)",
    "text": "Falls in Older Adults Revisited (4/5)\n\n\n\n\nExample 1: Falls in Older Adults\n\n\n\nSimulate \\(X\\) for 10000 groups and plot the approximated CDF.\n\n\n\n\nset.seed(4764)\nreps = 10000\n\nsims = rbinom(n = reps, \n              size = n, \n              prob = p)\n\nsims %&gt;% head(., 14)\n\n [1] 2 1 2 1 3 3 2 2 4 2 3 0 2 0\n\nfalls2 &lt;- tibble(x = 0:n) %&gt;%\n  rowwise() %&gt;%\n  mutate(c_prob = sum(sims &lt;= x) / reps)\n\n\n\nggplot(falls2, aes(x = x, y = c_prob)) +\n  geom_step(size = 1, color = \"black\") +\n  labs(\n    title = \"Approximate CDF of X\",\n    x = \"Number of adults (x)\",\n    y = \"Approximate Cumulative Probability\"\n  )"
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs_key_info.html",
    "href": "lessons/09_CDFs/09_CDFs_key_info.html",
    "title": "Key Info and Announcements",
    "section": "",
    "text": "Quiz 1 questions?\nCharles is still grading HW 2\n\nPosted solutions so you have as a reference during quiz\n\nIf links do not work on this site, there are two places where the files live:\n\nGithub page: https://github.com/nwakim/BSTA_550_25F\n\nLink also on this homepage\n\nOHSU OneDrive\n\nYou should have access to this folder\n\n\nIf you want to attend class virtually when we’re in-person, then you can use: https://pdx.zoom.us/j/82027616951\n\nHowever, I will not support virtual attendance when we’re in-person\nI will not be monitoring the chat or helping with technical issues"
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs_key_info.html#key-info",
    "href": "lessons/09_CDFs/09_CDFs_key_info.html#key-info",
    "title": "Key Info and Announcements",
    "section": "",
    "text": "Quiz 1 questions?\nCharles is still grading HW 2\n\nPosted solutions so you have as a reference during quiz\n\nIf links do not work on this site, there are two places where the files live:\n\nGithub page: https://github.com/nwakim/BSTA_550_25F\n\nLink also on this homepage\n\nOHSU OneDrive\n\nYou should have access to this folder\n\n\nIf you want to attend class virtually when we’re in-person, then you can use: https://pdx.zoom.us/j/82027616951\n\nHowever, I will not support virtual attendance when we’re in-person\nI will not be monitoring the chat or helping with technical issues"
  },
  {
    "objectID": "lessons/09_CDFs/09_CDFs_key_info.html#announcements",
    "href": "lessons/09_CDFs/09_CDFs_key_info.html#announcements",
    "title": "Key Info and Announcements",
    "section": "Announcements",
    "text": "Announcements\n\nHomework 3 due 10/26 at 11pm\nQuiz 1 opens on 10/22 at 3pm\n\nCloses 10/26 at 11pm"
  },
  {
    "objectID": "homework/HW_05.html#questions",
    "href": "homework/HW_05.html#questions",
    "title": "Homework 5",
    "section": "Questions",
    "text": "Questions\n\nThe following table shows the results of a survey in which the subjects were a sample of 300 adults residing in a certain metropolitan area. Each subject was asked to indicate which of three policies they favored with respect to smoking in public places. (Table is from Biostatistics: A Foundation for Analysis in the Health Sciences, 10th Edition, Daniel, Wayne W.; Cross, Chad L., pg. 630)\n\n\n\n\n\nLet \\(X=\\) highest education level and \\(Y=\\) policy favored. We can let \\(X=1\\) for college graduate, \\(X=2\\) for high-school graduate, etc., and similarly for \\(Y\\), or just keep the category names for the different levels of \\(X\\) and \\(Y\\)\n\nMake a table for the joint pmf \\(p_{X,Y}(x,y)\\) and briefly describe in words what the values are the probability of.\nFind the marginal pmf \\(p_{X}(x)\\) and briefly describe in words what the values are the probability of.\nFind the marginal pmf \\(p_{Y}(y)\\) and briefly describe in words what the values are the probability of.\nMake a table for the joint cdf \\(F_{X,Y}(x,y)\\) and briefly describe in words what the values are the probability of.\nFind the marginal cdf \\(F_{X}(x)\\) and briefly describe in words what the values are the probability of.\nFind the marginal cdf \\(F_{Y}(y)\\) and briefly describe in words what the values are the probability of.\n\nLet \\(X_1, X_2, \\ldots, X_n\\) be i.i.d. random variables with common pdf \\(f_X(x)\\) and cdf \\(F_X(x)\\). Find the pdf for the random variable \\(Z\\), where \\(Z = \\max(X_1, X_2, \\ldots, X_n)\\).\nLet \\(X\\) and \\(Y\\) be independent random variables with respective pdf’s \\(f_X(x)=\\frac{1}{5}\\), for \\(0\\leq x\\leq 5\\), and \\(f_Y(y)=2e^{-2y}\\), for \\(y&gt;0\\).\n\nFind the joint distribution \\(f_{X,Y}(x,y)\\).\nFind the probability that \\(X\\) is less than \\(Y\\).\nLet \\(Z\\) be the random variable that is the smaller of \\(X\\) and \\(Y\\). Find the cumulative distribution function for \\(Z\\).\nFind the pdf for Z.\n\nSuppose that the random variables \\(X\\) and \\(Y\\) have joint density \\(f_{X,Y}(x,y)\\), for \\(0&lt;x&lt;1\\), and \\(\\frac{1}{2}&lt;y&lt;1\\). Set up the equation for the cdf of \\(Z\\), where \\(Z=X/Y\\).\nHint: First determine what the possible values for \\(Z\\) are. Then make a sketch of the domain of the joint pdf and shade in the region representing the cdf of Z for different values of \\(z\\). Make sure to pay close attention to how the region we need to integrate over changes as \\(z\\) changes. The cdf has two different cases depending on the value of \\(z\\). Plug in specific values of \\(z\\) and shade in the region representing the cdf to see why two different cases are needed."
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#learning-objectives",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#learning-objectives",
    "title": "Lesson 11: Joint distributions",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate probabilities for a pair of discrete random variables\nCalculate a joint, marginal, and conditional probability mass function (pmf)\nCalculate a joint, marginal, and conditional cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#where-are-we",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#where-are-we",
    "title": "Lesson 11: Joint distributions",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#what-is-a-joint-pmf",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#what-is-a-joint-pmf",
    "title": "Lesson 11: Joint distributions",
    "section": "What is a joint pmf?",
    "text": "What is a joint pmf?\n\n\nDefinition: joint pmf\n\n\nThe joint pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[p_{X,Y}(x,y) = \\mathbb{P}(X=x\\ and\\ Y=y) = \\mathbb{P}(X=x, Y=y)\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#this-chapters-main-example",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#this-chapters-main-example",
    "title": "Lesson 11: Joint distributions",
    "section": "This chapter’s main example",
    "text": "This chapter’s main example\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-pmf",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-pmf",
    "title": "Lesson 11: Joint distributions",
    "section": "Joint pmf",
    "text": "Joint pmf\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\)\nFind \\(\\mathbb{P}(X+Y=3)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#marginal-pmfs",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#marginal-pmfs",
    "title": "Lesson 11: Joint distributions",
    "section": "Marginal pmf’s",
    "text": "Marginal pmf’s\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(\\mathbb{P}(Y = 1)\\)\nFind \\(\\mathbb{P}(Y \\leq 2)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#remarks-on-the-joint-pmf",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#remarks-on-the-joint-pmf",
    "title": "Lesson 11: Joint distributions",
    "section": "Remarks on the joint pmf",
    "text": "Remarks on the joint pmf\nSome properties of joint pmf’s:\n\nA joint pmf \\(p_{X,Y}(x,y)\\) must satisfy the following properties:\n\n\\(p_{X,Y}(x,y)\\geq 0\\) for all \\(x, y\\).\n\\(\\sum \\limits_{\\{all\\ x\\}} \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)=1\\).\n\nMarginal pmf’s:\n\n\\(p_X(x) = \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)\\)\n\\(p_Y(y) = \\sum \\limits_{\\{all\\ x\\}} p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#what-is-a-joint-cdf",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#what-is-a-joint-cdf",
    "title": "Lesson 11: Joint distributions",
    "section": "What is a joint CDF?",
    "text": "What is a joint CDF?\n\n\nDefinition: joint CDF\n\n\nThe joint CDF of a pair of discrete RV’s \\(X\\) and \\(Y\\) is \\[F_{X,Y}(x,y) = \\mathbb{P}(X \\leq x\\ and\\ Y \\leq y) = \\mathbb{P}(X \\leq x, Y \\leq y)\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-cdfs",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-cdfs",
    "title": "Lesson 11: Joint distributions",
    "section": "Joint CDFs",
    "text": "Joint CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#marginal-cdfs",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#marginal-cdfs",
    "title": "Lesson 11: Joint distributions",
    "section": "Marginal CDFs",
    "text": "Marginal CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#remarks-on-the-joint-and-marginal-cdf",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#remarks-on-the-joint-and-marginal-cdf",
    "title": "Lesson 11: Joint distributions",
    "section": "Remarks on the joint and marginal CDF",
    "text": "Remarks on the joint and marginal CDF\n\n\\(F_X(x)\\): right most columns of the CDF table (where the \\(Y\\) values are largest)\n\\(F_Y(y)\\): bottom row of the table (where X values are largest)\n\\(F_X(x)=\\lim\\limits_{y\\rightarrow\\infty}F_{X, Y}(x,y)\\)\n\\(F_Y(y)=\\lim\\limits_{x\\rightarrow\\infty}F_{X, Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#independence-and-conditioning",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#independence-and-conditioning",
    "title": "Lesson 11: Joint distributions",
    "section": "Independence and Conditioning",
    "text": "Independence and Conditioning\nRecall that for events \\(A\\) and \\(B\\),\n\n\\(\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}\\)\n\\(A\\) and \\(B\\) are independent if and only if\n\n\\(\\mathbb{P}(A|B) = \\mathbb{P}(A)\\)\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A)\\cdot\\mathbb{P}(B)\\)\n\n\nIndependence and conditioning are defined similarly for r.v.’s, since \\[p_X(x) = \\mathbb{P}(X=x)\\ \\mathrm{and}\\ \\ p_{X,Y}(x,y) = \\mathbb{P}(X = x ,Y = y).\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#what-is-the-conditional-pmf",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#what-is-the-conditional-pmf",
    "title": "Lesson 11: Joint distributions",
    "section": "What is the conditional pmf?",
    "text": "What is the conditional pmf?\n\n\nDefinition: conditional pmf\n\n\nThe conditional pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is defined as \\[p_{X|Y}(x|y) = \\mathbb{P}(X = x |Y = y) = \\frac{\\mathbb{P}(X = x\\ and\\ Y = y)}{\\mathbb{P}(Y = y)}\n=\\frac{p_{X,Y}(x,y) }{p_{Y}(y) }\\] if \\(p_{Y}(y) &gt; 0\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#remarks-on-the-conditional-pmf",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#remarks-on-the-conditional-pmf",
    "title": "Lesson 11: Joint distributions",
    "section": "Remarks on the conditional pmf",
    "text": "Remarks on the conditional pmf\nThe following properties follow from the conditional pmf definition:\n\nIf \\(X \\perp Y\\) (independent)\n\n\\(p_{X|Y}(x|y) = p_X(x)\\) for all \\(x\\) and \\(y\\)\n\\(p_{X,Y}(x,y) = p_X(x)p_Y(y)\\) for all \\(x\\) and \\(y\\)\nWhich also implies (\\(\\Rightarrow\\)): \\(F_{X,Y}(x,y) = F_X(x)F_Y(y)\\) for all \\(x\\) and \\(y\\)\n\nIf \\(X_1, X_2, …, X_n\\) are independent\n\n\\[p_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1=x_1, X_2=x_2, …, X_n=x_n)=\\prod\\limits_{i=1}^np_{X_i}(x_i)\\]\n\\[F_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1\\leq x_1, X_2\\leq x_2, …, X_n\\leq x_n)=\\prod\\limits_{i=1}^nP(X_i \\leq x_i) = \\prod\\limits_{i=1}^nF_{X_i}(x_i)\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#conditional-pmfs",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#conditional-pmfs",
    "title": "Lesson 11: Joint distributions",
    "section": "Conditional pmf’s",
    "text": "Conditional pmf’s\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?\n\n\n\n\n\nRemark:\n\nTo show that \\(X\\) and \\(Y\\) are not independent, we just need to find one counter example\nHowever, to show that they are independent, we need to verify this for all possible pairs of \\(x\\) and \\(y\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#learning-objectives-1",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#learning-objectives-1",
    "title": "Lesson 11: Joint distributions",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nSolve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#double-integrals-mini-lesson-13",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#double-integrals-mini-lesson-13",
    "title": "Lesson 11: Joint distributions",
    "section": "Double Integrals Mini Lesson (1/3)",
    "text": "Double Integrals Mini Lesson (1/3)\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 1\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} xy dydx\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#double-integrals-mini-lesson-23",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#double-integrals-mini-lesson-23",
    "title": "Lesson 11: Joint distributions",
    "section": "Double Integrals Mini Lesson (2/3)",
    "text": "Double Integrals Mini Lesson (2/3)\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 2\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} (x+y) dydx\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#double-integrals-mini-lesson-33",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#double-integrals-mini-lesson-33",
    "title": "Lesson 11: Joint distributions",
    "section": "Double Integrals Mini Lesson (3/3)",
    "text": "Double Integrals Mini Lesson (3/3)\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 3\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} e^{x+y} dydx\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "title": "Lesson 11: Joint distributions",
    "section": "How to define the joint pdf for continuous RVs?",
    "text": "How to define the joint pdf for continuous RVs?\n\n\nFor a single continuous RV \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\), \\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\]\n\nFor two continuous RVs (\\(X\\) and \\(Y\\)), we can define the joint pdf, \\(f_{X,Y}(x,y)\\), such that for all real values \\(a,b, c, d\\) with \\(a \\leq b\\) and \\(c \\leq d\\), \\[\\mathbb{P}(a \\leq X \\leq b, c \\leq Y \\leq d) = \\int_a^b \\int_c^d f_{X,Y}(x,y)dydx\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#important-properties-of-the-joint-pdf",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#important-properties-of-the-joint-pdf",
    "title": "Lesson 11: Joint distributions",
    "section": "Important properties of the joint pdf",
    "text": "Important properties of the joint pdf\n\nNote that \\(f_{X,Y}(x,y)\\neq \\mathbb{P}(X=x, Y=y)\\)!!!\nIn order for \\(f_{X,Y}(x,y)\\) to be a pdf, it needs to satisfy the properties\n\n\\(f_{X,Y}(x,y)\\geq 0\\) for all \\(x,y\\)\n\\(\\displaystyle\\int_{-\\infty}^{\\infty}\\displaystyle\\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dxdy=1\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#what-is-the-joint-cumulative-distribution-function",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#what-is-the-joint-cumulative-distribution-function",
    "title": "Lesson 11: Joint distributions",
    "section": "What is the joint cumulative distribution function?",
    "text": "What is the joint cumulative distribution function?\n\n\nDefinition: Joint cumulative distribution function (Joint CDF)\n\n\nThe joint cumulative distribution function (cdf) of continuous random variables \\(X\\) and \\(Y\\), is the function \\(F_{X,Y}(x,y)\\), such that for all real values of \\(x\\) and \\(y\\), \\[F_{X,Y}(x,y)= \\mathbb{P}(X \\leq x, Y \\leq y) = \\int_{-\\infty}^x\\int_{-\\infty}^y f_{X,Y}(s,t)dtds\\]\n\n\nRemarks:\n\nThe definition above for \\(F_{X,Y}(x,y)\\) is a function of \\(x\\) and \\(y\\).\nThe joint cdf at the point \\((a,b)\\), is \\[F_{X,Y}(a,b) = \\mathbb{P}(X \\leq a, Y \\leq b) = \\int_{-\\infty}^a\\int_{-\\infty}^b f_{X,Y}(s,t)dtds\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#what-are-the-marginal-pdfs",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#what-are-the-marginal-pdfs",
    "title": "Lesson 11: Joint distributions",
    "section": "What are the marginal pdf’s?",
    "text": "What are the marginal pdf’s?\n\n\nDefinition: Marginal pdf’s\n\n\nSuppose \\(X\\) and \\(Y\\) are continuous RV’s, with joint pdf \\(f_{X,Y}(x,y)\\). Then the marginal probability density functions are \\[\\begin{aligned}\nf_X(x)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dy\\\\\nf_Y(y)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dx\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#common-steps-for-solving-problems",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#common-steps-for-solving-problems",
    "title": "Lesson 11: Joint distributions",
    "section": "Common steps for solving problems",
    "text": "Common steps for solving problems\n\nSet up the domain of the pdf with a picture\n\n \n\nTranslate to needed integrands\n\nFor probability: shade in the area of interest, then translate\nFor expected value: translate domain\n\n\n \n\nSet up integral: \\(dxdy\\) or \\(dydx\\)?\n\n \n\nSolve integral!"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-of-joint-pdf",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-of-joint-pdf",
    "title": "Lesson 11: Joint distributions",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-of-joint-pdf-1",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-of-joint-pdf-1",
    "title": "Lesson 11: Joint distributions",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-of-a-more-complicated-joint-pdf",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-of-a-more-complicated-joint-pdf",
    "title": "Lesson 11: Joint distributions",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-of-a-more-complicated-joint-pdf-1",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-of-a-more-complicated-joint-pdf-1",
    "title": "Lesson 11: Joint distributions",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(\\mathbb{P}(Y &lt; 3)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#lets-complicate-this-even-more",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#lets-complicate-this-even-more",
    "title": "Lesson 11: Joint distributions",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.2\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(M = \\max(X,Y)\\). Find the pdf for \\(M\\), that is \\(f_M(m)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#finding-the-pdf-of-a-transformation",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#finding-the-pdf-of-a-transformation",
    "title": "Lesson 11: Joint distributions",
    "section": "Finding the pdf of a transformation",
    "text": "Finding the pdf of a transformation\n\nLet \\(M\\) be a transformation of \\(X\\) and \\(Y\\)\nWhen we have a transformation of \\(X\\) and \\(Y\\), \\(M\\), we need to follow a specific process to find the pdf of \\(M\\)\n\nWe follow this process:\n\nStart with the joint pdf for \\(X\\) and \\(Y\\)\n\naka \\(f_{X,Y}(x, y)\\)\n\nTranslate the domain of \\(X\\) and \\(Y\\) to \\(M\\)\nFind the CDF of \\(M\\)\n\naka \\(F_M(m)\\) or \\(P(M \\leq m)\\)\n\nTake the derivative of the CDF of \\(M\\) to find the pdf of \\(M\\)\n\naka \\(f_M(m) = \\dfrac{d}{dm}F_M(m)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#lets-complicate-this-even-more-1",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#lets-complicate-this-even-more-1",
    "title": "Lesson 11: Joint distributions",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.3\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(Z = \\min(X,Y)\\). Find the pdf for \\(Z\\), that is \\(f_Z(z)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#lets-complicate-this-even-more-2",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#lets-complicate-this-even-more-2",
    "title": "Lesson 11: Joint distributions",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 3.3\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(Z = \\min(X,Y)\\). Find the pdf for \\(Z\\), that is \\(f_Z(z)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#lets-complicate-this-even-further",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#lets-complicate-this-even-further",
    "title": "Lesson 11: Joint distributions",
    "section": "Let’s complicate this even further!",
    "text": "Let’s complicate this even further!\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 4\n\n\nLet \\(X\\) and \\(Y\\) have joint density \\(f_{X,Y}(x,y)= \\frac85(x+y)\\) in the region \\(0 &lt; x &lt; 1,\\ \\frac12 &lt; y &lt;1\\). Find the pdf of the RV \\(Z\\), where \\(Z=XY\\)."
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#cdf-method",
    "href": "lessons/10_Transformations/10_Transformations.html#cdf-method",
    "title": "Lesson 10: Transformations",
    "section": "Distributions of transformations of random variables",
    "text": "Distributions of transformations of random variables\n\nOften make transformations of RVs\nA function of a random variable is a random variable\n\nIf \\(X\\) is a random variable and \\(g\\) is a function then \\(Y=g(X)\\) is a random variable\nSince \\(g(X)\\) is a random variable it has a distribution\n\nDistribution of \\(g(X)\\) will have a different shape than the distribution of \\(X\\)\nTwo types:\n\nLinear rescalings: \\(g(u) = a + bu\\)\nNonlinear transformations: e.g. \\(g(u) = u^2\\), \\(g(u) = \\log(u)\\)"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#linear-rescaling",
    "href": "lessons/10_Transformations/10_Transformations.html#linear-rescaling",
    "title": "Lesson 10: Transformations",
    "section": "Linear rescaling",
    "text": "Linear rescaling\n\n\nDefinition: Linear Rescaling\n\n\nA linear rescaling is a transformation of the form \\(g(u) = a + bu\\), where \\(a\\) and \\(b\\) are constants\n\n\n\nThus, if we have a random variable, \\(X\\), then a linear rescaling of \\(X\\) could be \\(M = g(X) = a + bX\\)\nFor example, converting temperature from Celsius to Fahrenheit using \\(g(u) = 32 + 1.8u\\) is a linear rescaling."
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#linear",
    "href": "lessons/10_Transformations/10_Transformations.html#linear",
    "title": "Lesson 10: Transformations",
    "section": "linear",
    "text": "linear\nThink of a linear rescaling as just a consistent relabeling of the variable axis; every 1 unit increment in the original scale corresponds to a \\(b\\) unit increment in the linear rescaling.\nSuppose that SAT Math score \\(X\\) follows a Uniform(200, 800) distribution. (It doesn’t but go with in for now). One way to simulate values of \\(X\\) is to simulate values of \\(U\\) from a Uniform(0, 1) distribution and let \\(X = 200 + (800 - 200)U= 200 + 600U\\). Then \\(X\\) is a linear rescaling of \\(U\\), and \\(X\\) takes values in the interval [200, 800]. We can define and simulate values of \\(X\\) in Symbulate. Before looking at the results, sketch a plot of the distribution of \\(X\\) and make an educated guess for its mean and standard deviation."
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#section",
    "href": "lessons/10_Transformations/10_Transformations.html#section",
    "title": "Lesson 10: Transformations",
    "section": "",
    "text": "Therefore, it’s a little more convenient to consider the random variable \\(X=-\\log(1-U)\\) which takes values in \\([0,\\infty)\\). It also turns out, as we saw in earlier, that \\(-\\log(1-u)\\) is the quantile function of the Exponential(1) distribution. We have already seen that \\(X\\) has an Exponential(1) distribution. Now we’ll take a closer look why.\nThe following code defines \\(X\\) and plots a few simulated values.\nNotice that values near 0 occur with higher frequency than larger values. For example, there are many more simulated values of \\(X\\) that lie in the interval \\([0, 1]\\) than in the interval \\([3, 4]\\), even though these intervals both have length 1. Let’s see why this is happening.\n\n\n\n\n\n\n\n\n\n\n\n\nInterval of U\nLength of U interval\nProbability\nInterval of X\nLength of X interval\n\n\n\n\n(0, 0.1)\n\n\n\n\n\n\n(0.1, 0.2)\n\n\n\n\n\n\n(0.2, 0.3)\n\n\n\n\n\n\n(0.3, 0.4)\n\n\n\n\n\n\n(0.4, 0.5)\n\n\n\n\n\n\n(0.5, 0.6)\n\n\n\n\n\n\n(0.6, 0.7)\n\n\n\n\n\n\n(0.7, 0.8)\n\n\n\n\n\n\n(0.8, 0.9)\n\n\n\n\n\n\n(0.9, 1)"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#section-1",
    "href": "lessons/10_Transformations/10_Transformations.html#section-1",
    "title": "Lesson 10: Transformations",
    "section": "",
    "text": "Plug the endpoints into the conversion formula \\(u\\mapsto -\\log(1-u)\\) to find the corresponding \\(X\\) interval. For example, the \\(U\\) interval \\((0.1, 0.2)\\) corresponds to the \\(X\\) interval \\((-\\log(1-0.1), -\\log(1-0.2)) = (0.105, 0.223)\\). Since \\(U\\) has a Uniform(0, 1) distribution the probability is just the length of the \\(U\\) interval.\n\n\n\n\n\n\n\n\n\n\n\n\nInterval of U\nLength of U interval\nProbability\nInterval of X\nLength of X interval\n\n\n\n\n(0, 0.1)\n0.1\n0.1\n(0, 0.105)\n0.105\n\n\n(0.1, 0.2)\n0.1\n0.1\n(0.105, 0.223)\n0.118\n\n\n(0.2, 0.3)\n0.1\n0.1\n(0.223, 0.357)\n0.134\n\n\n(0.3, 0.4)\n0.1\n0.1\n(0.357, 0.511)\n0.154\n\n\n(0.4, 0.5)\n0.1\n0.1\n(0.511, 0.693)\n0.182\n\n\n(0.5, 0.6)\n0.1\n0.1\n(0.693, 0.916)\n0.223\n\n\n(0.6, 0.7)\n0.1\n0.1\n(0.916, 1.204)\n0.288\n\n\n(0.7, 0.8)\n0.1\n0.1\n(1.204, 1.609)\n0.405\n\n\n(0.8, 0.9)\n0.1\n0.1\n(1.609, 2.303)\n0.693\n\n\n(0.9, 1)\n0.1\n0.1\n(2.303, Inf)\nInf"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#section-2",
    "href": "lessons/10_Transformations/10_Transformations.html#section-2",
    "title": "Lesson 10: Transformations",
    "section": "",
    "text": "We see that the logarithmic transformation does not preserve relative interval length. Each of the original intervals of \\(U\\) values has the same length, but the nonlinear logarithmic transformation “stretches out” these intervals in different ways. The probability that \\(U\\) lies in each of these intervals is 0.1. As the transformation stretches the intervals, the 0.1 probability gets “spread” over intervals of different length. Since probability/relative frequency is represented by area in a histogram, if two regions of differing length have the same area, then they must have different heights. Thus the shape of the distribution of \\(X\\) will not be Uniform.\nThe following plot illustrates the results of Example @ref(exm:uniform-log-transform-calcs). Each bar in the top histogram corresponds to the same color bar in the bottom histogram. All bars have area 0.1. In the top histogram, the bins have equal width so the heights are the same. However, in the bottom histogram the bars have different widths but the same area, so they must have different heights, and we start to see where the Exponential(1) shape comes from."
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#section-3",
    "href": "lessons/10_Transformations/10_Transformations.html#section-3",
    "title": "Lesson 10: Transformations",
    "section": "",
    "text": "The following example provides a similar illustration, but from the reverse perspective.\n\n\n\n\n\n\n\n\n\n\n\n\nInterval of X\nLength of X interval\nProbability\nInterval of U\nLength of U interval\n\n\n\n\n(0, 0.5)\n\n\n\n\n\n\n(0.5, 1)\n\n\n\n\n\n\n(1, 1.5)\n\n\n\n\n\n\n(1.5, 2)\n\n\n\n\n\n\n(2, 2.5)\n\n\n\n\n\n\n(2.5, 3)\n\n\n\n\n\n\n(3, 3.5)\n\n\n\n\n\n\n(3.5, 4)\n\n\n\n\n\n\n(4, 4.5)\n\n\n\n\n\n\n(4.5, 5)"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#summary",
    "href": "lessons/10_Transformations/10_Transformations.html#summary",
    "title": "Lesson 10: Transformations",
    "section": "Summary",
    "text": "Summary\n\nA linear rescaling of a random variable does not change the basic shape of its distribution, just the range of possible values.\n\nIt can flip it, widen it, condense it, and/or shift it\n\nRemember, do NOT confuse a random variable with its distribution\n\nThe random variable is the numerical quantity being measured\nThe distribution is the long run pattern of variation of many observed values of the random variable"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#sim-nonlinear",
    "href": "lessons/10_Transformations/10_Transformations.html#sim-nonlinear",
    "title": "Lesson 10: Transformations",
    "section": "Nonlinear transformations of random variables",
    "text": "Nonlinear transformations of random variables\nA linear rescaling does not change the shape of a distribution, only the range of possible values. But what about a nonlinear transformation, like a logarithmic or square root transformation? In contrast to a linear rescaling, a nonlinear rescaling does not preserve relative interval length, so we might expect that a nonlinear rescaling can change the shape of a distribution. We’ll investigate by considering the Uniform(0, 1) spinner and a logarithmic1 transformation.\nLet \\(U\\) represent the result of a single spin of the Uniform(0, 1) spinner. We’ll basically consider \\(\\log(U)\\), but this leads to to two minor technicalities.\n\nSince \\(U\\in[0, 1]\\), \\(\\log(U)\\le 0\\). To obtain positive values we consider \\(-\\log(U)\\), which takes values in \\([0,\\infty)\\).\nTechnically, applying \\(-\\log(u)\\) to the values on the axis of the Uniform(0, 1) spinner, the resulting values would decrease from \\(\\infty\\) to 0 clockwise. To make the values start at 0 and increase to \\(\\infty\\) clockwise, we consider \\(-\\log(1-U)\\). (We saw in the previous section the transformation \\(u \\to 1-u\\) basically just changes direction from clockwise to counterclockwise.)\n\nAs in many other contexts and programming languages, in this text any reference to logarithms or \\(\\log\\) refers to natural (base \\(e\\)) logarithms. In the instances we need to consider another base, we’ll make that explicit."
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#section-4",
    "href": "lessons/10_Transformations/10_Transformations.html#section-4",
    "title": "Lesson 10: Transformations",
    "section": "",
    "text": "The corresponding \\(U\\) intervals are obtained by applying the inverse transformation \\(v\\mapsto 1-e^{-v}\\). For example, the \\(X\\) interval \\((0.5, 1)\\) corresponds to the \\(U\\) interval \\((1-e^{-0.5}, 1-e^{-1}) = (0.393, 0.632)\\).\n\n\n\n\n\n\n\n\n\n\n\n\nInterval of X\nLength of X interval\nProbability\nInterval of U\nLength of U interval\n\n\n\n\n(0, 0.5)\n0.5\n0.393\n(0, 0.393)\n0.393\n\n\n(0.5, 1)\n0.5\n0.239\n(0.393, 0.632)\n0.239\n\n\n(1, 1.5)\n0.5\n0.145\n(0.632, 0.777)\n0.145\n\n\n(1.5, 2)\n0.5\n0.088\n(0.777, 0.865)\n0.088\n\n\n(2, 2.5)\n0.5\n0.053\n(0.865, 0.918)\n0.053\n\n\n(2.5, 3)\n0.5\n0.032\n(0.918, 0.95)\n0.032\n\n\n(3, 3.5)\n0.5\n0.020\n(0.95, 0.97)\n0.020\n\n\n(3.5, 4)\n0.5\n0.012\n(0.97, 0.982)\n0.012\n\n\n(4, 4.5)\n0.5\n0.007\n(0.982, 0.989)\n0.007\n\n\n(4.5, 5)\n0.5\n0.004\n(0.989, 0.993)\n0.004\n\n\n\n\n\nSince \\(U\\) has a Uniform(0, 1) distribution the probability is just the length of the \\(U\\) interval. Each of the \\(X\\) intervals has the same length but they correspond to intervals of differing length in the original \\(U\\) scale, and hence intervals of different probability."
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#section-5",
    "href": "lessons/10_Transformations/10_Transformations.html#section-5",
    "title": "Lesson 10: Transformations",
    "section": "",
    "text": "The following plot illustrates the results of Example @ref(exm:uniform-log-transform-calcs2) (plots on the right). These two examples give some insight into how the transformed random variable \\(X = -\\log(1-U)\\) has an Exponential(1) distribution.\n\n“Spreadsheet” calculations like those in the previous two examples can help when sketching the distribution of a transformed random variable.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor a linear rescaling, we could just plug the mean of the original variable into the conversion formula to find the mean of the transformed variable. However, this will not work for nonlinear transformations."
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#section-6",
    "href": "lessons/10_Transformations/10_Transformations.html#section-6",
    "title": "Lesson 10: Transformations",
    "section": "",
    "text": "We know that since \\(U\\) has a Uniform(0, 1) distribution its long run average value is 0.5, and since \\(X\\) has an Exponential(1) distribution its long run average value is 1, but \\(-\\log(1 - 0.5) \\neq 1\\). The nonlinear “stretching” of the axis makes some value relatively larger and others relatively smaller than they were on the original scale, which influences the average. Remember, in general: whether in the short run or the long run \\[\\text{Average of } g(X) \\neq g(\\text{Average of }X)\\]\nRecall that a function of a random variable is also a random variable. If \\(X\\) is a random variable, then \\(Y=g(X)\\) is also a random variable and so it has a probability distribution. Unless \\(g\\) represents a linear rescaling, a transformation will change the shape of the distribution. So the question is: what is the distribution of \\(g(X)\\)? We’ll focus on transformations of continuous random variables, in which case the key to answering the question is to work with cdfs.\n\nIdentify the possible values of \\(X\\). (We have done this already, but this should always be your first step.)\nLet \\(F_X\\) denote the cdf of \\(X\\). Find \\(F_X(1)\\).\nFind \\(F_X(2)\\).\nFind the cdf \\(F_X(x)\\).\nFind the pdf \\(f_X(x)\\).\nWhy should we not be surprised that \\(X=-\\log(1-U)\\) has cdf \\(F_X(x) = 1 - e^{-x}\\)? Hint: what is the function \\(u\\mapsto -\\log(1-u)\\) in this case?\n\n(ref:cap-log-function-plot) A plot of the function \\(u\\mapsto -\\log(1-u)\\). The dotted lines illustrate that \\(-\\log(1-u)\\le 1\\) if and only if \\(u\\le 1-e^{-1}\\approx 0.632\\).\n\n(ref:cap-log-function-plot)"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#section-7",
    "href": "lessons/10_Transformations/10_Transformations.html#section-7",
    "title": "Lesson 10: Transformations",
    "section": "",
    "text": "The following example provides a similar illustration, but from the reverse perspective.\n\n\n\n\n\n\n\n\n\n\n\n\nInterval of X\nLength of X interval\nProbability\nInterval of U\nLength of U interval\n\n\n\n\n(0, 0.5)\n\n\n\n\n\n\n(0.5, 1)\n\n\n\n\n\n\n(1, 1.5)\n\n\n\n\n\n\n(1.5, 2)\n\n\n\n\n\n\n(2, 2.5)\n\n\n\n\n\n\n(2.5, 3)\n\n\n\n\n\n\n(3, 3.5)\n\n\n\n\n\n\n(3.5, 4)\n\n\n\n\n\n\n(4, 4.5)\n\n\n\n\n\n\n(4.5, 5)"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#section-8",
    "href": "lessons/10_Transformations/10_Transformations.html#section-8",
    "title": "Lesson 10: Transformations",
    "section": "",
    "text": "The corresponding \\(U\\) intervals are obtained by applying the inverse transformation \\(v\\mapsto 1-e^{-v}\\). For example, the \\(X\\) interval \\((0.5, 1)\\) corresponds to the \\(U\\) interval \\((1-e^{-0.5}, 1-e^{-1}) = (0.393, 0.632)\\).\n\n\n\n\n\n\n\n\n\n\n\n\nInterval of X\nLength of X interval\nProbability\nInterval of U\nLength of U interval\n\n\n\n\n(0, 0.5)\n0.5\n0.393\n(0, 0.393)\n0.393\n\n\n(0.5, 1)\n0.5\n0.239\n(0.393, 0.632)\n0.239\n\n\n(1, 1.5)\n0.5\n0.145\n(0.632, 0.777)\n0.145\n\n\n(1.5, 2)\n0.5\n0.088\n(0.777, 0.865)\n0.088\n\n\n(2, 2.5)\n0.5\n0.053\n(0.865, 0.918)\n0.053\n\n\n(2.5, 3)\n0.5\n0.032\n(0.918, 0.95)\n0.032\n\n\n(3, 3.5)\n0.5\n0.020\n(0.95, 0.97)\n0.020\n\n\n(3.5, 4)\n0.5\n0.012\n(0.97, 0.982)\n0.012\n\n\n(4, 4.5)\n0.5\n0.007\n(0.982, 0.989)\n0.007\n\n\n(4.5, 5)\n0.5\n0.004\n(0.989, 0.993)\n0.004\n\n\n\n\n\nSince \\(U\\) has a Uniform(0, 1) distribution the probability is just the length of the \\(U\\) interval. Each of the \\(X\\) intervals has the same length but they correspond to intervals of differing length in the original \\(U\\) scale, and hence intervals of different probability."
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#section-9",
    "href": "lessons/10_Transformations/10_Transformations.html#section-9",
    "title": "Lesson 10: Transformations",
    "section": "",
    "text": "The following plot illustrates the results of Example @ref(exm:uniform-log-transform-calcs2) (plots on the right). These two examples give some insight into how the transformed random variable \\(X = -\\log(1-U)\\) has an Exponential(1) distribution.\n\n“Spreadsheet” calculations like those in the previous two examples can help when sketching the distribution of a transformed random variable.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor a linear rescaling, we could just plug the mean of the original variable into the conversion formula to find the mean of the transformed variable. However, this will not work for nonlinear transformations."
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#section-10",
    "href": "lessons/10_Transformations/10_Transformations.html#section-10",
    "title": "Lesson 10: Transformations",
    "section": "",
    "text": "We know that since \\(U\\) has a Uniform(0, 1) distribution its long run average value is 0.5, and since \\(X\\) has an Exponential(1) distribution its long run average value is 1, but \\(-\\log(1 - 0.5) \\neq 1\\). The nonlinear “stretching” of the axis makes some value relatively larger and others relatively smaller than they were on the original scale, which influences the average. Remember, in general: whether in the short run or the long run \\[\\text{Average of } g(X) \\neq g(\\text{Average of }X)\\]\nRecall that a function of a random variable is also a random variable. If \\(X\\) is a random variable, then \\(Y=g(X)\\) is also a random variable and so it has a probability distribution. Unless \\(g\\) represents a linear rescaling, a transformation will change the shape of the distribution. So the question is: what is the distribution of \\(g(X)\\)? We’ll focus on transformations of continuous random variables, in which case the key to answering the question is to work with cdfs.\n\nIdentify the possible values of \\(X\\). (We have done this already, but this should always be your first step.)\nLet \\(F_X\\) denote the cdf of \\(X\\). Find \\(F_X(1)\\).\nFind \\(F_X(2)\\).\nFind the cdf \\(F_X(x)\\).\nFind the pdf \\(f_X(x)\\).\nWhy should we not be surprised that \\(X=-\\log(1-U)\\) has cdf \\(F_X(x) = 1 - e^{-x}\\)? Hint: what is the function \\(u\\mapsto -\\log(1-u)\\) in this case?\n\n(ref:cap-log-function-plot) A plot of the function \\(u\\mapsto -\\log(1-u)\\). The dotted lines illustrate that \\(-\\log(1-u)\\le 1\\) if and only if \\(u\\le 1-e^{-1}\\approx 0.632\\).\n\n(ref:cap-log-function-plot)"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#section-11",
    "href": "lessons/10_Transformations/10_Transformations.html#section-11",
    "title": "Lesson 10: Transformations",
    "section": "",
    "text": "If \\(X\\) is a continuous random variable whose distribution is known, the cdf method can be used to find the pdf of \\(Y=g(X)\\)\n\nDetermine the possible values of \\(Y\\). Let \\(y\\) represent a generic possible value of \\(Y\\).\nThe cdf of \\(Y\\) is \\(F_Y(y) = \\IP(Y\\le y) = \\IP(g(X) \\le y)\\).\nRearrange \\(\\{g(X) \\le y\\}\\) to get an event involving \\(X\\). Warning: it is not always \\(\\{X \\le g^{-1}(y)\\}\\). Sketching a picture of the function \\(g\\) helps.\nObtain an expression for the cdf of \\(Y\\) which involves \\(F_X\\) and some transformation of the value \\(y\\).\nDifferentiate the expression for \\(F_Y(y)\\) with respect to \\(y\\), and use what is known about \\(F'_X = f_X\\), to obtain the pdf of \\(Y\\). You will typically need to apply the chain rule when differentiating.\n\nYou will need to use information about \\(X\\) at some point in the last step above. You can either:\n\nPlug in the cdf of \\(X\\) and then differentiate with respect to \\(y\\).\nDifferentiate with respect to \\(y\\) and then plug in the pdf of \\(X\\).\n\nEither way gets you to the correct answer, but depending on the problem one way might be easier than the other. We’ll illustrate both methods in the next example.\n\nIdentify the possible values of \\(Y\\).\nSketch the pdf of \\(Y\\). Hint: consider a few equally spaced intervals of \\(Y\\) values and see what \\(X\\) values they correspond to.\nRun a simulation to approximate the pdf of \\(Y\\).\nFind \\(F_Y(0.49)\\).\nUse the cdf method to find the pdf of \\(Y\\). Is the pdf consistent with your simulation results?\n\n(ref:cap-square-function-plot) A plot of the function \\(x\\mapsto x^2\\) for \\(-1&lt;x&lt;1\\). The dotted lines illustrate that \\(x^2\\le 0.49\\) if and only if \\(-\\sqrt{0.49}\\le x\\le \\sqrt{0.49}\\).\n\n(ref:cap-square-function-plot)The table below helps us see how the transformation \\(Y = X^2\\) “pushes” density towards 0 if \\(X\\) has a Uniform(-1, 1) distribution.\n\n\n\n\n\nY interval\nX interval\nLength of X interval\nProbability\nLength of Y interval\nHeight of Y interval\n\n\n\n\n(0, 0.1)\n(-0.3162, 0) U (0,0.3162)\n0.6324\n0.3162\n0.1\n3.162\n\n\n(0.1, 0.2)\n(-0.4472, -0.3162) U (0.3162,0.4472)\n0.2620\n0.1310\n0.1\n1.310\n\n\n(0.2, 0.3)\n(-0.5477, -0.4472) U (0.4472,0.5477)\n0.2010\n0.1005\n0.1\n1.005\n\n\n(0.3, 0.4)\n(-0.6325, -0.5477) U (0.5477,0.6325)\n0.1696\n0.0848\n0.1\n0.848\n\n\n(0.4, 0.5)\n(-0.7071, -0.6325) U (0.6325,0.7071)\n0.1492\n0.0746\n0.1\n0.746\n\n\n(0.5, 0.6)\n(-0.7746, -0.7071) U (0.7071,0.7746)\n0.1350\n0.0675\n0.1\n0.675\n\n\n(0.6, 0.7)\n(-0.8367, -0.7746) U (0.7746,0.8367)\n0.1242\n0.0621\n0.1\n0.621\n\n\n(0.7, 0.8)\n(-0.8944, -0.8367) U (0.8367,0.8944)\n0.1154\n0.0577\n0.1\n0.577\n\n\n(0.8, 0.9)\n(-0.9487, -0.8944) U (0.8944,0.9487)\n0.1086\n0.0543\n0.1\n0.543\n\n\n(0.9, 1)\n(-1, -0.9487) U (0.9487,1)\n0.1026\n0.0513\n0.1\n0.513\n\n\n\n\n\nWe can use the table to sketch a histogram.\nIf we continued the above process with narrower and narrower \\(Y\\) intervals we would arrive at the smooth pdf given by \\(f_Y(y) = \\frac{1}{2\\sqrt{y}}, 0&lt;y&lt;1\\); see the black curve in the plot below.\nNow we’ll approximate the pdf via simulation. The density blows up at 0 so it’s hard for the chunky histogram to capture that, but we see the simulated values follow a distribution described by the smooth \\(f_Y(y) = \\frac{1}{2\\sqrt{y}}, 0&lt;y&lt;1\\) in the black curve."
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#finding-the-pdf-of-a-transformation",
    "href": "lessons/10_Transformations/10_Transformations.html#finding-the-pdf-of-a-transformation",
    "title": "Lesson 10: Transformations",
    "section": "Finding the pdf of a transformation",
    "text": "Finding the pdf of a transformation\n\nLet \\(M\\) be a transformation of \\(X\\): \\(M = g(X)\\)\nWhen we have a transformation of \\(X\\), \\(M\\), we need to follow the CDF method to find the pdf of \\(M\\)\n\nWe follow CDF method:\n\nStart with the pdf for \\(X\\)\n\naka \\(f_{X}(x)\\)\n\nTranslate the domain of \\(X\\) to \\(M\\): find the possible values of \\(M\\)\nFind the CDF of \\(M\\)\n\naka \\(F_M(m) = P(M \\leq m) = P(g(X) \\leq m)\\)\nWill require manipulating \\(g(X) \\leq m\\) in terms of \\(X\\) (aka \\(X\\) alone on the left side)\n\nTake the derivative of the CDF of \\(M\\) with respect to \\(m\\) to find the pdf of \\(M\\)\n\naka \\(f_M(m) = \\dfrac{d}{dm}F_M(m)\\)"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#cdf-method-1",
    "href": "lessons/10_Transformations/10_Transformations.html#cdf-method-1",
    "title": "Lesson 10: Transformations",
    "section": "CDF Method",
    "text": "CDF Method\nIf \\(X\\) is a continuous random variable whose distribution is known, the cdf method can be used to find the pdf of \\(Y=g(X)\\)\n\nDetermine the possible values of \\(Y\\). Let \\(y\\) represent a generic possible value of \\(Y\\).\nThe cdf of \\(Y\\) is \\(F_Y(y) = \\IP(Y\\le y) = \\IP(g(X) \\le y)\\).\nRearrange \\(\\{g(X) \\le y\\}\\) to get an event involving \\(X\\). Warning: it is not always \\(\\{X \\le g^{-1}(y)\\}\\). Sketching a picture of the function \\(g\\) helps.\nObtain an expression for the cdf of \\(Y\\) which involves \\(F_X\\) and some transformation of the value \\(y\\).\nDifferentiate the expression for \\(F_Y(y)\\) with respect to \\(y\\), and use what is known about \\(F'_X = f_X\\), to obtain the pdf of \\(Y\\). You will typically need to apply the chain rule when differentiating.\n\nYou will need to use information about \\(X\\) at some point in the last step above. You can either:\n\nPlug in the cdf of \\(X\\) and then differentiate with respect to \\(y\\).\nDifferentiate with respect to \\(y\\) and then plug in the pdf of \\(X\\).\n\nEither way gets you to the correct answer, but depending on the problem one way might be easier than the other."
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#example",
    "href": "lessons/10_Transformations/10_Transformations.html#example",
    "title": "Lesson 10: Transformations",
    "section": "Example",
    "text": "Example\nLet \\(X\\) be a random variable with a Uniform(-1, 1) distribution and Let \\(Y = X^2\\).\n\nIdentify the possible values of \\(Y\\).\nSketch the pdf of \\(Y\\). Hint: consider a few equally spaced intervals of \\(Y\\) values and see what \\(X\\) values they correspond to.\nRun a simulation to approximate the pdf of \\(Y\\).\nFind \\(F_Y(0.49)\\).\nUse the cdf method to find the pdf of \\(Y\\). Is the pdf consistent with your simulation results?\n\n(ref:cap-square-function-plot) A plot of the function \\(x\\mapsto x^2\\) for \\(-1&lt;x&lt;1\\). The dotted lines illustrate that \\(x^2\\le 0.49\\) if and only if \\(-\\sqrt{0.49}\\le x\\le \\sqrt{0.49}\\).\n\nThe table below helps us see how the transformation \\(Y = X^2\\) “pushes” density towards 0 if \\(X\\) has a Uniform(-1, 1) distribution.\n\n\n\n\n\nY interval\nX interval\nLength of X interval\nProbability\nLength of Y interval\nHeight of Y interval\n\n\n\n\n(0, 0.1)\n(-0.3162, 0) U (0,0.3162)\n0.6324\n0.3162\n0.1\n3.162\n\n\n(0.1, 0.2)\n(-0.4472, -0.3162) U (0.3162,0.4472)\n0.2620\n0.1310\n0.1\n1.310\n\n\n(0.2, 0.3)\n(-0.5477, -0.4472) U (0.4472,0.5477)\n0.2010\n0.1005\n0.1\n1.005\n\n\n(0.3, 0.4)\n(-0.6325, -0.5477) U (0.5477,0.6325)\n0.1696\n0.0848\n0.1\n0.848\n\n\n(0.4, 0.5)\n(-0.7071, -0.6325) U (0.6325,0.7071)\n0.1492\n0.0746\n0.1\n0.746\n\n\n(0.5, 0.6)\n(-0.7746, -0.7071) U (0.7071,0.7746)\n0.1350\n0.0675\n0.1\n0.675\n\n\n(0.6, 0.7)\n(-0.8367, -0.7746) U (0.7746,0.8367)\n0.1242\n0.0621\n0.1\n0.621\n\n\n(0.7, 0.8)\n(-0.8944, -0.8367) U (0.8367,0.8944)\n0.1154\n0.0577\n0.1\n0.577\n\n\n(0.8, 0.9)\n(-0.9487, -0.8944) U (0.8944,0.9487)\n0.1086\n0.0543\n0.1\n0.543\n\n\n(0.9, 1)\n(-1, -0.9487) U (0.9487,1)\n0.1026\n0.0513\n0.1\n0.513\n\n\n\n\n\nWe can use the table to sketch a histogram.\nIf we continued the above process with narrower and narrower \\(Y\\) intervals we would arrive at the smooth pdf given by \\(f_Y(y) = \\frac{1}{2\\sqrt{y}}, 0&lt;y&lt;1\\); see the black curve in the plot below.\nNow we’ll approximate the pdf via simulation. The density blows up at 0 so it’s hard for the chunky histogram to capture that, but we see the simulated values follow a distribution described by the smooth \\(f_Y(y) = \\frac{1}{2\\sqrt{y}}, 0&lt;y&lt;1\\) in the black curve."
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#types-of-transformations",
    "href": "lessons/10_Transformations/10_Transformations.html#types-of-transformations",
    "title": "Lesson 10: Transformations",
    "section": "Types of transformations",
    "text": "Types of transformations\n\nLinear rescaling\nNonlinear transformations"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#uniform-distribution",
    "href": "lessons/10_Transformations/10_Transformations.html#uniform-distribution",
    "title": "Lesson 10: Transformations",
    "section": "Uniform distribution",
    "text": "Uniform distribution\n\n\nExample 1: Linear rescaling of \\(U\\)\n\n\nLet \\(U\\) be a random variable with \\(f_U(u)= 4u^3\\) for \\(0\\leq u \\leq 1\\). Define \\(V=1-U\\)\n\nWhat are the possible values of \\(V\\)?\nIs \\(V\\) the same random variable as \\(U\\)?\nFind \\(P(U \\le 0.1)\\) and \\(P(V \\le 0.1)\\).\nSketch a plot of what the histogram of many simulated values of \\(V\\) would look like.\nDoes \\(V\\) have the same distribution as \\(U\\)?"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#standard-normal-example",
    "href": "lessons/10_Transformations/10_Transformations.html#standard-normal-example",
    "title": "Lesson 10: Transformations",
    "section": "Standard Normal Example",
    "text": "Standard Normal Example\nIn general, if \\(Z\\) has a Normal(0, 1) distribution then \\(X = \\mu + \\sigma Z\\) has a Normal(\\(\\mu\\), \\(\\sigma\\)) distribution.\n\nIs \\(Y\\) the same random variable as \\(X\\)?\nDoes \\(Y\\) have the same distribution as \\(X\\)?\nDonny Don’t says that the distribution of \\(-Z\\) will look like an “upside-down bell”. Is Donny correct? If not, explain why not and describe the distribution of \\(-Z\\).\nDonny Don’t says that the standard deviation of \\(-Z\\) is -1. Is Donny correct? If not, explain why not and determine the standard deviation of \\(-Z\\)."
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#nonlinear-transformations",
    "href": "lessons/10_Transformations/10_Transformations.html#nonlinear-transformations",
    "title": "Lesson 10: Transformations",
    "section": "Nonlinear transformations",
    "text": "Nonlinear transformations\n\nWhat happens when we make a nonlinear transformation, like a logarithmic or square root transformation?\nNonlinear transformations do not necessarily preserve the distribution shape\nExamples of nonlinear transformations:\n\n\\(g(u) = u^2\\)\n\\(g(u) = \\sqrt{u}\\)\n\\(g(u) = \\log(u)\\)\n\\(g(u) = e^u\\)\n\\(g(u) = \\dfrac{1}{u}\\)"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#example-1",
    "href": "lessons/10_Transformations/10_Transformations.html#example-1",
    "title": "Lesson 10: Transformations",
    "section": "Example",
    "text": "Example\nWe’ll illustrate both methods in the next example.\n\nIdentify the possible values of \\(Y\\).\nSketch the pdf of \\(Y\\). Hint: consider a few equally spaced intervals of \\(Y\\) values and see what \\(X\\) values they correspond to.\nRun a simulation to approximate the pdf of \\(Y\\).\nFind \\(F_Y(0.49)\\).\nUse the cdf method to find the pdf of \\(Y\\). Is the pdf consistent with your simulation results?\n\n(ref:cap-square-function-plot) A plot of the function \\(x\\mapsto x^2\\) for \\(-1&lt;x&lt;1\\). The dotted lines illustrate that \\(x^2\\le 0.49\\) if and only if \\(-\\sqrt{0.49}\\le x\\le \\sqrt{0.49}\\).\n\n(ref:cap-square-function-plot)The table below helps us see how the transformation \\(Y = X^2\\) “pushes” density towards 0 if \\(X\\) has a Uniform(-1, 1) distribution.\n\n\n\n\n\nY interval\nX interval\nLength of X interval\nProbability\nLength of Y interval\nHeight of Y interval\n\n\n\n\n(0, 0.1)\n(-0.3162, 0) U (0,0.3162)\n0.6324\n0.3162\n0.1\n3.162\n\n\n(0.1, 0.2)\n(-0.4472, -0.3162) U (0.3162,0.4472)\n0.2620\n0.1310\n0.1\n1.310\n\n\n(0.2, 0.3)\n(-0.5477, -0.4472) U (0.4472,0.5477)\n0.2010\n0.1005\n0.1\n1.005\n\n\n(0.3, 0.4)\n(-0.6325, -0.5477) U (0.5477,0.6325)\n0.1696\n0.0848\n0.1\n0.848\n\n\n(0.4, 0.5)\n(-0.7071, -0.6325) U (0.6325,0.7071)\n0.1492\n0.0746\n0.1\n0.746\n\n\n(0.5, 0.6)\n(-0.7746, -0.7071) U (0.7071,0.7746)\n0.1350\n0.0675\n0.1\n0.675\n\n\n(0.6, 0.7)\n(-0.8367, -0.7746) U (0.7746,0.8367)\n0.1242\n0.0621\n0.1\n0.621\n\n\n(0.7, 0.8)\n(-0.8944, -0.8367) U (0.8367,0.8944)\n0.1154\n0.0577\n0.1\n0.577\n\n\n(0.8, 0.9)\n(-0.9487, -0.8944) U (0.8944,0.9487)\n0.1086\n0.0543\n0.1\n0.543\n\n\n(0.9, 1)\n(-1, -0.9487) U (0.9487,1)\n0.1026\n0.0513\n0.1\n0.513\n\n\n\n\n\nWe can use the table to sketch a histogram.\nIf we continued the above process with narrower and narrower \\(Y\\) intervals we would arrive at the smooth pdf given by \\(f_Y(y) = \\frac{1}{2\\sqrt{y}}, 0&lt;y&lt;1\\); see the black curve in the plot below.\nNow we’ll approximate the pdf via simulation. The density blows up at 0 so it’s hard for the chunky histogram to capture that, but we see the simulated values follow a distribution described by the smooth \\(f_Y(y) = \\frac{1}{2\\sqrt{y}}, 0&lt;y&lt;1\\) in the black curve."
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#sim-linear-rescaling",
    "href": "lessons/10_Transformations/10_Transformations.html#sim-linear-rescaling",
    "title": "Lesson 10: Transformations",
    "section": "Example of linear rescaling (4/4)",
    "text": "Example of linear rescaling (4/4)\n\n\nExample 1: Linear rescaling of \\(U\\)\n\n\nLet \\(U\\) be a random variable with \\(f_U(u)= \\dfrac{4}{15}u^3\\) for \\(1\\leq u \\leq 2\\). Define \\(V=1-U\\)\n\nFind the pdf of \\(V\\).\nDoes \\(V\\) have the same distribution as \\(U\\)?"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#example-of-nonlinear-transformation-14",
    "href": "lessons/10_Transformations/10_Transformations.html#example-of-nonlinear-transformation-14",
    "title": "Lesson 10: Transformations",
    "section": "Example of nonlinear transformation (1/4)",
    "text": "Example of nonlinear transformation (1/4)\n\n\nExample 2: Nonlinear transformation of \\(U\\)\n\n\nLet \\(U\\) be a random variable with \\(f_U(u)= \\dfrac{4}{15}u^3\\) for \\(1\\leq u \\leq 2\\). Define \\(V=\\log(U)\\)\n\nWhat are the possible values of \\(V\\)?\nFind the CDF of \\(V\\)\nFind the pdf of \\(V\\)"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#example-of-nonlinear-transformation-24",
    "href": "lessons/10_Transformations/10_Transformations.html#example-of-nonlinear-transformation-24",
    "title": "Lesson 10: Transformations",
    "section": "Example of nonlinear transformation (2/4)",
    "text": "Example of nonlinear transformation (2/4)\n\n\nExample 2: Nonlinear transformation of \\(U\\)\n\n\nLet \\(U\\) be a random variable with \\(f_U(u)= \\dfrac{4}{15}u^3\\) for \\(1\\leq u \\leq 2\\). Define \\(V=\\log(U)\\)\n\nWhat are the possible values of \\(V\\)?"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#example-of-nonlinear-transformation-34",
    "href": "lessons/10_Transformations/10_Transformations.html#example-of-nonlinear-transformation-34",
    "title": "Lesson 10: Transformations",
    "section": "Example of nonlinear transformation (3/4)",
    "text": "Example of nonlinear transformation (3/4)\n\n\nExample 2: Nonlinear transformation of \\(U\\)\n\n\nLet \\(U\\) be a random variable with \\(f_U(u)= \\dfrac{4}{15}u^3\\) for \\(1\\leq u \\leq 2\\). Define \\(V=\\log(U)\\)\n\nFind the CDF of \\(V\\)"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#example-of-nonlinear-transformation-44",
    "href": "lessons/10_Transformations/10_Transformations.html#example-of-nonlinear-transformation-44",
    "title": "Lesson 10: Transformations",
    "section": "Example of nonlinear transformation (4/4)",
    "text": "Example of nonlinear transformation (4/4)\n\n\nExample 2: Nonlinear transformation of \\(U\\)\n\n\nLet \\(U\\) be a random variable with \\(f_U(u)= \\dfrac{4}{15}u^3\\) for \\(1\\leq u \\leq 2\\). Define \\(V=\\log(U)\\)\n\nFind the pdf of \\(V\\)"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#example-of-nonlinear-transformation-domain",
    "href": "lessons/10_Transformations/10_Transformations.html#example-of-nonlinear-transformation-domain",
    "title": "Lesson 10: Transformations",
    "section": "Example of nonlinear transformation: domain",
    "text": "Example of nonlinear transformation: domain\n\n\nExample 3: Nonlinear transformation of \\(X\\)\n\n\nLet \\(X\\) be a random variable with \\(f_X(x)= \\dfrac{1}{2}\\) for \\(-1\\leq x \\leq 1\\). Define \\(Y=X^2\\)\n\nWhat are the possible values of \\(V\\)?\nFind the CDF of \\(V\\)\nFind the pdf of \\(V\\)"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#example-of-nonlinear-transformation-domain-14",
    "href": "lessons/10_Transformations/10_Transformations.html#example-of-nonlinear-transformation-domain-14",
    "title": "Lesson 10: Transformations",
    "section": "Example of nonlinear transformation: domain (1/4)",
    "text": "Example of nonlinear transformation: domain (1/4)\n\n\nExample 3: Nonlinear transformation of \\(X\\)\n\n\nLet \\(X\\) be a random variable with \\(f_X(x)= \\dfrac{1}{2}\\) for \\(-1\\leq x \\leq 1\\). Define \\(Y=X^2\\)\n\nWhat are the possible values of \\(Y\\)?\nFind the CDF of \\(Y\\)\nFind the pdf of \\(Y\\)"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#example-of-nonlinear-transformation-domain-24",
    "href": "lessons/10_Transformations/10_Transformations.html#example-of-nonlinear-transformation-domain-24",
    "title": "Lesson 10: Transformations",
    "section": "Example of nonlinear transformation: domain (2/4)",
    "text": "Example of nonlinear transformation: domain (2/4)\n\n\nExample 3: Nonlinear transformation of \\(X\\)\n\n\nLet \\(X\\) be a random variable with \\(f_X(x)= \\dfrac{1}{2}\\) for \\(-1\\leq x \\leq 1\\). Define \\(Y=X^2\\)\n\nWhat are the possible values of \\(Y\\)?"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#example-of-nonlinear-transformation-domain-34",
    "href": "lessons/10_Transformations/10_Transformations.html#example-of-nonlinear-transformation-domain-34",
    "title": "Lesson 10: Transformations",
    "section": "Example of nonlinear transformation: domain (3/4)",
    "text": "Example of nonlinear transformation: domain (3/4)\n\n\nExample 3: Nonlinear transformation of \\(X\\)\n\n\nLet \\(X\\) be a random variable with \\(f_X(x)= \\dfrac{1}{2}\\) for \\(-1\\leq x \\leq 1\\). Define \\(Y=X^2\\)\n\nFind the CDF of \\(Y\\)"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#example-of-nonlinear-transformation-domain-44",
    "href": "lessons/10_Transformations/10_Transformations.html#example-of-nonlinear-transformation-domain-44",
    "title": "Lesson 10: Transformations",
    "section": "Example of nonlinear transformation: domain (4/4)",
    "text": "Example of nonlinear transformation: domain (4/4)\n\n\nExample 3: Nonlinear transformation of \\(X\\)\n\n\nLet \\(X\\) be a random variable with \\(f_X(x)= \\dfrac{1}{2}\\) for \\(-1\\leq x \\leq 1\\). Define \\(Y=X^2\\)\n\nFind the pdf of \\(Y\\)"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#summary-of-linear-rescaling",
    "href": "lessons/10_Transformations/10_Transformations.html#summary-of-linear-rescaling",
    "title": "Lesson 10: Transformations",
    "section": "Summary of linear rescaling",
    "text": "Summary of linear rescaling\n\nA linear rescaling of a random variable does not change the basic shape of its distribution, just the range of possible values.\n\nIt can flip it, widen it, condense it, and/or shift it\n\nRemember, do NOT confuse a random variable with its distribution\n\nThe random variable is the numerical quantity being measured\nThe distribution is the long run pattern of variation of many observed values of the random variable"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations.html#summary-of-nonlinear-transformations",
    "href": "lessons/10_Transformations/10_Transformations.html#summary-of-nonlinear-transformations",
    "title": "Lesson 10: Transformations",
    "section": "Summary of nonlinear transformations",
    "text": "Summary of nonlinear transformations\n\nNonlinear transformations can change the shape of a distribution\nAlways use the CDF method to find the pdf of a nonlinear transformation of a random variable\nRemember to carefully determine the possible values of the transformed random variable"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Transformations.html",
    "href": "lessons/11_Joint_distributions/11_Transformations.html",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "",
    "text": "Calculate probabilities for a pair of discrete random variables\nCalculate a joint, marginal, and conditional probability mass function (pmf)\nCalculate a joint, marginal, and conditional cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Transformations.html#learning-objectives",
    "href": "lessons/11_Joint_distributions/11_Transformations.html#learning-objectives",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "",
    "text": "Calculate probabilities for a pair of discrete random variables\nCalculate a joint, marginal, and conditional probability mass function (pmf)\nCalculate a joint, marginal, and conditional cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Transformations.html#where-are-we",
    "href": "lessons/11_Joint_distributions/11_Transformations.html#where-are-we",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Transformations.html#what-is-a-joint-pmf",
    "href": "lessons/11_Joint_distributions/11_Transformations.html#what-is-a-joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is a joint pmf?",
    "text": "What is a joint pmf?\n\n\nDefinition: joint pmf\n\n\nThe joint pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[p_{X,Y}(x,y) = \\mathbb{P}(X=x\\ and\\ Y=y) = \\mathbb{P}(X=x, Y=y)\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Transformations.html#this-chapters-main-example",
    "href": "lessons/11_Joint_distributions/11_Transformations.html#this-chapters-main-example",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "This chapter’s main example",
    "text": "This chapter’s main example\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Transformations.html#joint-pmf",
    "href": "lessons/11_Joint_distributions/11_Transformations.html#joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Joint pmf",
    "text": "Joint pmf\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Transformations.html#marginal-pmfs",
    "href": "lessons/11_Joint_distributions/11_Transformations.html#marginal-pmfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Marginal pmf’s",
    "text": "Marginal pmf’s\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Transformations.html#remarks-on-the-joint-pmf",
    "href": "lessons/11_Joint_distributions/11_Transformations.html#remarks-on-the-joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the joint pmf",
    "text": "Remarks on the joint pmf\nSome properties of joint pmf’s:\n\nA joint pmf \\(p_{X,Y}(x,y)\\) must satisfy the following properties:\n\n\\(p_{X,Y}(x,y)\\geq 0\\) for all \\(x, y\\).\n\\(\\sum \\limits_{\\{all\\ x\\}} \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)=1\\).\n\nMarginal pmf’s:\n\n\\(p_X(x) = \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)\\)\n\\(p_Y(y) = \\sum \\limits_{\\{all\\ x\\}} p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Transformations.html#what-is-a-joint-cdf",
    "href": "lessons/11_Joint_distributions/11_Transformations.html#what-is-a-joint-cdf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is a joint CDF?",
    "text": "What is a joint CDF?\n\n\nDefinition: joint CDF\n\n\nThe joint CDF of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[F_{X,Y}(x,y) = \\mathbb{P}(X \\leq x\\ and\\ Y \\leq y) = \\mathbb{P}(X \\leq x, Y \\leq y)\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Transformations.html#joint-cdfs",
    "href": "lessons/11_Joint_distributions/11_Transformations.html#joint-cdfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Joint CDFs",
    "text": "Joint CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Transformations.html#marginal-cdfs",
    "href": "lessons/11_Joint_distributions/11_Transformations.html#marginal-cdfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Marginal CDFs",
    "text": "Marginal CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Transformations.html#remarks-on-the-joint-and-marginal-cdf",
    "href": "lessons/11_Joint_distributions/11_Transformations.html#remarks-on-the-joint-and-marginal-cdf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the joint and marginal CDF",
    "text": "Remarks on the joint and marginal CDF\n\n\\(F_X(x)\\): right most columns of the CDf table (where the \\(Y\\) values are largest)\n\\(F_Y(y)\\): bottom row of the table (where X values are largest)\n\\(F_X(x)=\\lim\\limits_{y\\rightarrow\\infty}F_{X, Y}(x,y)\\)\n\\(F_Y(y)=\\lim\\limits_{x\\rightarrow\\infty}F_{X, Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Transformations.html#independence-and-conditioning",
    "href": "lessons/11_Joint_distributions/11_Transformations.html#independence-and-conditioning",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Independence and Conditioning",
    "text": "Independence and Conditioning\nRecall that for events \\(A\\) and \\(B\\),\n\n\\(\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}\\)\n\\(A\\) and \\(B\\) are independent if and only if\n\n\\(\\mathbb{P}(A|B) = \\mathbb{P}(A)\\)\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A)\\cdot\\mathbb{P}(B)\\)\n\n\nIndependence and conditioning are defined similarly for r.v.’s, since \\[p_X(x) = \\mathbb{P}(X=x)\\ \\mathrm{and}\\ \\ p_{X,Y}(x,y) = \\mathbb{P}(X = x ,Y = y).\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Transformations.html#what-is-the-conditional-pmf",
    "href": "lessons/11_Joint_distributions/11_Transformations.html#what-is-the-conditional-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is the conditional pmf?",
    "text": "What is the conditional pmf?\n\n\nDefinition: conditional pmf\n\n\nThe conditional pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is defined as \\[p_{X|Y}(x|y) = \\mathbb{P}(X = x |Y = y) = \\frac{\\mathbb{P}(X = x\\ and\\ Y = y)}{\\mathbb{P}(Y = y)}\n=\\frac{p_{X,Y}(x,y) }{p_{Y}(y) }\\] if \\(p_{Y}(y) &gt; 0\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Transformations.html#remarks-on-the-conditional-pmf",
    "href": "lessons/11_Joint_distributions/11_Transformations.html#remarks-on-the-conditional-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the conditional pmf",
    "text": "Remarks on the conditional pmf\nThe following properties follow from the conditional pmf definition:\n\nIf \\(X \\perp Y\\) (independent)\n\n\\(p_{X|Y}(x|y) = p_X(x)\\) for all \\(x\\) and \\(y\\)\n\\(p_{X,Y}(x,y) = p_X(x)p_Y(y)\\) for all \\(x\\) and \\(y\\)\nWhich also implies (\\(\\Rightarrow\\)): \\(F_{X,Y}(x,y) = F_X(x)F_Y(y)\\) for all \\(x\\) and \\(y\\)\n\nIf \\(X_1, X_2, …, X_n\\) are independent\n\n\\[p_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1=x_1, X_2=x_2, …, X_n=x_n)=\\prod\\limits_{i=1}^np_{X_i}(x_i)\\]\n\\[F_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1\\leq x_1, X_2\\leq x_2, …, X_n\\leq x_n)=\\prod\\limits_{i=1}^nP(X_i \\leq x_i) = \\prod\\limits_{i=1}^nF_{X_i}(x_i)\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Transformations.html#conditional-pmfs",
    "href": "lessons/11_Joint_distributions/11_Transformations.html#conditional-pmfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Conditional pmf’s",
    "text": "Conditional pmf’s\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?\n\n\n\n\n\nRemark:\n\nTo show that \\(X\\) and \\(Y\\) are not independent, we just need to find one counter example\nHowever, to show that they are independent, we need to verify this for all possible pairs of \\(x\\) and \\(y\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Transformations.html#hypothetical-4-sided-die",
    "href": "lessons/11_Joint_distributions/11_Transformations.html#hypothetical-4-sided-die",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Hypothetical 4-sided die",
    "text": "Hypothetical 4-sided die\n\n\nExample 3\n\n\n\nSuppose you have a 4-sided die, and you roll the 4-sided die until the first 4 appears.\nLet \\(X\\) be the number of rolls required until (and including) the first 4.\nAfter the first 4, you keep rolling it again until you roll a 3.\nLet \\(Y\\) be the number of rolls, after the first 4, required until (and including) the 3.\n\n\nFind \\(p_{X,Y}(x,y)\\).\nUsing \\(p_{X,Y}(x,y)\\), find \\(p_{Y}(y)\\).\nFind \\(p_{X}(x)\\).\nAre \\(X\\) and \\(Y\\) are independent? Why or why not?\nFind \\(F_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities_key_info.html",
    "href": "lessons/11_Joint_distributions/25_Joint_densities_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 6 assignment today!\n\nFeel free to turn in solutions later than 11/24 since I took so long to grade\n\nI made quite a few changes to the homeworks\n\nHW 10 is gone\nHW 9 is optional\nInstead of a HW assignment due over late November break\n\nHW 8 will include material from Week 8 and 9 and be due 12/5\n\n\nI have quite a bit of grading to catch up on!\nRealizing I never gave you mid-quarter feedback forms…\n\nLet’s chat about this and our assessment breakdown in the coming weeks\n\nAnything else?"
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities_key_info.html#announcements",
    "href": "lessons/11_Joint_distributions/25_Joint_densities_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 6 assignment today!\n\nFeel free to turn in solutions later than 11/24 since I took so long to grade\n\nI made quite a few changes to the homeworks\n\nHW 10 is gone\nHW 9 is optional\nInstead of a HW assignment due over late November break\n\nHW 8 will include material from Week 8 and 9 and be due 12/5\n\n\nI have quite a bit of grading to catch up on!\nRealizing I never gave you mid-quarter feedback forms…\n\nLet’s chat about this and our assessment breakdown in the coming weeks\n\nAnything else?"
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities_key_info.html#key-dates",
    "href": "lessons/11_Joint_distributions/25_Joint_densities_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 7 due\nSunday: HW 6 solutions due"
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities.html",
    "href": "lessons/11_Joint_distributions/25_Joint_densities.html",
    "title": "Chapter 25: Joint densities",
    "section": "",
    "text": "Solve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities.html#learning-objectives",
    "href": "lessons/11_Joint_distributions/25_Joint_densities.html#learning-objectives",
    "title": "Chapter 25: Joint densities",
    "section": "",
    "text": "Solve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-13",
    "href": "lessons/11_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-13",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (1/3)",
    "text": "Double Integrals Mini Lesson (1/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 1\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} xy dydx\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-23",
    "href": "lessons/11_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-23",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (2/3)",
    "text": "Double Integrals Mini Lesson (2/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 2\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} (x+y) dydx\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-33",
    "href": "lessons/11_Joint_distributions/25_Joint_densities.html#double-integrals-mini-lesson-33",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (3/3)",
    "text": "Double Integrals Mini Lesson (3/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 3\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} e^{x+y} dydx\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "href": "lessons/11_Joint_distributions/25_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "title": "Chapter 25: Joint densities",
    "section": "How to define the joint pdf for continuous RVs?",
    "text": "How to define the joint pdf for continuous RVs?\n\n\nFor a single continuous RV \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\), \\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\]\n\nFor two continuous RVs (\\(X\\) and \\(Y\\)), we can define the joint pdf, \\(f_{X,Y}(x,y)\\), such that for all real values \\(a,b, c, d\\) with \\(a \\leq b\\) and \\(c \\leq d\\), \\[\\mathbb{P}(a \\leq X \\leq b, c \\leq Y \\leq d) = \\int_a^b \\int_c^d f_{X,Y}(x,y)dydx\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities.html#important-properties-of-the-joint-pdf",
    "href": "lessons/11_Joint_distributions/25_Joint_densities.html#important-properties-of-the-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Important properties of the joint pdf",
    "text": "Important properties of the joint pdf\n\nNote that \\(f_{X,Y}(x,y)\\neq \\mathbb{P}(X=x, Y=y)\\)!!!\nIn order for \\(f_{X,Y}(x,y)\\) to be a pdf, it needs to satisfy the properties\n\n\\(f_{X,Y}(x,y)\\geq 0\\) for all \\(x,y\\)\n\\(\\displaystyle\\int_{-\\infty}^{\\infty}\\displaystyle\\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dxdy=1\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "href": "lessons/11_Joint_distributions/25_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "title": "Chapter 25: Joint densities",
    "section": "What is the joint cumulative distribution function?",
    "text": "What is the joint cumulative distribution function?\n\n\nDefinition: Joint cumulative distribution function (Joint CDF)\n\n\nThe joint cumulative distribution function (cdf) of continuous random variables \\(X\\) and \\(Y\\), is the function \\(F_{X,Y}(x,y)\\), such that for all real values of \\(x\\) and \\(y\\), \\[F_{X,Y}(x,y)= \\mathbb{P}(X \\leq x, Y \\leq y) = \\int_{-\\infty}^x\\int_{-\\infty}^y f_{X,Y}(s,t)dtds\\]\n\n\nRemarks:\n\nThe definition above for \\(F_{X,Y}(x,y)\\) is a function of \\(x\\) and \\(y\\).\nThe joint cdf at the point \\((a,b)\\), is \\[F_{X,Y}(a,b) = \\mathbb{P}(X \\leq a, Y \\leq b) = \\int_{-\\infty}^a\\int_{-\\infty}^b f_{X,Y}(s,t)dtds\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities.html#what-are-the-marginal-pdfs",
    "href": "lessons/11_Joint_distributions/25_Joint_densities.html#what-are-the-marginal-pdfs",
    "title": "Chapter 25: Joint densities",
    "section": "What are the marginal pdf’s?",
    "text": "What are the marginal pdf’s?\n\n\nDefinition: Marginal pdf’s\n\n\nSuppose \\(X\\) and \\(Y\\) are continuous r.v.’s, with joint pdf \\(f_{X,Y}(x,y)\\). Then the marginal probability density functions are \\[\\begin{aligned}\nf_X(x)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dy\\\\\nf_Y(y)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dx\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities.html#common-steps-for-solving-problems",
    "href": "lessons/11_Joint_distributions/25_Joint_densities.html#common-steps-for-solving-problems",
    "title": "Chapter 25: Joint densities",
    "section": "Common steps for solving problems",
    "text": "Common steps for solving problems\n\nSet up the domain of the pdf with a picture\nTranslate to needed integrands\n\nFor probability: shade in the area of interest, then translate\nFor expected value: translate domain\n\nSet up integral: \\(dxdy\\) or \\(dydx\\)?\nSolve integral!"
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities.html#example-of-joint-pdf",
    "href": "lessons/11_Joint_distributions/25_Joint_densities.html#example-of-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities.html#example-of-joint-pdf-1",
    "href": "lessons/11_Joint_distributions/25_Joint_densities.html#example-of-joint-pdf-1",
    "title": "Chapter 25: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "href": "lessons/11_Joint_distributions/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "href": "lessons/11_Joint_distributions/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "title": "Chapter 25: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(\\mathbb{P}(Y &lt; 3)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more",
    "href": "lessons/11_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.1\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nFind \\(\\mathbb{P}(|X-Y| &lt; 2)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "href": "lessons/11_Joint_distributions/25_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "title": "Chapter 25: Joint densities",
    "section": "Finding the pdf of a transformation",
    "text": "Finding the pdf of a transformation\n\nLet \\(M\\) be a transformation of \\(X\\) and \\(Y\\)\nWhen we have a transformation of \\(X\\) and \\(Y\\), \\(M\\), we need to follow a specific process to find the pdf of \\(M\\)\n\nWe follow this process:\n\nStart with the joint pdf for \\(X\\) and \\(Y\\)\n\naka \\(f_{X,Y}(x, y)\\)\n\nTranslate the domain of \\(X\\) and \\(Y\\) to \\(M\\)\nFind the CDF of \\(M\\)\n\naka \\(F_M(m)\\) or \\(P(M \\leq m)\\)\n\nTake the derivative of the CDF of \\(M\\) to find the pdf of \\(M\\)\n\naka \\(f_M(m) = \\dfrac{d}{dm}F_M(m)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more-1",
    "href": "lessons/11_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more-1",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.2\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(M = \\max(X,Y)\\). Find the pdf for \\(M\\), that is \\(f_M(m)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more-2",
    "href": "lessons/11_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-more-2",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 3.3\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(Z = \\min(X,Y)\\). Find the pdf for \\(Z\\), that is \\(f_Z(z)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-further",
    "href": "lessons/11_Joint_distributions/25_Joint_densities.html#lets-complicate-this-even-further",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even further!",
    "text": "Let’s complicate this even further!\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 4\n\n\nLet \\(X\\) and \\(Y\\) have joint density \\(f_{X,Y}(x,y)= \\frac85(x+y)\\) in the region \\(0 &lt; x &lt; 1,\\ \\frac12 &lt; y &lt;1\\). Find the pdf of the r.v. \\(Z\\), where \\(Z=XY\\)."
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities_muddy_points.html",
    "href": "lessons/10_Transformations/25_Joint_densities_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n1. How do pdf, CDF, and probability interact with each other?\nLet’s say we have a pdf, \\(f_X(x) = \\dfrac{1}{9}x^2\\) for \\(0 \\leq x \\leq 3\\). This is just a function. The pdf is not used on its own to report any probability. We must integrate over the pdf to find a probability.\n\nlibrary(\"ggplot2\")\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3)\n\n\n\n\n\n\n\n\nThe total area under the pdf is 1. This makes our pdf valid.\n\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 3),\n                geom = \"area\", \n                aes(fill = \"red\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 1\", color = \"black\")\n\n\n\n\n\n\n\n\nIf we only look at a proportion of the area under the pdf, then we start constructing our probabilities. For example, we can look at probability that we have a value between 0 and 1.5.\n\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 1.5),\n                geom = \"area\", \n                aes(fill = \"blue\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 0.125\", color = \"black\")\n\n\n\n\n\n\n\n\nInstead of calculating the EXACT probability for each value between 0 and 3, we can find the CDF of the pdf.\nThe CDF is: \\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;3 \\quad \\\\\n            \\dfrac{1}{27}x^3 & \\quad 0 \\leq x \\leq 3\\quad \\\\\n            1 & \\quad x&gt;3 \\quad\n        \\end{array}\n    \\right.\n\\]\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nWhen \\(x=1.5\\), we can calculate the probability using the CDF. Remember that \\(F_X(x) = P(X \\leq x)\\). So we can say \\(P(X \\leq 1.5) = F_X(1.5) = \\dfrac{1}{27}(1.5)^3\\), which equals 0.125.\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\") +\n  geom_point(aes(x=1.5, y=.125), colour=\"blue\", size=3) +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"CDF = 0.125\", color = \"black\")\n\nWarning in geom_point(aes(x = 1.5, y = 0.125), colour = \"blue\", size = 3): All aesthetics have length 1, but the data has 2 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\nWe can also calculate the probability with an integral: \\(P(X \\leq 1.5) = \\displaystyle\\int_0^{1.5} \\dfrac{1}{9}x^2 dx\\).\nWe can also find the probability that X is between two numbers. \\(P(1\\leq X \\leq 1.5) = F_X(1.5) - F_X(1)\\) or \\(P(1\\leq X \\leq 1.5) = \\displaystyle\\int_1^{1.5} \\dfrac{1}{9}x^2 dx\\).\n\n\n2. Joint vs marginal vs conditional: How are we calculating the probability?\nIf we start at a joint probability \\(f_{X,Y}(x,y)\\)…. we can look at a few probabilities:\n\nJoint probability: \\(P(a \\leq X \\leq b, c \\leq Y \\leq d)\\)\n\\[P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=c}^{y=d} f_{X,Y}(x,y) dydx\\]\nMarginal probability: \\(P(a \\leq X \\leq b)\\)\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b} f_{X}(x) dx\\]\nOR\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=-\\inf}^{y=\\inf} f_{X,Y}(x,y) dydx\\]\nConditional probability: \\(P(a \\leq X \\leq b | Y = c)\\)\n\\[P(a \\leq X \\leq b | Y=c) = \\displaystyle\\int_{x=a}^{x=b} f_{X|Y}(x|y=c) dx\\]\nYou cannot calculate \\(P(a \\leq X \\leq b | Y = c)\\) by \\(\\dfrac{P(a \\leq X \\leq b, Y=c)}{P(Y = c)}\\) because \\(P(Y = c)\\) is 0. Instead, we need to find \\(f_{X|Y}(x|y=c)\\) by \\(\\dfrac{f_{X,Y}(x,y=c)}{f_{Y}(y=c)}\\) and THEN integrate over X.\n\n\n\n3. What are we actually finding by solving the double integral. In the first example, we found the probability was 1/16 after integrating but what does 1/16 mean in relation to the random variables X and Y?\nIt means that the volume contained by \\(0\\leq X \\leq 1\\), \\(0\\leq Y \\leq 1/2\\), and their joint pdf is 1/16 of the total volume contained by \\(0\\leq X \\leq 2\\), \\(0\\leq Y \\leq 1\\), and their joint pdf. The probability for a joint pdf is now a measure of the proportion of the volume.\nThis is not be confused with a probability from marginal pdf or pdf from one RV. The probability for marginal/single RV pdfs is the proportion of the area under the pdf for a specific range of values.\n\n\n4. Here’s a 3D plot of one of our joint pdf’s\n\\[\nf_{X,Y}(x,y) = 5e^{-x-3y} \\text{ for } 0 \\leq y \\leq x/2\n\\]\n\nlibrary(plotly)\n\nx = seq(0, 5, 0.1)\ny = seq(0, max(x)/2, 0.1/2)\nfn = expand.grid(x=x,y=y)\nfn$z = ifelse(fn$y&lt;fn$x/2, 5*exp( (-1)*fn$x - 3*fn$y), NA)\n\nz = matrix(fn$z, ncol = 51, nrow = 51, byrow = T)\n\nfig &lt;- plot_ly(x = x, y=y, z=z) %&gt;% add_surface()\n\nfig"
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities_key_info.html",
    "href": "lessons/10_Transformations/25_Joint_densities_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 6 assignment today!\n\nFeel free to turn in solutions later than 11/24 since I took so long to grade\n\nI made quite a few changes to the homeworks\n\nHW 10 is gone\nHW 9 is optional\nInstead of a HW assignment due over late November break\n\nHW 8 will include material from Week 8 and 9 and be due 12/5\n\n\nI have quite a bit of grading to catch up on!\nRealizing I never gave you mid-quarter feedback forms…\n\nLet’s chat about this and our assessment breakdown in the coming weeks\n\nAnything else?"
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities_key_info.html#announcements",
    "href": "lessons/10_Transformations/25_Joint_densities_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 6 assignment today!\n\nFeel free to turn in solutions later than 11/24 since I took so long to grade\n\nI made quite a few changes to the homeworks\n\nHW 10 is gone\nHW 9 is optional\nInstead of a HW assignment due over late November break\n\nHW 8 will include material from Week 8 and 9 and be due 12/5\n\n\nI have quite a bit of grading to catch up on!\nRealizing I never gave you mid-quarter feedback forms…\n\nLet’s chat about this and our assessment breakdown in the coming weeks\n\nAnything else?"
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities_key_info.html#key-dates",
    "href": "lessons/10_Transformations/25_Joint_densities_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 7 due\nSunday: HW 6 solutions due"
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities.html",
    "href": "lessons/10_Transformations/25_Joint_densities.html",
    "title": "Chapter 25: Joint densities",
    "section": "",
    "text": "Solve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities.html#learning-objectives",
    "href": "lessons/10_Transformations/25_Joint_densities.html#learning-objectives",
    "title": "Chapter 25: Joint densities",
    "section": "",
    "text": "Solve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities.html#double-integrals-mini-lesson-13",
    "href": "lessons/10_Transformations/25_Joint_densities.html#double-integrals-mini-lesson-13",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (1/3)",
    "text": "Double Integrals Mini Lesson (1/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 1\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} xy dydx\\)"
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities.html#double-integrals-mini-lesson-23",
    "href": "lessons/10_Transformations/25_Joint_densities.html#double-integrals-mini-lesson-23",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (2/3)",
    "text": "Double Integrals Mini Lesson (2/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 2\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} (x+y) dydx\\)"
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities.html#double-integrals-mini-lesson-33",
    "href": "lessons/10_Transformations/25_Joint_densities.html#double-integrals-mini-lesson-33",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (3/3)",
    "text": "Double Integrals Mini Lesson (3/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 3\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} e^{x+y} dydx\\)"
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "href": "lessons/10_Transformations/25_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "title": "Chapter 25: Joint densities",
    "section": "How to define the joint pdf for continuous RVs?",
    "text": "How to define the joint pdf for continuous RVs?\n\n\nFor a single continuous RV \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\), \\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\]\n\nFor two continuous RVs (\\(X\\) and \\(Y\\)), we can define the joint pdf, \\(f_{X,Y}(x,y)\\), such that for all real values \\(a,b, c, d\\) with \\(a \\leq b\\) and \\(c \\leq d\\), \\[\\mathbb{P}(a \\leq X \\leq b, c \\leq Y \\leq d) = \\int_a^b \\int_c^d f_{X,Y}(x,y)dydx\\]"
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities.html#important-properties-of-the-joint-pdf",
    "href": "lessons/10_Transformations/25_Joint_densities.html#important-properties-of-the-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Important properties of the joint pdf",
    "text": "Important properties of the joint pdf\n\nNote that \\(f_{X,Y}(x,y)\\neq \\mathbb{P}(X=x, Y=y)\\)!!!\nIn order for \\(f_{X,Y}(x,y)\\) to be a pdf, it needs to satisfy the properties\n\n\\(f_{X,Y}(x,y)\\geq 0\\) for all \\(x,y\\)\n\\(\\displaystyle\\int_{-\\infty}^{\\infty}\\displaystyle\\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dxdy=1\\)"
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "href": "lessons/10_Transformations/25_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "title": "Chapter 25: Joint densities",
    "section": "What is the joint cumulative distribution function?",
    "text": "What is the joint cumulative distribution function?\n\n\nDefinition: Joint cumulative distribution function (Joint CDF)\n\n\nThe joint cumulative distribution function (cdf) of continuous random variables \\(X\\) and \\(Y\\), is the function \\(F_{X,Y}(x,y)\\), such that for all real values of \\(x\\) and \\(y\\), \\[F_{X,Y}(x,y)= \\mathbb{P}(X \\leq x, Y \\leq y) = \\int_{-\\infty}^x\\int_{-\\infty}^y f_{X,Y}(s,t)dtds\\]\n\n\nRemarks:\n\nThe definition above for \\(F_{X,Y}(x,y)\\) is a function of \\(x\\) and \\(y\\).\nThe joint cdf at the point \\((a,b)\\), is \\[F_{X,Y}(a,b) = \\mathbb{P}(X \\leq a, Y \\leq b) = \\int_{-\\infty}^a\\int_{-\\infty}^b f_{X,Y}(s,t)dtds\\]"
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities.html#what-are-the-marginal-pdfs",
    "href": "lessons/10_Transformations/25_Joint_densities.html#what-are-the-marginal-pdfs",
    "title": "Chapter 25: Joint densities",
    "section": "What are the marginal pdf’s?",
    "text": "What are the marginal pdf’s?\n\n\nDefinition: Marginal pdf’s\n\n\nSuppose \\(X\\) and \\(Y\\) are continuous r.v.’s, with joint pdf \\(f_{X,Y}(x,y)\\). Then the marginal probability density functions are \\[\\begin{aligned}\nf_X(x)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dy\\\\\nf_Y(y)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dx\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities.html#common-steps-for-solving-problems",
    "href": "lessons/10_Transformations/25_Joint_densities.html#common-steps-for-solving-problems",
    "title": "Chapter 25: Joint densities",
    "section": "Common steps for solving problems",
    "text": "Common steps for solving problems\n\nSet up the domain of the pdf with a picture\nTranslate to needed integrands\n\nFor probability: shade in the area of interest, then translate\nFor expected value: translate domain\n\nSet up integral: \\(dxdy\\) or \\(dydx\\)?\nSolve integral!"
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities.html#example-of-joint-pdf",
    "href": "lessons/10_Transformations/25_Joint_densities.html#example-of-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)."
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities.html#example-of-joint-pdf-1",
    "href": "lessons/10_Transformations/25_Joint_densities.html#example-of-joint-pdf-1",
    "title": "Chapter 25: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "href": "lessons/10_Transformations/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "href": "lessons/10_Transformations/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "title": "Chapter 25: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(\\mathbb{P}(Y &lt; 3)\\)."
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities.html#lets-complicate-this-even-more",
    "href": "lessons/10_Transformations/25_Joint_densities.html#lets-complicate-this-even-more",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.1\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nFind \\(\\mathbb{P}(|X-Y| &lt; 2)\\)"
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "href": "lessons/10_Transformations/25_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "title": "Chapter 25: Joint densities",
    "section": "Finding the pdf of a transformation",
    "text": "Finding the pdf of a transformation\n\nLet \\(M\\) be a transformation of \\(X\\) and \\(Y\\)\nWhen we have a transformation of \\(X\\) and \\(Y\\), \\(M\\), we need to follow a specific process to find the pdf of \\(M\\)\n\nWe follow this process:\n\nStart with the joint pdf for \\(X\\) and \\(Y\\)\n\naka \\(f_{X,Y}(x, y)\\)\n\nTranslate the domain of \\(X\\) and \\(Y\\) to \\(M\\)\nFind the CDF of \\(M\\)\n\naka \\(F_M(m)\\) or \\(P(M \\leq m)\\)\n\nTake the derivative of the CDF of \\(M\\) to find the pdf of \\(M\\)\n\naka \\(f_M(m) = \\dfrac{d}{dm}F_M(m)\\)"
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities.html#lets-complicate-this-even-more-1",
    "href": "lessons/10_Transformations/25_Joint_densities.html#lets-complicate-this-even-more-1",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.2\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(M = \\max(X,Y)\\). Find the pdf for \\(M\\), that is \\(f_M(m)\\)."
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities.html#lets-complicate-this-even-more-2",
    "href": "lessons/10_Transformations/25_Joint_densities.html#lets-complicate-this-even-more-2",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 3.3\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(Z = \\min(X,Y)\\). Find the pdf for \\(Z\\), that is \\(f_Z(z)\\)."
  },
  {
    "objectID": "lessons/10_Transformations/25_Joint_densities.html#lets-complicate-this-even-further",
    "href": "lessons/10_Transformations/25_Joint_densities.html#lets-complicate-this-even-further",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even further!",
    "text": "Let’s complicate this even further!\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 4\n\n\nLet \\(X\\) and \\(Y\\) have joint density \\(f_{X,Y}(x,y)= \\frac85(x+y)\\) in the region \\(0 &lt; x &lt; 1,\\ \\frac12 &lt; y &lt;1\\). Find the pdf of the r.v. \\(Z\\), where \\(Z=XY\\)."
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations_key_info.html",
    "href": "lessons/10_Transformations/10_Transformations_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Quiz 1 grades look pretty good! Everyone got score above 11/15\n\nFeedback released at 12:10pm today\nWill go over questions next class"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations_key_info.html#announcements",
    "href": "lessons/10_Transformations/10_Transformations_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Quiz 1 grades look pretty good! Everyone got score above 11/15\n\nFeedback released at 12:10pm today\nWill go over questions next class"
  },
  {
    "objectID": "lessons/10_Transformations/10_Transformations_key_info.html#key-dates",
    "href": "lessons/10_Transformations/10_Transformations_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHomework 4 due 11/02 at 11pm"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#conditional-probabilities-weve-seen-before",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#conditional-probabilities-weve-seen-before",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "Conditional probabilities we’ve seen before",
    "text": "Conditional probabilities we’ve seen before\n\n\nWhat do we know about conditional probabilities for events and discrete RVs?    \nFor events:\n\\[P(A | B) = \\dfrac{P(A \\cap B)}{P(B)}\\]    \nFor discrete RVs: \\[p_{X|Y}(x|y) = P(X=x|Y=y) = \\dfrac{p_{X,Y}(x,y)}{p_Y(y)}\\]\n\n\n\nWhat does it mean for conditional densities of continuous RVs?\nFor continuous RVs:"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#example-starting-from-a-joint-pdf-first-try",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#example-starting-from-a-joint-pdf-first-try",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "Example starting from a joint pdf: first try!",
    "text": "Example starting from a joint pdf: first try!\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(2&lt;X&lt;10|Y=4)\\)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#what-is-a-conditional-density",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#what-is-a-conditional-density",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "What is a conditional density?",
    "text": "What is a conditional density?\n\n\n\n\nDefinition: Conditional density\n\n\nThe conditional density of a r.v. \\(X\\) given \\(Y=y\\), is \\[f_{X|Y}(x|y)= \\frac{f_{X,Y}(x,y)}{f_Y(y)},\\] for \\(f_Y(y)&gt; 0\\)\n\n\n\n\n\nRemarks\n\nIt follows from the definition for the conditional density \\(f_{X|Y}(x|y)\\), that \\[f_{X,Y}(x,y)= f_{X|Y}(x|y)f_Y(y).\\]\n\n     \n\nFor a fixed value of \\(Y=y\\), the conditional density \\(f_{X|Y}(x|y)\\) is an actual pdf, meaning\n\n\\(f_{X|Y}(x|y)\\geq 0\\) for all \\(x\\) and \\(y\\), and\n\\(\\displaystyle\\int_{-\\infty}^{\\infty} f_{X|Y}(x|y)dx =1\\)."
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#example-starting-from-a-joint-pdf-second-try-12",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#example-starting-from-a-joint-pdf-second-try-12",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "Example starting from a joint pdf: second try! (1/2)",
    "text": "Example starting from a joint pdf: second try! (1/2)\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(2&lt;X&lt;10|Y=4)\\)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#example-starting-from-a-joint-pdf-second-try-22",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#example-starting-from-a-joint-pdf-second-try-22",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "Example starting from a joint pdf: second try! (2/2)",
    "text": "Example starting from a joint pdf: second try! (2/2)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#example-starting-from-a-joint-pdf",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#example-starting-from-a-joint-pdf",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "Example starting from a joint pdf",
    "text": "Example starting from a joint pdf\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= 5 e^{-x-3y}\\), for \\(0 &lt; y &lt; \\frac{x}{2}\\).\n\nFind \\(\\mathbb{P}(X&gt;20 |Y=5)\\)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#finding-probability-with-conditional-domain-and-pdf",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#finding-probability-with-conditional-domain-and-pdf",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "Finding probability with conditional domain and pdf",
    "text": "Finding probability with conditional domain and pdf\n\n\n\nDo this problem at home for extra practice. The solution is available in Meike’s video!\n\n\n\n\n\n\n\nExample 2\n\n\nRandomly choose a point \\(X\\) from the interval \\([0,1]\\), and given \\(X=x\\), randomly choose a point \\(Y\\) from \\([0,x]\\). Find \\(\\mathbb{P}(0 &lt; Y &lt; \\frac14)\\)."
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#independence-and-conditional-distributions",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#independence-and-conditional-distributions",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "Independence and conditional distributions",
    "text": "Independence and conditional distributions\n    Question What is \\(f_{X|Y}(x|y)\\) if \\(X\\) and \\(Y\\) are independent?\n\\[f_{X|Y}(x|y) = \\dfrac{f_{X,Y}(x,y)}{f_y(y)} = \\dfrac{f_{X}(x)f_y(y)}{f_y(y)} = f_{X}(x)\\]\n       \n\nIf \\(f_{X|Y}(x|y)\\) does not depend on \\(y\\) (including the bounds/domain), then \\(X\\) and \\(Y\\) are independent."
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_key_info.html",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Midterm feedback!\nHomework\n\nYou NEED to show your work! I am asking Charles to give half credit if you do not show sufficient work\nIf you have an html file and images of work, please insert the image into your html!\n\nHomework 2 feedback from Charles\n\nPeople forgot to use combinations for binary distribution\nSome people didn’t get all of the combinations for question 3\nSome didn’t know how to break up the venn diagram to find each prob. Or label it correctly\nSome people inserted \\(A \\cup B\\), \\(A \\cup C\\), \\(B \\cup C\\) into the equation for \\(A \\cup B \\cup C\\) …somehow it gets the same probability for A&B&C even though that the wrong way to do it"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_key_info.html#announcements",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Midterm feedback!\nHomework\n\nYou NEED to show your work! I am asking Charles to give half credit if you do not show sufficient work\nIf you have an html file and images of work, please insert the image into your html!\n\nHomework 2 feedback from Charles\n\nPeople forgot to use combinations for binary distribution\nSome people didn’t get all of the combinations for question 3\nSome didn’t know how to break up the venn diagram to find each prob. Or label it correctly\nSome people inserted \\(A \\cup B\\), \\(A \\cup C\\), \\(B \\cup C\\) into the equation for \\(A \\cup B \\cup C\\) …somehow it gets the same probability for A&B&C even though that the wrong way to do it"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_key_info.html#key-dates",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 04 due this Sunday!\nMidterm feedback due Sunday as well!"
  },
  {
    "objectID": "lessons/11_Joint_distributions/25_Joint_densities_muddy_points.html",
    "href": "lessons/11_Joint_distributions/25_Joint_densities_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n1. How do pdf, CDF, and probability interact with each other?\nLet’s say we have a pdf, \\(f_X(x) = \\dfrac{1}{9}x^2\\) for \\(0 \\leq x \\leq 3\\). This is just a function. The pdf is not used on its own to report any probability. We must integrate over the pdf to find a probability.\n\nlibrary(\"ggplot2\")\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3)\n\n\n\n\n\n\n\n\nThe total area under the pdf is 1. This makes our pdf valid.\n\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 3),\n                geom = \"area\", \n                aes(fill = \"red\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 1\", color = \"black\")\n\n\n\n\n\n\n\n\nIf we only look at a proportion of the area under the pdf, then we start constructing our probabilities. For example, we can look at probability that we have a value between 0 and 1.5.\n\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 1.5),\n                geom = \"area\", \n                aes(fill = \"blue\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 0.125\", color = \"black\")\n\n\n\n\n\n\n\n\nInstead of calculating the EXACT probability for each value between 0 and 3, we can find the CDF of the pdf.\nThe CDF is: \\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;3 \\quad \\\\\n            \\dfrac{1}{27}x^3 & \\quad 0 \\leq x \\leq 3\\quad \\\\\n            1 & \\quad x&gt;3 \\quad\n        \\end{array}\n    \\right.\n\\]\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nWhen \\(x=1.5\\), we can calculate the probability using the CDF. Remember that \\(F_X(x) = P(X \\leq x)\\). So we can say \\(P(X \\leq 1.5) = F_X(1.5) = \\dfrac{1}{27}(1.5)^3\\), which equals 0.125.\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\") +\n  geom_point(aes(x=1.5, y=.125), colour=\"blue\", size=3) +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"CDF = 0.125\", color = \"black\")\n\nWarning in geom_point(aes(x = 1.5, y = 0.125), colour = \"blue\", size = 3): All aesthetics have length 1, but the data has 2 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\nWe can also calculate the probability with an integral: \\(P(X \\leq 1.5) = \\displaystyle\\int_0^{1.5} \\dfrac{1}{9}x^2 dx\\).\nWe can also find the probability that X is between two numbers. \\(P(1\\leq X \\leq 1.5) = F_X(1.5) - F_X(1)\\) or \\(P(1\\leq X \\leq 1.5) = \\displaystyle\\int_1^{1.5} \\dfrac{1}{9}x^2 dx\\).\n\n\n2. Joint vs marginal vs conditional: How are we calculating the probability?\nIf we start at a joint probability \\(f_{X,Y}(x,y)\\)…. we can look at a few probabilities:\n\nJoint probability: \\(P(a \\leq X \\leq b, c \\leq Y \\leq d)\\)\n\\[P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=c}^{y=d} f_{X,Y}(x,y) dydx\\]\nMarginal probability: \\(P(a \\leq X \\leq b)\\)\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b} f_{X}(x) dx\\]\nOR\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=-\\inf}^{y=\\inf} f_{X,Y}(x,y) dydx\\]\nConditional probability: \\(P(a \\leq X \\leq b | Y = c)\\)\n\\[P(a \\leq X \\leq b | Y=c) = \\displaystyle\\int_{x=a}^{x=b} f_{X|Y}(x|y=c) dx\\]\nYou cannot calculate \\(P(a \\leq X \\leq b | Y = c)\\) by \\(\\dfrac{P(a \\leq X \\leq b, Y=c)}{P(Y = c)}\\) because \\(P(Y = c)\\) is 0. Instead, we need to find \\(f_{X|Y}(x|y=c)\\) by \\(\\dfrac{f_{X,Y}(x,y=c)}{f_{Y}(y=c)}\\) and THEN integrate over X.\n\n\n\n3. What are we actually finding by solving the double integral. In the first example, we found the probability was 1/16 after integrating but what does 1/16 mean in relation to the random variables X and Y?\nIt means that the volume contained by \\(0\\leq X \\leq 1\\), \\(0\\leq Y \\leq 1/2\\), and their joint pdf is 1/16 of the total volume contained by \\(0\\leq X \\leq 2\\), \\(0\\leq Y \\leq 1\\), and their joint pdf. The probability for a joint pdf is now a measure of the proportion of the volume.\nThis is not be confused with a probability from marginal pdf or pdf from one RV. The probability for marginal/single RV pdfs is the proportion of the area under the pdf for a specific range of values.\n\n\n4. Here’s a 3D plot of one of our joint pdf’s\n\\[\nf_{X,Y}(x,y) = 5e^{-x-3y} \\text{ for } 0 \\leq y \\leq x/2\n\\]\n\nlibrary(plotly)\n\nx = seq(0, 5, 0.1)\ny = seq(0, max(x)/2, 0.1/2)\nfn = expand.grid(x=x,y=y)\nfn$z = ifelse(fn$y&lt;fn$x/2, 5*exp( (-1)*fn$x - 3*fn$y), NA)\n\nz = matrix(fn$z, ncol = 51, nrow = 51, byrow = T)\n\nfig &lt;- plot_ly(x = x, y=y, z=z) %&gt;% add_surface()\n\nfig"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "How to define the joint pdf for continuous RVs?",
    "text": "How to define the joint pdf for continuous RVs?\n\n\nFor a single continuous RV \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\), \\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\]\n\nFor two continuous RVs (\\(X\\) and \\(Y\\)), we can define the joint pdf, \\(f_{X,Y}(x,y)\\), such that for all real values \\(a,b, c, d\\) with \\(a \\leq b\\) and \\(c \\leq d\\), \\[\\mathbb{P}(a \\leq X \\leq b, c \\leq Y \\leq d) = \\int_a^b \\int_c^d f_{X,Y}(x,y)dydx\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#what-is-a-joint-distribution",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#what-is-a-joint-distribution",
    "title": "Lesson 11: Joint distributions",
    "section": "What is a joint distribution?",
    "text": "What is a joint distribution?\n\n\n\n\nDefinition: joint pmf\n\n\nThe joint pmf of a pair of discrete RV’s \\(X\\) and \\(Y\\) is \\[\\begin{aligned}\np_{X,Y}(x,y) = & \\mathbb{P}(X=x \\cap Y=y) \\\\ = & \\mathbb{P}(X=x, Y=y)\n\\end{aligned}\\]\n\n\n\n\n\nDefinition: joint pdf\n\n\nThe joint pdf for two continuous RVs (\\(X\\) and \\(Y\\)) is \\(f_{X,Y}(x,y)\\), such that we have the following joint probability: \\[\\begin{aligned}\n\\mathbb{P}(a \\leq X \\leq b, & c \\leq Y \\leq d) = \\\\ & \\int_a^b \\int_c^d f_{X,Y}(x,y)dydx\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#important-properties-of-joint-distributions",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#important-properties-of-joint-distributions",
    "title": "Lesson 11: Joint distributions",
    "section": "Important properties of joint distributions",
    "text": "Important properties of joint distributions\n\n\n\n\nProperties of joint pmf’s\n\n\n\nA joint pmf \\(p_{X,Y}(x,y)\\) must satisfy the following properties:\n\n\\(0 \\geq p_{X,Y}(x,y) \\leq 1\\) for all \\(x, y\\)\n\n \n\n\\(\\sum \\limits_{\\{all\\ x\\}} \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)=1\\)\n\n\n\n\n\n\n\nProperties of joint pdf’s\n\n\n\nA joint pdf \\(f_{X,Y}(x,y)\\) must satisfy the following properties:\n\n\\(f_{X,Y}(x,y)\\geq 0\\) for all \\(x,y\\)\n\n \n\n\\(\\displaystyle\\int_{-\\infty}^{\\infty}\\displaystyle\\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dxdy=1\\)\n\n\n \n\nRemember that \\(f_{X,Y}(x,y)\\neq \\mathbb{P}(X=x, Y=y)\\)!!!"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#marginal-distributions",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#marginal-distributions",
    "title": "Lesson 11: Joint distributions",
    "section": "Marginal distributions",
    "text": "Marginal distributions\n\n\n\n\nMarginal pmf’s\n\n\nSuppose \\(X\\) and \\(Y\\) are discrete RV’s, with joint pmf \\(p_{X,Y}(x,y)\\). Then the marginal probability mass functions are\n\\[p_X(x) = \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)\\]\n\\[p_Y(y) = \\sum \\limits_{\\{all\\ x\\}} p_{X,Y}(x,y)\\]\n\n\n\n\n\nMarginal pdf’s\n\n\nSuppose \\(X\\) and \\(Y\\) are continuous RV’s, with joint pdf \\(f_{X,Y}(x,y)\\). Then the marginal probability density functions are \\[\\begin{aligned}\nf_X(x)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dy\\\\\nf_Y(y)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dx\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-cumulative-distribution-functions-cdfs",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-cumulative-distribution-functions-cdfs",
    "title": "Lesson 11: Joint distributions",
    "section": "Joint cumulative distribution functions (CDFs)",
    "text": "Joint cumulative distribution functions (CDFs)\n\n\n\n\nJoint CDF for discrete RVs\n\n\nThe joint CDF of a pair of discrete RV’s \\(X\\) and \\(Y\\) is \\[\\begin{aligned}\nF_{X,Y}(x,y) = &\\mathbb{P}(X \\leq x\\ and\\ Y \\leq y) \\\\ = &\\mathbb{P}(X \\leq x, Y \\leq y)\n\\end{aligned}\\]\n\n\n\n\n\nJoint CDF for continuous RVs\n\n\nThe joint CDF of continuous random variables \\(X\\) and \\(Y\\), is the function \\(F_{X,Y}(x,y)\\), such that for all real values of \\(x\\) and \\(y\\), \\[\\begin{aligned}\nF_{X,Y}(x,y)= \\mathbb{P}(X \\leq x, & Y \\leq y) = \\\\\n& \\int_{-\\infty}^x\\int_{-\\infty}^y f_{X,Y}(s,t)dtds\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-distribution-for-two-discrete-random-variables",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-distribution-for-two-discrete-random-variables",
    "title": "Lesson 11: Joint distributions",
    "section": "Joint distribution for two discrete random variables",
    "text": "Joint distribution for two discrete random variables\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\)\nFind \\(\\mathbb{P}(X+Y=3)\\)\nFind \\(\\mathbb{P}(Y = 1)\\)\nFind \\(\\mathbb{P}(Y \\leq 2)\\)\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#another-example-lets-complicate-this-even-more",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#another-example-lets-complicate-this-even-more",
    "title": "Lesson 11: Joint distributions",
    "section": "Another example: let’s complicate this even more!",
    "text": "Another example: let’s complicate this even more!\n\n\n\n\nExample 3.1\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nFind \\(\\mathbb{P}(|X-Y| &lt; 2)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#recall-finding-the-pdf-of-a-transformation",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#recall-finding-the-pdf-of-a-transformation",
    "title": "Lesson 11: Joint distributions",
    "section": "Recall: Finding the pdf of a transformation",
    "text": "Recall: Finding the pdf of a transformation\n\nLet \\(M\\) be a transformation of \\(X\\) and \\(Y\\): \\(M = g(X, Y)\\)\nWhen we have a transformation of \\(X\\) and \\(Y\\), \\(M\\), we need to follow the CDF method to find the pdf of \\(M\\)\n\nWe follow CDF method:\n\nStart with the joint pdf for \\(X\\) and \\(Y\\)\n\naka \\(f_{X,Y}(x, y)\\)\n\nTranslate the domain of \\(X\\) and \\(Y\\) to \\(M\\): find possible values of \\(M\\)\nFind the CDF of \\(M\\)\n\naka \\(F_M(m) = P(M \\leq m) = P(g(X, Y) \\leq m)\\)\n\nTake the derivative of the CDF of \\(M\\) with respect to \\(m\\) to find the pdf of \\(M\\)\n\naka \\(f_M(m) = \\dfrac{d}{dm}F_M(m)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-distribution-for-two-discrete-random-variables-16",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-distribution-for-two-discrete-random-variables-16",
    "title": "Lesson 11: Joint distributions",
    "section": "Joint distribution for two discrete random variables (1/6)",
    "text": "Joint distribution for two discrete random variables (1/6)\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\)\nFind \\(\\mathbb{P}(X+Y=3)\\)\nFind \\(\\mathbb{P}(Y = 1)\\)\nFind \\(\\mathbb{P}(Y \\leq 2)\\)\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-distribution-for-two-discrete-random-variables-16-1",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-distribution-for-two-discrete-random-variables-16-1",
    "title": "Lesson 11: Joint distributions",
    "section": "Joint distribution for two discrete random variables (1/6)",
    "text": "Joint distribution for two discrete random variables (1/6)\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\)\nFind \\(\\mathbb{P}(X+Y=3)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-distribution-for-two-discrete-random-variables-16-2",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-distribution-for-two-discrete-random-variables-16-2",
    "title": "Lesson 11: Joint distributions",
    "section": "Joint distribution for two discrete random variables (1/6)",
    "text": "Joint distribution for two discrete random variables (1/6)\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(\\mathbb{P}(Y = 1)\\)\nFind \\(\\mathbb{P}(Y \\leq 2)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-distribution-for-two-discrete-random-variables-16-3",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-distribution-for-two-discrete-random-variables-16-3",
    "title": "Lesson 11: Joint distributions",
    "section": "Joint distribution for two discrete random variables (1/6)",
    "text": "Joint distribution for two discrete random variables (1/6)\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-distribution-for-two-discrete-random-variables-15",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-distribution-for-two-discrete-random-variables-15",
    "title": "Lesson 11: Joint distributions",
    "section": "Joint distribution for two discrete random variables (1/5)",
    "text": "Joint distribution for two discrete random variables (1/5)\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\)\nFind \\(\\mathbb{P}(X+Y=3)\\)\nFind \\(\\mathbb{P}(Y = 1)\\)\nFind \\(\\mathbb{P}(Y \\leq 2)\\)\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-distribution-for-two-discrete-random-variables-25",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-distribution-for-two-discrete-random-variables-25",
    "title": "Lesson 11: Joint distributions",
    "section": "Joint distribution for two discrete random variables (2/5)",
    "text": "Joint distribution for two discrete random variables (2/5)\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\)\nFind \\(\\mathbb{P}(X+Y=3)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-distribution-for-two-discrete-random-variables-35",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-distribution-for-two-discrete-random-variables-35",
    "title": "Lesson 11: Joint distributions",
    "section": "Joint distribution for two discrete random variables (3/5)",
    "text": "Joint distribution for two discrete random variables (3/5)\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(\\mathbb{P}(Y = 1)\\)\nFind \\(\\mathbb{P}(Y \\leq 2)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-distribution-for-two-discrete-random-variables-45",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-distribution-for-two-discrete-random-variables-45",
    "title": "Lesson 11: Joint distributions",
    "section": "Joint distribution for two discrete random variables (4/5)",
    "text": "Joint distribution for two discrete random variables (4/5)\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-distribution-for-two-discrete-random-variables-55",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#joint-distribution-for-two-discrete-random-variables-55",
    "title": "Lesson 11: Joint distributions",
    "section": "Joint distribution for two discrete random variables (5/5)",
    "text": "Joint distribution for two discrete random variables (5/5)\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#common-steps-for-joint-pdfs-and-cdfs",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#common-steps-for-joint-pdfs-and-cdfs",
    "title": "Lesson 11: Joint distributions",
    "section": "Common steps for joint pdfs and CDFs",
    "text": "Common steps for joint pdfs and CDFs\n\nSet up the domain of the pdf with a picture\n\n \n\nTranslate to needed integrands\n\nFor probability: shade in the area of interest, then translate\nFor expected value: translate domain\n\n\n \n\nSet up integral: \\(dxdy\\) or \\(dydx\\)?\n\n \n\nSolve integral!"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-1-joint-pdf-12",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-1-joint-pdf-12",
    "title": "Lesson 11: Joint distributions",
    "section": "Example 1: Joint pdf (1/2)",
    "text": "Example 1: Joint pdf (1/2)\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-1-joint-pdf-22",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-1-joint-pdf-22",
    "title": "Lesson 11: Joint distributions",
    "section": "Example 1: Joint pdf (2/2)",
    "text": "Example 1: Joint pdf (2/2)\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-with-more-complicated-pdf-12",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-with-more-complicated-pdf-12",
    "title": "Lesson 11: Joint distributions",
    "section": "Example with more complicated pdf (1/2)",
    "text": "Example with more complicated pdf (1/2)\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 3.1\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-with-more-complicated-pdf-22",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-with-more-complicated-pdf-22",
    "title": "Lesson 11: Joint distributions",
    "section": "Example with more complicated pdf (2/2)",
    "text": "Example with more complicated pdf (2/2)\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 3.2\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(\\mathbb{P}(Y &lt; 3)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-of-a-joint-pdf-with-a-transformation-12",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-of-a-joint-pdf-with-a-transformation-12",
    "title": "Lesson 11: Joint distributions",
    "section": "Example of a joint pdf with a transformation (1/2)",
    "text": "Example of a joint pdf with a transformation (1/2)\n\n\n\n\nExample 4.1\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nFind \\(\\mathbb{P}(|X-Y| &lt; 2)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-of-a-joint-pdf-with-a-transformation-12-1",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-of-a-joint-pdf-with-a-transformation-12-1",
    "title": "Lesson 11: Joint distributions",
    "section": "Example of a joint pdf with a transformation (1/2)",
    "text": "Example of a joint pdf with a transformation (1/2)\n\n\n\n\nExample 4.2\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(M = \\max(X,Y)\\). Find the pdf for \\(M\\), that is \\(f_M(m)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-of-a-joint-pdf-with-a-transformation-12-2",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-of-a-joint-pdf-with-a-transformation-12-2",
    "title": "Lesson 11: Joint distributions",
    "section": "Example of a joint pdf with a transformation (1/2)",
    "text": "Example of a joint pdf with a transformation (1/2)\n\n\n\n\nExample 4.3\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(Z = \\min(X,Y)\\). Find the pdf for \\(Z\\), that is \\(f_Z(z)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#last-example-more-complicated-transformation",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#last-example-more-complicated-transformation",
    "title": "Lesson 11: Joint distributions",
    "section": "Last example: more complicated transformation",
    "text": "Last example: more complicated transformation\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 4\n\n\nLet \\(X\\) and \\(Y\\) have joint density \\(f_{X,Y}(x,y)= \\frac85(x+y)\\) in the region \\(0 &lt; x &lt; 1,\\ \\frac12 &lt; y &lt;1\\). Find the pdf of the RV \\(Z\\), where \\(Z=XY\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#last-example-for-home-more-complicated-transformation",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#last-example-for-home-more-complicated-transformation",
    "title": "Lesson 11: Joint distributions",
    "section": "Last example for home: more complicated transformation",
    "text": "Last example for home: more complicated transformation\n\n\n\n\nExample 5\n\n\nLet \\(X\\) and \\(Y\\) have joint density \\(f_{X,Y}(x,y)= \\frac85(x+y)\\) in the region \\(0 &lt; x &lt; 1,\\ \\frac12 &lt; y &lt;1\\). Find the pdf of the RV \\(Z\\), where \\(Z=XY\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-2-joint-pdf-12",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-2-joint-pdf-12",
    "title": "Lesson 11: Joint distributions",
    "section": "Example 2: Joint pdf (1/2)",
    "text": "Example 2: Joint pdf (1/2)\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-2-joint-pdf-22",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-2-joint-pdf-22",
    "title": "Lesson 11: Joint distributions",
    "section": "Example 2: Joint pdf (2/2)",
    "text": "Example 2: Joint pdf (2/2)\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#quick-remarks-on-the-joint-and-marginal-cdf",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#quick-remarks-on-the-joint-and-marginal-cdf",
    "title": "Lesson 11: Joint distributions",
    "section": "Quick remarks on the joint and marginal CDF",
    "text": "Quick remarks on the joint and marginal CDF\n\n\\(F_X(x)\\): right most columns of the CDF table (where the \\(Y\\) values are largest)\n\\(F_Y(y)\\): bottom row of the table (where X values are largest)\n\\(F_X(x)=\\lim\\limits_{y\\rightarrow\\infty}F_{X, Y}(x,y)\\)\n\\(F_Y(y)=\\lim\\limits_{x\\rightarrow\\infty}F_{X, Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities_muddy_points.html",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n1. How do pdf, CDF, and probability interact with each other?\nLet’s say we have a pdf, \\(f_X(x) = \\dfrac{1}{9}x^2\\) for \\(0 \\leq x \\leq 3\\). This is just a function. The pdf is not used on its own to report any probability. We must integrate over the pdf to find a probability.\n\nlibrary(\"ggplot2\")\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3)\n\n\n\n\n\n\n\n\nThe total area under the pdf is 1. This makes our pdf valid.\n\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 3),\n                geom = \"area\", \n                aes(fill = \"red\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 1\", color = \"black\")\n\n\n\n\n\n\n\n\nIf we only look at a proportion of the area under the pdf, then we start constructing our probabilities. For example, we can look at probability that we have a value between 0 and 1.5.\n\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 1.5),\n                geom = \"area\", \n                aes(fill = \"blue\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 0.125\", color = \"black\")\n\n\n\n\n\n\n\n\nInstead of calculating the EXACT probability for each value between 0 and 3, we can find the CDF of the pdf.\nThe CDF is: \\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;3 \\quad \\\\\n            \\dfrac{1}{27}x^3 & \\quad 0 \\leq x \\leq 3\\quad \\\\\n            1 & \\quad x&gt;3 \\quad\n        \\end{array}\n    \\right.\n\\]\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nWhen \\(x=1.5\\), we can calculate the probability using the CDF. Remember that \\(F_X(x) = P(X \\leq x)\\). So we can say \\(P(X \\leq 1.5) = F_X(1.5) = \\dfrac{1}{27}(1.5)^3\\), which equals 0.125.\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\") +\n  geom_point(aes(x=1.5, y=.125), colour=\"blue\", size=3) +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"CDF = 0.125\", color = \"black\")\n\nWarning in geom_point(aes(x = 1.5, y = 0.125), colour = \"blue\", size = 3): All aesthetics have length 1, but the data has 2 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\nWe can also calculate the probability with an integral: \\(P(X \\leq 1.5) = \\displaystyle\\int_0^{1.5} \\dfrac{1}{9}x^2 dx\\).\nWe can also find the probability that X is between two numbers. \\(P(1\\leq X \\leq 1.5) = F_X(1.5) - F_X(1)\\) or \\(P(1\\leq X \\leq 1.5) = \\displaystyle\\int_1^{1.5} \\dfrac{1}{9}x^2 dx\\).\n\n\n2. Joint vs marginal vs conditional: How are we calculating the probability?\nIf we start at a joint probability \\(f_{X,Y}(x,y)\\)…. we can look at a few probabilities:\n\nJoint probability: \\(P(a \\leq X \\leq b, c \\leq Y \\leq d)\\)\n\\[P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=c}^{y=d} f_{X,Y}(x,y) dydx\\]\nMarginal probability: \\(P(a \\leq X \\leq b)\\)\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b} f_{X}(x) dx\\]\nOR\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=-\\inf}^{y=\\inf} f_{X,Y}(x,y) dydx\\]\nConditional probability: \\(P(a \\leq X \\leq b | Y = c)\\)\n\\[P(a \\leq X \\leq b | Y=c) = \\displaystyle\\int_{x=a}^{x=b} f_{X|Y}(x|y=c) dx\\]\nYou cannot calculate \\(P(a \\leq X \\leq b | Y = c)\\) by \\(\\dfrac{P(a \\leq X \\leq b, Y=c)}{P(Y = c)}\\) because \\(P(Y = c)\\) is 0. Instead, we need to find \\(f_{X|Y}(x|y=c)\\) by \\(\\dfrac{f_{X,Y}(x,y=c)}{f_{Y}(y=c)}\\) and THEN integrate over X.\n\n\n\n3. What are we actually finding by solving the double integral. In the first example, we found the probability was 1/16 after integrating but what does 1/16 mean in relation to the random variables X and Y?\nIt means that the volume contained by \\(0\\leq X \\leq 1\\), \\(0\\leq Y \\leq 1/2\\), and their joint pdf is 1/16 of the total volume contained by \\(0\\leq X \\leq 2\\), \\(0\\leq Y \\leq 1\\), and their joint pdf. The probability for a joint pdf is now a measure of the proportion of the volume.\nThis is not be confused with a probability from marginal pdf or pdf from one RV. The probability for marginal/single RV pdfs is the proportion of the area under the pdf for a specific range of values.\n\n\n4. Here’s a 3D plot of one of our joint pdf’s\n\\[\nf_{X,Y}(x,y) = 5e^{-x-3y} \\text{ for } 0 \\leq y \\leq x/2\n\\]\n\nlibrary(plotly)\n\nx = seq(0, 5, 0.1)\ny = seq(0, max(x)/2, 0.1/2)\nfn = expand.grid(x=x,y=y)\nfn$z = ifelse(fn$y&lt;fn$x/2, 5*exp( (-1)*fn$x - 3*fn$y), NA)\n\nz = matrix(fn$z, ncol = 51, nrow = 51, byrow = T)\n\nfig &lt;- plot_ly(x = x, y=y, z=z) %&gt;% add_surface()\n\nfig"
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html",
    "title": "Chapter 25: Joint densities",
    "section": "",
    "text": "Solve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#learning-objectives",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#learning-objectives",
    "title": "Chapter 25: Joint densities",
    "section": "",
    "text": "Solve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#double-integrals-mini-lesson-13",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#double-integrals-mini-lesson-13",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (1/3)",
    "text": "Double Integrals Mini Lesson (1/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 1\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} xy dydx\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#double-integrals-mini-lesson-23",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#double-integrals-mini-lesson-23",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (2/3)",
    "text": "Double Integrals Mini Lesson (2/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 2\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} (x+y) dydx\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#double-integrals-mini-lesson-33",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#double-integrals-mini-lesson-33",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (3/3)",
    "text": "Double Integrals Mini Lesson (3/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 3\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} e^{x+y} dydx\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "title": "Chapter 25: Joint densities",
    "section": "How to define the joint pdf for continuous RVs?",
    "text": "How to define the joint pdf for continuous RVs?\n\n\nFor a single continuous RV \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\), \\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\]\n\nFor two continuous RVs (\\(X\\) and \\(Y\\)), we can define the joint pdf, \\(f_{X,Y}(x,y)\\), such that for all real values \\(a,b, c, d\\) with \\(a \\leq b\\) and \\(c \\leq d\\), \\[\\mathbb{P}(a \\leq X \\leq b, c \\leq Y \\leq d) = \\int_a^b \\int_c^d f_{X,Y}(x,y)dydx\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#important-properties-of-the-joint-pdf",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#important-properties-of-the-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Important properties of the joint pdf",
    "text": "Important properties of the joint pdf\n\nNote that \\(f_{X,Y}(x,y)\\neq \\mathbb{P}(X=x, Y=y)\\)!!!\nIn order for \\(f_{X,Y}(x,y)\\) to be a pdf, it needs to satisfy the properties\n\n\\(f_{X,Y}(x,y)\\geq 0\\) for all \\(x,y\\)\n\\(\\displaystyle\\int_{-\\infty}^{\\infty}\\displaystyle\\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dxdy=1\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "title": "Chapter 25: Joint densities",
    "section": "What is the joint cumulative distribution function?",
    "text": "What is the joint cumulative distribution function?\n\n\nDefinition: Joint cumulative distribution function (Joint CDF)\n\n\nThe joint cumulative distribution function (cdf) of continuous random variables \\(X\\) and \\(Y\\), is the function \\(F_{X,Y}(x,y)\\), such that for all real values of \\(x\\) and \\(y\\), \\[F_{X,Y}(x,y)= \\mathbb{P}(X \\leq x, Y \\leq y) = \\int_{-\\infty}^x\\int_{-\\infty}^y f_{X,Y}(s,t)dtds\\]\n\n\nRemarks:\n\nThe definition above for \\(F_{X,Y}(x,y)\\) is a function of \\(x\\) and \\(y\\).\nThe joint cdf at the point \\((a,b)\\), is \\[F_{X,Y}(a,b) = \\mathbb{P}(X \\leq a, Y \\leq b) = \\int_{-\\infty}^a\\int_{-\\infty}^b f_{X,Y}(s,t)dtds\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#what-are-the-marginal-pdfs",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#what-are-the-marginal-pdfs",
    "title": "Chapter 25: Joint densities",
    "section": "What are the marginal pdf’s?",
    "text": "What are the marginal pdf’s?\n\n\nDefinition: Marginal pdf’s\n\n\nSuppose \\(X\\) and \\(Y\\) are continuous r.v.’s, with joint pdf \\(f_{X,Y}(x,y)\\). Then the marginal probability density functions are \\[\\begin{aligned}\nf_X(x)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dy\\\\\nf_Y(y)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dx\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#common-steps-for-solving-problems",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#common-steps-for-solving-problems",
    "title": "Chapter 25: Joint densities",
    "section": "Common steps for solving problems",
    "text": "Common steps for solving problems\n\nSet up the domain of the pdf with a picture\nTranslate to needed integrands\n\nFor probability: shade in the area of interest, then translate\nFor expected value: translate domain\n\nSet up integral: \\(dxdy\\) or \\(dydx\\)?\nSolve integral!"
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#example-of-joint-pdf",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#example-of-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#example-of-joint-pdf-1",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#example-of-joint-pdf-1",
    "title": "Chapter 25: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "title": "Chapter 25: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(\\mathbb{P}(Y &lt; 3)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#lets-complicate-this-even-more",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#lets-complicate-this-even-more",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.1\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nFind \\(\\mathbb{P}(|X-Y| &lt; 2)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "title": "Chapter 25: Joint densities",
    "section": "Finding the pdf of a transformation",
    "text": "Finding the pdf of a transformation\n\nLet \\(M\\) be a transformation of \\(X\\) and \\(Y\\)\nWhen we have a transformation of \\(X\\) and \\(Y\\), \\(M\\), we need to follow a specific process to find the pdf of \\(M\\)\n\nWe follow this process:\n\nStart with the joint pdf for \\(X\\) and \\(Y\\)\n\naka \\(f_{X,Y}(x, y)\\)\n\nTranslate the domain of \\(X\\) and \\(Y\\) to \\(M\\)\nFind the CDF of \\(M\\)\n\naka \\(F_M(m)\\) or \\(P(M \\leq m)\\)\n\nTake the derivative of the CDF of \\(M\\) to find the pdf of \\(M\\)\n\naka \\(f_M(m) = \\dfrac{d}{dm}F_M(m)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#lets-complicate-this-even-more-1",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#lets-complicate-this-even-more-1",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.2\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(M = \\max(X,Y)\\). Find the pdf for \\(M\\), that is \\(f_M(m)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#lets-complicate-this-even-more-2",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#lets-complicate-this-even-more-2",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 3.3\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(Z = \\min(X,Y)\\). Find the pdf for \\(Z\\), that is \\(f_Z(z)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#lets-complicate-this-even-further",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities.html#lets-complicate-this-even-further",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even further!",
    "text": "Let’s complicate this even further!\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 4\n\n\nLet \\(X\\) and \\(Y\\) have joint density \\(f_{X,Y}(x,y)= \\frac85(x+y)\\) in the region \\(0 &lt; x &lt; 1,\\ \\frac12 &lt; y &lt;1\\). Find the pdf of the r.v. \\(Z\\), where \\(Z=XY\\)."
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities_key_info.html",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 6 assignment today!\n\nFeel free to turn in solutions later than 11/24 since I took so long to grade\n\nI made quite a few changes to the homeworks\n\nHW 10 is gone\nHW 9 is optional\nInstead of a HW assignment due over late November break\n\nHW 8 will include material from Week 8 and 9 and be due 12/5\n\n\nI have quite a bit of grading to catch up on!\nRealizing I never gave you mid-quarter feedback forms…\n\nLet’s chat about this and our assessment breakdown in the coming weeks\n\nAnything else?"
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities_key_info.html#announcements",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 6 assignment today!\n\nFeel free to turn in solutions later than 11/24 since I took so long to grade\n\nI made quite a few changes to the homeworks\n\nHW 10 is gone\nHW 9 is optional\nInstead of a HW assignment due over late November break\n\nHW 8 will include material from Week 8 and 9 and be due 12/5\n\n\nI have quite a bit of grading to catch up on!\nRealizing I never gave you mid-quarter feedback forms…\n\nLet’s chat about this and our assessment breakdown in the coming weeks\n\nAnything else?"
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities_key_info.html#key-dates",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 7 due\nSunday: HW 6 solutions due"
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities.html",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities.html",
    "title": "Chapter 25: Joint densities",
    "section": "",
    "text": "Solve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#learning-objectives",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#learning-objectives",
    "title": "Chapter 25: Joint densities",
    "section": "",
    "text": "Solve double integrals in our mini lesson!\nCalculate probabilities for a pair of continuous random variables\nCalculate a joint and marginal probability density function (pdf)\nCalculate a joint and marginal cumulative distribution function (CDF) from a pdf"
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#double-integrals-mini-lesson-13",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#double-integrals-mini-lesson-13",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (1/3)",
    "text": "Double Integrals Mini Lesson (1/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 1\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} xy dydx\\)"
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#double-integrals-mini-lesson-23",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#double-integrals-mini-lesson-23",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (2/3)",
    "text": "Double Integrals Mini Lesson (2/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 2\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} (x+y) dydx\\)"
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#double-integrals-mini-lesson-33",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#double-integrals-mini-lesson-33",
    "title": "Chapter 25: Joint densities",
    "section": "Double Integrals Mini Lesson (3/3)",
    "text": "Double Integrals Mini Lesson (3/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 3\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} e^{x+y} dydx\\)"
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#how-to-define-the-joint-pdf-for-continuous-rvs",
    "title": "Chapter 25: Joint densities",
    "section": "How to define the joint pdf for continuous RVs?",
    "text": "How to define the joint pdf for continuous RVs?\n\n\nFor a single continuous RV \\(X\\) is a function \\(f_X(x)\\), such that for all real values \\(a,b\\) with \\(a \\leq b\\), \\[\\mathbb{P}(a \\leq X \\leq b) = \\int_a^b f_X(x)dx\\]\n\nFor two continuous RVs (\\(X\\) and \\(Y\\)), we can define the joint pdf, \\(f_{X,Y}(x,y)\\), such that for all real values \\(a,b, c, d\\) with \\(a \\leq b\\) and \\(c \\leq d\\), \\[\\mathbb{P}(a \\leq X \\leq b, c \\leq Y \\leq d) = \\int_a^b \\int_c^d f_{X,Y}(x,y)dydx\\]"
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#important-properties-of-the-joint-pdf",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#important-properties-of-the-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Important properties of the joint pdf",
    "text": "Important properties of the joint pdf\n\nNote that \\(f_{X,Y}(x,y)\\neq \\mathbb{P}(X=x, Y=y)\\)!!!\nIn order for \\(f_{X,Y}(x,y)\\) to be a pdf, it needs to satisfy the properties\n\n\\(f_{X,Y}(x,y)\\geq 0\\) for all \\(x,y\\)\n\\(\\displaystyle\\int_{-\\infty}^{\\infty}\\displaystyle\\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dxdy=1\\)"
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#what-is-the-joint-cumulative-distribution-function",
    "title": "Chapter 25: Joint densities",
    "section": "What is the joint cumulative distribution function?",
    "text": "What is the joint cumulative distribution function?\n\n\nDefinition: Joint cumulative distribution function (Joint CDF)\n\n\nThe joint cumulative distribution function (cdf) of continuous random variables \\(X\\) and \\(Y\\), is the function \\(F_{X,Y}(x,y)\\), such that for all real values of \\(x\\) and \\(y\\), \\[F_{X,Y}(x,y)= \\mathbb{P}(X \\leq x, Y \\leq y) = \\int_{-\\infty}^x\\int_{-\\infty}^y f_{X,Y}(s,t)dtds\\]\n\n\nRemarks:\n\nThe definition above for \\(F_{X,Y}(x,y)\\) is a function of \\(x\\) and \\(y\\).\nThe joint cdf at the point \\((a,b)\\), is \\[F_{X,Y}(a,b) = \\mathbb{P}(X \\leq a, Y \\leq b) = \\int_{-\\infty}^a\\int_{-\\infty}^b f_{X,Y}(s,t)dtds\\]"
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#what-are-the-marginal-pdfs",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#what-are-the-marginal-pdfs",
    "title": "Chapter 25: Joint densities",
    "section": "What are the marginal pdf’s?",
    "text": "What are the marginal pdf’s?\n\n\nDefinition: Marginal pdf’s\n\n\nSuppose \\(X\\) and \\(Y\\) are continuous r.v.’s, with joint pdf \\(f_{X,Y}(x,y)\\). Then the marginal probability density functions are \\[\\begin{aligned}\nf_X(x)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dy\\\\\nf_Y(y)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dx\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#common-steps-for-solving-problems",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#common-steps-for-solving-problems",
    "title": "Chapter 25: Joint densities",
    "section": "Common steps for solving problems",
    "text": "Common steps for solving problems\n\nSet up the domain of the pdf with a picture\nTranslate to needed integrands\n\nFor probability: shade in the area of interest, then translate\nFor expected value: translate domain\n\nSet up integral: \\(dxdy\\) or \\(dydx\\)?\nSolve integral!"
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#example-of-joint-pdf",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#example-of-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.1\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)."
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#example-of-joint-pdf-1",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#example-of-joint-pdf-1",
    "title": "Chapter 25: Joint densities",
    "section": "Example of joint pdf",
    "text": "Example of joint pdf\n\n\n\n\nExample 1.2\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf",
    "title": "Chapter 25: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#example-of-a-more-complicated-joint-pdf-1",
    "title": "Chapter 25: Joint densities",
    "section": "Example of a more complicated joint pdf",
    "text": "Example of a more complicated joint pdf\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(\\mathbb{P}(Y &lt; 3)\\)."
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#lets-complicate-this-even-more",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#lets-complicate-this-even-more",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.1\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nFind \\(\\mathbb{P}(|X-Y| &lt; 2)\\)"
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#finding-the-pdf-of-a-transformation",
    "title": "Chapter 25: Joint densities",
    "section": "Finding the pdf of a transformation",
    "text": "Finding the pdf of a transformation\n\nLet \\(M\\) be a transformation of \\(X\\) and \\(Y\\)\nWhen we have a transformation of \\(X\\) and \\(Y\\), \\(M\\), we need to follow a specific process to find the pdf of \\(M\\)\n\nWe follow this process:\n\nStart with the joint pdf for \\(X\\) and \\(Y\\)\n\naka \\(f_{X,Y}(x, y)\\)\n\nTranslate the domain of \\(X\\) and \\(Y\\) to \\(M\\)\nFind the CDF of \\(M\\)\n\naka \\(F_M(m)\\) or \\(P(M \\leq m)\\)\n\nTake the derivative of the CDF of \\(M\\) to find the pdf of \\(M\\)\n\naka \\(f_M(m) = \\dfrac{d}{dm}F_M(m)\\)"
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#lets-complicate-this-even-more-1",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#lets-complicate-this-even-more-1",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\nExample 3.2\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(M = \\max(X,Y)\\). Find the pdf for \\(M\\), that is \\(f_M(m)\\)."
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#lets-complicate-this-even-more-2",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#lets-complicate-this-even-more-2",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even more!",
    "text": "Let’s complicate this even more!\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 3.3\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(Z = \\min(X,Y)\\). Find the pdf for \\(Z\\), that is \\(f_Z(z)\\)."
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#lets-complicate-this-even-further",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities.html#lets-complicate-this-even-further",
    "title": "Chapter 25: Joint densities",
    "section": "Let’s complicate this even further!",
    "text": "Let’s complicate this even further!\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 4\n\n\nLet \\(X\\) and \\(Y\\) have joint density \\(f_{X,Y}(x,y)= \\frac85(x+y)\\) in the region \\(0 &lt; x &lt; 1,\\ \\frac12 &lt; y &lt;1\\). Find the pdf of the r.v. \\(Z\\), where \\(Z=XY\\)."
  },
  {
    "objectID": "lessons/10_Transformations/Old_notes/25_Joint_densities_muddy_points.html",
    "href": "lessons/10_Transformations/Old_notes/25_Joint_densities_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n1. How do pdf, CDF, and probability interact with each other?\nLet’s say we have a pdf, \\(f_X(x) = \\dfrac{1}{9}x^2\\) for \\(0 \\leq x \\leq 3\\). This is just a function. The pdf is not used on its own to report any probability. We must integrate over the pdf to find a probability.\n\nlibrary(\"ggplot2\")\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3)\n\n\n\n\n\n\n\n\nThe total area under the pdf is 1. This makes our pdf valid.\n\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 3),\n                geom = \"area\", \n                aes(fill = \"red\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 1\", color = \"black\")\n\n\n\n\n\n\n\n\nIf we only look at a proportion of the area under the pdf, then we start constructing our probabilities. For example, we can look at probability that we have a value between 0 and 1.5.\n\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 1.5),\n                geom = \"area\", \n                aes(fill = \"blue\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 0.125\", color = \"black\")\n\n\n\n\n\n\n\n\nInstead of calculating the EXACT probability for each value between 0 and 3, we can find the CDF of the pdf.\nThe CDF is: \\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;3 \\quad \\\\\n            \\dfrac{1}{27}x^3 & \\quad 0 \\leq x \\leq 3\\quad \\\\\n            1 & \\quad x&gt;3 \\quad\n        \\end{array}\n    \\right.\n\\]\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nWhen \\(x=1.5\\), we can calculate the probability using the CDF. Remember that \\(F_X(x) = P(X \\leq x)\\). So we can say \\(P(X \\leq 1.5) = F_X(1.5) = \\dfrac{1}{27}(1.5)^3\\), which equals 0.125.\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\") +\n  geom_point(aes(x=1.5, y=.125), colour=\"blue\", size=3) +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"CDF = 0.125\", color = \"black\")\n\nWarning in geom_point(aes(x = 1.5, y = 0.125), colour = \"blue\", size = 3): All aesthetics have length 1, but the data has 2 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\nWe can also calculate the probability with an integral: \\(P(X \\leq 1.5) = \\displaystyle\\int_0^{1.5} \\dfrac{1}{9}x^2 dx\\).\nWe can also find the probability that X is between two numbers. \\(P(1\\leq X \\leq 1.5) = F_X(1.5) - F_X(1)\\) or \\(P(1\\leq X \\leq 1.5) = \\displaystyle\\int_1^{1.5} \\dfrac{1}{9}x^2 dx\\).\n\n\n2. Joint vs marginal vs conditional: How are we calculating the probability?\nIf we start at a joint probability \\(f_{X,Y}(x,y)\\)…. we can look at a few probabilities:\n\nJoint probability: \\(P(a \\leq X \\leq b, c \\leq Y \\leq d)\\)\n\\[P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=c}^{y=d} f_{X,Y}(x,y) dydx\\]\nMarginal probability: \\(P(a \\leq X \\leq b)\\)\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b} f_{X}(x) dx\\]\nOR\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=-\\inf}^{y=\\inf} f_{X,Y}(x,y) dydx\\]\nConditional probability: \\(P(a \\leq X \\leq b | Y = c)\\)\n\\[P(a \\leq X \\leq b | Y=c) = \\displaystyle\\int_{x=a}^{x=b} f_{X|Y}(x|y=c) dx\\]\nYou cannot calculate \\(P(a \\leq X \\leq b | Y = c)\\) by \\(\\dfrac{P(a \\leq X \\leq b, Y=c)}{P(Y = c)}\\) because \\(P(Y = c)\\) is 0. Instead, we need to find \\(f_{X|Y}(x|y=c)\\) by \\(\\dfrac{f_{X,Y}(x,y=c)}{f_{Y}(y=c)}\\) and THEN integrate over X.\n\n\n\n3. What are we actually finding by solving the double integral. In the first example, we found the probability was 1/16 after integrating but what does 1/16 mean in relation to the random variables X and Y?\nIt means that the volume contained by \\(0\\leq X \\leq 1\\), \\(0\\leq Y \\leq 1/2\\), and their joint pdf is 1/16 of the total volume contained by \\(0\\leq X \\leq 2\\), \\(0\\leq Y \\leq 1\\), and their joint pdf. The probability for a joint pdf is now a measure of the proportion of the volume.\nThis is not be confused with a probability from marginal pdf or pdf from one RV. The probability for marginal/single RV pdfs is the proportion of the area under the pdf for a specific range of values.\n\n\n4. Here’s a 3D plot of one of our joint pdf’s\n\\[\nf_{X,Y}(x,y) = 5e^{-x-3y} \\text{ for } 0 \\leq y \\leq x/2\n\\]\n\nlibrary(plotly)\n\nx = seq(0, 5, 0.1)\ny = seq(0, max(x)/2, 0.1/2)\nfn = expand.grid(x=x,y=y)\nfn$z = ifelse(fn$y&lt;fn$x/2, 5*exp( (-1)*fn$x - 3*fn$y), NA)\n\nz = matrix(fn$z, ncol = 51, nrow = 51, byrow = T)\n\nfig &lt;- plot_ly(x = x, y=y, z=z) %&gt;% add_surface()\n\nfig"
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities_key_info.html",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 6 assignment today!\n\nFeel free to turn in solutions later than 11/24 since I took so long to grade\n\nI made quite a few changes to the homeworks\n\nHW 10 is gone\nHW 9 is optional\nInstead of a HW assignment due over late November break\n\nHW 8 will include material from Week 8 and 9 and be due 12/5\n\n\nI have quite a bit of grading to catch up on!\nRealizing I never gave you mid-quarter feedback forms…\n\nLet’s chat about this and our assessment breakdown in the coming weeks\n\nAnything else?"
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities_key_info.html#announcements",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Grading HW 6 assignment today!\n\nFeel free to turn in solutions later than 11/24 since I took so long to grade\n\nI made quite a few changes to the homeworks\n\nHW 10 is gone\nHW 9 is optional\nInstead of a HW assignment due over late November break\n\nHW 8 will include material from Week 8 and 9 and be due 12/5\n\n\nI have quite a bit of grading to catch up on!\nRealizing I never gave you mid-quarter feedback forms…\n\nLet’s chat about this and our assessment breakdown in the coming weeks\n\nAnything else?"
  },
  {
    "objectID": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities_key_info.html#key-dates",
    "href": "lessons/11_Joint_distributions/Old_notes/25_Joint_densities_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 7 due\nSunday: HW 6 solutions due"
  },
  {
    "objectID": "homework/HW_05.html#extra-problems",
    "href": "homework/HW_05.html#extra-problems",
    "title": "Homework 5",
    "section": "Extra problems",
    "text": "Extra problems\n\nFreddy and Jane have entered a game in which they each win between 0 and 2 dollars. If X is the amount Freddy wins, and Y is the amount that Jane wins, they believe that the joint density of their winnings will be \\[f_{X,Y}(x, y) = \\dfrac{1}{4}xy \\text{ for } 0 \\leq x \\leq 2 \\text{ and } 0 \\leq y \\leq 2\\] and \\(f_{X,Y}(x, y) = 0\\) otherwise. Find the probability that their combined winnings exceed 2, i.e., find \\(P(X + Y &gt; 2)\\)."
  },
  {
    "objectID": "hw_answers/HW_05_ans.html#questions",
    "href": "hw_answers/HW_05_ans.html#questions",
    "title": "Homework 5 Answers",
    "section": "",
    "text": "Not given\n\\(f_Z(z) = nF_X(z)^{n-1}f_X(z)\\)\n\n\n\\(P(X&lt;Y) = 0.099995\\)\n\n\n\\(f_Z(z) = \\dfrac{11-2z}{5}e^{-2z}\\) for \\(0 \\leq z \\leq 5\\)\n\n\n2 cases: when \\(0&lt; z &lt; 1\\) and \\(1 \\leq z \\leq 2\\)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#probability-from-joint-pdf-from-two-independent-continuous-rvs",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#probability-from-joint-pdf-from-two-independent-continuous-rvs",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "Probability from joint pdf from two independent, continuous RVs",
    "text": "Probability from joint pdf from two independent, continuous RVs\n\n\n\n\nExample 1.2\n\n\nLet \\(X\\) and \\(Y\\) be independent r.v.’s with \\(f_X(x)= \\frac12\\), for \\(0 \\leq x \\leq 2\\) and \\(f_Y(y)= 3y^2\\), for \\(0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#how-do-we-represent-independent-rvs-in-a-joint-pmfpdf",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#how-do-we-represent-independent-rvs-in-a-joint-pmfpdf",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "How do we represent independent RVs in a joint pmf/pdf?",
    "text": "How do we represent independent RVs in a joint pmf/pdf?\nWhat do we know about independence for events?\nFor events: If \\(A \\perp B\\)\n\\[P(A \\cap B) = P(A)P(B)\\] \\[P(A|B) = P(A)\\]\n\n\n\n\nFor discrete RVs: If \\(X \\perp Y\\)\n\n\n\\[p_{X,Y}(x,y) = p_{X}(x)p_{Y}(y)\\] \\[F_{X,Y}(x,y) = F_{X}(x)F_{Y}(y)\\] \\[p_{X|Y}(x|y) = p_{X}(x)\\] \\[p_{Y|X}(y|x) = p_{Y}(y)\\]\n\n\n\n\n\n\n\nFor continuous RVs: If \\(X \\perp Y\\)\n\n\n\\[f_{X,Y}(x,y) = f_{X}(x)f_{Y}(y)\\] \\[F_{X,Y}(x,y) = F_{X}(x)F_{Y}(y)\\] \\[f_{X|Y}(x|y) = f_{X}(x)\\] \\[f_{Y|X}(y|x) = f_{Y}(y)\\]"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#how-do-we-represent-conditional-pmfspdfs",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#how-do-we-represent-conditional-pmfspdfs",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "How do we represent conditional pmfs/pdfs?",
    "text": "How do we represent conditional pmfs/pdfs?\nFor events:\n\\[P(A | B) = \\dfrac{P(A \\cap B)}{P(B)}\\]\n\n\n\n\nFor discrete RVs:\n\n\n\\[p_{X|Y}(x|y) = P(X=x|Y=y) = \\dfrac{p_{X,Y}(x,y)}{p_Y(y)}\\] \\[p_{Y|X}(y|x) = P(Y=y|X=x) = \\dfrac{p_{X,Y}(x,y)}{p_X(x)}\\]\nif denominator is greater than 0 (\\(p_Y(y) &gt; 0\\) or \\(p_X(x) &gt; 0\\))\n\n\n\n\n\n\n\nFor continuous RVs:\n\n\n\\[f_{X|Y}(x|y) = \\dfrac{f_{X,Y}(x,y)}{f_Y(y)}\\] \\[f_{Y|X}(y|x) = \\dfrac{f_{X,Y}(x,y)}{f_X(x)}\\]\nif denominator is greater than 0 (\\(f_Y(y) &gt; 0\\) or \\(f_X(x) &gt; 0\\))"
  },
  {
    "objectID": "homework/HW_06.html#questions",
    "href": "homework/HW_06.html#questions",
    "title": "Homework 6",
    "section": "Questions",
    "text": "Questions\n\nFrom last homework: The following table shows the results of a survey in which the subjects were a sample of 300 adults residing in a certain metropolitan area. Each subject was asked to indicate which of three policies they favored with respect to smoking in public places. (Table is from Biostatistics: A Foundation for Analysis in the Health Sciences, 10th Edition, Daniel, Wayne W.; Cross, Chad L., pg. 630)\n\n\n\n\n\nLet \\(X=\\) highest education level and \\(Y=\\) policy favored. We can let \\(X=1\\) for college graduate, \\(X=2\\) for high-school graduate, etc., and similarly for \\(Y\\), or just keep the category names for the different levels of \\(X\\) and \\(Y\\)\n\nMake a table for the conditional pmf \\(p_{X|Y}(x|y)\\) and briefly describe in words what the values are the probability of.\nMake a table for the conditional pmf \\(p_{Y|X}(y|x)\\) and briefly describe in words what the values are the probability of.\n\nEach day, Maude has a 1% chance of losing her cell phone (her behavior on different days is independent). Each day, Maude has a 3% chance of forgetting to eat breakfast (again, her behavior on different days is independent). Her breakfast and cell phone habits are independent. Let \\(X\\) be the number of days until she first loses her cell phone. Let \\(Y\\) be the number of days until she first forgets to eat breakfast. (Here, \\(X\\) and \\(Y\\) are independent.)\n\nFind the joint probability mass function of \\(X\\) and \\(Y\\).\nFind the joint cdf of \\(X\\) and \\(Y\\) and briefly explain what \\(F_{X,Y}(x,y)\\) represents in the context of the problem. (Hint: \\(\\sum_{n=1}^{N} r^{n-1} = \\frac{1-r^N}{1-r}\\) for \\(r \\neq 1\\).)\nFind the conditional pmf \\(p_{Y|X}(y|x)\\).\n\nConsider a pair of random variables \\(X\\), \\(Y\\) with constant joint density on the quadrilateral with vertices \\((0,0)\\), \\((2,0)\\), \\((2,6)\\), \\((0,12)\\).\n\nFor \\(0 \\leq y \\leq 6\\), find the conditional density \\(f_{X|Y}(x,y)\\) of \\(X\\), given \\(Y=y\\).\nFor \\(6 \\leq y \\leq 12\\), find the conditional density \\(f_{X|Y}(x,y)\\) of \\(X\\), given \\(Y=y\\).\nFind the conditional probability that \\(X \\leq 1\\), given \\(3 \\leq Y \\leq 9\\).\nFind \\(P(0.5 \\leq X \\leq 3 | Y=4)\\)\nFind \\(P(0.5 \\leq X \\leq 3 | Y=7)\\)"
  },
  {
    "objectID": "hw_answers/HW_06_ans.html#questions",
    "href": "hw_answers/HW_06_ans.html#questions",
    "title": "Homework 6 Answers",
    "section": "",
    "text": "Partial answers:\n\n\n\n\\(p_{X|Y}(X=\\text{high school}| Y=\\text{no smoking at all}) = 0.476\\)\n\n\n\\(p_{Y|X}( Y=\\text{no smoking at all}|X=\\text{high school}) = 0.200\\)\n\n\n\n\n\n\\(p_{X,Y}(x,y) = [0.99^{x-1}0.01][0.97^{y-1}0.03]\\) for \\(x,y = 0, 1, 2, ...\\)\n\n\n And hint: \n\n\n\n\n\n\n\n\\(f_{X|Y}(x|y)=\\frac{1}{2}\\) for (need \\(x\\) and \\(y\\) domains)\n\n\n\\(\\frac{4}{7}\\)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#learning-objectives",
    "href": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#learning-objectives",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCalculate probabilities for a pair of discrete random variables\nCalculate a joint, marginal, and conditional probability mass function (pmf)\nCalculate a joint, marginal, and conditional cumulative distribution function (CDF)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#where-are-we",
    "href": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#where-are-we",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#what-is-a-joint-pmf",
    "href": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#what-is-a-joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is a joint pmf?",
    "text": "What is a joint pmf?\n\n\nDefinition: joint pmf\n\n\nThe joint pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[p_{X,Y}(x,y) = \\mathbb{P}(X=x\\ and\\ Y=y) = \\mathbb{P}(X=x, Y=y)\\]"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#this-chapters-main-example",
    "href": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#this-chapters-main-example",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "This chapter’s main example",
    "text": "This chapter’s main example\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#joint-pmf",
    "href": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Joint pmf",
    "text": "Joint pmf\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\).\nFind \\(\\mathbb{P}(X+Y=3).\\)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#marginal-pmfs",
    "href": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#marginal-pmfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Marginal pmf’s",
    "text": "Marginal pmf’s\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(\\mathbb{P}(Y = 1).\\)\nFind \\(\\mathbb{P}(Y \\leq 2).\\)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#remarks-on-the-joint-pmf",
    "href": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#remarks-on-the-joint-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the joint pmf",
    "text": "Remarks on the joint pmf\nSome properties of joint pmf’s:\n\nA joint pmf \\(p_{X,Y}(x,y)\\) must satisfy the following properties:\n\n\\(p_{X,Y}(x,y)\\geq 0\\) for all \\(x, y\\).\n\\(\\sum \\limits_{\\{all\\ x\\}} \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)=1\\).\n\nMarginal pmf’s:\n\n\\(p_X(x) = \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)\\)\n\\(p_Y(y) = \\sum \\limits_{\\{all\\ x\\}} p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#what-is-a-joint-cdf",
    "href": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#what-is-a-joint-cdf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is a joint CDF?",
    "text": "What is a joint CDF?\n\n\nDefinition: joint CDF\n\n\nThe joint CDF of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is \\[F_{X,Y}(x,y) = \\mathbb{P}(X \\leq x\\ and\\ Y \\leq y) = \\mathbb{P}(X \\leq x, Y \\leq y)\\]"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#joint-cdfs",
    "href": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#joint-cdfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Joint CDFs",
    "text": "Joint CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#marginal-cdfs",
    "href": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#marginal-cdfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Marginal CDFs",
    "text": "Marginal CDFs\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#remarks-on-the-joint-and-marginal-cdf",
    "href": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#remarks-on-the-joint-and-marginal-cdf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the joint and marginal CDF",
    "text": "Remarks on the joint and marginal CDF\n\n\\(F_X(x)\\): right most columns of the CDf table (where the \\(Y\\) values are largest)\n\\(F_Y(y)\\): bottom row of the table (where X values are largest)\n\\(F_X(x)=\\lim\\limits_{y\\rightarrow\\infty}F_{X, Y}(x,y)\\)\n\\(F_Y(y)=\\lim\\limits_{x\\rightarrow\\infty}F_{X, Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#independence-and-conditioning",
    "href": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#independence-and-conditioning",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Independence and Conditioning",
    "text": "Independence and Conditioning\nRecall that for events \\(A\\) and \\(B\\),\n\n\\(\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}\\)\n\\(A\\) and \\(B\\) are independent if and only if\n\n\\(\\mathbb{P}(A|B) = \\mathbb{P}(A)\\)\n\\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A)\\cdot\\mathbb{P}(B)\\)\n\n\nIndependence and conditioning are defined similarly for r.v.’s, since \\[p_X(x) = \\mathbb{P}(X=x)\\ \\mathrm{and}\\ \\ p_{X,Y}(x,y) = \\mathbb{P}(X = x ,Y = y).\\]"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#what-is-the-conditional-pmf",
    "href": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#what-is-the-conditional-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "What is the conditional pmf?",
    "text": "What is the conditional pmf?\n\n\nDefinition: conditional pmf\n\n\nThe conditional pmf of a pair of discrete r.v.’s \\(X\\) and \\(Y\\) is defined as \\[p_{X|Y}(x|y) = \\mathbb{P}(X = x |Y = y) = \\frac{\\mathbb{P}(X = x\\ and\\ Y = y)}{\\mathbb{P}(Y = y)}\n=\\frac{p_{X,Y}(x,y) }{p_{Y}(y) }\\] if \\(p_{Y}(y) &gt; 0\\)."
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#remarks-on-the-conditional-pmf",
    "href": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#remarks-on-the-conditional-pmf",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Remarks on the conditional pmf",
    "text": "Remarks on the conditional pmf\nThe following properties follow from the conditional pmf definition:\n\nIf \\(X \\perp Y\\) (independent)\n\n\\(p_{X|Y}(x|y) = p_X(x)\\) for all \\(x\\) and \\(y\\)\n\\(p_{X,Y}(x,y) = p_X(x)p_Y(y)\\) for all \\(x\\) and \\(y\\)\nWhich also implies (\\(\\Rightarrow\\)): \\(F_{X,Y}(x,y) = F_X(x)F_Y(y)\\) for all \\(x\\) and \\(y\\)\n\nIf \\(X_1, X_2, …, X_n\\) are independent\n\n\\[p_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1=x_1, X_2=x_2, …, X_n=x_n)=\\prod\\limits_{i=1}^np_{X_i}(x_i)\\]\n\\[F_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1\\leq x_1, X_2\\leq x_2, …, X_n\\leq x_n)=\\prod\\limits_{i=1}^nP(X_i \\leq x_i) = \\prod\\limits_{i=1}^nF_{X_i}(x_i)\\]"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#conditional-pmfs",
    "href": "lessons/12_Independence_Conditioning/09_Joint_distributions.html#conditional-pmfs",
    "title": "Chapter 9: Independence and Conditioning (Joint Distributions)",
    "section": "Conditional pmf’s",
    "text": "Conditional pmf’s\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?\n\n\n\n\n\nRemark:\n\nTo show that \\(X\\) and \\(Y\\) are not independent, we just need to find one counter example\nHowever, to show that they are independent, we need to verify this for all possible pairs of \\(x\\) and \\(y\\)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#joint-distribution-for-two-discrete-random-variables-15",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#joint-distribution-for-two-discrete-random-variables-15",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "Joint distribution for two discrete random variables (1/5)",
    "text": "Joint distribution for two discrete random variables (1/5)\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X|Y}(x|y)\\).\nAre \\(X\\) and \\(Y\\) independent? Why or why not?\n\n\n\n\n\nRemark:\n\nTo show that \\(X\\) and \\(Y\\) are not independent, we just need to find one counter example\nHowever, to show that they are independent, we need to verify this for all possible pairs of \\(x\\) and \\(y\\)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#remarks-on-the-conditional-pmf",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#remarks-on-the-conditional-pmf",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "Remarks on the conditional pmf",
    "text": "Remarks on the conditional pmf\nThe following properties follow from the conditional pmf definition:\n\nIf \\(X \\perp Y\\) (independent)\n\n\\(p_{X|Y}(x|y) = p_X(x)\\) for all \\(x\\) and \\(y\\)\n\\(p_{X,Y}(x,y) = p_X(x)p_Y(y)\\) for all \\(x\\) and \\(y\\)\nWhich also implies (\\(\\Rightarrow\\)): \\(F_{X,Y}(x,y) = F_X(x)F_Y(y)\\) for all \\(x\\) and \\(y\\)\n\nIf \\(X_1, X_2, …, X_n\\) are independent\n\n\\[p_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1=x_1, X_2=x_2, …, X_n=x_n)=\\prod\\limits_{i=1}^np_{X_i}(x_i)\\]\n\\[F_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1\\leq x_1, X_2\\leq x_2, …, X_n\\leq x_n)=\\prod\\limits_{i=1}^nP(X_i \\leq x_i) = \\prod\\limits_{i=1}^nF_{X_i}(x_i)\\]"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#last-class-joint-distribution-for-two-discrete-random-variables-12",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#last-class-joint-distribution-for-two-discrete-random-variables-12",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "Last class: joint distribution for two discrete random variables (1/2)",
    "text": "Last class: joint distribution for two discrete random variables (1/2)\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X|Y}(x|y)\\)."
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#last-class-joint-distribution-for-two-discrete-random-variables-22",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#last-class-joint-distribution-for-two-discrete-random-variables-22",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "Last class: joint distribution for two discrete random variables (2/2)",
    "text": "Last class: joint distribution for two discrete random variables (2/2)\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nAre \\(X\\) and \\(Y\\) independent? Why or why not?\n\n\n\n\n\nRemark:\n\nTo show that \\(X\\) and \\(Y\\) are not independent, we just need to find one counter example\nHowever, to show that they are independent, we need to verify this for all possible pairs of \\(x\\) and \\(y\\)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#where-are-we",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#where-are-we",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#extra-notes-and-remarks",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#extra-notes-and-remarks",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "Extra notes and remarks",
    "text": "Extra notes and remarks\n\nIf \\(X_1, X_2, …, X_n\\) are independent\n\n\\[p_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1=x_1, X_2=x_2, …, X_n=x_n)=\\prod\\limits_{i=1}^np_{X_i}(x_i)\\] \\[f_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = \\prod\\limits_{i=1}^nf_{X_i}(x_i)\\] \\[F_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1\\leq x_1, X_2\\leq x_2, …, X_n\\leq x_n)=\\prod\\limits_{i=1}^nP(X_i \\leq x_i) = \\prod\\limits_{i=1}^nF_{X_i}(x_i)\\]\n\nDon’t forget, you can manipulate the conditional density to get the joint: \\[f_{X,Y}(x,y)= f_{X|Y}(x|y)f_Y(y)\\]\nFor a fixed value of \\(Y=y\\), the conditional density \\(f_{X|Y}(x|y)\\) is an actual pdf, meaning\n\n\\(f_{X|Y}(x|y)\\geq 0\\) for all \\(x\\) and \\(y\\), and\n\\(\\displaystyle\\int_{-\\infty}^{\\infty} f_{X|Y}(x|y)dx =1\\)."
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#remember-our-probability-rules-must-hold-for-these",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#remember-our-probability-rules-must-hold-for-these",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "Remember: our probability rules must hold for these!",
    "text": "Remember: our probability rules must hold for these!\n\n\n\n\nFor discrete RVs\n\n\nFor a valid joint pmf, we need:\n\n\\(0 \\geq p_{X,Y}(x,y) \\leq 1\\) for all \\(x, y\\)\n\\(\\sum \\limits_{\\{all\\ x\\}} \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)=1\\)\n\nFor a valid conditional pmf, we need:\n\n\\(0 \\geq p_{X|Y}(x|y) \\leq 1\\) for all \\(x, y\\)\n\\(\\sum \\limits_{\\{all\\ x\\}} p_{X|Y}(x|y)=1\\)\n\n\n\n\n\n\n\n\nFor continuous RVs\n\n\nFor a valid joint pdf, we need:\n\n\\(f_{X,Y}(x,y)\\geq 0\\) for all \\(x,y\\)\n\\(\\displaystyle\\int_{-\\infty}^{\\infty}\\displaystyle\\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dxdy=1\\)\n\nFor a valid conditional pdf, we need:\n\n\\(f_{X|Y}(x|y)\\geq 0\\) for all \\(x\\) and \\(y\\)\n\\(\\displaystyle\\int_{-\\infty}^{\\infty} f_{X|Y}(x|y)dx =1\\)"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#extra-notes",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning.html#extra-notes",
    "title": "Lesson 12: Independence and Conditioning",
    "section": "Extra notes",
    "text": "Extra notes\n\nIf \\(X_1, X_2, …, X_n\\) are independent\n\n\\[p_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1=x_1, X_2=x_2, …, X_n=x_n)=\\prod\\limits_{i=1}^np_{X_i}(x_i)\\] \\[f_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = \\prod\\limits_{i=1}^nf_{X_i}(x_i)\\] \\[F_{X_1, X_2, …, X_n}(x_1, x_2, …, x_n) = P(X_1\\leq x_1, X_2\\leq x_2, …, X_n\\leq x_n)=\\prod\\limits_{i=1}^nP(X_i \\leq x_i) = \\prod\\limits_{i=1}^nF_{X_i}(x_i)\\]\n\nDon’t forget, you can manipulate the conditional density to get the joint: \\[f_{X,Y}(x,y)= f_{X|Y}(x|y)f_Y(y)\\]"
  },
  {
    "objectID": "lessons/12_Independence_Conditioning/12_Independence_conditioning_muddy_points.html#fall-2023",
    "href": "lessons/12_Independence_Conditioning/12_Independence_conditioning_muddy_points.html#fall-2023",
    "title": "Muddy Points",
    "section": "",
    "text": "If we start at a joint probability \\(f_{X,Y}(x,y)\\)…. we can look at a few probabilities:\n\nJoint probability: \\(P(a \\leq X \\leq b, c \\leq Y \\leq d)\\)\n\\[P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=c}^{y=d} f_{X,Y}(x,y) dydx\\]\nMarginal probability: \\(P(a \\leq X \\leq b)\\)\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b} f_{X}(x) dx\\]\nOR\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=-\\inf}^{y=\\inf} f_{X,Y}(x,y) dydx\\]\nConditional probability: \\(P(a \\leq X \\leq b | Y = c)\\)\n\\[P(a \\leq X \\leq b | Y=c) = \\displaystyle\\int_{x=a}^{x=b} f_{X|Y}(x|y=c) dx\\]\nYou cannot calculate \\(P(a \\leq X \\leq b | Y = c)\\) by \\(\\dfrac{P(a \\leq X \\leq b, Y=c)}{P(Y = c)}\\) because \\(P(Y = c)\\) is 0. Instead, we need to find \\(f_{X|Y}(x|y=c)\\) by \\(\\dfrac{f_{X,Y}(x,y=c)}{f_{Y}(y=c)}\\) and THEN integrate over X."
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_muddy_points.html",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Yes! \\(M\\) is just a transformation of \\(X\\) and \\(Y\\)! Think of creating a new random variable that is dependent on \\(X\\) and \\(Y\\). We have created a single random variable from two. Then we want to see for the random variable, M, what does its pdf look like?\n\n\n\nYes! If we are going from a joint pdf to a marginal, we can to integrate over one of the random variables. If we want a marginal of X, then we integrate over Y, and that will be a single integral.\nIf we are working with a joint pdf, then we need to have two integrals if we have two random variables.\n\n\n\nI feel that. In general, a transformation (say \\(M\\)) of \\(X\\) and \\(Y\\) will be in the 3rd dimension (3D plot). The joint pdf of \\(X\\) and \\(Y\\) will be in the 3rd dimension (3D plot). But once we have \\(M\\) and its CDF/pdf, those are in 2D plot of \\(M\\) vs. \\(f_M(m)\\)."
  },
  {
    "objectID": "lessons/08_pdfs/08_pdfs_muddy_points.html#fall-2023",
    "href": "lessons/08_pdfs/08_pdfs_muddy_points.html#fall-2023",
    "title": "Muddy Points",
    "section": "Fall 2023",
    "text": "Fall 2023\n\n1. How do pdf, CDF, and probability interact with each other?\nLet’s say we have a pdf, \\(f_X(x) = \\dfrac{1}{9}x^2\\) for \\(0 \\leq x \\leq 3\\). This is just a function. The pdf is not used on its own to report any probability. We must integrate over the pdf to find a probability.\n\nlibrary(\"ggplot2\")\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3)\n\n\n\n\n\n\n\n\nThe total area under the pdf is 1. This makes our pdf valid.\n\neq = function(x){(1/9)*x^2}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 3),\n                geom = \"area\", \n                aes(fill = \"red\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 1\", color = \"black\")\n\n\n\n\n\n\n\n\nIf we only look at a proportion of the area under the pdf, then we start constructing our probabilities. For example, we can look at probability that we have a value between 0 and 1.5.\n\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=eq) +\n  xlab(\"x\") + ylab(\"pdf\") +\n  xlim(0,3) +\n  stat_function(fun=eq, \n                xlim = c(0, 1.5),\n                geom = \"area\", \n                aes(fill = \"blue\")) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"AUC = 0.125\", color = \"black\")\n\n\n\n\n\n\n\n\nInstead of calculating the EXACT probability for each value between 0 and 3, we can find the CDF of the pdf.\nThe CDF is: \\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;3 \\quad \\\\\n            \\dfrac{1}{27}x^3 & \\quad 0 \\leq x \\leq 3\\quad \\\\\n            1 & \\quad x&gt;3 \\quad\n        \\end{array}\n    \\right.\n\\]\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nWhen \\(x=1.5\\), we can calculate the probability using the CDF. Remember that \\(F_X(x) = P(X \\leq x)\\). So we can say \\(P(X \\leq 1.5) = F_X(1.5) = \\dfrac{1}{27}(1.5)^3\\), which equals 0.125.\n\ncdf = function(x){(1/27)*x^3}\nggplot(data.frame(x=c(1, 50)), aes(x=x)) + \n  stat_function(fun=cdf) +\n  xlab(\"x\") + ylab(\"CDF\") +\n  xlim(0,3) +\n  theme(legend.position = \"none\") +\n  geom_point(aes(x=1.5, y=.125), colour=\"blue\", size=3) +\n  annotate(\"text\", x = 0.5, y = 0.7, label = \"CDF = 0.125\", color = \"black\")\n\nWarning in geom_point(aes(x = 1.5, y = 0.125), colour = \"blue\", size = 3): All aesthetics have length 1, but the data has 2 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\nWe can also calculate the probability with an integral: \\(P(X \\leq 1.5) = \\displaystyle\\int_0^{1.5} \\dfrac{1}{9}x^2 dx\\).\nWe can also find the probability that X is between two numbers. \\(P(1\\leq X \\leq 1.5) = F_X(1.5) - F_X(1)\\) or \\(P(1\\leq X \\leq 1.5) = \\displaystyle\\int_1^{1.5} \\dfrac{1}{9}x^2 dx\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_muddy_points.html#fall-2024",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_muddy_points.html#fall-2024",
    "title": "Muddy Points",
    "section": "Fall 2024",
    "text": "Fall 2024\n\n1. What are we actually finding by solving the double integral. In the first example, we found the probability was 1/16 after integrating but what does 1/16 mean in relation to the random variables X and Y?\nIt means that the volume contained by \\(0\\leq X \\leq 1\\), \\(0\\leq Y \\leq 1/2\\), and their joint pdf is 1/16 of the total volume contained by \\(0\\leq X \\leq 2\\), \\(0\\leq Y \\leq 1\\), and their joint pdf. The probability for a joint pdf is now a measure of the proportion of the volume.\nThis is not be confused with a probability from marginal pdf or pdf from one RV. The probability for marginal/single RV pdfs is the proportion of the area under the pdf for a specific range of values.\n\n\n2. Here’s a 3D plot of one of our joint pdf’s\n\\[\nf_{X,Y}(x,y) = 5e^{-x-3y} \\text{ for } 0 \\leq y \\leq x/2\n\\]\n\nlibrary(plotly)\n\nx = seq(0, 5, 0.1)\ny = seq(0, max(x)/2, 0.1/2)\nfn = expand.grid(x=x,y=y)\nfn$z = ifelse(fn$y&lt;fn$x/2, 5*exp( (-1)*fn$x - 3*fn$y), NA)\n\nz = matrix(fn$z, ncol = 51, nrow = 51, byrow = T)\n\nfig &lt;- plot_ly(x = x, y=y, z=z) %&gt;% add_surface()\n\nfig"
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#where-are-we",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#where-are-we",
    "title": "Lesson 13: Expected Values",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#our-good-and-fair-friend-the-6-sided-die",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#our-good-and-fair-friend-the-6-sided-die",
    "title": "Lesson 13: Expected Values",
    "section": "Our good and fair friend, the 6-sided die",
    "text": "Our good and fair friend, the 6-sided die\n\n\n\n\nExample 1\n\n\nSuppose you roll a fair 6-sided die. What value do you expect to get?"
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#what-is-an-expected-value",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#what-is-an-expected-value",
    "title": "Lesson 13: Expected Values",
    "section": "What is an expected value?",
    "text": "What is an expected value?\n\n\n\n\nDefinition: Expected value of discrete RV\n\n\nThe expected value of a discrete RV \\(X\\) that takes on values \\(x_1, x_2, \\ldots, x_n\\) is \\[\\mathbb{E}[X] = \\sum_{i=1}^n x_ip_X(x_i)\\] where \\(n\\) can be \\(\\infty\\)\n\n\n\n\n\nDefinition: Expected value of continuous RV\n\n\nThe expected value of a continuous RV \\(X\\) is \\[\\mathbb{E}[X] = \\displaystyle\\int_{-\\infty}^\\infty xf_X(x) dx\\] where we adjust the integrand based on the bounds of \\(X\\)\n\n\n\n\nExpected values are not necessarily an actual outcome\n\nIn previous example, we cannot roll a 3.5\nIt could be that our expected value is not in the sample space (\\(E(X) \\notin S\\))"
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#our-good-and-not-so-fair-friend-the-6-sided-die",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#our-good-and-not-so-fair-friend-the-6-sided-die",
    "title": "Lesson 13: Expected Values",
    "section": "Our good and not-so-fair friend, the 6-sided die",
    "text": "Our good and not-so-fair friend, the 6-sided die\n\n\n\n\nExample 2\n\n\nSuppose the die is 6-sided, but not fair. And the probabilities of each side is distributed as:\n\n\n\n\\(x\\)\n\\(p_X(x)\\)\n\n\n\n\n1\n0.10\n\n\n2\n0.05\n\n\n3\n0.02\n\n\n4\n0.30\n\n\n5\n0.50\n\n\n6\n0.03\n\n\n\nWhat value do you expect to get on a roll?"
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#expected-value-of-a-bernoulli-distribution",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#expected-value-of-a-bernoulli-distribution",
    "title": "Lesson 13: Expected Values",
    "section": "Expected value of a Bernoulli distribution",
    "text": "Expected value of a Bernoulli distribution\n\n\n\n\nExample 3\n\n\nSuppose \\[X = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\quad\\mathrm{(success)}\\\\\n            0 & \\quad \\mathrm{with\\ probability}\\ 1-p \\quad\\mathrm{(failure)}\n        \\end{array}\n    \\right.\\] Find the expected value of \\(X\\)."
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#lets-slightly-change-our-random-variable",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#lets-slightly-change-our-random-variable",
    "title": "Lesson 13: Expected Values",
    "section": "Let’s slightly change our random variable",
    "text": "Let’s slightly change our random variable\n\n\n\n\nExample 4\n\n\nSuppose \\[X = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\\\\n            -1 & \\quad \\mathrm{with\\ probability}\\ 1-p\n        \\end{array}\n    \\right.\\] Find the expected value of \\(X\\)."
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#ghost",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#ghost",
    "title": "Lesson 13: Expected Values",
    "section": "Ghost! 👻",
    "text": "Ghost! 👻\n\n\n\n\nExample 6\n\n\nA ghost is trick-or-treating. It comes to a house where it is known that there are 30 candies in the bag and only one is a watermelon Jolly Rancher, which is the ghost’s favorite. The ghost takes pieces of candy without replacement until it gets the watermelon Jolly Rancher. How many pieces of candy do we expect the ghost to take?\n\n\nCan we model this with a distribution?"
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#revisiting-our-two-card-draw",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#revisiting-our-two-card-draw",
    "title": "Lesson 13: Expected Values",
    "section": "Revisiting our two card draw",
    "text": "Revisiting our two card draw\n\n\n\n\nExample 7\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw. Find \\(\\mathbb{E}[X]\\).\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#what-if-we-draw-a-lot-of-cards",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#what-if-we-draw-a-lot-of-cards",
    "title": "Lesson 13: Expected Values",
    "section": "What if we draw A LOT of cards?",
    "text": "What if we draw A LOT of cards?\n\n\n\n\nExample 2\n\n\nWhat is the expected number of hearts in Example 1 if you draw 200 cards?\n\n\n\n\nRecall Binomial RV with \\(n=200\\):\n\\[p_X(x) = {200 \\choose x}p^x(1-p)^{200-x}\\] \\[\\text{  for } x = 0, 1, 2, ..., 200\\]"
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#sum-of-discrete-rvs",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#sum-of-discrete-rvs",
    "title": "Lesson 13: Expected Values",
    "section": "Sum of discrete RVs",
    "text": "Sum of discrete RVs\n\n\nTheorem 11.1: Sum of discrete RVs\n\n\nFor discrete RV’s \\(X_i\\) and constants \\(a_i\\), \\(i=1,2,\\dots, n\\), \\[\\mathbb{E}\\Bigg[\\sum_{i=1}^n a_iX_i\\Bigg] = \\sum_{i=1}^n a_i\\mathbb{E}[X_i] .\\] Remark: The theorem holds for infinitely RV’s \\(X_i\\) as well.\n\n\n\nFor two RVs, \\(X\\) and \\(Y\\):\n\nWe can say \\(E[X+Y] = E[X] + E[Y]\\)\n… and constant numbers \\(a\\) and \\(b\\), we can also say \\(E[aX+bY] = aE[X] + bE[Y]\\)\nWe can also also say \\(E[X-Y] = E[X] - E[Y]\\), since \\(b=-1\\)"
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#corollaries-from-thm-11.1",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#corollaries-from-thm-11.1",
    "title": "Lesson 13: Expected Values",
    "section": "Corollaries from Thm 11.1",
    "text": "Corollaries from Thm 11.1\n\n\n\n\nFunction with two constants\n\n\nFor a RV \\(X\\), and constants \\(a\\) and \\(b\\), \\[\\mathbb{E}[aX+b] = a\\mathbb{E}[X] + b.\\]\n\n\n\n\n\nExpected value of sum of identically distributed RVs\n\n\nIf \\(X_i\\), \\(i=1,2,\\dots, n\\), are identically distributed RV’s, then \\[\\mathbb{E}\\bigg[\\sum_{i=1}^n X_i\\bigg] = n\\mathbb{E}[X_1] .\\]"
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#cost-of-hotel-rooms",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#cost-of-hotel-rooms",
    "title": "Lesson 13: Expected Values",
    "section": "Cost of hotel rooms",
    "text": "Cost of hotel rooms\n\n\n\n\nExample 8\n\n\nA tour group is planning a visit to the city of Minneapolis and needs to book 30 hotel rooms. The average price of a room is $200. In addition, there is a 10% tourism tax for each room. What is the expected cost for the 30 hotel rooms?"
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#expected-value-of-a-function-of-a-continuous-rv",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#expected-value-of-a-function-of-a-continuous-rv",
    "title": "Lesson 13: Expected Values",
    "section": "Expected value of a function of a continuous RV",
    "text": "Expected value of a function of a continuous RV\n\n\nHow do we calculate expected values of discrete RVs?\n       \nFor discrete RVs: weight average \\[\\mathbb{E}[X] = \\sum_{i=1}^n x_ip_X(x_i).\\]\n\n\n\nHow do we calculate expected values of continuous RVs?\n       \nFor continuous RVs:"
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#expected-value-of-the-uniform-distribution",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#expected-value-of-the-uniform-distribution",
    "title": "Lesson 13: Expected Values",
    "section": "Expected Value of the Uniform Distribution",
    "text": "Expected Value of the Uniform Distribution\n\n\n\n\nExample 5\n\n\nLet \\(f_X(x)= \\frac{1}{b-a}\\), for \\(a \\leq x \\leq b\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#expected-value-of-the-exponential-distribution",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#expected-value-of-the-exponential-distribution",
    "title": "Lesson 13: Expected Values",
    "section": "Expected Value of the Exponential Distribution",
    "text": "Expected Value of the Exponential Distribution\n\n\n\n\nExample 6\n\n\nLet \\(f_X(x)= \\lambda e^{-\\lambda x}\\), for \\(x &gt; 0\\) and \\(\\lambda&gt; 0\\). Find \\(\\mathbb{E}[X]\\).\n\n\n\n\nIntegrating by Parts\n\n\n\\(\\displaystyle\\int_a^b u dv = uv\\bigg|^b_a - \\displaystyle\\int_a^b vdu\\)"
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#remark-on-expected-value-of-one-rv-from-joint-pdf",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#remark-on-expected-value-of-one-rv-from-joint-pdf",
    "title": "Lesson 13: Expected Values",
    "section": "Remark on expected value of one RV from joint pdf",
    "text": "Remark on expected value of one RV from joint pdf\nIf you are given \\(f_{X,Y}(x,y)\\) and want to calculate \\(\\mathbb{E}[X]\\), you have two options:\n\nFind \\(f_X(x)\\) and use it to calculate \\(\\mathbb{E}[X]\\).\nOr, calculate \\(\\mathbb{E}[X]\\) using the joint density: \\[\\mathbb{E}[X] = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}x f_{X,Y}(x,y)dydx.\\]"
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#option-1-expected-value-from-a-joint-distribution",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#option-1-expected-value-from-a-joint-distribution",
    "title": "Lesson 13: Expected Values",
    "section": "Option 1: Expected value from a joint distribution",
    "text": "Option 1: Expected value from a joint distribution\n\n\n\n\nExample 3\n\n\nLet \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#option-2-expected-value-from-a-joint-distribution",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#option-2-expected-value-from-a-joint-distribution",
    "title": "Lesson 13: Expected Values",
    "section": "Option 2: Expected value from a joint distribution",
    "text": "Option 2: Expected value from a joint distribution\n\n\n\n\nExample 9\n\n\nLet \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs_key_info.html",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 videos should be in!\n\nSome presentations today\n\nNeed to grade HW 4 solutions and HW 5 assignment STILL\n\nHappy to be flexible on the HW 5 solutions deadline\n\nAnything else?"
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs_key_info.html#announcements",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 3 videos should be in!\n\nSome presentations today\n\nNeed to grade HW 4 solutions and HW 5 assignment STILL\n\nHappy to be flexible on the HW 5 solutions deadline\n\nAnything else?"
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs_key_info.html#key-dates",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 6 due\nSunday: HW 5 solutions due\n\nFLEXIBLE"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions_key_info.html",
    "href": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "LAST CLASS!!!!\nHomework 7and 6 solutions are graded\nHW 7 meetings are up on Calendly\n\nSee my announcement from Sakai\n\nI will be finalizing and posting HW 9 tomorrow\n\nOptional!\n\nPlease do your course evals!!\n\nEspecially in a small class\n\nFriday 12/13 is the absolute deadline for turning in materials if you are completing the course! _ Check Sakai that I have all your HW grades in!\nAnything else?"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions_key_info.html#announcements",
    "href": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "LAST CLASS!!!!\nHomework 7and 6 solutions are graded\nHW 7 meetings are up on Calendly\n\nSee my announcement from Sakai\n\nI will be finalizing and posting HW 9 tomorrow\n\nOptional!\n\nPlease do your course evals!!\n\nEspecially in a small class\n\nFriday 12/13 is the absolute deadline for turning in materials if you are completing the course! _ Check Sakai that I have all your HW grades in!\nAnything else?"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions_key_info.html#key-dates",
    "href": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday (12/5): HW 8 assignment due\nSunday (12/8): HW 7 presentations due at 11pm\n\nI can be pretty flexible until 12/13\n\nThursday (12/12): Optional HW 9 assignment due\nFriday (12/13): HW 8 solutions due"
  },
  {
    "objectID": "lessons/19_Moment_Generating_Functions/21_Moment_Generating_Functions.html",
    "href": "lessons/19_Moment_Generating_Functions/21_Moment_Generating_Functions.html",
    "title": "Chapter 43: Moment Generating Functions Part 2",
    "section": "",
    "text": "Chapter 43: Moment Generating Functions Part 2\nRecap: What is an mgf?\n\nExample 1.   Let \\(X\\) be a random variable with mgf \\[M_X(t)= \\frac{1}{5}e^t + \\frac{3}{10}e^{2t} + \\frac{1}{2}e^{3t}.\\] Find the pmf or pdf of \\(X\\).\n\n\nExample 2.   Let \\(X\\) be a normal random variable with mean \\(\\mu\\) and variance \\(\\sigma^2\\), i.e. \\(X \\sim N(\\mu,\\sigma^2)\\).\n\nFind the mgf of \\(X\\).\nFind \\(\\mathbb{E}[X]\\).\nFind \\(Var(X)\\).\n\n\n\n\nTheorem 3.   Let \\(X\\) have mgf \\(M_X(t)\\), and let \\(Y=aX+b\\), where \\(a\\) and \\(b\\) are constants. Then \\[M_Y(t)=\\]\n\n\nProof. Proof. ◻\n\nQuestion: Do linear transformations always preserve the distribution type?\nI.e., if \\(X\\) has a certain probability distribution, does \\(aX+b\\) always have the same distribution type?\n\n\nExample 4.   Let \\(X \\sim U[0,1]\\), and \\(Y = 2X+3\\). Is \\(Y\\) also a uniform rv? If so, what are its parameters?\n\n\nExample 5.   Let \\(X \\sim Exp(\\lambda=5)\\), and \\(Y = 2X+3\\). Is \\(Y\\) also an exponential rv? If so, what is its parameter?\n\nMgf’s of Sums of Independent rv’s\n\n\nTheorem 6.   Let \\(X_1, X_2, \\ldots, X_n\\) be independent rv’s with respective mgf’s \\(M_{X_i}(t)\\), for \\(i=1,2,\\ldots,n\\). Let \\(Y=\\sum_{i=1}^n a_iX_i\\), where \\(a_i\\) are constants. Then \\[M_Y(t)= %\\Pi_{i=1}^n M_{X_i}(a_it).\\]\n\n\nProof. Proof. ◻\n\n\n\nExample 7.   Let \\(X_i \\sim N(\\mu_i, \\sigma_i^2)\\) be independent normal rv’s. What is the distribution of  \\(Y=\\sum_{i=1}^n X_i\\)?\n\n\n\nExample 8.   Let \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). What is the distribution of  \\(\\bar{X}=\\frac{\\sum_{i=1}^n X_i}{n}\\)?\n\n\nExample 9.   Let \\(Z\\) be a standard normal random variable, i.e. \\(Z \\sim N(0,1)\\). Show that \\(Z^2 \\sim \\chi_1^2\\), i.e. is a chi-squared rv with 1 degree of freedom."
  },
  {
    "objectID": "lessons/14_Variance/16_Variance_muddy_points.html",
    "href": "lessons/14_Variance/16_Variance_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy Points from Fall 2023:\n\n1. Proof of variance formula\nHere is the variance formula that we worked through on slide 9 of Chapter 12’s notes.\n\n\n\n\n\n\nNoteLemma 6: “Computation formula” for variance\n\n\n\nThe variance of a r.v. \\(X\\), can be computed as \\[\\begin{align}\\sigma_X^2 & =Var(X) \\\\ & = \\mathbb{E}[X^2]-\\mu_X^2 \\\\ & = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2\\end{align}\\]\n\n\nI stepped through this quite quickly and made some implicit steps. So let’s revisit it with explicit steps!\n       \n\n\n2. What progression are we following in the course??\nSomeone asked if this is our progression: RV is function \\(\\to\\) Expected value is function to describe mean of RV \\(\\to\\) Use functions within expected value to set up variance\nBasically, yes! The random variable is a function of a random process. The RV inherits that randomness.\nFrom there, we’ve been working towards calculating the probability of a realized value ($x$) of the RV. The probability can be different for different realized values (as it links back to the random process).\nWe also want to construct ways to describe our random variables. We may want to figure out what to expect from our random variable (which translates to the mean value of the RV). Since our RV is rooted in a random process, we may want to get an idea of how spread out our realized values are. We use our expected value (mean) as an anchor in our spread. Variance is one way to measure this spread."
  },
  {
    "objectID": "lessons/14_Variance/16_Variance.html",
    "href": "lessons/14_Variance/16_Variance.html",
    "title": "Lesson 16: Variance",
    "section": "",
    "text": "Calculate the variance and standard deviation of discrete random variables\nCalculate the variance of sums of discrete random variables\nCalculate the variance of functions of discrete random variables\nCalculate expected value of functions of RVs\nCalculate variance of RVs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 1\n\n\nLet \\(g\\) be a function and let \\(g(x) = ax+b\\), for real-valued constants \\(a\\) and \\(b\\). What is \\(\\mathbb{E}[g(X)]\\)?\n\n\n\n\n\n\n\n\n\nDefinition: Expected value of function of RV\n\n\nFor any function \\(g\\) and discrete r.v. \\(X\\), the expected value of \\(g(X)\\) is \\[\\mathbb{E}[g(X)] = \\sum_{\\{all\\ x\\}}\\ g(x) p_X(x).\\]\n\n\n\n\n\n\n\n\n\nExample 2\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw.\n\nFind \\(\\mathbb{E}[X^2]\\).\n\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw.\n\nFind \\(\\mathbb{E}\\big[\\big(X-\\frac{1}{2}\\big)^2\\big]\\).\n\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]\n\n\n\n\n\n\n\n\n\n\nDefinition: Variance of RV\n\n\nThe variance of a r.v. \\(X\\), with (finite) expected value \\(\\mu_X=\\mathbb{E}[X]\\) is \\[\\sigma_X^2=Var(X)=\\mathbb{E}[(X-\\mu_X)^2] = \\mathbb{E}[(X-\\mathbb{E}[X])^2]\\]\n\n\n\n\nDefinition: Standard deviation of RV\n\n\nThe standard deviation of a r.v. \\(X\\) is \\[\\sigma_X = SD(X) = \\sqrt{\\sigma_X^2}=\\sqrt{Var(X)}.\\]\n\n\n\n\n\nQuestions: Why do we square the difference in the variance definition? \\((X-\\mu_X)^2\\)\n\nWhy not define the measure of spread as \\(\\mathbb{E}[X-\\mu_X] = \\mathbb{E}[X-\\mathbb{E}[X]]\\)?\nWhy not use \\(\\mathbb{E}[|X-\\mu_X|]\\)?\n\n\n\n\n\n\n\n\nLemma 6: “Computation formula” for Variance\n\n\nThe variance of a r.v. \\(X\\), can be computed as \\[\\begin{align}\n\\sigma_X^2 & =Var(X) \\\\ & = \\mathbb{E}[X^2]-\\mu_X^2 \\\\ & = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2\n\\end{align}\\]"
  },
  {
    "objectID": "lessons/14_Variance/16_Variance.html#lets-start-building-the-variance-through-expected-values-of-functions",
    "href": "lessons/14_Variance/16_Variance.html#lets-start-building-the-variance-through-expected-values-of-functions",
    "title": "Lesson 16: Variance",
    "section": "",
    "text": "Example 1\n\n\nLet \\(g\\) be a function and let \\(g(x) = ax+b\\), for real-valued constants \\(a\\) and \\(b\\). What is \\(\\mathbb{E}[g(X)]\\)?"
  },
  {
    "objectID": "lessons/14_Variance/16_Variance.html#what-is-the-expected-value-of-a-function",
    "href": "lessons/14_Variance/16_Variance.html#what-is-the-expected-value-of-a-function",
    "title": "Lesson 16: Variance",
    "section": "",
    "text": "Definition: Expected value of function of RV\n\n\nFor any function \\(g\\) and discrete r.v. \\(X\\), the expected value of \\(g(X)\\) is \\[\\mathbb{E}[g(X)] = \\sum_{\\{all\\ x\\}}\\ g(x) p_X(x).\\]"
  },
  {
    "objectID": "lessons/14_Variance/16_Variance.html#lets-revisit-the-card-example-12",
    "href": "lessons/14_Variance/16_Variance.html#lets-revisit-the-card-example-12",
    "title": "Lesson 16: Variance",
    "section": "",
    "text": "Example 2\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw.\n\nFind \\(\\mathbb{E}[X^2]\\).\n\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "lessons/14_Variance/16_Variance.html#lets-revisit-the-card-example-22",
    "href": "lessons/14_Variance/16_Variance.html#lets-revisit-the-card-example-22",
    "title": "Lesson 16: Variance",
    "section": "",
    "text": "Example 2\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw.\n\nFind \\(\\mathbb{E}\\big[\\big(X-\\frac{1}{2}\\big)^2\\big]\\).\n\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "lessons/14_Variance/16_Variance.html#variance-of-a-rv",
    "href": "lessons/14_Variance/16_Variance.html#variance-of-a-rv",
    "title": "Lesson 16: Variance",
    "section": "",
    "text": "Definition: Variance of RV\n\n\nThe variance of a r.v. \\(X\\), with (finite) expected value \\(\\mu_X=\\mathbb{E}[X]\\) is \\[\\sigma_X^2=Var(X)=\\mathbb{E}[(X-\\mu_X)^2] = \\mathbb{E}[(X-\\mathbb{E}[X])^2]\\]\n\n\n\n\nDefinition: Standard deviation of RV\n\n\nThe standard deviation of a r.v. \\(X\\) is \\[\\sigma_X = SD(X) = \\sqrt{\\sigma_X^2}=\\sqrt{Var(X)}.\\]"
  },
  {
    "objectID": "lessons/14_Variance/16_Variance.html#questions",
    "href": "lessons/14_Variance/16_Variance.html#questions",
    "title": "Lesson 16: Variance",
    "section": "",
    "text": "Questions: Why do we square the difference in the variance definition? \\((X-\\mu_X)^2\\)\n\nWhy not define the measure of spread as \\(\\mathbb{E}[X-\\mu_X] = \\mathbb{E}[X-\\mathbb{E}[X]]\\)?\nWhy not use \\(\\mathbb{E}[|X-\\mu_X|]\\)?"
  },
  {
    "objectID": "lessons/14_Variance/16_Variance.html#lets-calculate-the-variance-and-prove-it",
    "href": "lessons/14_Variance/16_Variance.html#lets-calculate-the-variance-and-prove-it",
    "title": "Lesson 16: Variance",
    "section": "",
    "text": "Lemma 6: “Computation formula” for Variance\n\n\nThe variance of a r.v. \\(X\\), can be computed as \\[\\begin{align}\n\\sigma_X^2 & =Var(X) \\\\ & = \\mathbb{E}[X^2]-\\mu_X^2 \\\\ & = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2\n\\end{align}\\]"
  },
  {
    "objectID": "lessons/14_Variance/16_Variance.html#variance-of-a-function-with-a-single-rv",
    "href": "lessons/14_Variance/16_Variance.html#variance-of-a-function-with-a-single-rv",
    "title": "Lesson 16: Variance",
    "section": "Variance of a function with a single RV",
    "text": "Variance of a function with a single RV\n\n\nLemma 7\n\n\nFor a r.v. \\(X\\) and constants \\(a\\) and \\(b\\), \\[Var(aX+b) = a^2Var(X).\\]\n\n\nProof will be exercise in homework. It’s fun! In a mathy kinda way."
  },
  {
    "objectID": "lessons/14_Variance/16_Variance.html#important-results-for-independent-rvs",
    "href": "lessons/14_Variance/16_Variance.html#important-results-for-independent-rvs",
    "title": "Lesson 16: Variance",
    "section": "Important results for independent RVs",
    "text": "Important results for independent RVs\n\n\nTheorem 8\n\n\nFor independent r.v.’s \\(X\\) and \\(Y\\), and functions \\(g\\) and \\(h\\), \\[\\mathbb{E}[g(X)h(Y)] = \\mathbb{E}[g(X)]\\mathbb{E}[h(Y)].\\]\n\n\n\n\nCorollary 1\n\n\nFor independent r.v.’s \\(X\\) and \\(Y\\), \\[\\mathbb{E}[XY] = \\mathbb{E}[X]\\mathbb{E}[Y].\\]"
  },
  {
    "objectID": "lessons/14_Variance/16_Variance.html#variance-of-sum-of-independent-discrete-rvs",
    "href": "lessons/14_Variance/16_Variance.html#variance-of-sum-of-independent-discrete-rvs",
    "title": "Lesson 16: Variance",
    "section": "Variance of sum of independent discrete RVs",
    "text": "Variance of sum of independent discrete RVs\n\n\nTheorem 9: Variance of sum of independent discrete r.v.’s\n\n\nFor independent discrete r.v.’s \\(X_i\\) and constants \\(a_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n a_iX_i\\Bigg) = \\sum_{i=1}^n a_i^2Var(X_i).\\]\n\n\nSimpler version:\n\\[Var(a_1 X + a_2 Y) = Var(a_1X) + Var(a_2 Y) = a_1^2 Var(X) + a_2^2 Var(Y)\\]"
  },
  {
    "objectID": "lessons/14_Variance/16_Variance.html#corollaries",
    "href": "lessons/14_Variance/16_Variance.html#corollaries",
    "title": "Lesson 16: Variance",
    "section": "Corollaries",
    "text": "Corollaries\n\n\nCorollary 2\n\n\nFor independent discrete r.v.’s \\(X_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n X_i\\Bigg) = \\sum_{i=1}^n Var(X_i).\\]\n\n\n\n\nCorollary 3\n\n\nFor independent identically distributed (i.i.d.) discrete r.v.’s \\(X_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n X_i\\Bigg) = n Var(X_1).\\]"
  },
  {
    "objectID": "lessons/14_Variance/16_Variance.html#lets-look-at-a-ghost-problem-with-replacement",
    "href": "lessons/14_Variance/16_Variance.html#lets-look-at-a-ghost-problem-with-replacement",
    "title": "Lesson 16: Variance",
    "section": "Let’s look at a ghost problem with replacement",
    "text": "Let’s look at a ghost problem with replacement\n\n\n\n\nExample 3.2\n\n\nThe ghost is trick-or-treating at a different house now. In this case it is known that the bag of candy has 10 chocolates, 20 lollipops, and 30 laffy taffies. The ghost grabs a handful of five pieces of candy. What is the variance for the number of chocolates the ghost takes? Let’s solve this for the cases with replacement.\n\n\n\n\nRecall probability with replacement:\n\\[\np_X(x) = {n \\choose k}p^k(1-p)^{n-k}\n\\]"
  },
  {
    "objectID": "lessons/14_Variance/16_Variance.html#back-to-our-hotel-example-from-chapter-11",
    "href": "lessons/14_Variance/16_Variance.html#back-to-our-hotel-example-from-chapter-11",
    "title": "Lesson 16: Variance",
    "section": "Back to our hotel example from Chapter 11",
    "text": "Back to our hotel example from Chapter 11\n\n\n\n\nExample 4\n\n\nA tour group is planning a visit to the city of Minneapolis and needs to book 30 hotel rooms. The average price of a room is $200 with standard deviation $10. In addition, there is a 10% tourism tax for each room. What is the standard deviation of the cost for the 30 hotel rooms? Assume rooms are independent.\n\n\nProblem to do at home if we don’t have enough time."
  },
  {
    "objectID": "lessons/14_Variance/16_Variance.html#expected-value-of-a-function-of-a-continuous-rv",
    "href": "lessons/14_Variance/16_Variance.html#expected-value-of-a-function-of-a-continuous-rv",
    "title": "Lesson 16: Variance",
    "section": "Expected value of a function of a continuous RV",
    "text": "Expected value of a function of a continuous RV\n\n\nHow do we calculate the expected value of a function of a discrete RV or joint RVs?\n   \nFor discrete RVs:\n\\[\\mathbb{E}[g(X)] = \\sum_{\\{all\\ x\\}}\\ g(x) p_X(x).\\] \\[\\mathbb{E}[g(X, Y)] = \\sum_{\\{all\\ x\\}}\\sum_{\\{all\\ y\\}}\\ g(x,y) p_{X,Y}(x,y).\\]\n\n\n\nHow do we calculate the expected value of a function of a continuous RV or joint RVs?\n   \nFor continuous RVs:"
  },
  {
    "objectID": "lessons/14_Variance/16_Variance.html#important-properties-of-expected-values-of-functions-of-continuous-rvs",
    "href": "lessons/14_Variance/16_Variance.html#important-properties-of-expected-values-of-functions-of-continuous-rvs",
    "title": "Lesson 16: Variance",
    "section": "Important properties of expected values of functions of continuous RVs",
    "text": "Important properties of expected values of functions of continuous RVs\n\n\n\n\nFunction of RV with two constants\n\n\n\\(\\mathbb{E}[aX+b] =a\\mathbb{E}[X]+b\\)\n\n\n\n\nFunction of two RVs added\n\n\n\\(\\mathbb{E}[X+Y] =\\mathbb{E}[X]+\\mathbb{E}[Y]\\)\n\n\n\n\nExpected value of sum of independent RVs pt 1\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are continuous RVs and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\[\\mathbb{E}\\Bigg[\\sum_{i=1}^{n} a_i X_i\\Bigg] = \\sum_{i=1}^{n}a_i\\mathbb{E}[X_i]\\]\n\n\n\n\n\nExpected value of multiplication of function of independent RVs\n\n\nIf \\(X\\) and \\(Y\\) are independent continuous RVs, and \\(g\\) and \\(h\\) are functions, then \\[\\mathbb{E}[g(X)h(Y)] =\\mathbb{E}[g(X)]\\mathbb{E}[h(Y)]\\]\n\n\n\n\nExpected value of multiplication of independent RVs\n\n\nIf \\(X\\) and \\(Y\\) are independent continuous RVs, then \\[\\mathbb{E}[XY] = \\mathbb{E}[X] \\mathbb{E}[Y] \\]"
  },
  {
    "objectID": "lessons/14_Variance/16_Variance.html#variance-of-continuous-rvs",
    "href": "lessons/14_Variance/16_Variance.html#variance-of-continuous-rvs",
    "title": "Lesson 16: Variance",
    "section": "Variance of continuous RVs",
    "text": "Variance of continuous RVs\n\n\nHow do we calculate the variance of a discrete RV?\n   \nFor discrete RVs:\n\\[\n\\begin{align}\nVar(X) & =\n\\mathbb{E}[(X-\\mu_X)^2] \\\\ & = \\mathbb{E}[(X-\\mathbb{E}[X])^2] \\\\ &= \\mathbb{E}[X^2]-(\\mathbb{E}[X])^2 \\\\ & = \\sum_{\\{all\\ x\\}}(x-\\mu_x)^2 p_{X}(x)\n\\end{align}\n\\]\n\n\n\nHow do we calculate the variance of a continuous RV?\n    \nFor continuous RVs:"
  },
  {
    "objectID": "lessons/14_Variance/16_Variance.html#variance-of-an-uniform-distribution",
    "href": "lessons/14_Variance/16_Variance.html#variance-of-an-uniform-distribution",
    "title": "Lesson 16: Variance",
    "section": "Variance of an Uniform distribution",
    "text": "Variance of an Uniform distribution\n\n\n\n\nExample 2\n\n\nLet \\(f_X(x)= \\frac{1}{b-a}\\), for \\(a \\leq x \\leq b\\). Find \\(Var[X]\\)."
  },
  {
    "objectID": "lessons/14_Variance/16_Variance.html#variance-of-exponential-distribution",
    "href": "lessons/14_Variance/16_Variance.html#variance-of-exponential-distribution",
    "title": "Lesson 16: Variance",
    "section": "Variance of exponential distribution",
    "text": "Variance of exponential distribution\n\n\nIn the homework:\n\n\nExample 3\n\n\nLet \\(f_X(x)= \\lambda e^{-\\lambda x}\\), for \\(x &gt; 0\\) and \\(\\lambda&gt; 0\\). Find \\(Var[X]\\)."
  },
  {
    "objectID": "lessons/14_Variance/16_Variance.html#important-properties-of-variances-of-continuous-rvs",
    "href": "lessons/14_Variance/16_Variance.html#important-properties-of-variances-of-continuous-rvs",
    "title": "Lesson 16: Variance",
    "section": "Important properties of variances of continuous RVs",
    "text": "Important properties of variances of continuous RVs\n\n\n\n\nFunction of RV with two constants\n\n\n\\[Var[aX+b] = a^2Var[X]\\]\n\n\n\n\n\nVariance of sum of independent RVs pt 1\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous RVs and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\[Var\\Bigg(\\sum_{i=1}^{n} a_i X_i\\Bigg) =\\sum_{i=1}^{n} a^2_i Var(X_i)\\]\n\n\n\n\nVariance of sum of independent RVs pt 2\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous RVs, then \\[Var\\Bigg(\\sum_{i=1}^{n} X_i\\Bigg) = \\sum_{i=1}^{n} Var(X_i)\\]"
  },
  {
    "objectID": "lessons/14_Variance/16_Variance.html#find-the-mean-and-sd-from-word-problem",
    "href": "lessons/14_Variance/16_Variance.html#find-the-mean-and-sd-from-word-problem",
    "title": "Lesson 16: Variance",
    "section": "Find the mean and sd from word problem",
    "text": "Find the mean and sd from word problem\n\n\n\n\nExample 4\n\n\nA machine manufactures cubes with a side length that varies uniformly from 1 to 2 inches. Assume the sides of the base and height are equal. The cost to make a cube is 10 ¢ per cubic inch, and 5 ¢ cents for the general cost per cube. Find the mean and standard deviation of the cost to make 10 cubes."
  },
  {
    "objectID": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance_muddy_points.html",
    "href": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n2. How do we set the bounds on a double integral?\nWhen the domain of the RVs are not dependent on each other, then we use the bounds as is. In example 2 of Chapter 26 notes, we have the joint pdf \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for\\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\). If we wanted to calculate something like \\(E(X)\\), then we could use the bounds as they are. Below is the domain for \\(x\\) and \\(y\\):\n\n\n\n\n\nHere is the integral for the expected value where we integrate over the whole domain of \\(x\\) and \\(y\\):\n\\[ E(X) = \\displaystyle\\int_0^1 \\displaystyle\\int_0^1 x (18 x^2 y^5 )dy dx \\]If we want to find the probability \\(P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75)\\), then we can look at the specific values of the probability:\n\n\n\n\n\nNote the blue lines above indicate how we integrate over \\(y\\) first from 0.5 to 0.75 and the green lines indicate how integrate over \\(x\\) first from 0.25 to 0.5. It seems like we’ve integrated over an area that isn’t within our specified probability. However, the integrated area is ONLY the overlap of the \\(x\\) and \\(y\\) bounds for the probability.\n\\[P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.25}^{0.5} \\displaystyle\\int_{0.5}^{0.75} 18 x^2 y^5 dy dx\\]\nLet’s use the same pdf, but now the domain of the two RVs is dependent on one another. We have the joint pdf \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for\\(0 \\leq x \\leq y\\leq1\\)\nIf we wanted to calculate something like \\(E(X)\\), then we need to account for fact that \\(x\\) must be less than of equal to \\(y\\). We can look back at the domain for this:\n\n\n\n\n\nNote the blue lines above still indicate how we integrate over \\(y\\) first from \\(x\\) to 1, and the green lines indicate how integrate over \\(x\\) first from 0 to 1. Once again, it seems like we’ve integrated over an area that isn’t within the domain. However, the integrated area is ONLY the overlap of the \\(x\\) and \\(y\\) bounds. Thus, once we’ve restricted \\(y\\) to the area between \\(x\\) and 1, we no longer need to restrict \\(x\\) to the are of 0 to \\(y\\).\n\\[ E(X) = \\displaystyle\\int_0^1 \\displaystyle\\int_x^1 x (18 x^2 y^5 )dy dx \\] If we want to find the probability \\(P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75)\\), then we should look back at our domain. For now, we are focusing on the orange area:\n\n\n\n\n\nBecause the orange area is totally within our domain, we can leave our integral our bounds as the exact values we specified:\n\\[P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.25}^{0.5} \\displaystyle\\int_{0.5}^{0.75} 18 x^2 y^5 dy dx\\]\nHowever, if we want the probability \\(P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75)\\), we would focus on the pink area above. We would limit one of our integrals to the \\(y=x\\) equation:\n\\[P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.5}^{0.75} \\displaystyle\\int_{x}^{0.75} 18 x^2 y^5 dy dx\\]\nOR\n\\[P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.5}^{0.75} \\displaystyle\\int_{0.5}^{y} 18 x^2 y^5 dx dy\\]\nThe key to these probabilities is that the bounds with the other variable is on the inside integral! Otherwise we end up with a answer that includes a RV."
  },
  {
    "objectID": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html",
    "href": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "",
    "text": "Calculate the mean (expected value) of sums of discrete random variables"
  },
  {
    "objectID": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#learning-objectives",
    "href": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#learning-objectives",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "",
    "text": "Calculate the mean (expected value) of sums of discrete random variables"
  },
  {
    "objectID": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#where-are-we",
    "href": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#where-are-we",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#revisiting-our-two-card-draw",
    "href": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#revisiting-our-two-card-draw",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Revisiting our two card draw",
    "text": "Revisiting our two card draw\n\n\n\n\nExample 1\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw. Find \\(\\mathbb{E}[X]\\).\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#what-if-we-draw-a-lot-of-cards",
    "href": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#what-if-we-draw-a-lot-of-cards",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "What if we draw A LOT of cards?",
    "text": "What if we draw A LOT of cards?\n\n\n\n\nExample 2\n\n\nWhat is the expected number of hearts in Example 1 if you draw 200 cards?\n\n\n\n\nRecall Binomial RV with \\(n=200\\):\n\\[p_X(x) = {200 \\choose x}p^x(1-p)^{200-x}\\] \\[\\text{  for } x = 0, 1, 2, ..., 200\\]"
  },
  {
    "objectID": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#sum-of-discrete-rvs",
    "href": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#sum-of-discrete-rvs",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Sum of discrete RVs",
    "text": "Sum of discrete RVs\n\n\nTheorem 11.1: Sum of discrete RVs\n\n\nFor discrete r.v.’s \\(X_i\\) and constants \\(a_i\\), \\(i=1,2,\\dots, n\\), \\[\\mathbb{E}\\Bigg[\\sum_{i=1}^n a_iX_i\\Bigg] = \\sum_{i=1}^n a_i\\mathbb{E}[X_i] .\\] Remark: The theorem holds for infinitely r.v.’s \\(X_i\\) as well.\n\n\n\nFor two RVs, \\(X\\) and \\(Y\\):\n\nWe can say \\(E[X+Y] = E[X] + E[Y]\\)\n… and constant numbers \\(a\\) and \\(b\\), we can also say \\(E[aX+bY] = aE[X] + bE[Y]\\)\nWe can also also say \\(E[X-Y] = E[X] - E[Y]\\), since \\(b=-1\\)"
  },
  {
    "objectID": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#corollaries-from-thm-11.1",
    "href": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#corollaries-from-thm-11.1",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Corollaries from Thm 11.1",
    "text": "Corollaries from Thm 11.1\n\n\n\n\nCorollary 11.1.1\n\n\nFor a discrete r.v. \\(X\\), and constants \\(a\\) and \\(b\\), \\[\\mathbb{E}[aX+b] = a\\mathbb{E}[X] + b.\\]\n\n\n\n\n\nCorollary 11.1.2\n\n\nIf \\(X_i\\), \\(i=1,2,\\dots, n\\), are identically distributed r.v.’s, then \\[\\mathbb{E}\\bigg[\\sum_{i=1}^n X_i\\bigg] = n\\mathbb{E}[X_1] .\\]"
  },
  {
    "objectID": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#cost-of-hotel-rooms",
    "href": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#cost-of-hotel-rooms",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Cost of hotel rooms",
    "text": "Cost of hotel rooms\n\n\n\n\nExample 4\n\n\nA tour group is planning a visit to the city of Minneapolis and needs to book 30 hotel rooms. The average price of a room is $200. In addition, there is a 10% tourism tax for each room. What is the expected cost for the 30 hotel rooms?"
  },
  {
    "objectID": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html",
    "href": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "",
    "text": "Calculate probability of a sample mean using a Normally distributed population"
  },
  {
    "objectID": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#learning-objectives",
    "href": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#learning-objectives",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "",
    "text": "Calculate probability of a sample mean using a Normally distributed population"
  },
  {
    "objectID": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#sum-of-normal-rvs",
    "href": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#sum-of-normal-rvs",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "Sum of Normal RVs",
    "text": "Sum of Normal RVs\n\n\nTheorem 1\n\n\nLet \\(X\\sim N(\\mu, \\sigma^2)\\), and let \\(Y=aX+b\\), where \\(a\\) and \\(b\\) are constants. Then \\[Y \\sim N(a\\mu+b, a^2\\sigma^2)\\]\n\n\n\n\nTheorem 2\n\n\nLet \\(X_i \\sim N(\\mu_i, \\sigma_i^2)\\) be independent normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\sim N\\Bigg(\\sum_{i=1}^n \\mu_i , \\sum_{i=1}^n \\sigma^2_i\\Bigg)\\]"
  },
  {
    "objectID": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#special-cases",
    "href": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#special-cases",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "Special Cases",
    "text": "Special Cases\n\nLet \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\sim N\\big(n\\mu, n \\sigma^2\\big)\\]\nLet \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\bar{X}=\\frac{\\sum_{i=1}^n X_i}{n} \\sim N\\big(\\mu, \\sigma^2 / n\\big)\\]\nLet \\(X\\sim N(\\mu_X,\\sigma_X^2)\\), and \\(Y\\sim N(\\mu_Y,\\sigma_Y^2)\\). Then \\[X-Y \\sim N\\big(\\mu_X - \\mu_Y, \\sigma^2_X + \\sigma^2_Y \\big)\\]"
  },
  {
    "objectID": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#detecting-and-solving-sums-of-normal-rvs-from-a-word-problem",
    "href": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#detecting-and-solving-sums-of-normal-rvs-from-a-word-problem",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "Detecting and solving sums of Normal RVs from a word problem",
    "text": "Detecting and solving sums of Normal RVs from a word problem\n\n\n\n\nExample 1\n\n\nGlaucoma is an eye disease that is manifested by high intraocular pressure (IOP). The distribution of IOP in the general population is approximately normal with mean 16 mmHg and standard deviation 3 mmHg.\n\nSuppose a patient has 40 IOP readings. What is the probability that their average reading is greater than 20.32 mmHg, assuming their eyes are healthy?\nRepeat the previous question for a patient with 10 IOP readings."
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values_key_info.html",
    "href": "lessons/13_Expected_Values/13_Expected_Values_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Quiz 2 back: everyone got at least a 12/14! Woo!\n\nMost common mistake: Question 10 - the fact that \\(f_X(x)\\) can be greater than 1 is:\n\nWrong answer: Invalid, because a pdf (like a probability) can never be greater than 1\nCorrect answer: Valid, because the area under the curve from 0 to 1 is 1, even if the height of the function is greater than 1\n\n\nFeel free to use your no-questions-asked extensions on homework\n\nAnd remember that there is no grade penalty for turning in homework late\n\nCharles is not obligated to give you feedback though\n\n\nSadly, there is no audio in the class on 11/5\n\nNot sure if human error or computer issue"
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values_key_info.html#announcements",
    "href": "lessons/13_Expected_Values/13_Expected_Values_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Quiz 2 back: everyone got at least a 12/14! Woo!\n\nMost common mistake: Question 10 - the fact that \\(f_X(x)\\) can be greater than 1 is:\n\nWrong answer: Invalid, because a pdf (like a probability) can never be greater than 1\nCorrect answer: Valid, because the area under the curve from 0 to 1 is 1, even if the height of the function is greater than 1\n\n\nFeel free to use your no-questions-asked extensions on homework\n\nAnd remember that there is no grade penalty for turning in homework late\n\nCharles is not obligated to give you feedback though\n\n\nSadly, there is no audio in the class on 11/5\n\nNot sure if human error or computer issue"
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values_key_info.html#key-dates",
    "href": "lessons/13_Expected_Values/13_Expected_Values_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 6 due this Sunday"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs_key_info.html",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 01 assignments are graded!\n\nSolutions and videos are posted!"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs_key_info.html#announcements",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 01 assignments are graded!\n\nSolutions and videos are posted!"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs_key_info.html#key-dates",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 02 Assignment due this Thursday at 11pm\nNo HW 01 Solutions"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "",
    "text": "Distinguish between Bernoulli, Binomial, Geometric, Hypergeometric, Discrete Uniform, Negative Binomial, and Poisson distributions when reading a story.\nIdentify the variable and the parameters in a story, and state what the variable and parameters mean.\nUse the formulas for the pmf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#learning-objectives",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#learning-objectives",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "",
    "text": "Distinguish between Bernoulli, Binomial, Geometric, Hypergeometric, Discrete Uniform, Negative Binomial, and Poisson distributions when reading a story.\nIdentify the variable and the parameters in a story, and state what the variable and parameters mean.\nUse the formulas for the pmf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#where-are-we",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#where-are-we",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#properties-of-bernoulli-rvs",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#properties-of-bernoulli-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Bernoulli RVs",
    "text": "Properties of Bernoulli RVs\n\nScenario: One trial, with outcome success or failure\nShorthand: \\(X \\sim \\text{Bernoulli}(p)\\)\n\n\\[\nX = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\quad \\\\\n            0 & \\quad \\mathrm{with\\ probability}\\ 1-p \\quad\n        \\end{array}\n    \\right.\n\\]\n\\[\np_X(x) = P(X=x) = p^x(1-p)^{1-x} \\text{ for } x=0,1\n\\]\n\\[\\text{E}(X) = p\\]\n\\[\\text{Var}(X) = pq = p(1-p)\\]"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#bernoulli-example-1",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#bernoulli-example-1",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bernoulli Example 1",
    "text": "Bernoulli Example 1\n\n\n\n\nExample 1\n\n\n\nWe roll a fair 6-sided die.\nWe get $1 if we roll a 5, and nothing otherwise.\nLet \\(X\\) be how much money we get.\nFind the mean and variance of \\(X\\)."
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#properties-of-binomial-rvs",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#properties-of-binomial-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Binomial RVs",
    "text": "Properties of Binomial RVs\n\nScenario: There are \\(n\\) independent trials, each resulting in a success or failure, with constant probability, \\(p\\), in each trial. We are counting the number of successes (or failures).\nShorthand: \\(X \\sim \\text{Binomial}(n, p)\\)\n\n\\[\nX = \\text{Number of successes of } n \\text{ independent trials}\n\\]\n\\[\np_X(x) = P(X=x) = {n \\choose x}p^x(1-p)^{n-x} \\text{ for } x=0,1,2,  ..., n\n\\]\n\\[\\text{E}(X) = np\\] \\[\\text{Var}(X) = npq = np(1-p)\\]"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#our-beloved-fair-sided-die",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#our-beloved-fair-sided-die",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Our beloved fair-sided die",
    "text": "Our beloved fair-sided die\n\n\n\n\nExample 2\n\n\n\nSuppose we roll a fair 6-sided die 50 times.\nWe get $1 every time we roll a 5, and nothing otherwise.\nLet \\(X\\) be how much money we get on the 50 rolls.\nFind the mean and variance of \\(X\\)."
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#geometric-rvs",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#geometric-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Geometric RVs",
    "text": "Geometric RVs\n\nScenario: There are repeated independent trials, each resulting in a success or failure, with constant probability of success for each trial. We are counting the number of trials until the first success.\nShorthand: \\(X \\sim \\text{Geo}(p)\\) or \\(X \\sim \\text{Geometric}(p)\\) or \\(X \\sim \\text{G}(p)\\)\n\n\n\n\n\n\n\n\n\\(X =\\) Number of trials needed for first success (count \\(x\\) includes the success)\n\\(X =\\) Number of failures before first success (count \\(x\\) does not include the success)\n\n\n\n\n\\(p _\nX( x ) = P(X=x) = (1-p)^{x-1}p\\)\nfor \\(x=1,2, 3,...\\)\n\\[F_\nX(x ) = P(X\\leq x) = 1-(1-p)^x\\]\nfor \\(x=1,2, 3,...\\)\n\\(p _X (x)= P(X=x) = (1-p)^{x}p\\)\nfor \\(x=0, 1,2,...\\)\n\\[F_X ( x\n)\n= P(X\\leq x) = 1-(1-p)^{x+1}\\]\nfor \\(x=0, 1,2,...\\)\n\n\n\\(E(X)=\\dfrac{1}{p}\\)\n\\(Var(X)= \\dfrac{1-p}{p^2}\\)\n\\(E(X)=\\dfrac{1-p}{p}\\)\n\\(Var(X) = \\dfrac{1-p}{p^2}\\)"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#bullseye-14",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#bullseye-14",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (1/4)",
    "text": "Bullseye (1/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the pmf for the number of throws needed to hit the bullseye?\nWhat are the mean and variance for the number of throws needed to hit the bullseye?\nFind the probability that our first bullseye:\n\nis on one of the first fifty tries\nis after the \\(50^{th}\\) try, given that it did not happen on the first 20 tries"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#bullseye-24",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#bullseye-24",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (2/4)",
    "text": "Bullseye (2/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the pmf for the number of throws needed to hit the bullseye?"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#bullseye-34",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#bullseye-34",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (3/4)",
    "text": "Bullseye (3/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat are the mean and variance for the number of throws needed to hit the bullseye?"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#bullseye-44",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#bullseye-44",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Bullseye (4/4)",
    "text": "Bullseye (4/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nFind the probability that our first bullseye:\n\nis on one of the first fifty tries\nis after the \\(50^{th}\\) try, given that it did not happen on the first 20 tries"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#memoryless-property-for-geometric-rvs",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#memoryless-property-for-geometric-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Memoryless property for Geometric RVs",
    "text": "Memoryless property for Geometric RVs\nIf we know \\(X\\) is greater than some number (aka given \\(X &gt;j\\)), then the probability of \\(X &gt; k+j\\) is just the probability that \\(X&gt;k\\).\n \n\\(P(X &gt; k+j |X &gt; j) = P(X &gt; k)\\) \\[ P(X &gt; k+j |X &gt; j) = \\dfrac{P(X&gt;k+j \\text{ and } X&gt;j)}{P(X&gt;j)} = \\dfrac{P(X&gt;k+j)}{P(X&gt;j)} = \\dfrac{(1-p)^{k+j}}{(1-p)^{j}} = (1-p)^{k} \\]"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#properties-of-negative-binomial-rvs",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#properties-of-negative-binomial-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Negative Binomial RVs",
    "text": "Properties of Negative Binomial RVs\n\nScenario: There are repeated independent trials, each resulting in a success or failure, with constant probability of success for each trial. We are counting the number of trials until the \\(r^{th}\\) success.\nShorthand: \\(X \\sim \\text{NegBin}(p, r)\\) or \\(X \\sim \\text{NB}(p, r)\\)\nNegative binomial is sum of \\(r\\) geometric distributions\n\n\\[\nX = \\text{Number of independent trials until } r^{th} \\text{ success}\n\\]\n\\[ p_X(x) = P(X=x) = {x-1 \\choose r-1}(1-p)^{x-r}p^r \\text{ for } x = r, r+1, r+2, ...\\]\n\\[ E(X) = \\dfrac{r}{p}\\]\n\\[Var(X) = \\dfrac{rq}{p^2} = \\dfrac{r(1-p)}{p^2}\\]"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#hitting-more-than-1-bullseye",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#hitting-more-than-1-bullseye",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Hitting more than 1 bullseye",
    "text": "Hitting more than 1 bullseye\n\n\n\n\nExample 1\n\n\nConsider again the bullseye example, where we throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the expected value and variance of the number of throws needed to hit 5 bullseyes?"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#hitting-more-than-1-bullseye-1",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#hitting-more-than-1-bullseye-1",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Hitting more than 1 bullseye",
    "text": "Hitting more than 1 bullseye\n\n\n\n\nExample 1\n\n\nConsider again the bullseye example, where we throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the probability that the \\(5^{th}\\) bullseye is on the \\(20^{th}\\) throw?"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#properties-of-poisson-rvs",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#properties-of-poisson-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Properties of Poisson RVs",
    "text": "Properties of Poisson RVs\n\nScenario: We are counting the number of successes in a fixed time period, which has a constant rate of successes\nShorthand: \\(X \\sim \\text{Poisson}(\\lambda)\\) or \\(X \\sim \\text{Pois}(\\lambda)\\)\n\n\\[\nX = \\text{Number of successes in a given period}\n\\]\n\\[ p_X(x) = P(X=x) = \\dfrac{e^{-\\lambda}\\lambda^x}{x!} \\text{ for } x = 0, 1, 2,3, ...\\]\n\\[ \\text{E}(X) = \\lambda\\]\n\\[\\text{Var}(X) = \\lambda\\]"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#distinguishing-between-binomial-and-poisson-rvs",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#distinguishing-between-binomial-and-poisson-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Distinguishing between Binomial and Poisson RVs",
    "text": "Distinguishing between Binomial and Poisson RVs\n\nRecall that if \\(X\\sim \\text{Binomial}(n,p)\\), then\n\n\\(X\\) models the number of successes …\nin \\(n\\) independent (Bernoulli) trials …\nthat each have the same probability of success \\(p\\).\n\nPoisson r.v.’s are similar,\n\nexcept that instead of having \\(n\\) discrete independent trials,\nthere is a fixed time period (or space) during which the successes happen"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#examples-of-poisson-rvs",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#examples-of-poisson-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Examples of Poisson RVs",
    "text": "Examples of Poisson RVs\n\nNumber of visitors to an emergency room in an hour during a weekend night\nNumber of study participants enrolled in a study per week\nNumber of pedestrians walking through a square mile\nAny more?"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#emergency-room-visitors",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#emergency-room-visitors",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Emergency Room Visitors",
    "text": "Emergency Room Visitors\n\n\n\n\nExample 1\n\n\nSuppose an emergency room has an average of 50 visitors per day. Find the following probabilities.\n\nProbability of 30 visitors in a day.\nProbability of 8 visitors in an hour.\nProbability of at least 8 visitors in an hour."
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#combining-independent-poisson-distributions",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#combining-independent-poisson-distributions",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Combining independent Poisson distributions",
    "text": "Combining independent Poisson distributions\n\n\nTheorem 1\n\n\nIf \\(X\\sim Pois(\\lambda_1)\\) and \\(Y\\sim Pois(\\lambda_2)\\) are independent of each other, then \\(Z=X+Y\\sim Pois(\\lambda_1 + \\lambda_2)\\)."
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#two-emergency-rooms",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#two-emergency-rooms",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Two emergency rooms",
    "text": "Two emergency rooms\n\n\n\n\nExample 2\n\n\nSuppose emergency room 1 has an average of 50 visitors per day, and emergency room 2 has an average of 70 visitors per day, independently of each other. What is the probability distribution to model of the total number of visitors to both?"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#poisson-approximation-of-the-binomial",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#poisson-approximation-of-the-binomial",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Poisson Approximation of the Binomial",
    "text": "Poisson Approximation of the Binomial\nBoth Poisson and Binomial r.v.’s are counting the number of successes\n\nIf for a Binomial r.v.\n\nthe number of trials \\(n\\) is very large, and\nthe probability of success \\(p\\) is close to 0 or 1,\n\nThen the Poisson distribution can be used to approximate Binomial probabilities\n\nand we use \\(\\lambda = np\\)\n\nRule of thumb: We can use the Poisson approximation when \\(\\dfrac{1}{10} \\leq np(1-p) \\leq 10\\)"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#medical-lab-errors",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#medical-lab-errors",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Medical lab errors",
    "text": "Medical lab errors\n\n\n\n\nExample 3\n\n\nSuppose that in the long run, errors in a medical testing lab are made 0.1% of the time. Find the probability that fewer than 4 mistakes are made in the next 2,000 tests.\n\nFind the probability using the Binomial distribution.\nApproximate the probability in part (1) using the Poisson distribution.\n\n\n\n\nTo do for extra practice - will also see a similar problem in BSTA 511"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#hypergeometric-rvs",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#hypergeometric-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Hypergeometric RVs",
    "text": "Hypergeometric RVs\n\nScenario: There are a fixed number of successes and failures (which are known in advance), from which we make \\(n\\) draws without replacement. We are counting the number of successes from the \\(n\\) trials.\n\nThere is a finite population of \\(N\\) items\nEach item in the population is either a success or a failure, and there are \\(M\\) successes total.\nWe randomly select (sample) \\(n\\) items from the population without replacement\n\nShorthand: \\(X \\sim \\text{Hypergeo}(M, N, n)\\)\n\n\n\n\\[\nX = \\text{Number of successes in } n \\text{ draws}\n\\]\n\\[\np_X(x) = P(X=x) = \\dfrac{{M \\choose x}{N-M \\choose n-x}}{{N \\choose n}}\n\\] \\[\\text{ for } x \\text{ integer-valued } \\\\ \\max(0, n-(N-M)) \\leq x \\leq \\min(n, M)\\]\n\n\\[\\text{E}(X) =\\dfrac{nM}{N}\\]\n\\[\\text{Var}(X) = n \\dfrac{M}{N} \\bigg(1- \\dfrac{M}{N} \\bigg)\\bigg(\\dfrac{N-n}{N-1} \\bigg)\\]"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#wolf-population",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#wolf-population",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Wolf population",
    "text": "Wolf population\n\n\n\n\nExample 4\n\n\nA wildlife biologist is using mark-recapture to research a wolf population. Suppose a specific study region is known to have 24 wolves, of which 11 have already been tagged. If 5 wolves are randomly captured, what is the probability that 3 of them have already been tagged?"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#binomial-approximation-of-the-hypergeometric-rv",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#binomial-approximation-of-the-hypergeometric-rv",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Binomial approximation of the hypergeometric RV",
    "text": "Binomial approximation of the hypergeometric RV\nSuppose a hypergeometric RV \\(X\\) has the following properties:\n\nthe population size \\(N\\) is really big,\nthe number of successes \\(M\\) in the population is relatively large,\n\n\\(\\frac{M}{N}\\) shouldn’t be close to 0 or 1\n\nand the number of items \\(n\\) selected is small\nRule of thumb: \\(\\dfrac{n}{N}&lt;0.05\\) or \\(N&gt;20n\\)\n\nThen, in this case, making \\(n\\) draws from the population doesn’t change the probability of success much, and the hypergeometric RV. can be approximated by a binomial RV"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#wolf-population-revisited",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#wolf-population-revisited",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Wolf population revisited",
    "text": "Wolf population revisited\n\n\n\n\nExample 5\n\n\nSuppose a specific study region is known to have 2400 wolves, of which 1100 have already been tagged.\n\nIf 50 wolves are randomly captured, what is the probability that 20 of them have already been tagged?\nApproximate the probability in part (1) using the binomial distribution."
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#discrete-uniform-rvs",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#discrete-uniform-rvs",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "Discrete Uniform RVs",
    "text": "Discrete Uniform RVs\n\nScenario: There are \\(N\\) possible outcomes, which are all equally likely.\nShorthand: \\(X \\sim \\text{Uniform}(N)\\)\n\n\\[\nX = \\text{Outcome of interest, with } x=1, 2, ..., N\n\\]\n\\[\np_X(x) = P(X=x) = \\dfrac{1}{N} \\text{ for } x=1, 2, 3, ..., N\n\\]\n\\[\\text{E}(X) =\\dfrac{N+1}{2}\\]\n\\[\\text{Var}(X) = \\dfrac{N^2 -1}{12}\\]"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#what-discrete-uniform-rvs-have-we-seen-already",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs.html#what-discrete-uniform-rvs-have-we-seen-already",
    "title": "Chapter 14-20: Some Important Discrete RVs",
    "section": "What discrete uniform RVs have we seen already?",
    "text": "What discrete uniform RVs have we seen already?\n\n\n\n\nExample 6\n\n\nExamples of discrete uniform RVs"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/17_Discrete_RVs_muddy_points.html",
    "href": "lessons/15_Discrete_RVs/17_Discrete_RVs_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "1. In-class example of the Poisson distribution\n\nlibrary(tidyverse)\n\nx &lt;- 0:250\n# n = c(6,14,30,60)\np = c(0.1, 0.5)\n\ngeom = expand.grid(x = x, p = p) %&gt;%\n  mutate(y = dgeom(x, prob = p))\n\nggplot(geom %&gt;% filter(y &gt; 1e-5), \n       aes(x, y, color=factor(p))) +\n  geom_point(size=1) +\n  geom_segment(aes(x=x, xend=x, y=0, yend=y, color=factor(p)), lwd=0.8, alpha=0.5) +\n  facet_grid(rows = vars(p), scales=\"free_x\", space=\"free_x\") +\n  theme(legend.position = \"none\",\n        axis.title = element_text(size = 14),    # Axis title size\n        axis.text = element_text(size = 12),     # Axis text size\n        strip.text = element_text(size = 13)) +  # Facet label size\n  labs(x = \"Number of trials\", y = \"Probability\")"
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values_muddy_points.html",
    "href": "lessons/13_Expected_Values/13_Expected_Values_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Here’s a pretty good video on integration by parts!\nHere’s the Calc review muddy points with a few words on integration by parts.\n\n\n\nGot a little help from Chatgpt:\nThink back to our discrete example with the die. Our expected value was the weighted average of all the possible outcomes (weighted by their probability). So our expected value for discrete RVs will always be that weighted average: \\[\\mathbb{E}[X] = \\sum_{i=1}^n x_ip_X(x_i)\\]\nFor continuous RVs, they can take infinite possible values, so we cannot sum across the pdf the same way. We still want the weighted average, so we need to find a way to “sum” the weighted outcomes for the continuous RV, which translates to an integral.\nHere’s a fairly good explanation on StackExchange..)\n\n\n\nFinal example: Let \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\).\nLet’s start with a plot for the domain. We have \\(0 \\leq x \\leq y\\), so we know that \\(x\\geq0\\) and because \\(y\\geq x\\), then \\(y\\geq0\\), so we’ll have a plot of all positive values of \\(x\\) and \\(y\\):\n\n\n\n\n\n\n\n\n\nOkay, now let’s add the information that \\(y \\geq x\\). We can look at the line, \\(y=x\\), and identify the area on the side of the line that upholds \\(y \\geq x\\):\n\n\n\n\n\n\n\n\n\nThe area above the line is where \\(y\\geq x\\):\n\n\n\n\n\n\n\n\n\nSo we need to find the bounds for the orange region in terms of \\(x\\) and \\(y\\).\nWhichever random variable is on the inner integral will need to incorporate the \\(y=x\\) line. If we integrate over \\(y\\) first, we will integrate from \\(y=x\\) to \\(y=\\infty\\). Once we have incorporated the line into our first integral, then we no longer need to worry about the \\(y=x\\) line. For \\(x\\), we can integrate from \\(x=0\\) to \\(x=\\infty\\)."
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values_muddy_points.html#fall-2023",
    "href": "lessons/13_Expected_Values/13_Expected_Values_muddy_points.html#fall-2023",
    "title": "Muddy Points",
    "section": "",
    "text": "If we start at a joint probability \\(f_{X,Y}(x,y)\\)…. we can look at a few probabilities:\n\nJoint probability: \\(P(a \\leq X \\leq b, c \\leq Y \\leq d)\\)\n\\[P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=c}^{y=d} f_{X,Y}(x,y) dydx\\]\nMarginal probability: \\(P(a \\leq X \\leq b)\\)\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b} f_{X}(x) dx\\]\nOR\n\\[P(a \\leq X \\leq b) = \\displaystyle\\int_{x=a}^{x=b}\\displaystyle\\int_{y=-\\inf}^{y=\\inf} f_{X,Y}(x,y) dydx\\]\nConditional probability: \\(P(a \\leq X \\leq b | Y = c)\\)\n\\[P(a \\leq X \\leq b | Y=c) = \\displaystyle\\int_{x=a}^{x=b} f_{X|Y}(x|y=c) dx\\]\nYou cannot calculate \\(P(a \\leq X \\leq b | Y = c)\\) by \\(\\dfrac{P(a \\leq X \\leq b, Y=c)}{P(Y = c)}\\) because \\(P(Y = c)\\) is 0. Instead, we need to find \\(f_{X|Y}(x|y=c)\\) by \\(\\dfrac{f_{X,Y}(x,y=c)}{f_{Y}(y=c)}\\) and THEN integrate over X."
  },
  {
    "objectID": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html",
    "href": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Homework 7 presentations due soon!\n\nI will check your HW 7 solutions ASAP!\n\nDepending on how far we get today and Wednesday, I might cancel the 12/9 class\nAnything else?"
  },
  {
    "objectID": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#announcements",
    "href": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Homework 7 presentations due soon!\n\nI will check your HW 7 solutions ASAP!\n\nDepending on how far we get today and Wednesday, I might cancel the 12/9 class\nAnything else?"
  },
  {
    "objectID": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#key-dates",
    "href": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 8 assignment due\nSunday: HW 7 presentations due at 11pm"
  },
  {
    "objectID": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html",
    "href": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "",
    "text": "Calculate the mean (expected value) of a joint distribution of continuous RV"
  },
  {
    "objectID": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#learning-objectives",
    "href": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#learning-objectives",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "",
    "text": "Calculate the mean (expected value) of a joint distribution of continuous RV"
  },
  {
    "objectID": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#remark-on-expected-value-of-one-rv-from-joint-pdf",
    "href": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#remark-on-expected-value-of-one-rv-from-joint-pdf",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "Remark on expected value of one RV from joint pdf",
    "text": "Remark on expected value of one RV from joint pdf\nIf you are given \\(f_{X,Y}(x,y)\\) and want to calculate \\(\\mathbb{E}[X]\\), you have two options:\n\nFind \\(f_X(x)\\) and use it to calculate \\(\\mathbb{E}[X]\\).\nOr, calculate \\(\\mathbb{E}[X]\\) using the joint density: \\[\\mathbb{E}[X] = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}x f_{X,Y}(x,y)dydx.\\]"
  },
  {
    "objectID": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-1-expected-value-from-a-joint-distribution",
    "href": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-1-expected-value-from-a-joint-distribution",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "Option 1: Expected value from a joint distribution",
    "text": "Option 1: Expected value from a joint distribution\n\n\n\n\nExample 3\n\n\nLet \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-2-expected-value-from-a-joint-distribution",
    "href": "lessons/13_Expected_Values/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-2-expected-value-from-a-joint-distribution",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "Option 2: Expected value from a joint distribution",
    "text": "Option 2: Expected value from a joint distribution\n\n\n\n\nExample 1\n\n\nLet \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons/14_Variance/29_Variance_and_Sums_of_rv.html",
    "href": "lessons/14_Variance/29_Variance_and_Sums_of_rv.html",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "",
    "text": "Calculate expected value of functions of RVs\nCalculate variance of RVs"
  },
  {
    "objectID": "lessons/14_Variance/29_Variance_and_Sums_of_rv.html#learning-objectives",
    "href": "lessons/14_Variance/29_Variance_and_Sums_of_rv.html#learning-objectives",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "",
    "text": "Calculate expected value of functions of RVs\nCalculate variance of RVs"
  },
  {
    "objectID": "lessons/14_Variance/29_Variance_and_Sums_of_rv.html#expected-value-of-a-function-of-a-continuous-rv",
    "href": "lessons/14_Variance/29_Variance_and_Sums_of_rv.html#expected-value-of-a-function-of-a-continuous-rv",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Expected value of a function of a continuous RV",
    "text": "Expected value of a function of a continuous RV\n\n\nHow do we calculate the expected value of a function of a discrete RV or joint RVs?\n   \nFor discrete RVs:\n\\[\\mathbb{E}[g(X)] = \\sum_{\\{all\\ x\\}}\\ g(x) p_X(x).\\] \\[\\mathbb{E}[g(X, Y)] = \\sum_{\\{all\\ x\\}}\\sum_{\\{all\\ y\\}}\\ g(x,y) p_{X,Y}(x,y).\\]\n\n\n\nHow do we calculate the expected value of a function of a continuous RV or joint RVs?\n   \nFor continuous RVs:"
  },
  {
    "objectID": "lessons/14_Variance/29_Variance_and_Sums_of_rv.html#important-properties-of-expected-values-of-functions-of-continuous-rvs",
    "href": "lessons/14_Variance/29_Variance_and_Sums_of_rv.html#important-properties-of-expected-values-of-functions-of-continuous-rvs",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Important properties of expected values of functions of continuous RVs",
    "text": "Important properties of expected values of functions of continuous RVs\n\n\n\n\nFunction of RV with two constants\n\n\n\\(\\mathbb{E}[aX+b] =a\\mathbb{E}[X]+b\\)\n\n\n\n\nFunction of two RVs added\n\n\n\\(\\mathbb{E}[X+Y] =\\mathbb{E}[X]+\\mathbb{E}[Y]\\)\n\n\n\n\nExpected value of sum of independent RVs pt 1\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are continuous RVs and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\[\\mathbb{E}\\Bigg[\\sum_{i=1}^{n} a_i X_i\\Bigg] = \\sum_{i=1}^{n}a_i\\mathbb{E}[X_i]\\]\n\n\n\n\n\nExpected value of multiplication of function of independent RVs\n\n\nIf \\(X\\) and \\(Y\\) are independent continuous RVs, and \\(g\\) and \\(h\\) are functions, then \\[\\mathbb{E}[g(X)h(Y)] =\\mathbb{E}[g(X)]\\mathbb{E}[h(Y)]\\]\n\n\n\n\nExpected value of multiplication of independent RVs\n\n\nIf \\(X\\) and \\(Y\\) are independent continuous RVs, then \\[\\mathbb{E}[XY] = \\mathbb{E}[X] \\mathbb{E}[Y] \\]"
  },
  {
    "objectID": "lessons/14_Variance/29_Variance_and_Sums_of_rv.html#variance-of-continuous-rvs",
    "href": "lessons/14_Variance/29_Variance_and_Sums_of_rv.html#variance-of-continuous-rvs",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Variance of continuous RVs",
    "text": "Variance of continuous RVs\n\n\nHow do we calculate the variance of a discrete RV?\n   \nFor discrete RVs:\n\\[\n\\begin{align}\nVar(X) & =\n\\mathbb{E}[(X-\\mu_X)^2] \\\\ & = \\mathbb{E}[(X-\\mathbb{E}[X])^2] \\\\ &= \\mathbb{E}[X^2]-(\\mathbb{E}[X])^2 \\\\ & = \\sum_{\\{all\\ x\\}}(x-\\mu_x)^2 p_{X}(x)\n\\end{align}\n\\]\n\n\n\nHow do we calculate the variance of a continuous RV?\n    \nFor continuous RVs:"
  },
  {
    "objectID": "lessons/14_Variance/29_Variance_and_Sums_of_rv.html#variance-of-an-uniform-distribution",
    "href": "lessons/14_Variance/29_Variance_and_Sums_of_rv.html#variance-of-an-uniform-distribution",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Variance of an Uniform distribution",
    "text": "Variance of an Uniform distribution\n\n\n\n\nExample 2\n\n\nLet \\(f_X(x)= \\frac{1}{b-a}\\), for \\(a \\leq x \\leq b\\). Find \\(Var[X]\\)."
  },
  {
    "objectID": "lessons/14_Variance/29_Variance_and_Sums_of_rv.html#variance-of-exponential-distribution",
    "href": "lessons/14_Variance/29_Variance_and_Sums_of_rv.html#variance-of-exponential-distribution",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Variance of exponential distribution",
    "text": "Variance of exponential distribution\n\n\nIn the homework:\n\n\nExample 3\n\n\nLet \\(f_X(x)= \\lambda e^{-\\lambda x}\\), for \\(x &gt; 0\\) and \\(\\lambda&gt; 0\\). Find \\(Var[X]\\)."
  },
  {
    "objectID": "lessons/14_Variance/29_Variance_and_Sums_of_rv.html#important-properties-of-variances-of-continuous-rvs",
    "href": "lessons/14_Variance/29_Variance_and_Sums_of_rv.html#important-properties-of-variances-of-continuous-rvs",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Important properties of variances of continuous RVs",
    "text": "Important properties of variances of continuous RVs\n\n\n\n\nFunction of RV with two constants\n\n\n\\[Var[aX+b] = a^2Var[X]\\]\n\n\n\n\n\nVariance of sum of independent RVs pt 1\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous RVs and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\[Var\\Bigg(\\sum_{i=1}^{n} a_i X_i\\Bigg) =\\sum_{i=1}^{n} a^2_i Var(X_i)\\]\n\n\n\n\nVariance of sum of independent RVs pt 2\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous RVs, then \\[Var\\Bigg(\\sum_{i=1}^{n} X_i\\Bigg) = \\sum_{i=1}^{n} Var(X_i)\\]"
  },
  {
    "objectID": "lessons/14_Variance/29_Variance_and_Sums_of_rv.html#find-the-mean-and-sd-from-word-problem",
    "href": "lessons/14_Variance/29_Variance_and_Sums_of_rv.html#find-the-mean-and-sd-from-word-problem",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Find the mean and sd from word problem",
    "text": "Find the mean and sd from word problem\n\n\n\n\nExample 4\n\n\nA machine manufactures cubes with a side length that varies uniformly from 1 to 2 inches. Assume the sides of the base and height are equal. The cost to make a cube is 10 ¢ per cubic inch, and 5 ¢ cents for the general cost per cube. Find the mean and standard deviation of the cost to make 10 cubes."
  },
  {
    "objectID": "lessons/14_Variance/16_Variance_key_info.html",
    "href": "lessons/14_Variance/16_Variance_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "HW 4 assignment due last night!\nHW 3 solutions also due\nTime to grade later today: HW 3 solutions or HW 4 assignment?"
  },
  {
    "objectID": "lessons/14_Variance/16_Variance_key_info.html#announcements",
    "href": "lessons/14_Variance/16_Variance_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "HW 4 assignment due last night!\nHW 3 solutions also due\nTime to grade later today: HW 3 solutions or HW 4 assignment?"
  },
  {
    "objectID": "lessons/14_Variance/16_Variance_key_info.html#key-dates",
    "href": "lessons/14_Variance/16_Variance_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/19_Central_Limit_Theorem.html",
    "href": "lessons/17_Central_Limit_Theorem/19_Central_Limit_Theorem.html",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "",
    "text": "Calculate probability of a sample mean using a population mean and variance with unknown distribution\nUse the Central Limit Theorem to construct the Normal approximation of the Binomial and Poisson distributions"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/19_Central_Limit_Theorem.html#learning-objectives",
    "href": "lessons/17_Central_Limit_Theorem/19_Central_Limit_Theorem.html#learning-objectives",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "",
    "text": "Calculate probability of a sample mean using a population mean and variance with unknown distribution\nUse the Central Limit Theorem to construct the Normal approximation of the Binomial and Poisson distributions"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/19_Central_Limit_Theorem.html#the-central-limit-theorem",
    "href": "lessons/17_Central_Limit_Theorem/19_Central_Limit_Theorem.html#the-central-limit-theorem",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\n\n\nTheorem 1: Central Limit Theorem (CLT)\n\n\nLet \\(X_i\\) be iid rv’s with common mean \\(\\mu\\) and variance \\(\\sigma^2\\), for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\rightarrow \\text{N}(n\\mu, n\\sigma^2)\\]"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/19_Central_Limit_Theorem.html#extension-of-the-clt",
    "href": "lessons/17_Central_Limit_Theorem/19_Central_Limit_Theorem.html#extension-of-the-clt",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "Extension of the CLT",
    "text": "Extension of the CLT\n\n\nCorollary 1\n\n\nLet \\(X_i\\) be iid rv’s with common mean \\(\\mu\\) and variance \\(\\sigma^2\\), for \\(i=1,2,\\ldots,n\\). Then \\[\\overline{X}=\\frac{\\sum_{i=1}^n X_i}{n}  \\rightarrow \\text{N}\\Bigg(\\mu, \\dfrac{\\sigma^2}{n}\\Bigg)\\]"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/19_Central_Limit_Theorem.html#example-of-corollary-in-use",
    "href": "lessons/17_Central_Limit_Theorem/19_Central_Limit_Theorem.html#example-of-corollary-in-use",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "Example of Corollary in use",
    "text": "Example of Corollary in use\n\n\n\n\nExample 1\n\n\nAccording to a large US study, the mean resting heart rate of adult women is about 74 beats per minutes (bpm), with standard deviation 13 bpm (NHANES 2003-2004).\n\nFind the probability that the average resting heart rate for a random sample of 36 adult women is more than 3 bpm away from the mean.\nRepeat the previous question for a single adult woman."
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/19_Central_Limit_Theorem.html#example-of-clt-for-exponential-distribution",
    "href": "lessons/17_Central_Limit_Theorem/19_Central_Limit_Theorem.html#example-of-clt-for-exponential-distribution",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "Example of CLT for exponential distribution",
    "text": "Example of CLT for exponential distribution\n\n\n\n\nExample 2\n\n\nLet \\(X_i \\sim Exp(\\lambda)\\) be iid RVs for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\rightarrow\\]"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/19_Central_Limit_Theorem.html#clt-for-discrete-rvs",
    "href": "lessons/17_Central_Limit_Theorem/19_Central_Limit_Theorem.html#clt-for-discrete-rvs",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "CLT for Discrete RVs",
    "text": "CLT for Discrete RVs\n\n\n\nBinomial rv’s: Let \\(X \\sim Bin(n,p)\\)\n\n\\(X = \\displaystyle\\sum_{i=1}^n X_i\\), where \\(X_i\\) are iid \\(\\text{Bernoulli}(p)\\)\nRule of thumb: \\(np\\geq10\\) and \\(n(1-p)\\geq 10\\) to use Normal approximation\n\n\n\n\n\n\nPoisson rv’s: Let \\(X \\sim Poisson(\\lambda)\\)\n\n\\(X = \\displaystyle\\sum_{i=1}^n X_i\\), where \\(X_i\\) are iid \\(\\text{Poiss}(1)\\)\nRecall from Chapter 18 that if \\(X_i \\sim Poiss(\\lambda_i)\\) and \\(X_i\\) independent, then \\(\\sum_{i=1}^n X_i \\sim Poiss(\\sum_{i=1}^n \\lambda_i)\\)\nRule of thumb: \\(\\lambda \\geq10\\) to use Normal approximation"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/19_Central_Limit_Theorem.html#at-home-example",
    "href": "lessons/17_Central_Limit_Theorem/19_Central_Limit_Theorem.html#at-home-example",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "At home example",
    "text": "At home example\n\n\nExample 3\n\n\nSuppose that the probability of developing a specific type of breast cancer in women aged 40-49 is 0.001. Assume the occurrences of cancer are independent. Suppose you have data from a random sample of 20,000 women aged 40-49.\n\nHow many of the 20,000 women would you expect to develop this type of breast cancer, and what is the standard deviation?\nFind the exact probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to find the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to approximate the following probabilities, where \\(X\\) is the number of women that will develop this type of breast cancer.\n\n\\(\\mathbb{P}(15 \\leq X \\leq 22)\\)\n\\(\\mathbb{P}(X &gt; 20)\\)\n\\(\\mathbb{P}(X &lt; 20)\\)\n\nFind the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer - not using the CLT!\nUse the CLT to approximate the approximate probability in the previous question!"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html",
    "href": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "",
    "text": "Learn the definition of a moment-generating function.\nFind the moment-generating function of a binomial random variable.\nUse a moment-generating function to find the mean and variance of a random variable."
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#learning-objectives",
    "href": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#learning-objectives",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "",
    "text": "Learn the definition of a moment-generating function.\nFind the moment-generating function of a binomial random variable.\nUse a moment-generating function to find the mean and variance of a random variable."
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#where-are-we",
    "href": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#where-are-we",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#what-are-moments",
    "href": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#what-are-moments",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "What are moments?",
    "text": "What are moments?\n\n\nDefinition 1\n\n\nThe \\(j^{th}\\) moment of a r.v. \\(X\\) is \\(\\mathbb{E}[X^j]\\)\n\n\n\n\nExample 1\n\n\n\\(1^{st}-4^{th}\\) moments"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#what-is-a-moment-generating-function-mgf",
    "href": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#what-is-a-moment-generating-function-mgf",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "What is a moment generating function (mgf)??",
    "text": "What is a moment generating function (mgf)??\n\n\nDefinition 3\n\n\nIf \\(X\\) is a r.v., then the moment generating function (mgf) associated with \\(X\\) is: \\[M_X(t)= \\mathbb{E}[e^{tX}]\\]\n\n\nRemarks\n\n\n\nFor a discrete r.v., the mgf of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\sum_{all \\ x}e^{tx}p_X(x)\\]\nFor a continuous r.v., the mgf of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\int_{-\\infty}^{\\infty}e^{tx}f_X(x)dx\\]\n\n\n\nThe mgf \\(M_X(t)\\) is a function of \\(t\\), not of \\(X\\), and it might not be defined (i.e. finite) for all values of \\(t\\). We just need it to be defined for \\(t=0\\)."
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#example",
    "href": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#example",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Example",
    "text": "Example\n\n\n\n\nExample 4\n\n\nWhat is \\(M_X(t)\\) for \\(t=0\\)?"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#theorem",
    "href": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#theorem",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Theorem",
    "text": "Theorem\n\n\nTheorem 5\n\n\nThe moment generating function uniquely specifies a probability distribution.\n\n\n\n\nTheorem 6\n\n\n\\[\\mathbb{E}[X^r] = M_X^{(r)}(0)\\]\n\\((r)\\) in this equation is the \\(r\\)th derivative with respect to \\(t\\)\n\n\n\nWhen \\(r=1\\), we are taking the first derivative\nWhen \\(r=4\\), we are taking the fourth derivative"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-a-probability-distribution",
    "href": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-a-probability-distribution",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Using the mgf to uniquely describe a probability distribution",
    "text": "Using the mgf to uniquely describe a probability distribution\n\n\n\n\nExample 7\n\n\nLet \\(X \\sim Poisson(\\lambda)\\)\n\nFind the mgf of \\(X\\)\nFind \\(\\mathbb{E}[X]\\)\nFind \\(Var(X)\\)"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#theorem-1",
    "href": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#theorem-1",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Theorem",
    "text": "Theorem\nRemark: Finding the mean and variance is sometimes easier with the following trick\n\n\nTheorem 8\n\n\nLet \\(R_X(t) = \\ln[M_X(t)]\\). Then,\n\\[\\mu = \\mathbb{E}[X] = R_X'(0) \\text{, and}\\] \\[\\sigma^2 = Var(X) = R_X''(0)\\]\n\n\n\nProof."
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#using-r_xt-to-uniquely-describe-a-probability-distribution",
    "href": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#using-r_xt-to-uniquely-describe-a-probability-distribution",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Using \\(R_X(t)\\) to uniquely describe a probability distribution",
    "text": "Using \\(R_X(t)\\) to uniquely describe a probability distribution\n\n\n\n\nExample 9\n\n\nLet \\(X \\sim Poisson(\\lambda)\\).\n\nFind \\(\\mathbb{E}[X]\\) using \\(R_X(t)\\)\nFind \\(Var(X)\\) using \\(R_X(t)\\)"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-the-standard-normal-distribution",
    "href": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-the-standard-normal-distribution",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Using the mgf to uniquely describe the standard normal distribution",
    "text": "Using the mgf to uniquely describe the standard normal distribution\n\n\n\n\nExample 10\n\n\nLet \\(Z\\) be a standard normal random variable, i.e. \\(Z \\sim N(0,1)\\).\n\nFind the mgf of \\(Z\\)\nFind \\(\\mathbb{E}[Z]\\)\nFind \\(Var(Z)\\)"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#mgfs-of-sums-of-independent-rvs",
    "href": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#mgfs-of-sums-of-independent-rvs",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Mgf’s of sums of independent RV’s",
    "text": "Mgf’s of sums of independent RV’s\n\n\nTheorem 9\n\n\nIf \\(X\\) and \\(Y\\) are independent RV’s with respective mgf’s \\(M_X(t)\\) and \\(M_Y(t)\\), then\n\\[M_{X+Y}(t) = E[e^{t(X+Y)}] = E[e^{tX} e^{tY}] = E[e^{tX}]E[e^{tY}]=M_{X}(t)M_{Y}(t)\\]"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#main-takeaways",
    "href": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#main-takeaways",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "Main takeaways",
    "text": "Main takeaways\n\nMgf’s are a purely mathematically definition\n\nWe can’t really relate it to our real world analysis\n\nThey are helpful mathematically because they are unique to a probability distribution\n\nWe can find the unique mgf from for a probability distribution\nAnd we can find a distribution from an mgf\n\nMgf’s can sometimes make it easier to find the mean and variance of an RV\nMgf’s are most helpful when we are finding a joint distribution that is a sum or transformation of two RV’s\n\nMake the calculation easier!\n\nMgf’s are often used to prove certain distribution are sums of other ones!"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#more-resources",
    "href": "lessons/18_Moment_Generating_Functions/20_Moment_Generating_Functions.html#more-resources",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "More resources",
    "text": "More resources\n\nhttps://online.stat.psu.edu/stat414/book/export/html/676\nhttps://www.youtube.com/watch/ez_vq23xWrQ\nhttps://www.youtube.com/watch/2p9J9ChTeFI\nhttps://www.youtube.com/watch/A5bWU8xcQkE\nhttps://www.youtube.com/watch/QeUrTGFTFm4\nhttps://www.youtube.com/watch/HhrkwyyRtgI"
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs.html",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs.html",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "",
    "text": "Distinguish between Uniform, Exponential, Gamma, and Normal distributions when reading a story.\nIdentify the variable and the parameters in a story, and state what the variable and parameters mean.\nUse the formulas for the pdf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs.html#properties-of-continuous-uniform-rvs",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs.html#properties-of-continuous-uniform-rvs",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Properties of continuous uniform RVs",
    "text": "Properties of continuous uniform RVs\n\nScenario: Events are equally likely to happen anywhere or anytime in an interval of values\nShorthand: \\(X \\sim \\text{U}[a,b]\\)\n\n\\[\nf_X(x) = \\dfrac{1}{b-a}, \\text{ for }a \\leq x \\leq b\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;a \\quad \\\\\n            \\dfrac{x-a}{b-a} & \\quad a \\leq x \\leq b\\quad \\\\\n            1 & \\quad x&gt;b \\quad\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{a+b}{2} \\text{, } \\text{ Var}(X) = \\dfrac{(b-a)^2}{12}\\]"
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs.html#identifying-continuous-uniform-rv-from-word-problems",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs.html#identifying-continuous-uniform-rv-from-word-problems",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Identifying continuous uniform RV from word problems",
    "text": "Identifying continuous uniform RV from word problems\n\nLook for some indication that all events are equally likely\n\nCould also say “uniformly distributed”\n\nLook for an interval\n\nTime example: Costumer in your store will approach the cash register in next 30 minutes. Approaching the register throughout the 30 minutes is equally likely.\nLength example: You have a 12 inch string that you need to cut. You are equally likely to cut anywhere on the string.\n\nDifferent than the discrete uniform\n\nDiscrete usually includes a countable number of events that are equally likely\nContinuous is not countable\n\nExact time and length can be measured with infinite decimal places"
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs.html#helpful-r-code",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs.html#helpful-r-code",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re looking at equally likely arrival times between 10 am and 11 am.\n\nIf we want to know the probability that someone arrives at 10:30am or earlier:\n\npunif(q = 30, min = 0, max = 60)\n\n[1] 0.5\n\n\nIf we want to know the time, say \\(t\\), where the probability of arriving at \\(t\\) or earlier is 0.35:\n\nqunif(p = 0.35, min = 0, max = 60)\n\n[1] 21\n\n\nIf we want to know the probability that someone arrives between 10:14 and 10:16 am:\n\npunif(q = 16, min = 0, max = 60) - punif(q = 14, min = 0, max = 60)\n\n[1] 0.03333333\n\n\nIf we want to sample 20 arrival times from the distribution:\n\nrunif(n = 20, min = 0, max = 60)\n\n [1] 44.728144 44.223830 17.688727 20.538375 28.303912 19.627502 10.466090\n [8]  1.308244  9.330204 12.466751 36.475512 39.274551 53.383038 39.779082\n[15] 16.199058 59.224016 24.238999  4.346521 43.161210 38.681433"
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs.html#bird-on-a-wire-tb-31.5",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs.html#bird-on-a-wire-tb-31.5",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Bird on a wire (TB 31.5)",
    "text": "Bird on a wire (TB 31.5)\n\n\n\n\nExample 1\n\n\nA bird lands at a location that is Uniformly distributed along an electrical wire of length 150 feet. The wire is stretched tightly between two poles. What is the probability that the bird is 20 feet or less from one or the other of the poles?"
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs.html#properties-of-exponential-rvs",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs.html#properties-of-exponential-rvs",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Properties of exponential RVs",
    "text": "Properties of exponential RVs\n\nScenario: Modeling the time until the next (first) event\nContinuous analog to the geometric distribution!\nShorthand: \\(X \\sim \\text{Exp}(\\lambda)\\)\n\n\\[\nf_X(x) = \\lambda e^{-\\lambda x}\\text{ for } x&gt;0, \\lambda&gt;0\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;0 \\quad \\\\\n            1 - e^{-\\lambda x} & \\quad x\\geq0 \\\\\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{1}{\\lambda}\\] \\[\\text{Var}(X) = \\dfrac{1}{\\lambda^2}\\]"
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs.html#memoryless-property",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs.html#memoryless-property",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Memoryless Property",
    "text": "Memoryless Property\n   \nIf \\(b&gt;0\\),\n\\[P(X &gt; a +b | X&gt; a) = P(X &gt; b)\\]\n     \n\nThis can be interpreted as:\n\nIf you have waited \\(a\\) seconds (or any other measure of time) without a success\nThen the probability that you have to wait \\(b\\) more seconds is the same as as the probability of waiting \\(b\\) seconds initially."
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs.html#identifying-exponential-rv-from-word-problems",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs.html#identifying-exponential-rv-from-word-problems",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Identifying exponential RV from word problems",
    "text": "Identifying exponential RV from word problems\n\nLook for time between events/successes\nLook for a rate of the events over time period\nHow does it differ from the geometric distribution?\n\nGeometric is number of trials until first success\nExponential is time until first success\n\nRelation to the Poisson distribution?\n\nWhen the time between arrivals is exponential, the number of arrivals in a fixed time interval is Poisson with the mean \\(\\lambda\\)"
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs.html#helpful-r-code-1",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs.html#helpful-r-code-1",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re sitting at the bus stop, measuring the time until our bus arrives. We know the bus comes every 10 minutes on average.\n\nIf we want to know the probability that the bus arrives in the next 5 minutes:\n\npexp(q = 5, rate = 1/10)\n\n[1] 0.3934693\n\n\nIf we want to know the time, say \\(t\\), where the probability of the bus arriving at \\(t\\) or earlier is 0.35:\n\nqexp(p = 0.35, rate = 1/10)\n\n[1] 4.307829\n\n\nIf we want to know the probability that the bus arrives between 3 and 5 minutes:\n\npexp(q = 5, rate = 1/10) - pexp(q = 3, rate = 1/10)\n\n[1] 0.1342876\n\n\nIf we want to sample 20 bus arrival times from the distribution:\n\nrexp(n = 20, rate = 1/10)\n\n [1] 32.9936037  6.5122405  1.2366077 32.7022810  0.7516901 10.6307367\n [7]  2.1835628  3.1642249  1.4068712  6.5647109 10.3807690 10.8590575\n[13]  3.2709649  0.7911985  4.2802231 38.6698675  6.9815956 21.2753954\n[19]  8.3067711 18.5987567"
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs.html#transformation-of-independent-exponential-rvs",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs.html#transformation-of-independent-exponential-rvs",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Transformation of independent exponential RVs",
    "text": "Transformation of independent exponential RVs\n\n\nRevisit after joint notes:\n\n\nExample 1\n\n\nLet \\(X_i \\sim \\textrm{Exp}(\\lambda_i)\\) be independent RVs, for \\(i=1 \\ldots n\\). Find the pdf for the first of the arrival times."
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs.html#properties-of-gamma-rvs",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs.html#properties-of-gamma-rvs",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Properties of gamma RVs",
    "text": "Properties of gamma RVs\n\nScenario: Modeling the time until the \\(r^{th}\\) event.\nContinuous analog to the Negative Binomial distribution\nShorthand: \\(X \\sim \\text{Gamma}(r, \\lambda)\\)\n\n\\[\nf_X(x) = \\dfrac{\\lambda^r}{\\Gamma(r)}x^{r-1} e^{-\\lambda x}\\text{ for } x&gt;0, \\lambda&gt;0, \\Gamma(r) = (r-1)!\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;0 \\quad \\\\\n            1 - e^{-\\lambda x}\\displaystyle\\sum_{j=0}^{r-1}\\dfrac{(\\lambda x)^j}{j!}  & \\quad x\\geq0 \\\\\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{r}{\\lambda}\\text{, }\\text{ Var}(X) = \\dfrac{r}{\\lambda^2}\\]\nCommon to see \\(\\alpha = r\\) and \\(\\beta = \\lambda\\)"
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs.html#identifying-gamma-rv-from-word-problems",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs.html#identifying-gamma-rv-from-word-problems",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Identifying gamma RV from word problems",
    "text": "Identifying gamma RV from word problems\n\nGamma distribution with \\(r=1\\) is same as exponential\n\nJust like Negative Binomial with \\(r=1\\) is same as the geometric distribution\n\nSimilar to exponential\n\nLook for time between or until events/successes\n\nBUT now we are measuring time until more than 1 success\n\nLook for a rate of the events over time period"
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs.html#helpful-r-code-2",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs.html#helpful-r-code-2",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re sitting at the bus stop, measuring the time until 4 buses arrive. We know the bus comes every 10 minutes on average.\n\nIf we want to know the probability that the 4 buses arrive in the next 50 minutes:\n\n\n\n\npgamma(q = 50, rate = 1/10, shape = 4)\n\n[1] 0.7349741\n\n\n\n\npgamma(q = 50, scale = 10, shape = 4)\n\n[1] 0.7349741\n\n\n\n\n\nIf we want to know the time, say \\(t\\), where the probability of the 4 buses arriving at \\(t\\) or earlier is 0.35:\n\nqgamma(p = 0.35, rate = 1/10, shape = 4)\n\n[1] 29.87645\n\n\nIf we want to know the probability that the 4 buses arrives between 30 and 50 minutes:\n\npgamma(q = 50, scale = 10, shape = 4) - pgamma(q = 30, scale = 10, shape = 4)\n\n[1] 0.382206\n\n\nIf we want to sample 20 arrival times for the 4 buses:\n\nrgamma(n = 20, scale = 10, shape = 4)\n\n [1] 24.63878 27.46757 22.66421 73.27711 24.81321 20.05810 21.36662 50.75139\n [9] 18.04786 50.93798 42.54043 58.53472 34.15742 20.38195 74.17785 37.13080\n[17] 30.03118 92.84465 69.95391 45.04315"
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs.html#remarks",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs.html#remarks",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Remarks",
    "text": "Remarks\n\nThe parameter \\(r\\) in a Gamma(\\(r\\),\\(\\lambda\\)) distribution does NOT need to be a positive integer\n\n\\(r\\) is usually a positive integer\n\nWhen \\(r\\) is a positive integer, the distribution is sometimes called an Erlang(\\(r\\),\\(\\lambda\\)) distribution\n \n \nWhen \\(r\\) is any positive real number, we have a general gamma distribution that is usually instead parameterized by \\(\\alpha&gt;0\\) and \\(\\beta&gt;0\\), where:\n\n\\(\\alpha = \\text{shape parameter}\\) : same as \\(k\\), the total number of events we must witness\n\nIn R code example: 4 buses to wait for\n\n\\(\\beta = \\text{scale parameter}\\) : same as \\(\\lambda\\), the rate parameter\n\nIn R code example: 1 bus per 10 minutes (1/10)"
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs.html#sending-money-orders",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs.html#sending-money-orders",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Sending money orders",
    "text": "Sending money orders\n\n\n\n\nExample 1\n\n\nOn average, someone sends a money order once per 15 minutes. What is the probability someone sends 10 money orders in less than 3 hours?"
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs.html#additional-resource",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs.html#additional-resource",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Additional Resource",
    "text": "Additional Resource\n\nAnother helpful site with R code: https://rpubs.com/mpfoley73/459051"
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs.html#properties-of-normal-rvs",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs.html#properties-of-normal-rvs",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Properties of Normal RVs",
    "text": "Properties of Normal RVs\n\nNo scenario description here because the Normal distribution is so universal\n\nCentral Limit Theorem (next class) makes it applicable to many types of events\n\nShorthand: \\(X \\sim \\text{Normal}(\\mu, \\sigma^2)\\)\n\n\\[\nf_X(x) = \\dfrac{1}{\\sqrt{2\\pi \\sigma^2}}e^{-(x-\\mu)^2/(2\\sigma^2)} \\text{, for} -inf &lt; x &lt; inf\n\\]\n\\[\\text{E}(X) = \\mu \\] \\[\\text{Var}(X) = \\sigma^2\\]"
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs.html#helpful-r-code-3",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs.html#helpful-r-code-3",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re measuring the high temperature today. The average high temperature on this day across many, many years is 50 degrees with a standard deviation of 4 degrees.\n\nIf we want to know the probability that the high temperature is below 45 degrees:\n\npnorm(q = 45, mean = 50, sd = 4)\n\n[1] 0.1056498\n\n\nIf we want to know the temoerature, say \\(t\\), where the probability of that the temperature is at \\(t\\) or lower is 0.35:\n\nqnorm(p = 0.35, mean = 50, sd = 4)\n\n[1] 48.45872\n\n\nIf we want to know the probability that the temperature is between 45 and 50 degrees:\n\npnorm(q = 50, mean = 50, sd = 4) - pnorm(q = 45, mean = 50, sd = 4)\n\n[1] 0.3943502\n\n\nIf we want to sample 20 days’ temperature (over the years) from the distribution:\n\nrnorm(n = 20, mean = 50, sd = 4)\n\n [1] 49.04321 44.59006 55.47434 47.21813 47.97353 52.54195 50.88295 46.26922\n [9] 49.11485 51.04601 49.97159 56.72557 50.71698 53.70847 47.52182 51.43601\n[17] 49.32552 49.85977 54.12113 40.51289"
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs.html#movie-night-while-studying",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs.html#movie-night-while-studying",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Movie night while studying",
    "text": "Movie night while studying\n\n\n\n\nExample 1\n\n\nChildren’s movies run an average of 98 minutes with a standard deviation of 10 minutes. You check out a random movie from the library to entertain your kids so you can study for your test. Assume that your kids will be occupied for the entire length of the movie.\n\nWhat is the probability that your kids will be occupied for at least the 2 hours you would like to study?\nWhat is range for the bottom quartile (lowest 25%) of time they will be occupied?"
  },
  {
    "objectID": "lessons/16_Cont_RVs/18_Cont_RVs.html#standard-normal-distribution",
    "href": "lessons/16_Cont_RVs/18_Cont_RVs.html#standard-normal-distribution",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "Standard Normal Distribution",
    "text": "Standard Normal Distribution\n\\[ Z \\sim \\text{Normal}(\\mu = 0, \\sigma^2 = 1)\\]\n\nUsed to be more helpful when computing was not as advanced\n\nUse tables of the standard normal\nYou can convert any normal distribution to a standard normal through transformation\n\n\\(Z = \\dfrac{X - \\mu_X}{\\sigma_X}\\)\n\nComes from \\(X = \\sigma_X Z + \\mu_X\\)\nSince \\(\\sigma_X\\) and \\(\\mu_X\\) are constants, then \\(E(X) = \\mu_X\\) and \\(SD(X) = \\sigma_X SD(Z) = \\sigma_X\\)"
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs.html",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs.html",
    "title": "Lesson 18: Some Important Continuous RVs",
    "section": "",
    "text": "Distinguish between Uniform, Exponential, Gamma, and Normal distributions when reading a story.\nIdentify the variable and the parameters in a story, and state what the variable and parameters mean.\nUse the formulas for the pdf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs.html#properties-of-continuous-uniform-rvs",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs.html#properties-of-continuous-uniform-rvs",
    "title": "Lesson 16: Some Important Continuous RVs",
    "section": "Properties of continuous uniform RVs",
    "text": "Properties of continuous uniform RVs\n\nScenario: Events are equally likely to happen anywhere or anytime in an interval of values\nShorthand: \\(X \\sim \\text{U}[a,b]\\)\n\n\\[\nf_X(x) = \\dfrac{1}{b-a}, \\text{ for }a \\leq x \\leq b\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;a \\quad \\\\\n            \\dfrac{x-a}{b-a} & \\quad a \\leq x \\leq b\\quad \\\\\n            1 & \\quad x&gt;b \\quad\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{a+b}{2} \\text{, } \\text{ Var}(X) = \\dfrac{(b-a)^2}{12}\\]"
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs.html#identifying-continuous-uniform-rv-from-word-problems",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs.html#identifying-continuous-uniform-rv-from-word-problems",
    "title": "Lesson 16: Some Important Continuous RVs",
    "section": "Identifying continuous uniform RV from word problems",
    "text": "Identifying continuous uniform RV from word problems\n\nLook for some indication that all events are equally likely\n\nCould also say “uniformly distributed”\n\nLook for an interval\n\nTime example: Costumer in your store will approach the cash register in next 30 minutes. Approaching the register throughout the 30 minutes is equally likely.\nLength example: You have a 12 inch string that you need to cut. You are equally likely to cut anywhere on the string.\n\nDifferent than the discrete uniform\n\nDiscrete usually includes a countable number of events that are equally likely\nContinuous is not countable\n\nExact time and length can be measured with infinite decimal places"
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs.html#helpful-r-code",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs.html#helpful-r-code",
    "title": "Lesson 16: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re looking at equally likely arrival times between 10 am and 11 am.\n\nIf we want to know the probability that someone arrives at 10:30am or earlier:\n\npunif(q = 30, min = 0, max = 60)\n\n[1] 0.5\n\n\nIf we want to know the time, say \\(t\\), where the probability of arriving at \\(t\\) or earlier is 0.35:\n\nqunif(p = 0.35, min = 0, max = 60)\n\n[1] 21\n\n\nIf we want to know the probability that someone arrives between 10:14 and 10:16 am:\n\npunif(q = 16, min = 0, max = 60) - punif(q = 14, min = 0, max = 60)\n\n[1] 0.03333333\n\n\nIf we want to sample 20 arrival times from the distribution:\n\nrunif(n = 20, min = 0, max = 60)\n\n [1] 57.254766 34.877635  9.463305  9.299211 44.853180 24.713062  7.637811\n [8] 56.432479 57.911681 26.541762 41.756752 32.239442 54.968374  4.029851\n[15] 33.138835 40.718886  5.610676 19.739926 21.084020 36.677654"
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs.html#bird-on-a-wire-tb-31.5",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs.html#bird-on-a-wire-tb-31.5",
    "title": "Lesson 16: Some Important Continuous RVs",
    "section": "Bird on a wire (TB 31.5)",
    "text": "Bird on a wire (TB 31.5)\n\n\n\n\nExample 1\n\n\nA bird lands at a location that is Uniformly distributed along an electrical wire of length 150 feet. The wire is stretched tightly between two poles. What is the probability that the bird is 20 feet or less from one or the other of the poles?"
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs.html#properties-of-exponential-rvs",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs.html#properties-of-exponential-rvs",
    "title": "Lesson 16: Some Important Continuous RVs",
    "section": "Properties of exponential RVs",
    "text": "Properties of exponential RVs\n\nScenario: Modeling the time until the next (first) event\nContinuous analog to the geometric distribution!\nShorthand: \\(X \\sim \\text{Exp}(\\lambda)\\)\n\n\\[\nf_X(x) = \\lambda e^{-\\lambda x}\\text{ for } x&gt;0, \\lambda&gt;0\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;0 \\quad \\\\\n            1 - e^{-\\lambda x} & \\quad x\\geq0 \\\\\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{1}{\\lambda}\\] \\[\\text{Var}(X) = \\dfrac{1}{\\lambda^2}\\]"
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs.html#memoryless-property",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs.html#memoryless-property",
    "title": "Lesson 16: Some Important Continuous RVs",
    "section": "Memoryless Property",
    "text": "Memoryless Property\n   \nIf \\(b&gt;0\\),\n\\[P(X &gt; a +b | X&gt; a) = P(X &gt; b)\\]\n     \n\nThis can be interpreted as:\n\nIf you have waited \\(a\\) seconds (or any other measure of time) without a success\nThen the probability that you have to wait \\(b\\) more seconds is the same as as the probability of waiting \\(b\\) seconds initially."
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs.html#identifying-exponential-rv-from-word-problems",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs.html#identifying-exponential-rv-from-word-problems",
    "title": "Lesson 16: Some Important Continuous RVs",
    "section": "Identifying exponential RV from word problems",
    "text": "Identifying exponential RV from word problems\n\nLook for time between events/successes\nLook for a rate of the events over time period\nHow does it differ from the geometric distribution?\n\nGeometric is number of trials until first success\nExponential is time until first success\n\nRelation to the Poisson distribution?\n\nWhen the time between arrivals is exponential, the number of arrivals in a fixed time interval is Poisson with the mean \\(\\lambda\\)"
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs.html#helpful-r-code-1",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs.html#helpful-r-code-1",
    "title": "Lesson 16: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re sitting at the bus stop, measuring the time until our bus arrives. We know the bus comes every 10 minutes on average.\n\nIf we want to know the probability that the bus arrives in the next 5 minutes:\n\npexp(q = 5, rate = 1/10)\n\n[1] 0.3934693\n\n\nIf we want to know the time, say \\(t\\), where the probability of the bus arriving at \\(t\\) or earlier is 0.35:\n\nqexp(p = 0.35, rate = 1/10)\n\n[1] 4.307829\n\n\nIf we want to know the probability that the bus arrives between 3 and 5 minutes:\n\npexp(q = 5, rate = 1/10) - pexp(q = 3, rate = 1/10)\n\n[1] 0.1342876\n\n\nIf we want to sample 20 bus arrival times from the distribution:\n\nrexp(n = 20, rate = 1/10)\n\n [1]  3.27079121  9.21887422 23.15584516  1.43197788  7.13709980  2.46155182\n [7]  1.25854357 16.49368095  2.07284506  9.61934986  1.72675516  9.66994375\n[13]  0.60112111  8.14090359 27.93188929  0.02541741 22.76283795  4.51165567\n[19] 15.79182468  2.31727717"
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs.html#transformation-of-independent-exponential-rvs",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs.html#transformation-of-independent-exponential-rvs",
    "title": "Lesson 16: Some Important Continuous RVs",
    "section": "Transformation of independent exponential RVs",
    "text": "Transformation of independent exponential RVs\n\n\nRevisit after joint notes:\n\n\nExample 2\n\n\nLet \\(X_i \\sim \\textrm{Exp}(\\lambda_i)\\) be independent RVs, for \\(i=1 \\ldots n\\). Find the pdf for the first of the arrival times."
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs.html#properties-of-gamma-rvs",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs.html#properties-of-gamma-rvs",
    "title": "Lesson 16: Some Important Continuous RVs",
    "section": "Properties of gamma RVs",
    "text": "Properties of gamma RVs\n\nScenario: Modeling the time until the \\(r^{th}\\) event.\nContinuous analog to the Negative Binomial distribution\nShorthand: \\(X \\sim \\text{Gamma}(r, \\lambda)\\) or \\(X \\sim \\text{Gamma}(\\alpha, \\beta)\\)\n\n\\[\nf_X(x) = \\dfrac{\\lambda^r}{\\Gamma(r)}x^{r-1} e^{-\\lambda x}\\text{ for } x&gt;0, \\lambda&gt;0, \\Gamma(r) = (r-1)!\n\\]\n\\[\nF_X(x) = \\left\\{\n        \\begin{array}{ll}\n            0 & \\quad x&lt;0 \\quad \\\\\n            1 - e^{-\\lambda x}\\displaystyle\\sum_{j=0}^{r-1}\\dfrac{(\\lambda x)^j}{j!}  & \\quad x\\geq0 \\\\\n        \\end{array}\n    \\right.\n\\]\n\\[\\text{E}(X) = \\dfrac{r}{\\lambda}\\text{, }\\text{ Var}(X) = \\dfrac{r}{\\lambda^2}\\]\nCommon to see \\(\\alpha = r\\) and \\(\\beta = \\lambda\\)"
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs.html#identifying-gamma-rv-from-word-problems",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs.html#identifying-gamma-rv-from-word-problems",
    "title": "Lesson 16: Some Important Continuous RVs",
    "section": "Identifying gamma RV from word problems",
    "text": "Identifying gamma RV from word problems\n\nGamma distribution with \\(r=1\\) is same as exponential\n\nJust like Negative Binomial with \\(r=1\\) is same as the geometric distribution\n\nSimilar to exponential\n\nLook for time between or until events/successes\n\nBUT now we are measuring time until more than 1 success\n\nLook for a rate of the events over time period"
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs.html#helpful-r-code-2",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs.html#helpful-r-code-2",
    "title": "Lesson 16: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re sitting at the bus stop, measuring the time until 4 buses arrive. We know the bus comes every 10 minutes on average.\n\nIf we want to know the probability that the 4 buses arrive in the next 50 minutes:\n\n\n\n\npgamma(q = 50, rate = 1/10, shape = 4)\n\n[1] 0.7349741\n\n\n\n\npgamma(q = 50, scale = 10, shape = 4)\n\n[1] 0.7349741\n\n\n\n\nIf we want to know the time, say \\(t\\), where the probability of the 4 buses arriving at \\(t\\) or earlier is 0.35:\n\nqgamma(p = 0.35, rate = 1/10, shape = 4)\n\n[1] 29.87645\n\n\nIf we want to know the probability that the 4 buses arrives between 30 and 50 minutes:\n\npgamma(q = 50, scale = 10, shape = 4) - pgamma(q = 30, scale = 10, shape = 4)\n\n[1] 0.382206\n\n\nIf we want to sample 20 arrival times for the 4 buses:\n\nrgamma(n = 20, scale = 10, shape = 4)\n\n [1] 67.04894 14.44306 43.05435 12.51608 30.58018 34.94098 28.34891 26.01258\n [9] 37.60928 24.73837 32.30761 45.71904 54.58035 41.08169 18.69450 28.78482\n[17] 51.66387 40.08829 56.18500 22.85659"
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs.html#remarks",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs.html#remarks",
    "title": "Lesson 16: Some Important Continuous RVs",
    "section": "Remarks",
    "text": "Remarks\n\nThe parameter \\(r\\) in a Gamma(\\(r\\),\\(\\lambda\\)) distribution does NOT need to be a positive integer\n\n\\(r\\) is usually a positive integer\n\nWhen \\(r\\) is a positive integer, the distribution is sometimes called an Erlang(\\(r\\),\\(\\lambda\\)) distribution\n \n \nWhen \\(r\\) is any positive real number, we have a general gamma distribution that is usually instead parameterized by \\(\\alpha&gt;0\\) and \\(\\beta&gt;0\\), where:\n\n\\(\\alpha = \\text{shape parameter}\\) : same as \\(k\\), the total number of events we must witness\n\nIn R code example: 4 buses to wait for\n\n\\(\\beta = \\text{scale parameter}\\) : same as \\(\\lambda\\), the rate parameter\n\nIn R code example: 1 bus per 10 minutes (1/10)"
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs.html#sending-money-orders",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs.html#sending-money-orders",
    "title": "Lesson 16: Some Important Continuous RVs",
    "section": "Sending money orders",
    "text": "Sending money orders\n\n\n\n\nExample 3\n\n\nOn average, someone sends a money order once per 15 minutes. What is the probability someone sends 10 money orders in less than 3 hours?"
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs.html#additional-resource",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs.html#additional-resource",
    "title": "Lesson 16: Some Important Continuous RVs",
    "section": "Additional Resource",
    "text": "Additional Resource\n\nAnother helpful site with R code: https://rpubs.com/mpfoley73/459051"
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs.html#properties-of-normal-rvs",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs.html#properties-of-normal-rvs",
    "title": "Lesson 16: Some Important Continuous RVs",
    "section": "Properties of Normal RVs",
    "text": "Properties of Normal RVs\n\nNo scenario description here because the Normal distribution is so universal\n\nCentral Limit Theorem (next class) makes it applicable to many types of events\n\nShorthand: \\(X \\sim \\text{Normal}(\\mu, \\sigma^2)\\)\n\n\\[\nf_X(x) = \\dfrac{1}{\\sqrt{2\\pi \\sigma^2}}e^{-(x-\\mu)^2/(2\\sigma^2)} \\text{, for} -\\infty &lt; x &lt; \\infty\n\\]\n\\[\\text{E}(X) = \\mu \\] \\[\\text{Var}(X) = \\sigma^2\\]"
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs.html#helpful-r-code-3",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs.html#helpful-r-code-3",
    "title": "Lesson 16: Some Important Continuous RVs",
    "section": "Helpful R code",
    "text": "Helpful R code\nLet’s say we’re measuring the high temperature today. The average high temperature on this day across many, many years is 50 degrees with a standard deviation of 4 degrees.\n\nIf we want to know the probability that the high temperature is below 45 degrees:\n\npnorm(q = 45, mean = 50, sd = 4)\n\n[1] 0.1056498\n\n\nIf we want to know the temoerature, say \\(t\\), where the probability of that the temperature is at \\(t\\) or lower is 0.35:\n\nqnorm(p = 0.35, mean = 50, sd = 4)\n\n[1] 48.45872\n\n\nIf we want to know the probability that the temperature is between 45 and 50 degrees:\n\npnorm(q = 50, mean = 50, sd = 4) - pnorm(q = 45, mean = 50, sd = 4)\n\n[1] 0.3943502\n\n\nIf we want to sample 20 days’ temperature (over the years) from the distribution:\n\nrnorm(n = 20, mean = 50, sd = 4)\n\n [1] 51.25746 45.35334 49.66657 51.78714 47.45682 53.39772 52.86730 47.12661\n [9] 49.79689 52.23243 50.95174 58.17850 51.36292 46.18399 52.27518 53.80362\n[17] 51.33378 49.25484 54.50188 55.77698"
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs.html#movie-night-while-studying",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs.html#movie-night-while-studying",
    "title": "Lesson 16: Some Important Continuous RVs",
    "section": "Movie night while studying",
    "text": "Movie night while studying\n\n\n\n\nExample 4\n\n\nChildren’s movies run an average of 98 minutes with a standard deviation of 10 minutes. You check out a random movie from the library to entertain your kids so you can study for your test. Assume that your kids will be occupied for the entire length of the movie.\n\nWhat is the probability that your kids will be occupied for at least the 2 hours you would like to study?\nWhat is range for the bottom quartile (lowest 25%) of time they will be occupied?"
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs.html#standard-normal-distribution",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs.html#standard-normal-distribution",
    "title": "Lesson 16: Some Important Continuous RVs",
    "section": "Standard Normal Distribution",
    "text": "Standard Normal Distribution\n\\[ Z \\sim \\text{Normal}(\\mu = 0, \\sigma^2 = 1)\\]\n\nUsed to be more helpful when computing was not as advanced\n\nUse tables of the standard normal\nYou can convert any normal distribution to a standard normal through transformation\n\n\\(Z = \\dfrac{X - \\mu_X}{\\sigma_X}\\)\n\nComes from \\(X = \\sigma_X Z + \\mu_X\\)\nSince \\(\\sigma_X\\) and \\(\\mu_X\\) are constants, then \\(E(X) = \\mu_X\\) and \\(SD(X) = \\sigma_X\\)"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html",
    "href": "lessons/14_Variance/14_Variance.html",
    "title": "Lesson 16: Variance",
    "section": "",
    "text": "Calculate the variance and standard deviation of discrete random variables\nCalculate the variance of sums of discrete random variables\nCalculate the variance of functions of discrete random variables\nCalculate expected value of functions of RVs\nCalculate variance of RVs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 1\n\n\nLet \\(g\\) be a function and let \\(g(x) = ax+b\\), for real-valued constants \\(a\\) and \\(b\\). What is \\(\\mathbb{E}[g(X)]\\)?\n\n\n\n\n\n\n\n\n\nDefinition: Expected value of function of RV\n\n\nFor any function \\(g\\) and discrete r.v. \\(X\\), the expected value of \\(g(X)\\) is \\[\\mathbb{E}[g(X)] = \\sum_{\\{all\\ x\\}}\\ g(x) p_X(x).\\]\n\n\n\n\n\n\n\n\n\nExample 2\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw.\n\nFind \\(\\mathbb{E}[X^2]\\).\n\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw.\n\nFind \\(\\mathbb{E}\\big[\\big(X-\\frac{1}{2}\\big)^2\\big]\\).\n\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]\n\n\n\n\n\n\n\n\n\n\nDefinition: Variance of RV\n\n\nThe variance of a r.v. \\(X\\), with (finite) expected value \\(\\mu_X=\\mathbb{E}[X]\\) is \\[\\sigma_X^2=Var(X)=\\mathbb{E}[(X-\\mu_X)^2] = \\mathbb{E}[(X-\\mathbb{E}[X])^2]\\]\n\n\n\n\nDefinition: Standard deviation of RV\n\n\nThe standard deviation of a r.v. \\(X\\) is \\[\\sigma_X = SD(X) = \\sqrt{\\sigma_X^2}=\\sqrt{Var(X)}.\\]\n\n\n\n\n\nQuestions: Why do we square the difference in the variance definition? \\((X-\\mu_X)^2\\)\n\nWhy not define the measure of spread as \\(\\mathbb{E}[X-\\mu_X] = \\mathbb{E}[X-\\mathbb{E}[X]]\\)?\nWhy not use \\(\\mathbb{E}[|X-\\mu_X|]\\)?\n\n\n\n\n\n\n\n\nLemma 6: “Computation formula” for Variance\n\n\nThe variance of a r.v. \\(X\\), can be computed as \\[\\begin{align}\n\\sigma_X^2 & =Var(X) \\\\ & = \\mathbb{E}[X^2]-\\mu_X^2 \\\\ & = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2\n\\end{align}\\]"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#lets-start-building-the-variance-through-expected-values-of-functions",
    "href": "lessons/14_Variance/14_Variance.html#lets-start-building-the-variance-through-expected-values-of-functions",
    "title": "Lesson 14: Variance",
    "section": "Let’s start building the variance through expected values of functions",
    "text": "Let’s start building the variance through expected values of functions\n\n\n\n\nExample 1\n\n\nLet \\(g\\) be a function and let \\(g(x) = ax+b\\), for real-valued constants \\(a\\) and \\(b\\). What is \\(\\mathbb{E}[g(X)]\\)?"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#what-is-the-expected-value-of-a-function",
    "href": "lessons/14_Variance/14_Variance.html#what-is-the-expected-value-of-a-function",
    "title": "Lesson 14: Variance",
    "section": "What is the expected value of a function?",
    "text": "What is the expected value of a function?\n\n\n\n\nExpected value of function of discrete RV\n\n\nFor any function \\(g\\) and discrete RV \\(X\\), the expected value of \\(g(X)\\) is \\[\\mathbb{E}[g(X)] = \\sum_{\\{all\\ x\\}}\\ g(x) p_X(x)\\]\n\n\n\n\n\nExpected value of function of continuous RV\n\n\nFor any function \\(g\\) and continuous RV \\(X\\), the expected value of \\(g(X)\\) is \\[\\mathbb{E}[g(X)] = \\displaystyle\\int_{-\\infty}^\\infty g(x)f_X(x) dx\\]\n\n\n\n\nFor example, if we have \\(g(x)=x^2\\), then \\[\\mathbb{E}[X^2)] = \\sum_{\\{all\\ x\\}}\\ x^2 p_X(x) \\neq \\left(\\sum_{\\{all\\ x\\}}\\ x p_X(x)) \\right)^2 = \\left( \\mathbb{E}[X] \\right)^2\\]"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#lets-revisit-the-card-example-12",
    "href": "lessons/14_Variance/14_Variance.html#lets-revisit-the-card-example-12",
    "title": "Lesson 14: Variance",
    "section": "Let’s revisit the card example (1/2)",
    "text": "Let’s revisit the card example (1/2)\n\n\n\n\nExample 2\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw.\n\nFind \\(\\mathbb{E}[X^2]\\).\n\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#lets-revisit-the-card-example-22",
    "href": "lessons/14_Variance/14_Variance.html#lets-revisit-the-card-example-22",
    "title": "Lesson 14: Variance",
    "section": "Let’s revisit the card example (2/2)",
    "text": "Let’s revisit the card example (2/2)\n\n\n\n\nExample 2\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw.\n\nFind \\(\\mathbb{E}\\big[\\big(X-\\frac{1}{2}\\big)^2\\big]\\).\n\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#variance-of-a-rv",
    "href": "lessons/14_Variance/14_Variance.html#variance-of-a-rv",
    "title": "Lesson 14: Variance",
    "section": "Variance of a RV",
    "text": "Variance of a RV\n\n\nDefinition: Variance of RV\n\n\nThe variance of a RV \\(X\\), with (finite) expected value \\(\\mu_X=\\mathbb{E}[X]\\) is \\[\\sigma_X^2=Var(X)=\\mathbb{E}[(X-\\mu_X)^2] = \\mathbb{E}[(X-\\mathbb{E}[X])^2]\\]\n\n\n\n\nDefinition: Standard deviation of RV\n\n\nThe standard deviation of a RV \\(X\\) is \\[\\sigma_X = SD(X) = \\sqrt{\\sigma_X^2}=\\sqrt{Var(X)}.\\]"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#questions",
    "href": "lessons/14_Variance/14_Variance.html#questions",
    "title": "Lesson 16: Variance",
    "section": "",
    "text": "Questions: Why do we square the difference in the variance definition? \\((X-\\mu_X)^2\\)\n\nWhy not define the measure of spread as \\(\\mathbb{E}[X-\\mu_X] = \\mathbb{E}[X-\\mathbb{E}[X]]\\)?\nWhy not use \\(\\mathbb{E}[|X-\\mu_X|]\\)?"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#lets-calculate-the-variance-and-prove-it",
    "href": "lessons/14_Variance/14_Variance.html#lets-calculate-the-variance-and-prove-it",
    "title": "Lesson 14: Variance",
    "section": "Let’s calculate the variance and prove it!",
    "text": "Let’s calculate the variance and prove it!\n\n\n\n\nLemma 6: “Computation formula” for Variance\n\n\nThe variance of a RV \\(X\\), can be computed as \\[\\begin{align}\n\\sigma_X^2 & =Var(X) \\\\ & = \\mathbb{E}[X^2]-\\mu_X^2 \\\\ & = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2\n\\end{align}\\]"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#variance-of-a-function-with-a-single-rv",
    "href": "lessons/14_Variance/14_Variance.html#variance-of-a-function-with-a-single-rv",
    "title": "Lesson 14: Variance",
    "section": "Variance of a function with a single RV",
    "text": "Variance of a function with a single RV\n\n\nLemma 7\n\n\nFor a RV \\(X\\) and constants \\(a\\) and \\(b\\), \\[Var(aX+b) = a^2Var(X).\\]\n\n\nProof will be exercise in homework. It’s fun! In a mathy kinda way."
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#important-results-for-independent-rvs",
    "href": "lessons/14_Variance/14_Variance.html#important-results-for-independent-rvs",
    "title": "Lesson 14: Variance",
    "section": "Important results for independent RVs",
    "text": "Important results for independent RVs\n\n\nTheorem 8\n\n\nFor independent RV’s \\(X\\) and \\(Y\\), and functions \\(g\\) and \\(h\\), \\[\\mathbb{E}[g(X)h(Y)] = \\mathbb{E}[g(X)]\\mathbb{E}[h(Y)].\\]\n\n\n\n\nCorollary 1\n\n\nFor independent RV’s \\(X\\) and \\(Y\\), \\[\\mathbb{E}[XY] = \\mathbb{E}[X]\\mathbb{E}[Y].\\]"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#variance-of-sum-of-independent-discrete-rvs",
    "href": "lessons/14_Variance/14_Variance.html#variance-of-sum-of-independent-discrete-rvs",
    "title": "Lesson 14: Variance",
    "section": "Variance of sum of independent discrete RVs",
    "text": "Variance of sum of independent discrete RVs\n\n\nTheorem 9: Variance of sum of independent discrete RV’s\n\n\nFor independent discrete RV’s \\(X_i\\) and constants \\(a_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n a_iX_i\\Bigg) = \\sum_{i=1}^n a_i^2Var(X_i).\\]\n\n\nSimpler version:\n\\[Var(a_1 X + a_2 Y) = Var(a_1X) + Var(a_2 Y) = a_1^2 Var(X) + a_2^2 Var(Y)\\]"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#corollaries",
    "href": "lessons/14_Variance/14_Variance.html#corollaries",
    "title": "Lesson 14: Variance",
    "section": "Corollaries",
    "text": "Corollaries\n\n\nCorollary 2\n\n\nFor independent discrete RV’s \\(X_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n X_i\\Bigg) = \\sum_{i=1}^n Var(X_i).\\]\n\n\n\n\nCorollary 3\n\n\nFor independent identically distributed (i.i.d.) discrete RV’s \\(X_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n X_i\\Bigg) = n Var(X_1).\\]"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#lets-look-at-a-ghost-problem-with-replacement",
    "href": "lessons/14_Variance/14_Variance.html#lets-look-at-a-ghost-problem-with-replacement",
    "title": "Lesson 14: Variance",
    "section": "Let’s look at a ghost problem with replacement",
    "text": "Let’s look at a ghost problem with replacement\n\n\n\n\nExample 3.2\n\n\nThe ghost is trick-or-treating at a different house now. In this case it is known that the bag of candy has 10 chocolates, 20 lollipops, and 30 laffy taffies. The ghost grabs a handful of five pieces of candy. What is the variance for the number of chocolates the ghost takes? Let’s solve this for the cases with replacement.\n\n\n\n\nRecall probability with replacement:\n\\[\np_X(x) = {n \\choose k}p^k(1-p)^{n-k}\n\\]"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#back-to-our-hotel-example-from-chapter-11",
    "href": "lessons/14_Variance/14_Variance.html#back-to-our-hotel-example-from-chapter-11",
    "title": "Lesson 14: Variance",
    "section": "Back to our hotel example from Chapter 11",
    "text": "Back to our hotel example from Chapter 11\n\n\n\n\nExample 4\n\n\nA tour group is planning a visit to the city of Minneapolis and needs to book 30 hotel rooms. The average price of a room is $200 with standard deviation $10. In addition, there is a 10% tourism tax for each room. What is the standard deviation of the cost for the 30 hotel rooms? Assume rooms are independent.\n\n\nProblem to do at home if we don’t have enough time."
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#expected-value-of-a-function-of-a-continuous-rv",
    "href": "lessons/14_Variance/14_Variance.html#expected-value-of-a-function-of-a-continuous-rv",
    "title": "Lesson 14: Variance",
    "section": "Expected value of a function of a continuous RV",
    "text": "Expected value of a function of a continuous RV\n\n\nHow do we calculate the expected value of a function of a discrete RV or joint RVs?\n   \nFor discrete RVs:\n\\[\\mathbb{E}[g(X)] = \\sum_{\\{all\\ x\\}}\\ g(x) p_X(x).\\] \\[\\mathbb{E}[g(X, Y)] = \\sum_{\\{all\\ x\\}}\\sum_{\\{all\\ y\\}}\\ g(x,y) p_{X,Y}(x,y).\\]\n\n\n\nHow do we calculate the expected value of a function of a continuous RV or joint RVs?\n   \nFor continuous RVs:"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#important-properties-of-expected-values-of-functions-of-continuous-rvs",
    "href": "lessons/14_Variance/14_Variance.html#important-properties-of-expected-values-of-functions-of-continuous-rvs",
    "title": "Lesson 14: Variance",
    "section": "Important properties of expected values of functions of continuous RVs",
    "text": "Important properties of expected values of functions of continuous RVs\n\n\n\n\nFunction of RV with two constants\n\n\n\\(\\mathbb{E}[aX+b] =a\\mathbb{E}[X]+b\\)\n\n\n\n\nFunction of two RVs added\n\n\n\\(\\mathbb{E}[X+Y] =\\mathbb{E}[X]+\\mathbb{E}[Y]\\)\n\n\n\n\nExpected value of sum of independent RVs pt 1\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are continuous RVs and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\[\\mathbb{E}\\Bigg[\\sum_{i=1}^{n} a_i X_i\\Bigg] = \\sum_{i=1}^{n}a_i\\mathbb{E}[X_i]\\]\n\n\n\n\n\nExpected value of multiplication of function of independent RVs\n\n\nIf \\(X\\) and \\(Y\\) are independent continuous RVs, and \\(g\\) and \\(h\\) are functions, then \\[\\mathbb{E}[g(X)h(Y)] =\\mathbb{E}[g(X)]\\mathbb{E}[h(Y)]\\]\n\n\n\n\nExpected value of multiplication of independent RVs\n\n\nIf \\(X\\) and \\(Y\\) are independent continuous RVs, then \\[\\mathbb{E}[XY] = \\mathbb{E}[X] \\mathbb{E}[Y] \\]"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#variance-of-continuous-rvs",
    "href": "lessons/14_Variance/14_Variance.html#variance-of-continuous-rvs",
    "title": "Lesson 14: Variance",
    "section": "Variance of continuous RVs",
    "text": "Variance of continuous RVs\n\n\nHow do we calculate the variance of a discrete RV?\n   \nFor discrete RVs:\n\\[\n\\begin{align}\nVar(X) & =\n\\mathbb{E}[(X-\\mu_X)^2] \\\\ & = \\mathbb{E}[(X-\\mathbb{E}[X])^2] \\\\ &= \\mathbb{E}[X^2]-(\\mathbb{E}[X])^2 \\\\ & = \\sum_{\\{all\\ x\\}}(x-\\mu_x)^2 p_{X}(x)\n\\end{align}\n\\]\n\n\n\nHow do we calculate the variance of a continuous RV?\n    \nFor continuous RVs:"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#variance-of-an-uniform-distribution",
    "href": "lessons/14_Variance/14_Variance.html#variance-of-an-uniform-distribution",
    "title": "Lesson 14: Variance",
    "section": "Variance of an Uniform distribution",
    "text": "Variance of an Uniform distribution\n\n\n\n\nExample 2\n\n\nLet \\(f_X(x)= \\frac{1}{b-a}\\), for \\(a \\leq x \\leq b\\). Find \\(Var[X]\\)."
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#variance-of-exponential-distribution",
    "href": "lessons/14_Variance/14_Variance.html#variance-of-exponential-distribution",
    "title": "Lesson 14: Variance",
    "section": "Variance of exponential distribution",
    "text": "Variance of exponential distribution\n\n\nIn the homework:\n\n\nExample 3\n\n\nLet \\(f_X(x)= \\lambda e^{-\\lambda x}\\), for \\(x &gt; 0\\) and \\(\\lambda&gt; 0\\). Find \\(Var[X]\\)."
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#important-properties-of-variances-of-continuous-rvs",
    "href": "lessons/14_Variance/14_Variance.html#important-properties-of-variances-of-continuous-rvs",
    "title": "Lesson 14: Variance",
    "section": "Important properties of variances of continuous RVs",
    "text": "Important properties of variances of continuous RVs\n\n\n\n\nFunction of RV with two constants\n\n\n\\[Var[aX+b] = a^2Var[X]\\]\n\n\n\n\n\nVariance of sum of independent RVs pt 1\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous RVs and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\[Var\\Bigg(\\sum_{i=1}^{n} a_i X_i\\Bigg) =\\sum_{i=1}^{n} a^2_i Var(X_i)\\]\n\n\n\n\nVariance of sum of independent RVs pt 2\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous RVs, then \\[Var\\Bigg(\\sum_{i=1}^{n} X_i\\Bigg) = \\sum_{i=1}^{n} Var(X_i)\\]"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#find-the-mean-and-sd-from-word-problem",
    "href": "lessons/14_Variance/14_Variance.html#find-the-mean-and-sd-from-word-problem",
    "title": "Lesson 14: Variance",
    "section": "Find the mean and sd from word problem",
    "text": "Find the mean and sd from word problem\n\n\n\n\nExample 4\n\n\nA machine manufactures cubes with a side length that varies uniformly from 1 to 2 inches. Assume the sides of the base and height are equal. The cost to make a cube is 10 ¢ per cubic inch, and 5 ¢ cents for the general cost per cube. Find the mean and standard deviation of the cost to make 10 cubes."
  },
  {
    "objectID": "lessons/14_Variance/14_Variance_key_info.html",
    "href": "lessons/14_Variance/14_Variance_key_info.html",
    "title": "Key Info and Announcements",
    "section": "",
    "text": "Homework 5\n\nCharles said it looks good! Impressed with everyone’s work on questions 3 and 4!\n\nQuestion for today’s exit ticket\n\nHow would you feel if we cancelled class on 12/1 and covered MGFs only in one class?\n\nMain reason I cover MGFs is to prepare you for the next course (BSSTA 551), but I talked to Jessica and she does not think they are needed for her class…\n\n\n\n\n\nWe have had a little delay with onboarding new peer-tutors this year, but Charles Parker will be available starting November 17th to support folks with biostatistics!\nUnlike TAs, tutors are not closely associated with any particular course sections or professors, nor do they have any grading responsibilities. Consider meeting with a tutor when you feel stuck on a project, need help with R coding, want to review course concepts, or simply complete assignments in a social learning environment. There is no cost to use tutoring. ​\nCharles is looking forward to working with you in a one-to-one or group setting, depending on your needs. Starting November 17th, you will be able to schedule to meet with them. \nYou can contact the Academic Success Center with questions learningsupport@ohsu.edu.​"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance_key_info.html#announcements",
    "href": "lessons/14_Variance/14_Variance_key_info.html#announcements",
    "title": "Key Info and Announcements",
    "section": "",
    "text": "Homework 5\n\nCharles said it looks good! Impressed with everyone’s work on questions 3 and 4!\n\nQuestion for today’s exit ticket\n\nHow would you feel if we cancelled class on 12/1 and covered MGFs only in one class?\n\nMain reason I cover MGFs is to prepare you for the next course (BSSTA 551), but I talked to Jessica and she does not think they are needed for her class…\n\n\n\n\n\nWe have had a little delay with onboarding new peer-tutors this year, but Charles Parker will be available starting November 17th to support folks with biostatistics!\nUnlike TAs, tutors are not closely associated with any particular course sections or professors, nor do they have any grading responsibilities. Consider meeting with a tutor when you feel stuck on a project, need help with R coding, want to review course concepts, or simply complete assignments in a social learning environment. There is no cost to use tutoring. ​\nCharles is looking forward to working with you in a one-to-one or group setting, depending on your needs. Starting November 17th, you will be able to schedule to meet with them. \nYou can contact the Academic Success Center with questions learningsupport@ohsu.edu.​"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance_key_info.html#key-dates",
    "href": "lessons/14_Variance/14_Variance_key_info.html#key-dates",
    "title": "Key Info and Announcements",
    "section": "Key Dates",
    "text": "Key Dates\n\nHomework 6 due 11/16\nHomework 7 due 11/23"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs_key_info.html",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "We will finish up the example from last class\nNo class on 12/1\n\nMajority voted for no class on 12/1\nVote 7 to 4\n\nBiostatistics tutoring starts today\n\nSchedule a meeting here\nOr email Charles directly"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs_key_info.html#announcements",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "We will finish up the example from last class\nNo class on 12/1\n\nMajority voted for no class on 12/1\nVote 7 to 4\n\nBiostatistics tutoring starts today\n\nSchedule a meeting here\nOr email Charles directly"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs_key_info.html#key-dates",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 7 dues Sunday 11/23\nQuiz 3 opens 12/3\nHW 8 due 12/7"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs_muddy_points.html",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Haha, so true. Hopefully more examples next class will be helpful.\n\n\n\nYes, it gets tricky especially when \\(X\\) can take infinite values. The good news is these are all very common random variables and there are many videos that go through the proofs.\nFor example, here is one from Khan Academy on the geometric distribution."
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "",
    "text": "Distinguish between Bernoulli, Binomial, Geometric, Hypergeometric, Discrete Uniform, Negative Binomial, and Poisson distributions when reading a world problem.\nIdentify the variable and the parameters in a world problem, and state what the variable and parameters mean.\nUse the formulas for the pmf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#learning-objectives",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#learning-objectives",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDistinguish between Bernoulli, Binomial, Geometric, Hypergeometric, Discrete Uniform, Negative Binomial, and Poisson distributions when reading a world problem.\nIdentify the variable and the parameters in a world problem, and state what the variable and parameters mean.\nUse the formulas for the pmf/CDF, expected value, and variance to answer questions and find probabilities."
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#where-are-we",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#where-are-we",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#properties-of-bernoulli-rvs",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#properties-of-bernoulli-rvs",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Properties of Bernoulli RVs",
    "text": "Properties of Bernoulli RVs\n\nScenario: One trial, with outcome success or failure\nShorthand: \\(X \\sim \\text{Bernoulli}(p)\\)\n\n\\[\nX = \\left\\{\n        \\begin{array}{ll}\n            1 & \\quad \\mathrm{with\\ probability}\\ p \\quad \\\\\n            0 & \\quad \\mathrm{with\\ probability}\\ 1-p \\quad\n        \\end{array}\n    \\right.\n\\]\n\\[\np_X(x) = P(X=x) = p^x(1-p)^{1-x} \\text{ for } x=0,1\n\\]\n\\[\\text{E}(X) = p\\]\n\\[\\text{Var}(X) = pq = p(1-p)\\]"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#bernoulli-example-1",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#bernoulli-example-1",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Bernoulli Example 1",
    "text": "Bernoulli Example 1\n\n\n\n\nExample 1\n\n\n\nWe roll a fair 6-sided die.\nWe get $1 if we roll a 5, and nothing otherwise.\nLet \\(X\\) be how much money we get.\nFind the mean and variance of \\(X\\)."
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#properties-of-binomial-rvs",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#properties-of-binomial-rvs",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Properties of Binomial RVs",
    "text": "Properties of Binomial RVs\n\nScenario: There are \\(n\\) independent trials, each resulting in a success or failure, with constant probability, \\(p\\), in each trial. We are counting the number of successes (or failures).\nShorthand: \\(X \\sim \\text{Binomial}(n, p)\\)\n\n\\[\nX = \\text{Number of successes of } n \\text{ independent trials}\n\\]\n\\[\np_X(x) = P(X=x) = {n \\choose x}p^x(1-p)^{n-x} \\text{ for } x=0,1,2,  ..., n\n\\]\n\\[\\text{E}(X) = np\\] \\[\\text{Var}(X) = npq = np(1-p)\\]"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#our-beloved-fair-sided-die",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#our-beloved-fair-sided-die",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Our beloved fair-sided die",
    "text": "Our beloved fair-sided die\n\n\n\n\nExample 2\n\n\n\nSuppose we roll a fair 6-sided die 50 times.\nWe get $1 every time we roll a 5, and nothing otherwise.\nLet \\(X\\) be how much money we get on the 50 rolls.\nFind the mean and variance of \\(X\\)."
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#geometric-rvs",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#geometric-rvs",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Geometric RVs",
    "text": "Geometric RVs\n\nScenario: There are repeated independent trials, each resulting in a success or failure, with constant probability of success for each trial. We are counting the number of trials until the first success.\nShorthand: \\(X \\sim \\text{Geo}(p)\\) or \\(X \\sim \\text{Geometric}(p)\\) or \\(X \\sim \\text{G}(p)\\)\n\n\n\n\n\n\n\n\n\\(X =\\) Number of trials needed for first success (count \\(x\\) includes the success)\n\\(X =\\) Number of failures before first success (count \\(x\\) does not include the success)\n\n\n\n\n$p _\nX( x ) = P(X=x) = (1-p)^{x-1}p$\nfor \\(x=1,2, 3,...\\)\n$$F_ X ( x\n) = P(Xx) = 1-(1-p)^x$$\nfor \\(x=1,2, 3,...\\)\n$ p _X (x)= P(X=x) = (1-p)^{x}p$\nfor \\(x=0, 1,2,...\\)\n$$F_X ( x )\n= P(Xx) = 1-(1-p)^{x+1}$$\nfor \\(x=0, 1,2,...\\)\n\n\n\\(E(X)=\\dfrac{1}{p}\\)\n\\(Var(X)= \\dfrac{1-p}{p^2}\\)\n\\(E(X)=\\dfrac{1-p}{p}\\)\n\\(Var(X) = \\dfrac{1-p}{p^2}\\)"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#bullseye-14",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#bullseye-14",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Bullseye (1/4)",
    "text": "Bullseye (1/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the pmf for the number of throws needed to hit the bullseye?\nWhat are the mean and variance for the number of throws needed to hit the bullseye?\nFind the probability that our first bullseye:\n\nis on one of the first fifty tries\nis after the \\(50^{th}\\) try, given that it did not happen on the first 20 tries"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#bullseye-24",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#bullseye-24",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Bullseye (2/4)",
    "text": "Bullseye (2/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the pmf for the number of throws needed to hit the bullseye?"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#bullseye-34",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#bullseye-34",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Bullseye (3/4)",
    "text": "Bullseye (3/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat are the mean and variance for the number of throws needed to hit the bullseye?"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#bullseye-44",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#bullseye-44",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Bullseye (4/4)",
    "text": "Bullseye (4/4)\n\n\n\n\nExample 3\n\n\nWe throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nFind the probability that our first bullseye:\n\nis on one of the first fifty tries\nis after the \\(50^{th}\\) try, given that it did not happen on the first 20 tries"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#memoryless-property-for-geometric-rvs",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#memoryless-property-for-geometric-rvs",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Memoryless property for Geometric RVs",
    "text": "Memoryless property for Geometric RVs\nIf we know \\(X\\) is greater than some number (aka given \\(X &gt;j\\)), then the probability of \\(X &gt; k+j\\) is just the probability that \\(X&gt;k\\).\n \n\\(P(X &gt; k+j |X &gt; j) = P(X &gt; k)\\)\n\\[ P(X &gt; k+j |X &gt; j) = \\dfrac{P(X&gt;k+j \\text{ and } X&gt;j)}{P(X&gt;j)} = \\dfrac{P(X&gt;k+j)}{P(X&gt;j)} = \\dfrac{(1-p)^{k+j}}{(1-p)^{j}} = (1-p)^{k} \\]"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#properties-of-negative-binomial-rvs",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#properties-of-negative-binomial-rvs",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Properties of Negative Binomial RVs",
    "text": "Properties of Negative Binomial RVs\n\nScenario: There are repeated independent trials, each resulting in a success or failure, with constant probability of success for each trial. We are counting the number of trials until the \\(r^{th}\\) success.\nShorthand: \\(X \\sim \\text{NegBin}(p, r)\\) or \\(X \\sim \\text{NB}(p, r)\\)\nNegative binomial is sum of \\(r\\) geometric distributions\n\n\\[\nX = \\text{Number of independent trials until } r^{th} \\text{ success}\n\\]\n\\[ p_X(x) = P(X=x) = {x-1 \\choose r-1}(1-p)^{x-r}p^r \\text{ for } x = r, r+1, r+2, ...\\]\n\\[ E(X) = \\dfrac{r}{p}\\]\n\\[Var(X) = \\dfrac{rq}{p^2} = \\dfrac{r(1-p)}{p^2}\\]"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#hitting-more-than-1-bullseye",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#hitting-more-than-1-bullseye",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Hitting more than 1 bullseye",
    "text": "Hitting more than 1 bullseye\n\n\n\n\nExample 1\n\n\nConsider again the bullseye example, where we throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the expected value and variance of the number of throws needed to hit 5 bullseyes?"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#hitting-more-than-1-bullseye-1",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#hitting-more-than-1-bullseye-1",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Hitting more than 1 bullseye",
    "text": "Hitting more than 1 bullseye\n\n\n\n\nExample 1\n\n\nConsider again the bullseye example, where we throw darts at a dartboard until we hit the bullseye. Assume throws are independent and the probability of hitting the bullseye is 0.01 for each throw.\n\nWhat is the probability that the \\(5^{th}\\) bullseye is on the \\(20^{th}\\) throw?"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#properties-of-poisson-rvs",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#properties-of-poisson-rvs",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Properties of Poisson RVs",
    "text": "Properties of Poisson RVs\n\nScenario: We are counting the number of successes in a fixed time period (or fixed space), which has a constant rate (\\(\\lambda\\)) of successes\nShorthand: \\(X \\sim \\text{Poisson}(\\lambda)\\) or \\(X \\sim \\text{Pois}(\\lambda)\\)\n\n\\[\nX = \\text{Number of successes in a given period}\n\\]\n\\[ p_X(x) = P(X=x) = \\dfrac{e^{-\\lambda}\\lambda^x}{x!} \\text{ for } x = 0, 1, 2,3, ...\\]\n\\[ \\text{E}(X) = \\lambda\\]\n\\[\\text{Var}(X) = \\lambda\\]"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#distinguishing-between-binomial-and-poisson-rvs",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#distinguishing-between-binomial-and-poisson-rvs",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Distinguishing between Binomial and Poisson RVs",
    "text": "Distinguishing between Binomial and Poisson RVs\n\nRecall that if \\(X\\sim \\text{Binomial}(n,p)\\), then\n\n\\(X\\) models the number of successes …\nin \\(n\\) independent (Bernoulli) trials …\nthat each have the same probability of success \\(p\\).\n\nPoisson RV’s are similar,\n\nexcept that instead of having \\(n\\) discrete independent trials,\nthere is a fixed time period (or space) during which the successes happen"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#examples-of-poisson-rvs",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#examples-of-poisson-rvs",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Examples of Poisson RVs",
    "text": "Examples of Poisson RVs\n\nNumber of visitors to an emergency room in an hour during a weekend night\nNumber of study participants enrolled in a study per week\nNumber of pedestrians walking through a square mile\nAny more?"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#emergency-room-visitors",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#emergency-room-visitors",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Emergency Room Visitors",
    "text": "Emergency Room Visitors\n\n\n\n\nExample 1\n\n\nSuppose an emergency room has an average of 50 visitors per day. Find the following probabilities.\n\nProbability of 30 visitors in a day.\nProbability of 8 visitors in an hour.\nProbability of at least 8 visitors in an hour."
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#combining-independent-poisson-distributions",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#combining-independent-poisson-distributions",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Combining independent Poisson distributions",
    "text": "Combining independent Poisson distributions\n\n\nTheorem 1\n\n\nIf \\(X\\sim Pois(\\lambda_1)\\) and \\(Y\\sim Pois(\\lambda_2)\\) are independent of each other, then \\(Z=X+Y\\sim Pois(\\lambda_1 + \\lambda_2)\\)."
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#two-emergency-rooms",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#two-emergency-rooms",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Two emergency rooms",
    "text": "Two emergency rooms\n\n\n\n\nExample 2\n\n\nSuppose emergency room 1 has an average of 50 visitors per day, and emergency room 2 has an average of 70 visitors per day, independently of each other. What is the probability distribution to model of the total number of visitors to both?"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#poisson-approximation-of-the-binomial",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#poisson-approximation-of-the-binomial",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Poisson Approximation of the Binomial",
    "text": "Poisson Approximation of the Binomial\nBoth Poisson and Binomial RV’s are counting the number of successes\n\nIf for a Binomial RV\n\nthe number of trials \\(n\\) is very large, and\nthe probability of success \\(p\\) is close to 0 or 1,\n\nThen the Poisson distribution can be used to approximate Binomial probabilities\n\nand we use \\(\\lambda = np\\)\n\nRule of thumb: We can use the Poisson approximation when \\(\\dfrac{1}{10} \\leq np(1-p) \\leq 10\\)"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#medical-lab-errors",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#medical-lab-errors",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Medical lab errors",
    "text": "Medical lab errors\n\n\n\n\nExample 3\n\n\nSuppose that in the long run, errors in a medical testing lab are made 0.1% of the time. Find the probability that fewer than 4 mistakes are made in the next 2,000 tests.\n\nFind the probability using the Binomial distribution.\nApproximate the probability in part (1) using the Poisson distribution.\n\n\n\n\nTo do for extra practice - will also see a similar problem in BSTA 511"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#hypergeometric-rvs",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#hypergeometric-rvs",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Hypergeometric RVs",
    "text": "Hypergeometric RVs\n\nScenario: There are a fixed number of successes and failures (which are known in advance), from which we make \\(n\\) draws without replacement. We are counting the number of successes from the \\(n\\) trials.\n\nThere is a finite population of \\(N\\) items\nEach item in the population is either a success or a failure, and there are \\(M\\) successes total.\nWe randomly select (sample) \\(n\\) items from the population without replacement\n\nShorthand: \\(X \\sim \\text{Hypergeo}(M, N, n)\\)\n\n\n\n\\[\nX = \\text{Number of successes in } n \\text{ draws}\n\\]\n\\[\np_X(x) = P(X=x) = \\dfrac{{M \\choose x}{N-M \\choose n-x}}{{N \\choose n}}\n\\] \\[\\text{ for } x \\text{ integer-valued } \\\\ \\max(0, n-(N-M)) \\leq x \\leq \\min(n, M)\\]\n\n\\[\\text{E}(X) =\\dfrac{nM}{N}\\]\n\\[\\text{Var}(X) = n \\dfrac{M}{N} \\bigg(1- \\dfrac{M}{N} \\bigg)\\bigg(\\dfrac{N-n}{N-1} \\bigg)\\]"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#wolf-population",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#wolf-population",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Wolf population",
    "text": "Wolf population\n\n\n\n\nExample 4\n\n\nA wildlife biologist is using mark-recapture to research a wolf population. Suppose a specific study region is known to have 24 wolves, of which 11 have already been tagged. If 5 wolves are randomly captured, what is the probability that 3 of them have already been tagged?"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#binomial-approximation-of-the-hypergeometric-rv",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#binomial-approximation-of-the-hypergeometric-rv",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Binomial approximation of the hypergeometric RV",
    "text": "Binomial approximation of the hypergeometric RV\nSuppose a hypergeometric RV \\(X\\) has the following properties:\n\nthe population size \\(N\\) is really big,\nthe number of successes \\(M\\) in the population is relatively large,\n\n\\(\\frac{M}{N}\\) shouldn’t be close to 0 or 1\n\nand the number of items \\(n\\) selected is small\nRule of thumb: \\(\\dfrac{n}{N}&lt;0.05\\) or \\(N&gt;20n\\)\n\nThen, in this case, making \\(n\\) draws from the population doesn’t change the probability of success much, and the hypergeometric RV. can be approximated by a binomial RV"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#wolf-population-revisited",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#wolf-population-revisited",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Wolf population revisited",
    "text": "Wolf population revisited\n\n\n\n\nExample 5\n\n\nSuppose a specific study region is known to have 2400 wolves, of which 1100 have already been tagged.\n\nIf 50 wolves are randomly captured, what is the probability that 20 of them have already been tagged?\nApproximate the probability in part (1) using the binomial distribution."
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#discrete-uniform-rvs",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#discrete-uniform-rvs",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "Discrete Uniform RVs",
    "text": "Discrete Uniform RVs\n\nScenario: There are \\(N\\) possible outcomes, which are all equally likely.\nShorthand: \\(X \\sim \\text{Uniform}(N)\\)\n\n\\[\nX = \\text{Outcome of interest, with } x=1, 2, ..., N\n\\]\n\\[\np_X(x) = P(X=x) = \\dfrac{1}{N} \\text{ for } x=1, 2, 3, ..., N\n\\]\n\\[\\text{E}(X) =\\dfrac{N+1}{2}\\]\n\\[\\text{Var}(X) = \\dfrac{N^2 -1}{12}\\]"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#what-discrete-uniform-rvs-have-we-seen-already",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#what-discrete-uniform-rvs-have-we-seen-already",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "What discrete uniform RVs have we seen already?",
    "text": "What discrete uniform RVs have we seen already?\n\n\n\n\nExample 6\n\n\nExamples of discrete uniform RVs"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance_muddy_points.html",
    "href": "lessons/14_Variance/14_Variance_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "You are right, the hotel room problem did not need the identical distributions in either class. I definitely mispoke by saying they were iid. Even though they have the same expected value and variance, they are not necessarily from the same distribution. They are independent, but not necessarily identically distributed. They all have the same variance, so I can still use \\[\\sum_{i=1}^{30} Var(X_i) = 30Var(X)\\]\nIt was more that, last class, we did not specify the standard deviation. We could find the expected value of the total cost without knowing the standard deviation, and thus without necessarily assuming the cost of the hotel rooms were identical random variables. In this class, we needed the standard deviation for the cost of each hotel room. We could have made them different, but we made all of them $10.\n\n\n\nI go through that breakdown in the first muddy point from Fall 2023 (below). Check out the term 2 part that is highlighted in green-ish.\n\n\n\nHere are the corollaries:\n\n\nCorollary 2\n\n\nFor independent RV’s \\(X_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n X_i\\Bigg) = \\sum_{i=1}^n Var(X_i).\\]\n\n\n\n\nCorollary 3\n\n\nFor independent identically distributed (i.i.d.) RV’s \\(X_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n X_i\\Bigg) = n Var(X_1).\\]\n\n\nIn Corollary 2, the variance can be different for each \\(X_i\\) so we need to sum each together. In Corollary 3, the variance is the same for each \\(X_i\\) so we can recognize that we will have \\(n\\) identical terms to sum together."
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs_key_info.html",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "We will finish up the example from last class\nNo class on 11/26 and 12/1\nBiostatistics tutoring starts today\n\nSchedule a meeting here\nOr email Charles directly\n\nHomework 6\n\nLooks pretty good!\nPlease attempt all problems! This is how you get practice."
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs_key_info.html#announcements",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "We will finish up the example from last class\nNo class on 11/26 and 12/1\nBiostatistics tutoring starts today\n\nSchedule a meeting here\nOr email Charles directly\n\nHomework 6\n\nLooks pretty good!\nPlease attempt all problems! This is how you get practice."
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs_key_info.html#key-dates",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 7 due Sunday 11/23\nQuiz 3 opens 12/3\nHW 8 due 12/7"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#where-are-we",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#where-are-we",
    "title": "Lesson 11: Joint distributions",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#what-is-a-joint-distribution",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#what-is-a-joint-distribution",
    "title": "Lesson 11: Joint distributions",
    "section": "What is a joint distribution?",
    "text": "What is a joint distribution?\n\n\n\n\nDefinition: joint pmf\n\n\nThe joint pmf of a pair of discrete RV’s \\(X\\) and \\(Y\\) is \\[\\begin{aligned}\np_{X,Y}(x,y) = & \\mathbb{P}(X=x \\cap Y=y) \\\\ = & \\mathbb{P}(X=x, Y=y)\n\\end{aligned}\\]\n\n\n\n\n\nDefinition: joint pdf\n\n\nThe joint pdf for two continuous RVs (\\(X\\) and \\(Y\\)) is \\(f_{X,Y}(x,y)\\), such that we have the following joint probability: \\[\\begin{aligned}\n\\mathbb{P}(a \\leq X \\leq b, & c \\leq Y \\leq d) = \\\\ & \\int_a^b \\int_c^d f_{X,Y}(x,y)dydx\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#important-properties-of-joint-distributions",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#important-properties-of-joint-distributions",
    "title": "Lesson 11: Joint distributions",
    "section": "Important properties of joint distributions",
    "text": "Important properties of joint distributions\n\n\n\n\nProperties of joint pmf’s\n\n\n\nA joint pmf \\(p_{X,Y}(x,y)\\) must satisfy the following properties:\n\n\\(0 \\geq p_{X,Y}(x,y) \\leq 1\\) for all \\(x, y\\)\n\n \n\n\\(\\sum \\limits_{\\{all\\ x\\}} \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)=1\\)\n\n\n\n\n\n\n\nProperties of joint pdf’s\n\n\n\nA joint pdf \\(f_{X,Y}(x,y)\\) must satisfy the following properties:\n\n\\(f_{X,Y}(x,y)\\geq 0\\) for all \\(x,y\\)\n\n \n\n\\(\\displaystyle\\int_{-\\infty}^{\\infty}\\displaystyle\\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dxdy=1\\)\n\n\n \n\nRemember that \\(f_{X,Y}(x,y)\\neq \\mathbb{P}(X=x, Y=y)\\)!!!"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#marginal-distributions",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#marginal-distributions",
    "title": "Lesson 11: Joint distributions",
    "section": "Marginal distributions",
    "text": "Marginal distributions\n\n\n\n\nMarginal pmf’s\n\n\nSuppose \\(X\\) and \\(Y\\) are discrete RV’s, with joint pmf \\(p_{X,Y}(x,y)\\). Then the marginal probability mass functions are\n\\[p_X(x) = \\sum \\limits_{\\{all\\ y\\}} p_{X,Y}(x,y)\\]\n\\[p_Y(y) = \\sum \\limits_{\\{all\\ x\\}} p_{X,Y}(x,y)\\]\n\n\n\n\n\nMarginal pdf’s\n\n\nSuppose \\(X\\) and \\(Y\\) are continuous RV’s, with joint pdf \\(f_{X,Y}(x,y)\\). Then the marginal probability density functions are \\[\\begin{aligned}\nf_X(x)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dy\\\\\nf_Y(y)&=& \\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)dx\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#joint-cumulative-distribution-functions-cdfs",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#joint-cumulative-distribution-functions-cdfs",
    "title": "Lesson 11: Joint distributions",
    "section": "Joint cumulative distribution functions (CDFs)",
    "text": "Joint cumulative distribution functions (CDFs)\n\n\n\n\nJoint CDF for discrete RVs\n\n\nThe joint CDF of a pair of discrete RV’s \\(X\\) and \\(Y\\) is \\[\\begin{aligned}\nF_{X,Y}(x,y) = &\\mathbb{P}(X \\leq x\\ and\\ Y \\leq y) \\\\ = &\\mathbb{P}(X \\leq x, Y \\leq y)\n\\end{aligned}\\]\n\n\n\n\n\nJoint CDF for continuous RVs\n\n\nThe joint CDF of continuous random variables \\(X\\) and \\(Y\\), is the function \\(F_{X,Y}(x,y)\\), such that for all real values of \\(x\\) and \\(y\\), \\[\\begin{aligned}\nF_{X,Y}(x,y)= \\mathbb{P}(X \\leq x, & Y \\leq y) = \\\\\n& \\int_{-\\infty}^x\\int_{-\\infty}^y f_{X,Y}(s,t)dtds\n\\end{aligned}\\]"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#joint-distribution-for-two-discrete-random-variables-15",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#joint-distribution-for-two-discrete-random-variables-15",
    "title": "Lesson 11: Joint distributions",
    "section": "Joint distribution for two discrete random variables (1/5)",
    "text": "Joint distribution for two discrete random variables (1/5)\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\)\nFind \\(\\mathbb{P}(X+Y=3)\\)\nFind \\(\\mathbb{P}(Y = 1)\\)\nFind \\(\\mathbb{P}(Y \\leq 2)\\)\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#joint-distribution-for-two-discrete-random-variables-25",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#joint-distribution-for-two-discrete-random-variables-25",
    "title": "Lesson 11: Joint distributions",
    "section": "Joint distribution for two discrete random variables (2/5)",
    "text": "Joint distribution for two discrete random variables (2/5)\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(p_{X,Y}(x,y)\\)\nFind \\(\\mathbb{P}(X+Y=3)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#joint-distribution-for-two-discrete-random-variables-35",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#joint-distribution-for-two-discrete-random-variables-35",
    "title": "Lesson 11: Joint distributions",
    "section": "Joint distribution for two discrete random variables (3/5)",
    "text": "Joint distribution for two discrete random variables (3/5)\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind \\(\\mathbb{P}(Y = 1)\\)\nFind \\(\\mathbb{P}(Y \\leq 2)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#joint-distribution-for-two-discrete-random-variables-45",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#joint-distribution-for-two-discrete-random-variables-45",
    "title": "Lesson 11: Joint distributions",
    "section": "Joint distribution for two discrete random variables (4/5)",
    "text": "Joint distribution for two discrete random variables (4/5)\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the joint CDF \\(F_{X,Y}(x,y)\\) for the joint pmf \\(p_{X,Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#joint-distribution-for-two-discrete-random-variables-55",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#joint-distribution-for-two-discrete-random-variables-55",
    "title": "Lesson 11: Joint distributions",
    "section": "Joint distribution for two discrete random variables (5/5)",
    "text": "Joint distribution for two discrete random variables (5/5)\n\n\n\n\nExample 1\n\n\nLet \\(X\\) and \\(Y\\) be two random draws from a box containing balls labelled 1, 2, and 3 without replacement.\n\nFind the marginal CDFs \\(F_{X}(x)\\) and \\(F_{Y}(y)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#quick-remarks-on-the-joint-and-marginal-cdf",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#quick-remarks-on-the-joint-and-marginal-cdf",
    "title": "Lesson 11: Joint distributions",
    "section": "Quick remarks on the joint and marginal CDF",
    "text": "Quick remarks on the joint and marginal CDF\n\n\\(F_X(x)\\): right most columns of the CDF table (where the \\(Y\\) values are largest)\n\\(F_Y(y)\\): bottom row of the table (where X values are largest)\n\\(F_X(x)=\\lim\\limits_{y\\rightarrow\\infty}F_{X, Y}(x,y)\\)\n\\(F_Y(y)=\\lim\\limits_{x\\rightarrow\\infty}F_{X, Y}(x,y)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#common-steps-for-joint-pdfs-and-cdfs",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#common-steps-for-joint-pdfs-and-cdfs",
    "title": "Lesson 11: Joint distributions",
    "section": "Common steps for joint pdfs and CDFs",
    "text": "Common steps for joint pdfs and CDFs\n\nSet up the domain of the pdf with a picture\n\n \n\nTranslate to needed integrands\n\nFor probability: shade in the area of interest, then translate\nFor expected value: translate domain\n\n\n \n\nSet up integral: \\(dxdy\\) or \\(dydx\\)?\n\n \n\nSolve integral!"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#example-2-joint-pdf-12",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#example-2-joint-pdf-12",
    "title": "Lesson 11: Joint distributions",
    "section": "Example 2: Joint pdf (1/2)",
    "text": "Example 2: Joint pdf (1/2)\n\n\n\n\nExample 2.1\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(\\mathbb{P}(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac12)\\)\n\n\n\n\nlibrary(tidyverse)\njoint1 = tibble(\n  x = seq(0, 2, 0.01), \n  y = seq(0, 1, 0.005)\n)\n\nx_y_plot1 = ggplot(joint1, aes(x = x, y = y)) +\n  labs(x = \"x\", y = \"y\") +\n  scale_x_continuous(breaks = c(0, 1, 2)) +\n  scale_y_continuous(breaks = c(0, 0.5, 1)) +\n  theme_bw() +\n  theme(text = element_text(size=30))\nx_y_plot1"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#example-2-joint-pdf-22",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#example-2-joint-pdf-22",
    "title": "Lesson 11: Joint distributions",
    "section": "Example 2: Joint pdf (2/2)",
    "text": "Example 2: Joint pdf (2/2)\n\n\n\n\nExample 2.2\n\n\nLet \\(f_{X,Y}(x,y)= \\frac32 y^2\\), for \\(0 \\leq x \\leq 2, \\ 0 \\leq y \\leq 1\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\).\n\n\n\n\nx_y_plot1"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#example-with-more-complicated-pdf-12",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#example-with-more-complicated-pdf-12",
    "title": "Lesson 11: Joint distributions",
    "section": "Example with more complicated pdf (1/2)",
    "text": "Example with more complicated pdf (1/2)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 3.1\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(f_X(x)\\) and \\(f_Y(y)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#example-with-more-complicated-pdf-22",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#example-with-more-complicated-pdf-22",
    "title": "Lesson 11: Joint distributions",
    "section": "Example with more complicated pdf (2/2)",
    "text": "Example with more complicated pdf (2/2)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nExample 3.2\n\n\nLet \\(f_{X,Y}(x,y)= 2 e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\).\n\nFind \\(\\mathbb{P}(Y &lt; 3)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#recall-finding-the-pdf-of-a-transformation",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#recall-finding-the-pdf-of-a-transformation",
    "title": "Lesson 11: Joint distributions",
    "section": "",
    "text": "Let \\(M\\) be a transformation of \\(X\\) and \\(Y\\): \\(M = g(X, Y)\\)\nWhen we have a transformation of \\(X\\) and \\(Y\\), \\(M\\), we need to follow the CDF method to find the pdf of \\(M\\)\n\nWe follow CDF method:\n\nStart with the joint pdf for \\(X\\) and \\(Y\\)\n\naka \\(f_{X,Y}(x, y)\\)\n\nTranslate the domain of \\(X\\) and \\(Y\\) to \\(M\\): find possible values of \\(M\\)\nFind the CDF of \\(M\\)\n\naka \\(F_M(m) = P(M \\leq m) = P(g(X, Y) \\leq m)\\)\n\nTake the derivative of the CDF of \\(M\\) with respect to \\(m\\) to find the pdf of \\(M\\)\n\naka \\(f_M(m) = \\dfrac{d}{dm}F_M(m)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#example-of-a-joint-pdf-with-a-transformation-12",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#example-of-a-joint-pdf-with-a-transformation-12",
    "title": "Lesson 11: Joint distributions",
    "section": "Example of a joint pdf with a transformation (1/2)",
    "text": "Example of a joint pdf with a transformation (1/2)\n\n\n\n\nExample 4.1\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nFind \\(\\mathbb{P}(|X-Y| &lt; 2)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#example-of-a-joint-pdf-with-a-transformation-12-1",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#example-of-a-joint-pdf-with-a-transformation-12-1",
    "title": "Lesson 11: Joint distributions",
    "section": "Example of a joint pdf with a transformation (1/2)",
    "text": "Example of a joint pdf with a transformation (1/2)\n\n\n\n\nExample 4.2\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(M = \\max(X,Y)\\). Find the pdf for \\(M\\), that is \\(f_M(m)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#example-of-a-joint-pdf-with-a-transformation-12-2",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#example-of-a-joint-pdf-with-a-transformation-12-2",
    "title": "Lesson 11: Joint distributions",
    "section": "Example of a joint pdf with a transformation (1/2)",
    "text": "Example of a joint pdf with a transformation (1/2)\n\n\n\n\nExample 4.3\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(Z = \\min(X,Y)\\). Find the pdf for \\(Z\\), that is \\(f_Z(z)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#last-example-for-home-more-complicated-transformation",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#last-example-for-home-more-complicated-transformation",
    "title": "Lesson 11: Joint distributions",
    "section": "Last example for home: more complicated transformation",
    "text": "Last example for home: more complicated transformation\n\n\n\n\nExample 5\n\n\nLet \\(X\\) and \\(Y\\) have joint density \\(f_{X,Y}(x,y)= \\frac85(x+y)\\) in the region \\(0 &lt; x &lt; 1,\\ \\frac12 &lt; y &lt;1\\). Find the pdf of the RV \\(Z\\), where \\(Z=XY\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can look at the joint pdf of X and Y:\n\n\n\n\n\n\nAnd let’s look at \\(P(Z \\leq 0.5)\\) aka \\(P(XY \\leq 0.5)\\) to get a better sense of the volume needed:\n\n\n\n\n\n\nNow I want to show the domain for Z:\n\n\n\n\n\n\nNow I want to show the domain for Z:"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#double-integrals-mini-lesson-13",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#double-integrals-mini-lesson-13",
    "title": "Lesson 11: Joint distributions",
    "section": "Double Integrals Mini Lesson (1/3)",
    "text": "Double Integrals Mini Lesson (1/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 1\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} xy dydx\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#double-integrals-mini-lesson-23",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#double-integrals-mini-lesson-23",
    "title": "Lesson 11: Joint distributions",
    "section": "Double Integrals Mini Lesson (2/3)",
    "text": "Double Integrals Mini Lesson (2/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 2\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} (x+y) dydx\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#double-integrals-mini-lesson-33",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#double-integrals-mini-lesson-33",
    "title": "Lesson 11: Joint distributions",
    "section": "Double Integrals Mini Lesson (3/3)",
    "text": "Double Integrals Mini Lesson (3/3)\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!\n\n\n\n\n\n\n\nMini Lesson Example 3\n\n\nSolve the following integral: \\(\\displaystyle\\int_{2}^{3}\\displaystyle\\int_{0}^{1} e^{x+y} dydx\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html",
    "title": "Lesson 11: Joint distributions",
    "section": "",
    "text": "Let \\(M\\) be a transformation of \\(X\\) and \\(Y\\): \\(M = g(X, Y)\\)\nWhen we have a transformation of \\(X\\) and \\(Y\\), \\(M\\), we need to follow the CDF method to find the pdf of \\(M\\)\n\nWe follow CDF method:\n\nStart with the joint pdf for \\(X\\) and \\(Y\\)\n\naka \\(f_{X,Y}(x, y)\\)\n\nTranslate the domain of \\(X\\) and \\(Y\\) to \\(M\\): find possible values of \\(M\\)\nFind the CDF of \\(M\\)\n\naka \\(F_M(m) = P(M \\leq m) = P(g(X, Y) \\leq m)\\)\n\nTake the derivative of the CDF of \\(M\\) with respect to \\(m\\) to find the pdf of \\(M\\)\n\naka \\(f_M(m) = \\dfrac{d}{dm}F_M(m)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-of-a-joint-pdf-with-a-transformation-13",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-of-a-joint-pdf-with-a-transformation-13",
    "title": "Lesson 11: Joint distributions",
    "section": "Example of a joint pdf with a transformation (1/3)",
    "text": "Example of a joint pdf with a transformation (1/3)\n\n\n\n\nExample 4.1\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nFind \\(\\mathbb{P}(|X-Y| &lt; 2)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-of-a-joint-pdf-with-a-transformation-23",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-of-a-joint-pdf-with-a-transformation-23",
    "title": "Lesson 11: Joint distributions",
    "section": "Example of a joint pdf with a transformation (2/3)",
    "text": "Example of a joint pdf with a transformation (2/3)\n\n\n\n\nExample 4.2\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(M = \\max(X,Y)\\). Find the pdf for \\(M\\), that is \\(f_M(m)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-of-a-joint-pdf-with-a-transformation-33",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions.html#example-of-a-joint-pdf-with-a-transformation-33",
    "title": "Lesson 11: Joint distributions",
    "section": "Example of a joint pdf with a transformation (3/3)",
    "text": "Example of a joint pdf with a transformation (3/3)\n\n\n\n\nExample 4.3\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(Z = \\min(X,Y)\\). Find the pdf for \\(Z\\), that is \\(f_Z(z)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo this problem at home for extra practice. I’ll add the solution to the annotated notes!"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#example-of-a-joint-pdf-with-a-transformation-13",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#example-of-a-joint-pdf-with-a-transformation-13",
    "title": "Lesson 11: Joint distributions",
    "section": "Example of a joint pdf with a transformation (1/3)",
    "text": "Example of a joint pdf with a transformation (1/3)\n\n\n\n\nExample 4.1\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nFind \\(\\mathbb{P}(|X-Y| &lt; 2)\\)"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#example-of-a-joint-pdf-with-a-transformation-23",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#example-of-a-joint-pdf-with-a-transformation-23",
    "title": "Lesson 11: Joint distributions",
    "section": "Example of a joint pdf with a transformation (2/3)",
    "text": "Example of a joint pdf with a transformation (2/3)\n\n\nExample 4.2\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(M = \\max(X,Y)\\). Find the pdf for \\(M\\), that is \\(f_M(m)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\nf_{X,Y}(x,y) = \\dfrac{1}{16} \\text{ for } 0 \\leq x \\leq 4, 0 \\leq y \\leq 4\n\\]\nPlot of \\(f_{X,Y}(x,y)\\):\n\n\n\n\n\n\nFor first problem, we want:\n\n\n\n\n\n\nNow I want to show the domain for the max, M:"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#example-of-a-joint-pdf-with-a-transformation-33",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review.html#example-of-a-joint-pdf-with-a-transformation-33",
    "title": "Lesson 11: Joint distributions",
    "section": "Example of a joint pdf with a transformation (3/3)",
    "text": "Example of a joint pdf with a transformation (3/3)\n\n\n\n\nExample 4.3\n\n\nLet \\(X\\) and \\(Y\\) have constant density on the square \\(0 \\leq X \\leq 4, 0 \\leq Y \\leq 4\\).\n\nLet \\(Z = \\min(X,Y)\\). Find the pdf for \\(Z\\), that is \\(f_Z(z)\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review_key_info.html",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Midterm feedback!\n\nDid you fill out the final survey to record your name?\nDislikes/suggestions\n\nTextbook\nWant more R code\npdf lectures posted earlier\nSome in-class work\nSlower on slides + more examples:\n\nI can try to post more completed examples, but ultimately both of these are limited by the content we need to cover and the total lecture time in quarter\n\n\n\nWe will be taking a pause before expected values\n\nFinish conditional pdf problem\nReview joint distributions\n\nHW 4: looked pretty good!\nCome to office hours!\n\nDon’t spend hours on a problem! Charles and I can help you!"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review_key_info.html#announcements",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Midterm feedback!\n\nDid you fill out the final survey to record your name?\nDislikes/suggestions\n\nTextbook\nWant more R code\npdf lectures posted earlier\nSome in-class work\nSlower on slides + more examples:\n\nI can try to post more completed examples, but ultimately both of these are limited by the content we need to cover and the total lecture time in quarter\n\n\n\nWe will be taking a pause before expected values\n\nFinish conditional pdf problem\nReview joint distributions\n\nHW 4: looked pretty good!\nCome to office hours!\n\nDon’t spend hours on a problem! Charles and I can help you!"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_review_key_info.html#key-dates",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_review_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nHW 05 due this Sunday!"
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_muddy_points.html#fall-2025",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_muddy_points.html#fall-2025",
    "title": "Muddy Points",
    "section": "",
    "text": "Yes! \\(M\\) is just a transformation of \\(X\\) and \\(Y\\)! Think of creating a new random variable that is dependent on \\(X\\) and \\(Y\\). We have created a single random variable from two. Then we want to see for the random variable, M, what does its pdf look like?\n\n\n\nYes! If we are going from a joint pdf to a marginal, we can to integrate over one of the random variables. If we want a marginal of X, then we integrate over Y, and that will be a single integral.\nIf we are working with a joint pdf, then we need to have two integrals if we have two random variables.\n\n\n\nI feel that. In general, a transformation (say \\(M\\)) of \\(X\\) and \\(Y\\) will be in the 3rd dimension (3D plot). The joint pdf of \\(X\\) and \\(Y\\) will be in the 3rd dimension (3D plot). But once we have \\(M\\) and its CDF/pdf, those are in 2D plot of \\(M\\) vs. \\(f_M(m)\\)."
  },
  {
    "objectID": "homework/HW_07.html#questions",
    "href": "homework/HW_07.html#questions",
    "title": "Homework 7",
    "section": "Questions",
    "text": "Questions\n\nProve that for a r.v. \\(X\\) and constants \\(a\\) and \\(b\\), that \\[\\mathrm{Var}[aX+b]=a^2\\mathrm{Var}[X].\\]\nLet \\(\\overline{X}\\) be the random variable for the sample mean, \\(\\overline{X}=\\frac{\\sum_{i=1}^nX_i}{n}\\), where the \\(X_i\\) are i.i.d. random variables with common mean \\(\\mu\\) and variance \\(\\sigma^2\\).\n\nFind \\(\\mathbb{E}[\\overline{X}]\\).\nFind \\(Var[\\overline{X}]\\).\n\nLet \\(f_X(x)=\\lambda e^{-\\lambda x}\\) for \\(x&gt;0\\), where \\(\\lambda&gt;0\\).\n\nShow \\(Var[X]=\\frac{1}{\\lambda^2}\\). You may use the result from class for \\(\\mathbb{E}[X]\\) without first proving it.\n\nA shipping company handles containers in three different sizes: (1) 27 \\(ft^3\\) (3 x 3 x 3), (2) 125 \\(ft^3\\), and (3) 512 \\(ft^3\\). Let \\(X_i\\) (\\(i = 1, 2, 3\\)) denote the number of type \\(i\\) containers shipped during a given week. Suppose that \\(\\mu_1 =200,\\sigma_1=10,\\mu_2 =250,\\sigma_2=12,\\mu_3 =100,\\sigma_3=8\\).\n\nAssuming that \\(X_1,X_2,X_3\\) are independent, calculate the expected value and variance of the total volume shipped.\nWould your calculations necessarily be correct if the \\(X_i\\)’s were not independent? Explain.\n\nConsider the joint density of \\(X\\) and \\(Y\\): \\[f_{X,Y}(x,y)= \\dfrac32 x y\\] for \\(0 \\leq x\\) and \\(0 \\leq y\\) and \\(x+y \\leq 2\\) and \\(f_{X,Y}(x,y)=0\\) otherwise. Find \\(E(Y)\\)."
  },
  {
    "objectID": "homework/HW_07.html#extra-problems",
    "href": "homework/HW_07.html#extra-problems",
    "title": "Homework 7",
    "section": "Extra problems",
    "text": "Extra problems\n\nThere is a bowl containing 30 cashews, 20 pecans, 25 almonds, and 25 walnuts. I am going to randomly pick and eat 3 nuts (without replacement). Find the expected value of the number of cashews by defining the number of cashews as a sum of random variables. (This one takes a little while if we don’t rely on the\nLet \\(\\hat{p}\\) be the random variable for the sample proportion, \\(\\hat{p}=\\frac{X}{n}\\), where \\(X\\) is the number of successes in a random sample of size \\(n\\). Assume the probability of success is \\(p\\).\n\nFind \\(\\mathbb{E}[\\hat{p}]\\).\nFind \\(Var[\\hat{p}]\\).\n\nSuppose your waiting time for a bus in the morning is uniformly distributed on [0, 8] (minutes), whereas waiting time in the evening is uniformly distributed on [0, 10] (minutes) independent of morning waiting time. Make sure to FIRST set up an equation for calculating the total waiting time in each question before calculating the mean and variance of the total waiting time. You may use results from class for the expected value and variance of uniform r.v.’s without proving them.\n\nIf you take the bus each morning and evening for a week (7 days), what is your total expected waiting time?\nWhat is the variance of your total waiting time?\nWhat are the expected value and variance of the difference between morning and evening waiting times on a given day?\nWhat are the expected value and variance of the difference between total morning waiting time and total evening waiting time for a particular week?"
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#sums-of-random-variables",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#sums-of-random-variables",
    "title": "Lesson 13: Expected Values",
    "section": "Sums of Random Variables",
    "text": "Sums of Random Variables\n\n\nTheorem: Sum of random variables\n\n\nFor RVs (discrete or continuous) \\(X_i\\) and constants \\(a_i\\), \\(i=1,2,\\dots, n\\), \\[\\mathbb{E}\\Bigg[\\sum_{i=1}^n a_iX_i\\Bigg] = \\sum_{i=1}^n a_i\\mathbb{E}[X_i] .\\] Remark: The theorem holds for infinitely RV’s \\(X_i\\) as well.\n\n\n\nFor two RVs, \\(X\\) and \\(Y\\):\n\nWe can say \\(E[X+Y] = E[X] + E[Y]\\)\n… and constant numbers \\(a\\) and \\(b\\), we can also say \\(E[aX+bY] = aE[X] + bE[Y]\\)\nWe can also also say \\(E[X-Y] = E[X] - E[Y]\\), since \\(b=-1\\)"
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#corollaries-from-theorem",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#corollaries-from-theorem",
    "title": "Lesson 13: Expected Values",
    "section": "Corollaries from Theorem",
    "text": "Corollaries from Theorem\n\n\n\n\nFunction with two constants\n\n\nFor a RV \\(X\\), and constants \\(a\\) and \\(b\\), \\[\\mathbb{E}[aX+b] = a\\mathbb{E}[X] + b.\\]\n\n\n\n\n\nExpected value of sum of identically distributed RVs\n\n\nIf \\(X_i\\), \\(i=1,2,\\dots, n\\), are identically distributed RV’s, then \\[\\mathbb{E}\\bigg[\\sum_{i=1}^n X_i\\bigg] = n\\mathbb{E}[X_1] .\\]"
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#manufacturing-cubes",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#manufacturing-cubes",
    "title": "Lesson 13: Expected Values",
    "section": "Manufacturing cubes",
    "text": "Manufacturing cubes\n\n\n\n\nExample 4\n\n\nA machine manufactures cubes with a side length that varies uniformly from 1 to 2 inches. Assume the sides of the base and height are equal. The cost to make a cube is 10 ¢ per cubic inch, and 5 ¢ cents for the general cost per cube. Find the mean of the cost to make 10 cubes."
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#expected-value-of-one-rv-from-joint-pdf",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#expected-value-of-one-rv-from-joint-pdf",
    "title": "Lesson 13: Expected Values",
    "section": "Expected value of one RV from joint pdf",
    "text": "Expected value of one RV from joint pdf\nIf you have a joint distribution \\(f_{X,Y}(x,y)\\) and want to calculate \\(\\mathbb{E}[X]\\), you have two options:\n\nFind \\(f_X(x)\\) and use it to calculate \\(\\mathbb{E}[X]\\).\nCalculate \\(\\mathbb{E}[X]\\) using the joint density: \\[\\mathbb{E}[X] = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}x f_{X,Y}(x,y)dydx.\\]\n\nYou can do the same for \\(\\mathbb{E}[Y]\\)!"
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values.html#option-1-find-marginal-first",
    "href": "lessons/13_Expected_Values/13_Expected_Values.html#option-1-find-marginal-first",
    "title": "Lesson 13: Expected Values",
    "section": "Option 1: Find marginal first",
    "text": "Option 1: Find marginal first\n\n\n\n\nExample 9\n\n\nLet \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\).\n\n\n\nDo this one at home by finding \\(f_X(x)\\) then \\(\\mathbb{E}[X] = \\displaystyle\\int_{-\\infty}^\\infty xf_X(x) dx\\). See if you get the same result as next page’s answer!"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#where-are-we",
    "href": "lessons/14_Variance/14_Variance.html#where-are-we",
    "title": "Lesson 14: Variance",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#lets-calculate-the-variance-and-prove-it-12",
    "href": "lessons/14_Variance/14_Variance.html#lets-calculate-the-variance-and-prove-it-12",
    "title": "Lesson 14: Variance",
    "section": "Let’s calculate the variance and prove it! (1/2)",
    "text": "Let’s calculate the variance and prove it! (1/2)\n\n\n\n\nLemma 6: “Computation formula” for Variance\n\n\nThe variance of a RV \\(X\\), can be computed as \\[\\begin{align}\n\\sigma_X^2 & =Var(X) \\\\ & = \\mathbb{E}[X^2]-\\mu_X^2 \\\\ & = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2\n\\end{align}\\]"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#lets-calculate-the-variance-and-prove-it-22",
    "href": "lessons/14_Variance/14_Variance.html#lets-calculate-the-variance-and-prove-it-22",
    "title": "Lesson 14: Variance",
    "section": "Let’s calculate the variance and prove it! (2/2)",
    "text": "Let’s calculate the variance and prove it! (2/2)"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#variance-of-discrete-and-continuous-rvs",
    "href": "lessons/14_Variance/14_Variance.html#variance-of-discrete-and-continuous-rvs",
    "title": "Lesson 14: Variance",
    "section": "Variance of discrete and continuous RVs",
    "text": "Variance of discrete and continuous RVs\n\n\nHow do we calculate the variance of a discrete RV?\n   \nFor discrete RVs:\n\\[\n\\begin{align}\nVar(X) & = \\\\ & = \\sum_{\\{all\\ x\\}}(x-\\mu_x)^2 p_{X}(x) \\\\ & =\n\\mathbb{E}[(X-\\mu_X)^2] \\\\ & = \\mathbb{E}[(X-\\mathbb{E}[X])^2] \\\\ &= \\mathbb{E}[X^2]-(\\mathbb{E}[X])^2\n\\end{align}\n\\]\n\n\n\nHow do we calculate the variance of a continuous RV?\n    \nFor continuous RVs:\n\\[\n\\begin{align}\nVar(X) & =\n\\displaystyle\\int_{-\\infty}^\\infty (x-\\mu_X)^2f_X(x) dx \\\\ & = \\mathbb{E}[(X-\\mu_X)^2] \\\\ & = \\mathbb{E}[(X-\\mathbb{E}[X])^2] \\\\ &= \\mathbb{E}[X^2]-(\\mathbb{E}[X])^2 \\end{align}\n\\]"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#ghost-problem-with-replacement",
    "href": "lessons/14_Variance/14_Variance.html#ghost-problem-with-replacement",
    "title": "Lesson 14: Variance",
    "section": "Ghost problem: with replacement",
    "text": "Ghost problem: with replacement\n\n\n\n\nExample 3.2\n\n\nThe ghost is trick-or-treating at a different house now. In this case it is known that the bag of candy has 10 chocolates, 20 lollipops, and 30 laffy taffies. The ghost grabs a handful of five pieces of candy. What is the variance for the number of chocolates the ghost takes? Let’s solve this for the cases with replacement.\n\n\n\n\nRecall probability with replacement:\n\\[\np_X(x) = {n \\choose k}p^k(1-p)^{n-k}\n\\]"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#back-to-our-hotel-example-from-lesson-13",
    "href": "lessons/14_Variance/14_Variance.html#back-to-our-hotel-example-from-lesson-13",
    "title": "Lesson 14: Variance",
    "section": "Back to our hotel example from Lesson 13",
    "text": "Back to our hotel example from Lesson 13\n\n\n\n\nExample 4\n\n\nA tour group is planning a visit to the city of Minneapolis and needs to book 30 hotel rooms. The average price of a room is $200 with standard deviation $10. In addition, there is a 10% tourism tax for each room. What is the standard deviation of the cost for the 30 hotel rooms? Assume rooms are independent.\n\n\nProblem to do at home if we don’t have enough time."
  },
  {
    "objectID": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance_muddy_points.html",
    "href": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "Muddy points from Fall 2023:\n\n2. How do we set the bounds on a double integral?\nWhen the domain of the RVs are not dependent on each other, then we use the bounds as is. In example 2 of Chapter 26 notes, we have the joint pdf \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for\\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\). If we wanted to calculate something like \\(E(X)\\), then we could use the bounds as they are. Below is the domain for \\(x\\) and \\(y\\):\n\n\n\n\n\nHere is the integral for the expected value where we integrate over the whole domain of \\(x\\) and \\(y\\):\n\\[ E(X) = \\displaystyle\\int_0^1 \\displaystyle\\int_0^1 x (18 x^2 y^5 )dy dx \\]If we want to find the probability \\(P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75)\\), then we can look at the specific values of the probability:\n\n\n\n\n\nNote the blue lines above indicate how we integrate over \\(y\\) first from 0.5 to 0.75 and the green lines indicate how integrate over \\(x\\) first from 0.25 to 0.5. It seems like we’ve integrated over an area that isn’t within our specified probability. However, the integrated area is ONLY the overlap of the \\(x\\) and \\(y\\) bounds for the probability.\n\\[P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.25}^{0.5} \\displaystyle\\int_{0.5}^{0.75} 18 x^2 y^5 dy dx\\]\nLet’s use the same pdf, but now the domain of the two RVs is dependent on one another. We have the joint pdf \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for\\(0 \\leq x \\leq y\\leq1\\)\nIf we wanted to calculate something like \\(E(X)\\), then we need to account for fact that \\(x\\) must be less than of equal to \\(y\\). We can look back at the domain for this:\n\n\n\n\n\nNote the blue lines above still indicate how we integrate over \\(y\\) first from \\(x\\) to 1, and the green lines indicate how integrate over \\(x\\) first from 0 to 1. Once again, it seems like we’ve integrated over an area that isn’t within the domain. However, the integrated area is ONLY the overlap of the \\(x\\) and \\(y\\) bounds. Thus, once we’ve restricted \\(y\\) to the area between \\(x\\) and 1, we no longer need to restrict \\(x\\) to the are of 0 to \\(y\\).\n\\[ E(X) = \\displaystyle\\int_0^1 \\displaystyle\\int_x^1 x (18 x^2 y^5 )dy dx \\] If we want to find the probability \\(P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75)\\), then we should look back at our domain. For now, we are focusing on the orange area:\n\n\n\n\n\nBecause the orange area is totally within our domain, we can leave our integral our bounds as the exact values we specified:\n\\[P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.25}^{0.5} \\displaystyle\\int_{0.5}^{0.75} 18 x^2 y^5 dy dx\\]\nHowever, if we want the probability \\(P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75)\\), we would focus on the pink area above. We would limit one of our integrals to the \\(y=x\\) equation:\n\\[P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.5}^{0.75} \\displaystyle\\int_{x}^{0.75} 18 x^2 y^5 dy dx\\]\nOR\n\\[P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.5}^{0.75} \\displaystyle\\int_{0.5}^{y} 18 x^2 y^5 dx dy\\]\nThe key to these probabilities is that the bounds with the other variable is on the inside integral! Otherwise we end up with a answer that includes a RV."
  },
  {
    "objectID": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html",
    "href": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "",
    "text": "Calculate the mean (expected value) of sums of discrete random variables"
  },
  {
    "objectID": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#learning-objectives",
    "href": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#learning-objectives",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "",
    "text": "Calculate the mean (expected value) of sums of discrete random variables"
  },
  {
    "objectID": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#where-are-we",
    "href": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#where-are-we",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#revisiting-our-two-card-draw",
    "href": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#revisiting-our-two-card-draw",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Revisiting our two card draw",
    "text": "Revisiting our two card draw\n\n\n\n\nExample 1\n\n\nSuppose you draw 2 cards from a standard deck of cards with replacement. Let \\(X\\) be the number of hearts you draw. Find \\(\\mathbb{E}[X]\\).\n\n\n\n\nRecall Binomial RV with \\(n=2\\):\n\\[p_X(x) = {2 \\choose x}p^x(1-p)^{2-x} \\text{  for } x = 0, 1, 2\\]"
  },
  {
    "objectID": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#what-if-we-draw-a-lot-of-cards",
    "href": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#what-if-we-draw-a-lot-of-cards",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "What if we draw A LOT of cards?",
    "text": "What if we draw A LOT of cards?\n\n\n\n\nExample 2\n\n\nWhat is the expected number of hearts in Example 1 if you draw 200 cards?\n\n\n\n\nRecall Binomial RV with \\(n=200\\):\n\\[p_X(x) = {200 \\choose x}p^x(1-p)^{200-x}\\] \\[\\text{  for } x = 0, 1, 2, ..., 200\\]"
  },
  {
    "objectID": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#sum-of-discrete-rvs",
    "href": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#sum-of-discrete-rvs",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Sum of discrete RVs",
    "text": "Sum of discrete RVs\n\n\nTheorem 11.1: Sum of discrete RVs\n\n\nFor discrete r.v.’s \\(X_i\\) and constants \\(a_i\\), \\(i=1,2,\\dots, n\\), \\[\\mathbb{E}\\Bigg[\\sum_{i=1}^n a_iX_i\\Bigg] = \\sum_{i=1}^n a_i\\mathbb{E}[X_i] .\\] Remark: The theorem holds for infinitely r.v.’s \\(X_i\\) as well.\n\n\n\nFor two RVs, \\(X\\) and \\(Y\\):\n\nWe can say \\(E[X+Y] = E[X] + E[Y]\\)\n… and constant numbers \\(a\\) and \\(b\\), we can also say \\(E[aX+bY] = aE[X] + bE[Y]\\)\nWe can also also say \\(E[X-Y] = E[X] - E[Y]\\), since \\(b=-1\\)"
  },
  {
    "objectID": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#corollaries-from-thm-11.1",
    "href": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#corollaries-from-thm-11.1",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Corollaries from Thm 11.1",
    "text": "Corollaries from Thm 11.1\n\n\n\n\nCorollary 11.1.1\n\n\nFor a discrete r.v. \\(X\\), and constants \\(a\\) and \\(b\\), \\[\\mathbb{E}[aX+b] = a\\mathbb{E}[X] + b.\\]\n\n\n\n\n\nCorollary 11.1.2\n\n\nIf \\(X_i\\), \\(i=1,2,\\dots, n\\), are identically distributed r.v.’s, then \\[\\mathbb{E}\\bigg[\\sum_{i=1}^n X_i\\bigg] = n\\mathbb{E}[X_1] .\\]"
  },
  {
    "objectID": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#cost-of-hotel-rooms",
    "href": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/11_Expected_Values_of_Sums_of_rvs.html#cost-of-hotel-rooms",
    "title": "Chapter 11: Expected Values of Sums of Discrete RVs",
    "section": "Cost of hotel rooms",
    "text": "Cost of hotel rooms\n\n\n\n\nExample 4\n\n\nA tour group is planning a visit to the city of Minneapolis and needs to book 30 hotel rooms. The average price of a room is $200. In addition, there is a 10% tourism tax for each room. What is the expected cost for the 30 hotel rooms?"
  },
  {
    "objectID": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html",
    "href": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "",
    "text": "Calculate probability of a sample mean using a Normally distributed population"
  },
  {
    "objectID": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#learning-objectives",
    "href": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#learning-objectives",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "",
    "text": "Calculate probability of a sample mean using a Normally distributed population"
  },
  {
    "objectID": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#sum-of-normal-rvs",
    "href": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#sum-of-normal-rvs",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "Sum of Normal RVs",
    "text": "Sum of Normal RVs\n\n\nTheorem 1\n\n\nLet \\(X\\sim N(\\mu, \\sigma^2)\\), and let \\(Y=aX+b\\), where \\(a\\) and \\(b\\) are constants. Then \\[Y \\sim N(a\\mu+b, a^2\\sigma^2)\\]\n\n\n\n\nTheorem 2\n\n\nLet \\(X_i \\sim N(\\mu_i, \\sigma_i^2)\\) be independent normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\sim N\\Bigg(\\sum_{i=1}^n \\mu_i , \\sum_{i=1}^n \\sigma^2_i\\Bigg)\\]"
  },
  {
    "objectID": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#special-cases",
    "href": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#special-cases",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "Special Cases",
    "text": "Special Cases\n\nLet \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\sim N\\big(n\\mu, n \\sigma^2\\big)\\]\nLet \\(X_i \\sim N(\\mu, \\sigma^2)\\) be iid normal rv’s, for \\(i=1,2,\\ldots,n\\). Then \\[\\bar{X}=\\frac{\\sum_{i=1}^n X_i}{n} \\sim N\\big(\\mu, \\sigma^2 / n\\big)\\]\nLet \\(X\\sim N(\\mu_X,\\sigma_X^2)\\), and \\(Y\\sim N(\\mu_Y,\\sigma_Y^2)\\). Then \\[X-Y \\sim N\\big(\\mu_X - \\mu_Y, \\sigma^2_X + \\sigma^2_Y \\big)\\]"
  },
  {
    "objectID": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#detecting-and-solving-sums-of-normal-rvs-from-a-word-problem",
    "href": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv.html#detecting-and-solving-sums-of-normal-rvs-from-a-word-problem",
    "title": "Chapter 36: Sums of Independent Normal RVs",
    "section": "Detecting and solving sums of Normal RVs from a word problem",
    "text": "Detecting and solving sums of Normal RVs from a word problem\n\n\n\n\nExample 1\n\n\nGlaucoma is an eye disease that is manifested by high intraocular pressure (IOP). The distribution of IOP in the general population is approximately normal with mean 16 mmHg and standard deviation 3 mmHg.\n\nSuppose a patient has 40 IOP readings. What is the probability that their average reading is greater than 20.32 mmHg, assuming their eyes are healthy?\nRepeat the previous question for a patient with 10 IOP readings."
  },
  {
    "objectID": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html",
    "href": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "Homework 7 presentations due soon!\n\nI will check your HW 7 solutions ASAP!\n\nDepending on how far we get today and Wednesday, I might cancel the 12/9 class\nAnything else?"
  },
  {
    "objectID": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#announcements",
    "href": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "Homework 7 presentations due soon!\n\nI will check your HW 7 solutions ASAP!\n\nDepending on how far we get today and Wednesday, I might cancel the 12/9 class\nAnything else?"
  },
  {
    "objectID": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#key-dates",
    "href": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/36_Sums_of_Independent_Normal_rv/36_Sums_of_Independent_Normal_rv_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nThursday: HW 8 assignment due\nSunday: HW 7 presentations due at 11pm"
  },
  {
    "objectID": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html",
    "href": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "",
    "text": "Calculate the mean (expected value) of a joint distribution of continuous RV"
  },
  {
    "objectID": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#learning-objectives",
    "href": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#learning-objectives",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "",
    "text": "Calculate the mean (expected value) of a joint distribution of continuous RV"
  },
  {
    "objectID": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#remark-on-expected-value-of-one-rv-from-joint-pdf",
    "href": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#remark-on-expected-value-of-one-rv-from-joint-pdf",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "Remark on expected value of one RV from joint pdf",
    "text": "Remark on expected value of one RV from joint pdf\nIf you are given \\(f_{X,Y}(x,y)\\) and want to calculate \\(\\mathbb{E}[X]\\), you have two options:\n\nFind \\(f_X(x)\\) and use it to calculate \\(\\mathbb{E}[X]\\).\nOr, calculate \\(\\mathbb{E}[X]\\) using the joint density: \\[\\mathbb{E}[X] = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}x f_{X,Y}(x,y)dydx.\\]"
  },
  {
    "objectID": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-1-expected-value-from-a-joint-distribution",
    "href": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-1-expected-value-from-a-joint-distribution",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "Option 1: Expected value from a joint distribution",
    "text": "Option 1: Expected value from a joint distribution\n\n\n\n\nExample 3\n\n\nLet \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-2-expected-value-from-a-joint-distribution",
    "href": "lessons/13_Expected_Values/old_notes/15_Expected_Values_of_Sums_of_rvs/28_29_Joint_expected_value_Variance/28_29_Joint_expected_value_Variance.html#option-2-expected-value-from-a-joint-distribution",
    "title": "Chapter 28: Revisiting Expected Values for Joint Distributions",
    "section": "Option 2: Expected value from a joint distribution",
    "text": "Option 2: Expected value from a joint distribution\n\n\n\n\nExample 1\n\n\nLet \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\)."
  },
  {
    "objectID": "lessons/11_Joint_distributions/11_Joint_distributions_muddy_points.html#fall-2023",
    "href": "lessons/11_Joint_distributions/11_Joint_distributions_muddy_points.html#fall-2023",
    "title": "Muddy Points",
    "section": "Fall 2023",
    "text": "Fall 2023\n\n1. How do we set the bounds on a double integral?\nWhen the domain of the RVs are not dependent on each other, then we use the bounds as is. In example 2 of Chapter 26 notes, we have the joint pdf \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for\\(0 \\leq x \\leq 1, \\ 0 \\leq y \\leq 1\\). If we wanted to calculate something like \\(E(X)\\), then we could use the bounds as they are. Below is the domain for \\(x\\) and \\(y\\):\n\n\n\n\n\nHere is the integral for the expected value where we integrate over the whole domain of \\(x\\) and \\(y\\):\n\\[ E(X) = \\displaystyle\\int_0^1 \\displaystyle\\int_0^1 x (18 x^2 y^5 )dy dx \\]If we want to find the probability \\(P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75)\\), then we can look at the specific values of the probability:\n\n\n\n\n\nNote the blue lines above indicate how we integrate over \\(y\\) first from 0.5 to 0.75 and the green lines indicate how integrate over \\(x\\) first from 0.25 to 0.5. It seems like we’ve integrated over an area that isn’t within our specified probability. However, the integrated area is ONLY the overlap of the \\(x\\) and \\(y\\) bounds for the probability.\n\\[P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.25}^{0.5} \\displaystyle\\int_{0.5}^{0.75} 18 x^2 y^5 dy dx\\]\nLet’s use the same pdf, but now the domain of the two RVs is dependent on one another. We have the joint pdf \\(f_{X,Y}(x,y)= 18 x^2 y^5\\), for\\(0 \\leq x \\leq y\\leq1\\)\nIf we wanted to calculate something like \\(E(X)\\), then we need to account for fact that \\(x\\) must be less than of equal to \\(y\\). We can look back at the domain for this:\n\n\n\n\n\nNote the blue lines above still indicate how we integrate over \\(y\\) first from \\(x\\) to 1, and the green lines indicate how integrate over \\(x\\) first from 0 to 1. Once again, it seems like we’ve integrated over an area that isn’t within the domain. However, the integrated area is ONLY the overlap of the \\(x\\) and \\(y\\) bounds. Thus, once we’ve restricted \\(y\\) to the area between \\(x\\) and 1, we no longer need to restrict \\(x\\) to the are of 0 to \\(y\\).\n\\[ E(X) = \\displaystyle\\int_0^1 \\displaystyle\\int_x^1 x (18 x^2 y^5 )dy dx \\] If we want to find the probability \\(P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75)\\), then we should look back at our domain. For now, we are focusing on the orange area:\n\n\n\n\n\nBecause the orange area is totally within our domain, we can leave our integral our bounds as the exact values we specified:\n\\[P(0.25 \\leq X \\leq 0.5, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.25}^{0.5} \\displaystyle\\int_{0.5}^{0.75} 18 x^2 y^5 dy dx\\]\nHowever, if we want the probability \\(P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75)\\), we would focus on the pink area above. We would limit one of our integrals to the \\(y=x\\) equation:\n\\[P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.5}^{0.75} \\displaystyle\\int_{x}^{0.75} 18 x^2 y^5 dy dx\\]\nOR\n\\[P(0.5 \\leq X \\leq 0.75, 0.5 \\leq Y \\leq 0.75) = \\displaystyle\\int_{0.5}^{0.75} \\displaystyle\\int_{0.5}^{y} 18 x^2 y^5 dx dy\\]\nThe key to these probabilities is that the bounds with the other variable is on the inside integral! Otherwise we end up with a answer that includes a RV."
  },
  {
    "objectID": "lessons/13_Expected_Values/13_Expected_Values_muddy_points.html#fall-2025",
    "href": "lessons/13_Expected_Values/13_Expected_Values_muddy_points.html#fall-2025",
    "title": "Muddy Points",
    "section": "",
    "text": "Here’s a pretty good video on integration by parts!\nHere’s the Calc review muddy points with a few words on integration by parts.\n\n\n\nGot a little help from Chatgpt:\nThink back to our discrete example with the die. Our expected value was the weighted average of all the possible outcomes (weighted by their probability). So our expected value for discrete RVs will always be that weighted average: \\[\\mathbb{E}[X] = \\sum_{i=1}^n x_ip_X(x_i)\\]\nFor continuous RVs, they can take infinite possible values, so we cannot sum across the pdf the same way. We still want the weighted average, so we need to find a way to “sum” the weighted outcomes for the continuous RV, which translates to an integral.\nHere’s a fairly good explanation on StackExchange..)\n\n\n\nFinal example: Let \\(f_{X,Y}(x,y)= 2e^{-(x+y)}\\), for \\(0 \\leq x \\leq y\\). Find \\(\\mathbb{E}[X]\\).\nLet’s start with a plot for the domain. We have \\(0 \\leq x \\leq y\\), so we know that \\(x\\geq0\\) and because \\(y\\geq x\\), then \\(y\\geq0\\), so we’ll have a plot of all positive values of \\(x\\) and \\(y\\):\n\n\n\n\n\n\n\n\n\nOkay, now let’s add the information that \\(y \\geq x\\). We can look at the line, \\(y=x\\), and identify the area on the side of the line that upholds \\(y \\geq x\\):\n\n\n\n\n\n\n\n\n\nThe area above the line is where \\(y\\geq x\\):\n\n\n\n\n\n\n\n\n\nSo we need to find the bounds for the orange region in terms of \\(x\\) and \\(y\\).\nWhichever random variable is on the inner integral will need to incorporate the \\(y=x\\) line. If we integrate over \\(y\\) first, we will integrate from \\(y=x\\) to \\(y=\\infty\\). Once we have incorporated the line into our first integral, then we no longer need to worry about the \\(y=x\\) line. For \\(x\\), we can integrate from \\(x=0\\) to \\(x=\\infty\\)."
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#find-the-mean-and-sd-from-word-problem-12",
    "href": "lessons/14_Variance/14_Variance.html#find-the-mean-and-sd-from-word-problem-12",
    "title": "Lesson 14: Variance",
    "section": "Find the mean and sd from word problem (1/2)",
    "text": "Find the mean and sd from word problem (1/2)\n\n\n\n\nExample 4\n\n\nA machine manufactures cubes with a side length that varies uniformly from 1 to 2 inches. Assume the sides of the base and height are equal. The cost to make a cube is 10 ¢ per cubic inch, and 5 ¢ cents for the general cost per cube. Find the mean and standard deviation of the cost to make 10 cubes."
  },
  {
    "objectID": "lessons/14_Variance/14_Variance.html#find-the-mean-and-sd-from-word-problem-12-1",
    "href": "lessons/14_Variance/14_Variance.html#find-the-mean-and-sd-from-word-problem-12-1",
    "title": "Lesson 14: Variance",
    "section": "Find the mean and sd from word problem (1/2)",
    "text": "Find the mean and sd from word problem (1/2)"
  },
  {
    "objectID": "lessons/14_Variance/old_lessons/29_Variance_and_Sums_of_rv.html",
    "href": "lessons/14_Variance/old_lessons/29_Variance_and_Sums_of_rv.html",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "",
    "text": "Calculate expected value of functions of RVs\nCalculate variance of RVs"
  },
  {
    "objectID": "lessons/14_Variance/old_lessons/29_Variance_and_Sums_of_rv.html#learning-objectives",
    "href": "lessons/14_Variance/old_lessons/29_Variance_and_Sums_of_rv.html#learning-objectives",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "",
    "text": "Calculate expected value of functions of RVs\nCalculate variance of RVs"
  },
  {
    "objectID": "lessons/14_Variance/old_lessons/29_Variance_and_Sums_of_rv.html#expected-value-of-a-function-of-a-continuous-rv",
    "href": "lessons/14_Variance/old_lessons/29_Variance_and_Sums_of_rv.html#expected-value-of-a-function-of-a-continuous-rv",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Expected value of a function of a continuous RV",
    "text": "Expected value of a function of a continuous RV\n\n\nHow do we calculate the expected value of a function of a discrete RV or joint RVs?\n   \nFor discrete RVs:\n\\[\\mathbb{E}[g(X)] = \\sum_{\\{all\\ x\\}}\\ g(x) p_X(x).\\] \\[\\mathbb{E}[g(X, Y)] = \\sum_{\\{all\\ x\\}}\\sum_{\\{all\\ y\\}}\\ g(x,y) p_{X,Y}(x,y).\\]\n\n\n\nHow do we calculate the expected value of a function of a continuous RV or joint RVs?\n   \nFor continuous RVs:"
  },
  {
    "objectID": "lessons/14_Variance/old_lessons/29_Variance_and_Sums_of_rv.html#important-properties-of-expected-values-of-functions-of-continuous-rvs",
    "href": "lessons/14_Variance/old_lessons/29_Variance_and_Sums_of_rv.html#important-properties-of-expected-values-of-functions-of-continuous-rvs",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Important properties of expected values of functions of continuous RVs",
    "text": "Important properties of expected values of functions of continuous RVs\n\n\n\n\nFunction of RV with two constants\n\n\n\\(\\mathbb{E}[aX+b] =a\\mathbb{E}[X]+b\\)\n\n\n\n\nFunction of two RVs added\n\n\n\\(\\mathbb{E}[X+Y] =\\mathbb{E}[X]+\\mathbb{E}[Y]\\)\n\n\n\n\nExpected value of sum of independent RVs pt 1\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are continuous RVs and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\[\\mathbb{E}\\Bigg[\\sum_{i=1}^{n} a_i X_i\\Bigg] = \\sum_{i=1}^{n}a_i\\mathbb{E}[X_i]\\]\n\n\n\n\n\nExpected value of multiplication of function of independent RVs\n\n\nIf \\(X\\) and \\(Y\\) are independent continuous RVs, and \\(g\\) and \\(h\\) are functions, then \\[\\mathbb{E}[g(X)h(Y)] =\\mathbb{E}[g(X)]\\mathbb{E}[h(Y)]\\]\n\n\n\n\nExpected value of multiplication of independent RVs\n\n\nIf \\(X\\) and \\(Y\\) are independent continuous RVs, then \\[\\mathbb{E}[XY] = \\mathbb{E}[X] \\mathbb{E}[Y] \\]"
  },
  {
    "objectID": "lessons/14_Variance/old_lessons/29_Variance_and_Sums_of_rv.html#variance-of-continuous-rvs",
    "href": "lessons/14_Variance/old_lessons/29_Variance_and_Sums_of_rv.html#variance-of-continuous-rvs",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Variance of continuous RVs",
    "text": "Variance of continuous RVs\n\n\nHow do we calculate the variance of a discrete RV?\n   \nFor discrete RVs:\n\\[\n\\begin{align}\nVar(X) & =\n\\mathbb{E}[(X-\\mu_X)^2] \\\\ & = \\mathbb{E}[(X-\\mathbb{E}[X])^2] \\\\ &= \\mathbb{E}[X^2]-(\\mathbb{E}[X])^2 \\\\ & = \\sum_{\\{all\\ x\\}}(x-\\mu_x)^2 p_{X}(x)\n\\end{align}\n\\]\n\n\n\nHow do we calculate the variance of a continuous RV?\n    \nFor continuous RVs:"
  },
  {
    "objectID": "lessons/14_Variance/old_lessons/29_Variance_and_Sums_of_rv.html#variance-of-an-uniform-distribution",
    "href": "lessons/14_Variance/old_lessons/29_Variance_and_Sums_of_rv.html#variance-of-an-uniform-distribution",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Variance of an Uniform distribution",
    "text": "Variance of an Uniform distribution\n\n\n\n\nExample 2\n\n\nLet \\(f_X(x)= \\frac{1}{b-a}\\), for \\(a \\leq x \\leq b\\). Find \\(Var[X]\\)."
  },
  {
    "objectID": "lessons/14_Variance/old_lessons/29_Variance_and_Sums_of_rv.html#variance-of-exponential-distribution",
    "href": "lessons/14_Variance/old_lessons/29_Variance_and_Sums_of_rv.html#variance-of-exponential-distribution",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Variance of exponential distribution",
    "text": "Variance of exponential distribution\n\n\nIn the homework:\n\n\nExample 3\n\n\nLet \\(f_X(x)= \\lambda e^{-\\lambda x}\\), for \\(x &gt; 0\\) and \\(\\lambda&gt; 0\\). Find \\(Var[X]\\)."
  },
  {
    "objectID": "lessons/14_Variance/old_lessons/29_Variance_and_Sums_of_rv.html#important-properties-of-variances-of-continuous-rvs",
    "href": "lessons/14_Variance/old_lessons/29_Variance_and_Sums_of_rv.html#important-properties-of-variances-of-continuous-rvs",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Important properties of variances of continuous RVs",
    "text": "Important properties of variances of continuous RVs\n\n\n\n\nFunction of RV with two constants\n\n\n\\[Var[aX+b] = a^2Var[X]\\]\n\n\n\n\n\nVariance of sum of independent RVs pt 1\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous RVs and \\(a_1, a_2, \\ldots a_n\\) are constants, then \\[Var\\Bigg(\\sum_{i=1}^{n} a_i X_i\\Bigg) =\\sum_{i=1}^{n} a^2_i Var(X_i)\\]\n\n\n\n\nVariance of sum of independent RVs pt 2\n\n\nIf \\(X_1, X_2, \\ldots X_n\\) are independent continuous RVs, then \\[Var\\Bigg(\\sum_{i=1}^{n} X_i\\Bigg) = \\sum_{i=1}^{n} Var(X_i)\\]"
  },
  {
    "objectID": "lessons/14_Variance/old_lessons/29_Variance_and_Sums_of_rv.html#find-the-mean-and-sd-from-word-problem",
    "href": "lessons/14_Variance/old_lessons/29_Variance_and_Sums_of_rv.html#find-the-mean-and-sd-from-word-problem",
    "title": "Chapter 29: Variance of Continuous Random Variables",
    "section": "Find the mean and sd from word problem",
    "text": "Find the mean and sd from word problem\n\n\n\n\nExample 4\n\n\nA machine manufactures cubes with a side length that varies uniformly from 1 to 2 inches. Assume the sides of the base and height are equal. The cost to make a cube is 10 ¢ per cubic inch, and 5 ¢ cents for the general cost per cube. Find the mean and standard deviation of the cost to make 10 cubes."
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs.html#where-are-we",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs.html#where-are-we",
    "title": "Lesson 16: Some Important Continuous RVs",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html",
    "href": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html",
    "title": "Chapter 43: Moment Generating Functions",
    "section": "",
    "text": "Learn the definition of a moment-generating function.\nFind the moment-generating function of a binomial random variable.\nUse a moment-generating function to find the mean and variance of a random variable."
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#learning-objectives",
    "href": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#learning-objectives",
    "title": "Lesson 18: Moment Generating Functions",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nLearn the definition of a moment-generating function.\nFind the moment-generating function of a random variable.\nUse a moment-generating function to find the mean and variance of a random variable."
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#where-are-we",
    "href": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#where-are-we",
    "title": "Lesson 18: Moment Generating Functions",
    "section": "Where are we?",
    "text": "Where are we?"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#what-are-moments",
    "href": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#what-are-moments",
    "title": "Lesson 18: Moment Generating Functions",
    "section": "What are moments?",
    "text": "What are moments?\n\n\nDefinition 1\n\n\nThe \\(j^{th}\\) moment of a r.v. \\(X\\) is \\(\\mathbb{E}[X^j]\\)"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#what-is-a-moment-generating-function-mgf",
    "href": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#what-is-a-moment-generating-function-mgf",
    "title": "Lesson 18: Moment Generating Functions",
    "section": "What is a moment generating function (MGF)??",
    "text": "What is a moment generating function (MGF)??\n\n\nDefinition 3\n\n\nIf \\(X\\) is a r.v., then the moment generating function (MGF) associated with \\(X\\) is: \\[M_X(t)= \\mathbb{E}[e^{tX}]\\]\n\n\nRemarks\n\n\n\nFor a discrete r.v., the MGF of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\sum_{all \\ x}e^{tx}p_X(x)\\]\nFor a continuous r.v., the MGF of \\(X\\) is \\[M_X(t)= \\mathbb{E}[e^{tX}]=\\int_{-\\infty}^{\\infty}e^{tx}f_X(x)dx\\]\n\n\n\nThe MGF \\(M_X(t)\\) is a function of \\(t\\), not of \\(X\\), and it might not be defined (i.e. finite) for all values of \\(t\\). We just need it to be defined for \\(t=0\\)."
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#example",
    "href": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#example",
    "title": "Lesson 18: Moment Generating Functions",
    "section": "Example",
    "text": "Example\n\n\n\n\nExample 4\n\n\nWhat is \\(M_X(t)\\) for \\(t=0\\)?"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#theorem",
    "href": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#theorem",
    "title": "Lesson 18: Moment Generating Functions",
    "section": "Theorem",
    "text": "Theorem\nRemark: Finding the mean and variance is sometimes easier with the following trick\n\n\nTheorem 8\n\n\nLet \\(R_X(t) = \\ln[M_X(t)]\\). Then,\n\\[\\mu = \\mathbb{E}[X] = R_X'(0) \\text{, and}\\] \\[\\sigma^2 = Var(X) = R_X''(0)\\]\n\n\n\nProof."
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-a-probability-distribution",
    "href": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-a-probability-distribution",
    "title": "Lesson 18: Moment Generating Functions",
    "section": "Using the MGF to uniquely describe a probability distribution",
    "text": "Using the MGF to uniquely describe a probability distribution\n\n\n\n\nExample 7\n\n\nLet \\(X \\sim Poisson(\\lambda)\\)\n\nFind the MGF of \\(X\\)\nFind \\(\\mathbb{E}[X]\\)\nFind \\(Var(X)\\)"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#theorem-1",
    "href": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#theorem-1",
    "title": "Lesson 18: Moment Generating Functions",
    "section": "Theorem",
    "text": "Theorem\nRemark: Finding the mean and variance is sometimes easier with the following trick\n\n\nTheorem 8\n\n\nLet \\(R_X(t) = \\ln[M_X(t)]\\). Then,\n\\[\\mu = \\mathbb{E}[X] = R_X'(0) \\text{, and}\\] \\[\\sigma^2 = Var(X) = R_X''(0)\\]\n\n\n\nProof."
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#using-r_xt-to-uniquely-describe-a-probability-distribution",
    "href": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#using-r_xt-to-uniquely-describe-a-probability-distribution",
    "title": "Lesson 18: Moment Generating Functions",
    "section": "Using \\(R_X(t)\\) to uniquely describe a probability distribution",
    "text": "Using \\(R_X(t)\\) to uniquely describe a probability distribution\n\n\n\n\nExample 9\n\n\nLet \\(X \\sim Poisson(\\lambda)\\).\n\nFind \\(\\mathbb{E}[X]\\) using \\(R_X(t)\\)\nFind \\(Var(X)\\) using \\(R_X(t)\\)"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-the-standard-normal-distribution",
    "href": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-the-standard-normal-distribution",
    "title": "Lesson 18: Moment Generating Functions",
    "section": "Using the MGF to uniquely describe the standard normal distribution",
    "text": "Using the MGF to uniquely describe the standard normal distribution\n\n\n\n\nExample 10\n\n\nLet \\(Z\\) be a standard normal random variable, i.e. \\(Z \\sim N(0,1)\\).\n\nFind the MGF of \\(Z\\)\nFind \\(\\mathbb{E}[Z]\\)\nFind \\(Var(Z)\\)"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#mgfs-of-sums-of-independent-rvs",
    "href": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#mgfs-of-sums-of-independent-rvs",
    "title": "Lesson 18: Moment Generating Functions",
    "section": "MGFs of sums of independent RV’s",
    "text": "MGFs of sums of independent RV’s\n\n\nTheorem 9\n\n\nIf \\(X\\) and \\(Y\\) are independent RV’s with respective MGFs \\(M_X(t)\\) and \\(M_Y(t)\\), then\n\\[M_{X+Y}(t) = E[e^{t(X+Y)}] = E[e^{tX} e^{tY}] = E[e^{tX}]E[e^{tY}]=M_{X}(t)M_{Y}(t)\\]"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#main-takeaways",
    "href": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#main-takeaways",
    "title": "Lesson 18: Moment Generating Functions",
    "section": "Main takeaways",
    "text": "Main takeaways\n\nMGFs are a purely mathematically definition\n\nWe can’t really relate it to our real world analysis\n\nThey are helpful mathematically because they are unique to a probability distribution\n\nWe can find the unique MGF from for a probability distribution\nAnd we can find a distribution from an MGF\n\nMGFs can sometimes make it easier to find the mean and variance of an RV\nMGFs are most helpful when we are finding a joint distribution that is a sum or transformation of two RV’s\n\nMake the calculation easier!\n\nMGFs are often used to prove certain distribution are sums of other ones!"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#more-resources",
    "href": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#more-resources",
    "title": "Lesson 18: Moment Generating Functions",
    "section": "More resources",
    "text": "More resources\n\nhttps://online.stat.psu.edu/stat414/book/export/html/676\nhttps://www.youtube.com/watch/ez_vq23xWrQ\nhttps://www.youtube.com/watch/2p9J9ChTeFI\nhttps://www.youtube.com/watch/A5bWU8xcQkE\nhttps://www.youtube.com/watch/QeUrTGFTFm4\nhttps://www.youtube.com/watch/HhrkwyyRtgI"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "",
    "text": "Calculate probability of a sample mean using a population mean and variance with unknown distribution\nUse the Central Limit Theorem to construct the Normal approximation of the Binomial and Poisson distributions"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#learning-objectives",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#learning-objectives",
    "title": "Chapter 37: Central Limit Theorem",
    "section": "",
    "text": "Calculate probability of a sample mean using a population mean and variance with unknown distribution\nUse the Central Limit Theorem to construct the Normal approximation of the Binomial and Poisson distributions"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#the-central-limit-theorem",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#the-central-limit-theorem",
    "title": "Lesson 17: Central Limit Theorem",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\n\n\nTheorem 1: Central Limit Theorem (CLT)\n\n\nLet \\(X_i\\) be iid rv’s with common mean \\(\\mu\\) and variance \\(\\sigma^2\\), for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\rightarrow \\text{N}(n\\mu, n\\sigma^2)\\]"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#extension-of-the-clt",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#extension-of-the-clt",
    "title": "Lesson 17: Central Limit Theorem",
    "section": "Extension of the CLT",
    "text": "Extension of the CLT\n\n\nCorollary 1\n\n\nLet \\(X_i\\) be iid rv’s with common mean \\(\\mu\\) and variance \\(\\sigma^2\\), for \\(i=1,2,\\ldots,n\\). Then \\[\\overline{X}=\\frac{\\sum_{i=1}^n X_i}{n}  \\rightarrow \\text{N}\\Bigg(\\mu, \\dfrac{\\sigma^2}{n}\\Bigg)\\]"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#example-of-corollary-in-use",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#example-of-corollary-in-use",
    "title": "Lesson 17: Central Limit Theorem",
    "section": "Example of Corollary in use",
    "text": "Example of Corollary in use\n\n\n\n\nExample 1\n\n\nAccording to a large US study, the mean resting heart rate of adult women is about 74 beats per minutes (bpm), with standard deviation 13 bpm (NHANES 2003-2004).\n\nFind the probability that the average resting heart rate for a random sample of 36 adult women is more than 3 bpm away from the mean.\nRepeat the previous question for a single adult woman."
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#example-of-clt-for-exponential-distribution",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#example-of-clt-for-exponential-distribution",
    "title": "Lesson 17: Central Limit Theorem",
    "section": "Example of CLT for exponential distribution",
    "text": "Example of CLT for exponential distribution\n\n\n\n\nExample 2\n\n\nLet \\(X_i \\sim Exp(\\lambda)\\) be iid RVs for \\(i=1,2,\\ldots,n\\). Then \\[\\sum_{i=1}^n X_i \\rightarrow\\]"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#clt-for-discrete-rvs",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#clt-for-discrete-rvs",
    "title": "Lesson 17: Central Limit Theorem",
    "section": "CLT for Discrete RVs",
    "text": "CLT for Discrete RVs\n\n\n\nBinomial rv’s: Let \\(X \\sim Bin(n,p)\\)\n\n\\(X = \\displaystyle\\sum_{i=1}^n X_i\\), where \\(X_i\\) are iid \\(\\text{Bernoulli}(p)\\)\nRule of thumb: \\(np\\geq10\\) and \\(n(1-p)\\geq 10\\) to use Normal approximation\n\n\n\n\n\n\nPoisson rv’s: Let \\(X \\sim Poisson(\\lambda)\\)\n\n\\(X = \\displaystyle\\sum_{i=1}^n X_i\\), where \\(X_i\\) are iid \\(\\text{Poiss}(1)\\)\nRecall from Chapter 18 that if \\(X_i \\sim Poiss(\\lambda_i)\\) and \\(X_i\\) independent, then \\(\\sum_{i=1}^n X_i \\sim Poiss(\\sum_{i=1}^n \\lambda_i)\\)\nRule of thumb: \\(\\lambda \\geq10\\) to use Normal approximation"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#at-home-example",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#at-home-example",
    "title": "Lesson 17: Central Limit Theorem",
    "section": "At home example",
    "text": "At home example\n\n\nExample 3\n\n\nSuppose that the probability of developing a specific type of breast cancer in women aged 40-49 is 0.001. Assume the occurrences of cancer are independent. Suppose you have data from a random sample of 20,000 women aged 40-49.\n\nHow many of the 20,000 women would you expect to develop this type of breast cancer, and what is the standard deviation?\nFind the exact probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to find the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to approximate the following probabilities, where \\(X\\) is the number of women that will develop this type of breast cancer.\n\n\\(\\mathbb{P}(15 \\leq X \\leq 22)\\)\n\\(\\mathbb{P}(X &gt; 20)\\)\n\\(\\mathbb{P}(X &lt; 20)\\)\n\nFind the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer - not using the CLT!\nUse the CLT to approximate the approximate probability in the previous question!"
  },
  {
    "objectID": "lessons/14_Variance/14_Variance_muddy_points.html#fall-2023",
    "href": "lessons/14_Variance/14_Variance_muddy_points.html#fall-2023",
    "title": "Muddy Points",
    "section": "Fall 2023",
    "text": "Fall 2023\n\n1. Proof of variance formula\nHere is the variance formula that we worked through in class:\n\n\n\n\n\n\nNoteLemma 6: “Computation formula” for variance\n\n\n\nThe variance of a r.v. \\(X\\), can be computed as \\[\\begin{align}\\sigma_X^2 & =Var(X) \\\\ & = \\mathbb{E}[X^2]-\\mu_X^2 \\\\ & = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2\\end{align}\\]\n\n\nI stepped through this quite quickly and made some implicit steps. So let’s revisit it with explicit steps!\n       \n\n\n2. What progression are we following in the course??\nSomeone asked if this is our progression: RV is function \\(\\to\\) Expected value is function to describe mean of RV \\(\\to\\) Use functions within expected value to set up variance\nBasically, yes! The random variable is a function of a random process. The RV inherits that randomness.\nFrom there, we’ve been working towards calculating the probability of a realized value (\\(x\\)) of the RV. The probability can be different for different realized values (as it links back to the random process).\nWe also want to construct ways to describe our random variables. We may want to figure out what to expect from our random variable (which translates to the mean value of the RV). Since our RV is rooted in a random process, we may want to get an idea of how spread out our realized values are. We use our expected value (mean) as an anchor in our spread. Variance is one way to measure this spread."
  },
  {
    "objectID": "lessons/14_Variance/14_Variance_muddy_points.html#fall-2025",
    "href": "lessons/14_Variance/14_Variance_muddy_points.html#fall-2025",
    "title": "Muddy Points",
    "section": "",
    "text": "You are right, the hotel room problem did not need the identical distributions in either class. I definitely mispoke by saying they were iid. Even though they have the same expected value and variance, they are not necessarily from the same distribution. They are independent, but not necessarily identically distributed. They all have the same variance, so I can still use \\[\\sum_{i=1}^{30} Var(X_i) = 30Var(X)\\]\nIt was more that, last class, we did not specify the standard deviation. We could find the expected value of the total cost without knowing the standard deviation, and thus without necessarily assuming the cost of the hotel rooms were identical random variables. In this class, we needed the standard deviation for the cost of each hotel room. We could have made them different, but we made all of them $10.\n\n\n\nI go through that breakdown in the first muddy point from Fall 2023 (below). Check out the term 2 part that is highlighted in green-ish.\n\n\n\nHere are the corollaries:\n\n\nCorollary 2\n\n\nFor independent RV’s \\(X_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n X_i\\Bigg) = \\sum_{i=1}^n Var(X_i).\\]\n\n\n\n\nCorollary 3\n\n\nFor independent identically distributed (i.i.d.) RV’s \\(X_i\\), \\(i=1,2,\\dots, n\\), \\[Var\\Bigg(\\sum_{i=1}^n X_i\\Bigg) = n Var(X_1).\\]\n\n\nIn Corollary 2, the variance can be different for each \\(X_i\\) so we need to sum each together. In Corollary 3, the variance is the same for each \\(X_i\\) so we can recognize that we will have \\(n\\) identical terms to sum together."
  },
  {
    "objectID": "hw_answers/HW_07_ans.html#questions",
    "href": "hw_answers/HW_07_ans.html#questions",
    "title": "Homework 7 Answers",
    "section": "",
    "text": "Not given.\n\n\\(E\\left(\\overline{X}\\right) = \\mu\\)\n\\(\\text{Var}\\left(\\overline{X}\\right) = \\dfrac{\\sigma^2}{n}\\)\n\nSee notes for how I start this problem!\n\n\\(E(V) = 87850 \\text{ ft}^3\\), \\(\\text{Var}(V) = 19100116 \\ (\\text{ft}^3)^2\\)\nExpected value correct, variance incorrect"
  },
  {
    "objectID": "homework/HW_08.html#questions",
    "href": "homework/HW_08.html#questions",
    "title": "Homework 8",
    "section": "Questions",
    "text": "Questions\n\nLet \\(X_i\\sim\\) Binomial(\\(n_i,p\\)) be independent r.v.’s for \\(i=1,\\ldots,m\\).\n\nWhat does the r.v. \\(X=\\sum_{i=1}^mX_i\\) count, and what is the distribution of \\(X\\)? Make sure to specify the parameters of \\(X\\)’s distribution.\nFind \\(\\mathbb{E}[X]\\). Make sure to show your work for (b) and (c). However, you may use without proof what you know about the mean and variance of each \\(X_i\\).\nFind \\(Var[X]\\)\n\nSuppose that voters arrive at a polling station at the rate of 120 per hour.For each of the following parts, give the name and parameter(s) of the distribution to be used to model the event and set up the expression to find the specified probability.You do not need to compute the probability.\n\nThe probability that the next voter will arrive in less than 30 seconds.\nThe probability that 200 voters will arrive within two hours of each other.\nThe probability that the \\(50^{th}\\) voter will arrive in between 15 and 30 minutes.\n\nPizza delivery. Suppose that the times until Hector, Ivan, and Jacob’s pizza arrives are independent exponential random variables, each with average of 20 minutes. Find the probability that none of the waiting times exceed 20 minutes, i.e., find \\(P(\\max(X, Y,Z) \\leq 20)\\).\nI would like us to create a reference table for the important distributions. Fill out the following table and save it for future reference.\n\n\n\n\n\n\n\n\n\n\n\n\n\nRV / Distribution\nType\nParameters\nPossible values \\(X\\)\nPMF / PDF\nMean \\(E[X]\\)\nVariance \\(Var(X)\\)\n\n\n\n\nBernoulli\nDiscrete\n\\(p\\)\n\\(X = \\{0, 1\\}\\)\n\\(p^x(1-p)^{1-x}\\)\n\\(p\\)\n\\(p(1-p)\\)\n\n\nBinomial\n\n\n\n\n\n\n\n\nGeometric\n\n\n\n\n\n\n\n\nNegative Binomial\n\n\n\n\n\n\n\n\nHypergeometric\n\n\n\n\n\n\n\n\nPoisson\n\n\n\n\n\n\n\n\nDiscrete Uniform\n\n\n\n\n\n\n\n\nContinuous Uniform\n\n\n\n\n\n\n\n\nExponential\n\n\n\n\n\n\n\n\nGamma\n\n\n\n\n\n\n\n\nNormal\n\n\n\n\n\n\n\n\n\n\nIt is also important to know how different RVs/distributions relate to one another. In the following web, please fill in the relationships between each distribution. You can recreate the web or you can write out the relationships in a numbered list.\n\n\n\n\n\n\ngraph TD\n    \n    %% Define Node Styles\n    classDef discrete fill:#D6EAF8,stroke:#5DADE2,color:#333\n    classDef continuous fill:#D5F5E3,stroke:#58D68D,color:#333\n\n    %% === NODES ===\n    \n    %% Discrete Distributions\n    Bern(Bernoulli)\n    Geo(Geometric)\n    Bin(Binomial)\n    NegBin(Negative Binomial)\n    Hyper(Hypergeometric)\n    Pois(Poisson)\n    \n    %% Continuous Distributions\n    Exp(Exponential)\n    Gam(Gamma)\n    Norm(Normal)\n    Chi(Chi-Squared)\n    \n    %% === CONNECTIONS ===\n    Bern -- \"1\" --&gt; Geo\n    Bern -- \"2\" --&gt; Bin\n    Pois -- \"3\" --&gt; Bin\n    Bin -- \"9\" --&gt; Hyper\n    Norm -- \"4\" --&gt; Bin\n    Norm -- \"5\" --&gt; Chi\n        \n    Geo -- \"8\" --&gt; NegBin\n    Pois -- \"7\" --&gt; Exp\n    Gam -- \"6\" --&gt; Exp\n\n\n\n    %% Apply Styles\n    class Bern,Bin,Geo,NegBin,Hyper,DiscUnif,Pois discrete\n    class ContUnif,Exp,Gam,Norm,Chi continuous"
  },
  {
    "objectID": "homework/HW_08.html#distribution-properties-table",
    "href": "homework/HW_08.html#distribution-properties-table",
    "title": "Probability Distribution Compendium",
    "section": "Distribution Properties Table",
    "text": "Distribution Properties Table\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistribution\nType\nParameters\nSupport (\\(X\\))\nPMF / PDF\nMean (\\(E[X]\\))\nVariance (\\(Var(X)\\))\n“Story” / Key Relationship\n\n\n\n\nBernoulli\nDiscrete\n\\(p\\) (probability of success)\n\\(k \\in \\{0, 1\\}\\)\n\\(p^k(1-p)^{1-k}\\)\n\\(p\\)\n\\(p(1-p)\\)\nA single trial (success/failure). The building block for Binomial, Geometric, etc.\n\n\nBinomial\n\n\n\n\n\n\n\n\n\nGeometric\n\n\n\n\n\n\n\n\n\nNegative Binomial\n\n\n\n\n\n\n\n\n\nHypergeometric\n\n\n\n\n\n\n\n\n\nPoisson\n\n\n\n\n\n\n\n\n\nDiscrete Uniform\n\n\n\n\n\n\n\n\n\nContinuous Uniform\n\n\n\n\n\n\n\n\n\nExponential\n\n\n\n\n\n\n\n\n\nGamma\n\n\n\n\n\n\n\n\n\nNormal"
  },
  {
    "objectID": "hw_answers/HW_08_ans.html#questions",
    "href": "hw_answers/HW_08_ans.html#questions",
    "title": "Homework 8 Answers",
    "section": "",
    "text": "parameters: \\(\\sum_{i=1}^m n_i\\) and \\(p\\)\nNot given\n\\[p(1-p)\\sum_{i=1}^m n_i\\]\n\n\nExponential distribution\n\\(\\lambda = 240\\)\nNot given\n\n0.252\nFirst row given in homework problem\n#3: Poisson approximation of Binomial when \\(n\\) is large and \\(p\\) is small"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#all-the-r-code-for-these",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs.html#all-the-r-code-for-these",
    "title": "Lesson 15: Some Important Discrete RVs",
    "section": "All the R code for these!",
    "text": "All the R code for these!\nCheck out this page with all the different functions for distributions in R\nExample of R commands for hypergeometric distribution with their input and output:\n\n\n\n\n\n\n\nR code\nWhat does it return?\n\n\n\n\nrhyper()\nreturns sample of random v ariables with specified dist ribution\n\n\ndhyper()\nreturns value of probability density at certain point of the dist ribution\n\n\nphyper()\nreturns cumulative pro bability of getting certain point (or less) of the normal dist ribution\n\n\nqhyper()\nreturns inverse CDF corresponding to desired quantile"
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs_muddy_points.html#fall-2025",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs_muddy_points.html#fall-2025",
    "title": "Muddy Points",
    "section": "",
    "text": "Haha, so true. Hopefully more examples next class will be helpful.\n\n\n\nYes, it gets tricky especially when \\(X\\) can take infinite values. The good news is these are all very common random variables and there are many videos that go through the proofs.\nFor example, here is one from Khan Academy on the geometric distribution."
  },
  {
    "objectID": "lessons/15_Discrete_RVs/15_Discrete_RVs_muddy_points.html#fall-2024",
    "href": "lessons/15_Discrete_RVs/15_Discrete_RVs_muddy_points.html#fall-2024",
    "title": "Muddy Points",
    "section": "Fall 2024",
    "text": "Fall 2024\n\n1. In-class example of the Poisson distribution\n\nlibrary(tidyverse)\n\nx &lt;- 0:250\n# n = c(6,14,30,60)\np = c(0.1, 0.5)\n\ngeom = expand.grid(x = x, p = p) %&gt;%\n  mutate(y = dgeom(x, prob = p))\n\nggplot(geom %&gt;% filter(y &gt; 1e-5), \n       aes(x, y, color=factor(p))) +\n  geom_point(size=1) +\n  geom_segment(aes(x=x, xend=x, y=0, yend=y, color=factor(p)), lwd=0.8, alpha=0.5) +\n  facet_grid(rows = vars(p), scales=\"free_x\", space=\"free_x\") +\n  theme(legend.position = \"none\",\n        axis.title = element_text(size = 14),    # Axis title size\n        axis.text = element_text(size = 12),     # Axis text size\n        strip.text = element_text(size = 13)) +  # Facet label size\n  labs(x = \"Number of trials\", y = \"Probability\")"
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs.html#chi-squared-distribution",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs.html#chi-squared-distribution",
    "title": "Lesson 16: Some Important Continuous RVs",
    "section": "Chi-squared distribution",
    "text": "Chi-squared distribution\n\n\n\nIf \\(Z \\sim \\text{Normal}(0,1)\\), then \\(X = Z^2\\) has a Chi-squared distribution with 1 degree of freedom\n\nShorthand: \\(X \\sim \\chi^2_{(1)}\\)\n\nIf \\(Z_1, Z_2, \\ldots, Z_n\\) are independent standard normal RVs, then\n\\[X = \\sum_{i=1}^n Z_i^2\\]\nhas a Chi-squared distribution with \\(n\\) degrees of freedom\n\nShorthand: \\(X \\sim \\chi^2_{(n)}\\)"
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs_muddy_points.html",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs_muddy_points.html",
    "title": "Muddy Points",
    "section": "",
    "text": "In this example, I was demonstrating how we could make a joint pdf from \\(n\\) exponential distributions. The joint pdf was for the random variable \\(M\\), which was the minimum of randomly distributed arrival times (\\(X_i\\))."
  },
  {
    "objectID": "lessons/16_Cont_RVs/16_Cont_RVs_muddy_points.html#fall-2023",
    "href": "lessons/16_Cont_RVs/16_Cont_RVs_muddy_points.html#fall-2023",
    "title": "Muddy Points",
    "section": "",
    "text": "In this example, I was demonstrating how we could make a joint pdf from \\(n\\) exponential distributions. The joint pdf was for the random variable \\(M\\), which was the minimum of randomly distributed arrival times (\\(X_i\\))."
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem_key_info.html",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "We will finish up the example from last class\nNo class on 11/26 and 12/1\nBiostatistics tutoring starts today\n\nSchedule a meeting here\nOr email Charles directly\n\n\n\n\nThe Division of Biostatistics in the Department of Preventive Medicine at the University of Tennessee Health Science Center in Memphis, Tennessee invites applications for paid internships in Biomedical Data Science.\nWe expect to have at least two positions for the summer 2026. Interns will work with one or more of our faculty members on a statistical project of mutual interest. The work is expected to lead to a tangible research product, such as a software package or methodological paper. Interested individuals must have strong programming skills in at least one language (eg. R, Python, Julia, C/C++, SAS), possess basic data analysis skills, and have a willingness to learn biomedical science.\nApplicants should possess a relevant (e.g. statistics, mathematics, computer science) bachelor’s or master’s degree; undergraduate students must be rising juniors or seniors. Most internships are 20-40 hours per week for 10 weeks, but total hours are negotiable. Internships may be paid or for credit at the student’s home institution, depending on institutional policies, student and faculty mentor preference.\nMore info: www.uthsc.edu/preventive-medicine/internships.php\nAlumni info: www.uthsc.edu/preventive-medicine/internshipalumni.php"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem_key_info.html#announcements",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "We will finish up the example from last class\nNo class on 11/26 and 12/1\nBiostatistics tutoring starts today\n\nSchedule a meeting here\nOr email Charles directly\n\n\n\n\nThe Division of Biostatistics in the Department of Preventive Medicine at the University of Tennessee Health Science Center in Memphis, Tennessee invites applications for paid internships in Biomedical Data Science.\nWe expect to have at least two positions for the summer 2026. Interns will work with one or more of our faculty members on a statistical project of mutual interest. The work is expected to lead to a tangible research product, such as a software package or methodological paper. Interested individuals must have strong programming skills in at least one language (eg. R, Python, Julia, C/C++, SAS), possess basic data analysis skills, and have a willingness to learn biomedical science.\nApplicants should possess a relevant (e.g. statistics, mathematics, computer science) bachelor’s or master’s degree; undergraduate students must be rising juniors or seniors. Most internships are 20-40 hours per week for 10 weeks, but total hours are negotiable. Internships may be paid or for credit at the student’s home institution, depending on institutional policies, student and faculty mentor preference.\nMore info: www.uthsc.edu/preventive-medicine/internships.php\nAlumni info: www.uthsc.edu/preventive-medicine/internshipalumni.php"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem_key_info.html#key-dates",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nQuiz 3 opens 12/3\nI posted some info on it\nHW 8 due 12/7"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-17",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-17",
    "title": "Lesson 17: Central Limit Theorem",
    "section": "Larger example (1/7)",
    "text": "Larger example (1/7)\n\n\nExample 3\n\n\nSuppose that the probability of developing a specific type of breast cancer in women aged 40-49 is 0.001. Assume the occurrences of cancer are independent. Suppose you have data from a random sample of 20,000 women aged 40-49.\n\nHow many of the 20,000 women would you expect to develop this type of breast cancer, and what is the standard deviation?\nFind the exact probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to find the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to approximate the following probabilities, where \\(X\\) is the number of women that will develop this type of breast cancer.\n\n\\(\\mathbb{P}(15 \\leq X \\leq 22)\\)\n\\(\\mathbb{P}(X &gt; 20)\\)\n\\(\\mathbb{P}(X &lt; 20)\\)\n\nFind the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer - not using the CLT!\nUse the CLT to approximate the approximate probability in the previous question!"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-17-1",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-17-1",
    "title": "Lesson 17: Central Limit Theorem",
    "section": "Larger example (1/7)",
    "text": "Larger example (1/7)\n\n\nExample 3\n\n\nSuppose that the probability of developing a specific type of breast cancer in women aged 40-49 is 0.001. Assume the occurrences of cancer are independent. Suppose you have data from a random sample of 20,000 women aged 40-49.\n\nHow many of the 20,000 women would you expect to develop this type of breast cancer, and what is the standard deviation?"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-17-2",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-17-2",
    "title": "Lesson 17: Central Limit Theorem",
    "section": "Larger example (1/7)",
    "text": "Larger example (1/7)\n\n\nExample 3\n\n\nSuppose that the probability of developing a specific type of breast cancer in women aged 40-49 is 0.001. Assume the occurrences of cancer are independent. Suppose you have data from a random sample of 20,000 women aged 40-49.\n\nHow many of the 20,000 women would you expect to develop this type of breast cancer, and what is the standard deviation?\nFind the exact probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to find the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to approximate the following probabilities, where \\(X\\) is the number of women that will develop this type of breast cancer.\n\n\\(\\mathbb{P}(15 \\leq X \\leq 22)\\)\n\\(\\mathbb{P}(X &gt; 20)\\)\n\\(\\mathbb{P}(X &lt; 20)\\)\n\nFind the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer - not using the CLT!\nUse the CLT to approximate the approximate probability in the previous question!"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-17-3",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-17-3",
    "title": "Lesson 17: Central Limit Theorem",
    "section": "Larger example (1/7)",
    "text": "Larger example (1/7)\n\n\nExample 3\n\n\nSuppose that the probability of developing a specific type of breast cancer in women aged 40-49 is 0.001. Assume the occurrences of cancer are independent. Suppose you have data from a random sample of 20,000 women aged 40-49.\n\nHow many of the 20,000 women would you expect to develop this type of breast cancer, and what is the standard deviation?\nFind the exact probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to find the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to approximate the following probabilities, where \\(X\\) is the number of women that will develop this type of breast cancer.\n\n\\(\\mathbb{P}(15 \\leq X \\leq 22)\\)\n\\(\\mathbb{P}(X &gt; 20)\\)\n\\(\\mathbb{P}(X &lt; 20)\\)\n\nFind the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer - not using the CLT!\nUse the CLT to approximate the approximate probability in the previous question!"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-17-4",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-17-4",
    "title": "Lesson 17: Central Limit Theorem",
    "section": "Larger example (1/7)",
    "text": "Larger example (1/7)\n\n\nExample 3\n\n\nSuppose that the probability of developing a specific type of breast cancer in women aged 40-49 is 0.001. Assume the occurrences of cancer are independent. Suppose you have data from a random sample of 20,000 women aged 40-49.\n\nHow many of the 20,000 women would you expect to develop this type of breast cancer, and what is the standard deviation?\nFind the exact probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to find the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to approximate the following probabilities, where \\(X\\) is the number of women that will develop this type of breast cancer.\n\n\\(\\mathbb{P}(15 \\leq X \\leq 22)\\)\n\\(\\mathbb{P}(X &gt; 20)\\)\n\\(\\mathbb{P}(X &lt; 20)\\)\n\nFind the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer - not using the CLT!\nUse the CLT to approximate the approximate probability in the previous question!"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-17-5",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-17-5",
    "title": "Lesson 17: Central Limit Theorem",
    "section": "Larger example (1/7)",
    "text": "Larger example (1/7)\n\n\nExample 3\n\n\nSuppose that the probability of developing a specific type of breast cancer in women aged 40-49 is 0.001. Assume the occurrences of cancer are independent. Suppose you have data from a random sample of 20,000 women aged 40-49.\n\nHow many of the 20,000 women would you expect to develop this type of breast cancer, and what is the standard deviation?\nFind the exact probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to find the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to approximate the following probabilities, where \\(X\\) is the number of women that will develop this type of breast cancer.\n\n\\(\\mathbb{P}(15 \\leq X \\leq 22)\\)\n\\(\\mathbb{P}(X &gt; 20)\\)\n\\(\\mathbb{P}(X &lt; 20)\\)\n\nFind the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer - not using the CLT!\nUse the CLT to approximate the approximate probability in the previous question!"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-17-6",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-17-6",
    "title": "Lesson 17: Central Limit Theorem",
    "section": "Larger example (1/7)",
    "text": "Larger example (1/7)\n\n\nExample 3\n\n\nSuppose that the probability of developing a specific type of breast cancer in women aged 40-49 is 0.001. Assume the occurrences of cancer are independent. Suppose you have data from a random sample of 20,000 women aged 40-49.\n\nHow many of the 20,000 women would you expect to develop this type of breast cancer, and what is the standard deviation?\nFind the exact probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to find the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer.\nUse the CLT to approximate the following probabilities, where \\(X\\) is the number of women that will develop this type of breast cancer.\n\n\\(\\mathbb{P}(15 \\leq X \\leq 22)\\)\n\\(\\mathbb{P}(X &gt; 20)\\)\n\\(\\mathbb{P}(X &lt; 20)\\)\n\nFind the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer - not using the CLT!\nUse the CLT to approximate the approximate probability in the previous question!"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-27",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-27",
    "title": "Lesson 17: Central Limit Theorem",
    "section": "Larger example (2/7)",
    "text": "Larger example (2/7)\n\n\nExample 3\n\n\nSuppose that the probability of developing a specific type of breast cancer in women aged 40-49 is 0.001. Assume the occurrences of cancer are independent. Suppose you have data from a random sample of 20,000 women aged 40-49.\n\nHow many of the 20,000 women would you expect to develop this type of breast cancer, and what is the standard deviation?"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-37",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-37",
    "title": "Lesson 17: Central Limit Theorem",
    "section": "Larger example (3/7)",
    "text": "Larger example (3/7)\n\n\nExample 3\n\n\nSuppose that the probability of developing a specific type of breast cancer in women aged 40-49 is 0.001. Assume the occurrences of cancer are independent. Suppose you have data from a random sample of 20,000 women aged 40-49.\n\nFind the exact probability that more than 15 of the 20,000 women will develop this type of breast cancer."
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-47",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-47",
    "title": "Lesson 17: Central Limit Theorem",
    "section": "Larger example (4/7)",
    "text": "Larger example (4/7)\n\n\nExample 3\n\n\nSuppose that the probability of developing a specific type of breast cancer in women aged 40-49 is 0.001. Assume the occurrences of cancer are independent. Suppose you have data from a random sample of 20,000 women aged 40-49.\n\nUse the CLT to find the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer."
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-57",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-57",
    "title": "Lesson 17: Central Limit Theorem",
    "section": "Larger example (5/7)",
    "text": "Larger example (5/7)\n\n\nExample 3\n\n\nSuppose that the probability of developing a specific type of breast cancer in women aged 40-49 is 0.001. Assume the occurrences of cancer are independent. Suppose you have data from a random sample of 20,000 women aged 40-49.\n\nUse the CLT to approximate the following probabilities, where \\(X\\) is the number of women that will develop this type of breast cancer.\n\n\\(\\mathbb{P}(15 \\leq X \\leq 22)\\)\n\\(\\mathbb{P}(X &gt; 20)\\)\n\\(\\mathbb{P}(X &lt; 20)\\)"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-67",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-67",
    "title": "Lesson 17: Central Limit Theorem",
    "section": "Larger example (6/7)",
    "text": "Larger example (6/7)\n\n\nExample 3\n\n\nSuppose that the probability of developing a specific type of breast cancer in women aged 40-49 is 0.001. Assume the occurrences of cancer are independent. Suppose you have data from a random sample of 20,000 women aged 40-49.\n\nFind the approximate probability that more than 15 of the 20,000 women will develop this type of breast cancer - not using the CLT!"
  },
  {
    "objectID": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-77",
    "href": "lessons/17_Central_Limit_Theorem/17_Central_Limit_Theorem.html#larger-example-77",
    "title": "Lesson 17: Central Limit Theorem",
    "section": "Larger example (7/7)",
    "text": "Larger example (7/7)\n\n\nExample 3\n\n\nSuppose that the probability of developing a specific type of breast cancer in women aged 40-49 is 0.001. Assume the occurrences of cancer are independent. Suppose you have data from a random sample of 20,000 women aged 40-49.\n\nUse the CLT to approximate the approximate probability in the previous question!"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-the-standard-normal-distribution-1",
    "href": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#using-the-mgf-to-uniquely-describe-the-standard-normal-distribution-1",
    "title": "Lesson 18: Moment Generating Functions",
    "section": "Using the MGF to uniquely describe the standard normal distribution",
    "text": "Using the MGF to uniquely describe the standard normal distribution"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#how-do-mgfs-give-us-moments",
    "href": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#how-do-mgfs-give-us-moments",
    "title": "Lesson 18: Moment Generating Functions",
    "section": "How do MGFs give us moments?",
    "text": "How do MGFs give us moments?\n\n\nTheorem 5\n\n\nThe moment generating function uniquely specifies a probability distribution. AKA all moments can be found from the MGF through its derivatives at \\(t=0\\).\n\n\n\n\nTheorem 6\n\n\n\\[\\mathbb{E}[X^r] = M_X^{(r)}(0)\\]\n\\((r)\\) in this equation is the \\(r\\)th derivative with respect to \\(t\\). We calculate the derivative at \\(t=0\\)\n\n\n\nWhen \\(r=1\\), we are taking the first derivative\nWhen \\(r=4\\), we are taking the fourth derivative"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#okay-but-what-are-they",
    "href": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions.html#okay-but-what-are-they",
    "title": "Lesson 18: Moment Generating Functions",
    "section": "Okay, but what are they?",
    "text": "Okay, but what are they?\n\n\nExample 1\n\n\n\\(1^{st}-4^{th}\\) moments\n\n\n\n1st moment:\n\n \n\n2nd moment:\n\n \n\n3rd moment:\n\n \n\n4th moment:"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions_key_info.html",
    "href": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions_key_info.html",
    "title": "Key Info",
    "section": "",
    "text": "LAST CLASS!!!!\n\nOffice hours will continue through 12/12\n\nFinish CLT lesson\nHW 7: Charles said it looked good!\nHW 9 is optional!\n\nCan use HW 9 to replace a 0 for another homework\nBut you can also turn in any homework up until 12/12 at 11pm\n\nPlease, please, please do your course eval!\n\nIt helps me improve the course\nIt helps me get recognition for my work\nIt is anonymous\nIt takes like 5 minutes: you really only need to do the scorings, and maybe a sentence or two of comments"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions_key_info.html#announcements",
    "href": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions_key_info.html#announcements",
    "title": "Key Info",
    "section": "",
    "text": "LAST CLASS!!!!\n\nOffice hours will continue through 12/12\n\nFinish CLT lesson\nHW 7: Charles said it looked good!\nHW 9 is optional!\n\nCan use HW 9 to replace a 0 for another homework\nBut you can also turn in any homework up until 12/12 at 11pm\n\nPlease, please, please do your course eval!\n\nIt helps me improve the course\nIt helps me get recognition for my work\nIt is anonymous\nIt takes like 5 minutes: you really only need to do the scorings, and maybe a sentence or two of comments"
  },
  {
    "objectID": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions_key_info.html#key-dates",
    "href": "lessons/18_Moment_Generating_Functions/18_Moment_Generating_Functions_key_info.html#key-dates",
    "title": "Key Info",
    "section": "Key Dates",
    "text": "Key Dates\n\nQuiz 3 opens TODAY at 3pm\nI posted some info on it\nHW 8 due 12/7\nIMPORTANT: ALL coursework due by 12/12 at 11pm"
  },
  {
    "objectID": "homework/HW_09.html#questions",
    "href": "homework/HW_09.html#questions",
    "title": "Homework 9",
    "section": "Questions",
    "text": "Questions\n\nLet \\(R_X(t)=\\ln(M_X(t))\\). Show that \\(\\text{Var}(X)=R''_X(0)\\).\nThe mgf for a Gamma distribution is \\(M_X(t)=\\frac{1}{(1-t/\\lambda)^r}\\). Use the mgf of an Exponential distribution (from #43.9), to show that the sum of \\(n\\) i.i.d. Exponential(\\(\\lambda)\\) random variables has a Gamma(\\(r,\\lambda\\)) distribution.\n\n\nExtra problems\n\nUsing mgf’s, show that the sum of \\(n\\) i.i.d. Chi Square random variables with one degree of freedom (\\(\\chi^2_{(1)}\\)) r.v.’s has a Chi Square with \\(n\\) degrees of freedom (\\(\\chi^2_{(n)}\\)) distribution.\nHint: First, look up the pdf of a \\(\\chi^2_{(n)}\\). This is a special case of the Gamma distribution with what parameters? Based on that and the information from # 2 above, you can determine what the mgf of a \\(\\chi^2_{(n)}\\) is, which will help you determine whether the mgf of the sum of \\(n\\) i.i.d. \\(\\chi^2_{(1)}\\) r.v.’s has a \\(\\chi^2_{(n)}\\) distribution.\nUse the mgf of a Poisson distribution to find the mgf of the following distributions. If the mgf is that of a common named distribution, then name the distribution and state its parameter(s).\n\nThe distribution of \\(\\sum_{i=1}^nX_i\\), if \\(X_i\\sim\\)Poisson\\((\\lambda_i)\\) and are independent.\nThe distribution of \\(\\sum_{i=1}^3X_i\\), if \\(X_i\\sim\\)Poisson\\((\\lambda)\\) and are independent (i.i.d. in this case).\nThe distribution of \\(3X\\), if \\(X\\sim\\)Poisson\\((\\lambda)\\).\nWhy are the answers to (b) and (c) different?"
  }
]